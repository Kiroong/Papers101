{"10.1109/TVCG.2014.38": {"doi": "10.1109/TVCG.2014.38", "author": ["R. Mehra", "L. Antani", "S. Kim", "D. Manocha"], "title": "Source and Listener Directivity for Interactive Wave-Based Sound Propagation", "year": "2014", "abstract": "We present an approach to model dynamic, data-driven source and listener directivity for interactive wave-based sound propagation in virtual environments and computer games. Our directional source representation is expressed as a linear combination of elementary spherical harmonic (SH) sources. In the preprocessing stage, we precompute and encode the propagated sound fields due to each SH source. At runtime, we perform the SH decomposition of the varying source directivity interactively and compute the total sound field at the listener position as a weighted sum of precomputed SH sound fields. We propose a novel plane-wave decomposition approach based on higher-order derivatives of the sound field that enables dynamic HRTF-based listener directivity at runtime. We provide a generic framework to incorporate our source and listener directivity in any offline or online frequency-domain wave-based sound propagation algorithm. We have integrated our sound propagation system in Valve's Source game engine and use it to demonstrate realistic acoustic effects such as sound amplification, diffraction low-passing, scattering, localization, externalization, and spatial sound, generated by wave-based propagation of directional sources and listener in complex scenarios. We also present results from our preliminary user study.", "keywords": ["acoustic wave propagation", "computer games", "Helmholtz equations", "virtual reality", "interactive wave-based sound propagation", "dynamic data-driven source directivity", "virtual environments", "computer games", "directional source representation", "elementary spherical harmonic sources", "SH sources", "propagated sound field encoding", "SH decomposition", "listener position", "precomputed SH sound field weighted sum", "plane-wave decomposition approach", "higher-order derivatives", "dynamic HRTF-based listener directivity", "online frequency-domain wave-based sound propagation algorithm", "offline frequency-domain wave-based sound propagation algorithm", "Valve source game engine", "realistic acoustic effects", "sound amplification", "diffraction low-passing", "spatial sound", "Helmholtz equation", "Runtime", "Mathematical model", "Equations", "Acoustics", "Frequency-domain analysis", "Computational modeling", "Ear", "Sound propagation", " directivity", " spatial sound", " plane-wave decomposition", " helmholtz equation", "Acoustic Stimulation", "Computer Simulation", "Humans", "Models, Theoretical", "Scattering, Radiation", "Sound", "Sound Localization", "Sound Spectrography", "Task Performance and Analysis", "User-Computer Interface"], "referenced_by": ["IKEY:6948409", "IKEY:7006289", "IKEY:7014276", "IKEY:7383327", "IKEY:7384541", "IKEY:7892239", "IKEY:8656507", "IKEY:9053099", "IKEY:9257177", "10.1145/2601097.2601216", "10.1145/3386569.3392459", "10.1250/ast.38.128", "10.12693/APhysPolA.128.A-5", "10.3390/app7060558", "10.1121/1.5096171", "10.1121/1.5130194", "10.1121/10.0002425", "10.1121/10.0002956"], "referencing": ["IKEY:4494749", "IKEY:4907060", "IKEY:4494749", "IKEY:4907060", "IKEY:4494749", "IKEY:4907060", "10.1145/1179352.1141983", "10.1145/2451236.2451245", "10.1145/1833349.1778805", "10.1145/1179352.1141983", "10.1145/2451236.2451245", "10.1145/1833349.1778805", "10.1145/1179352.1141983", "10.1145/2451236.2451245", "10.1145/1833349.1778805", "10.1121/1.4785700", "10.1017/CBO9780511605345", "10.1007/978-3-662-07296-7_14", "10.1121/1.2063108", "10.3813/AAA.918493", "10.1121/1.3278605", "10.1121/1.428071", "10.1121/1.3009552", "10.1121/1.398336", "10.1121/1.4785700", "10.1017/CBO9780511605345", "10.1007/978-3-662-07296-7_14", "10.1121/1.2063108", "10.3813/AAA.918493", "10.1121/1.3278605", "10.1121/1.428071", "10.1121/1.3009552", "10.1121/1.398336", "10.1121/1.4785700", "10.1017/CBO9780511605345", "10.1007/978-3-662-07296-7_14", "10.1121/1.2063108", "10.3813/AAA.918493", "10.1121/1.3278605", "10.1121/1.428071", "10.1121/1.3009552", "10.1121/1.398336"]}, "10.1109/TVCG.2014.20": {"doi": "10.1109/TVCG.2014.20", "author": ["B. Laha", "D. A. Bowman", "J. J. Socha"], "title": "Effects of VR System Fidelity on Analyzing Isosurface Visualization of Volume Datasets", "year": "2014", "abstract": "Volume visualization is an important technique for analyzing datasets from a variety of different scientific domains. Volume data analysis is inherently difficult because volumes are three-dimensional, dense, and unfamiliar, requiring scientists to precisely control the viewpoint and to make precise spatial judgments. Researchers have proposed that more immersive (higher fidelity) VR systems might improve task performance with volume datasets, and significant results tied to different components of display fidelity have been reported. However, more information is needed to generalize these results to different task types, domains, and rendering styles. We visualized isosurfaces extracted from synchrotron microscopic computed tomography (SR-\u03bcCT) scans of beetles, in a CAVE-like display. We ran a controlled experiment evaluating the effects of three components of system fidelity (field of regard, stereoscopy, and head tracking) on a variety of abstract task categories that are applicable to various scientific domains, and also compared our results with those from our prior experiment using 3D texture-based rendering. We report many significant findings. For example, for search and spatial judgment tasks with isosurface visualization, a stereoscopic display provides better performance, but for tasks with 3D texture-based rendering, displays with higher field of regard were more effective, independent of the levels of the other display components. We also found that systems with high field of regard and head tracking improve performance in spatial judgment tasks. Our results extend existing knowledge and produce new guidelines for designing VR systems to improve the effectiveness of volume data analysis.", "keywords": ["computerised tomography", "data analysis", "data visualisation", "image texture", "rendering (computer graphics)", "virtual reality", "head tracking", "3D texture-based rendering", "CAVE-like display", "beetles", "SR-\u03bcCT scans", "synchrotron microscopic computed tomography", "volume data analysis", "volume visualization", "volume datasets", "isosurface visualization", "VR system fidelity", "Rendering (computer graphics)", "Isosurfaces", "Three-dimensional displays", "Visualization", "Abstracts", "Measurement", "Computed tomography", "Immersion", " micro-CT", " data analysis", " volume visualization", " 3D visualization", " CAVE", " virtual environments", " virtual reality"], "referenced_by": ["10.1145/2927929.2927931", "10.1007/978-3-319-50862-7_12", "10.1007/s41095-016-0035-7", "10.1016/j.promfg.2018.01.022", "10.1111/cgf.12939", "10.1039/C8CP03417F", "10.3154/jvs.37.146_2", "10.1002/pra2.2018.14505501033", "10.3389/frobt.2019.00082", "10.4018/IJVAR.2019070103", "10.1007/s10055-020-00433-x", "10.1016/j.cag.2020.05.024", "10.3390/mti4030054", "10.1021/acs.jchemed.0c00954"], "referencing": ["IKEY:4287241", "IKEY:6327218", "IKEY:1608019", "IKEY:5290732", "IKEY:6479179", "IKEY:6165141", "IKEY:6165144", "IKEY:6261311", "IKEY:964545", "IKEY:1260740", "IKEY:4287241", "IKEY:6327218", "IKEY:1608019", "IKEY:5290732", "IKEY:6479179", "IKEY:6165141", "IKEY:6165144", "IKEY:6261311", "IKEY:964545", "IKEY:1260740", "IKEY:4287241", "IKEY:6327218", "IKEY:1608019", "IKEY:5290732", "IKEY:6479179", "IKEY:6165141", "IKEY:6165144", "IKEY:6261311", "IKEY:964545", "IKEY:1260740", "10.1145/229459.229467", "10.1145/166117.166134", "10.1145/234313.234383", "10.1145/1315184.1315205", "10.1145/234972.234975", "10.1145/229459.229467", "10.1145/166117.166134", "10.1145/234313.234383", "10.1145/1315184.1315205", "10.1145/234972.234975", "10.1145/229459.229467", "10.1145/166117.166134", "10.1145/234313.234383", "10.1145/1315184.1315205", "10.1145/234972.234975", "10.1017/CBO9780511818202", "10.1162/105474603763835314", "10.1007/978-3-540-89639-5_86", "10.1117/12.795210", "10.1016/j.resp.2010.03.013", "10.1242/jeb.019877", "10.1201/9781420058772", "10.1126/science.1078008", "10.1146/annurev.physiol.70.113006.100434", "10.1017/CBO9780511818202", "10.1162/105474603763835314", "10.1007/978-3-540-89639-5_86", "10.1117/12.795210", "10.1016/j.resp.2010.03.013", "10.1242/jeb.019877", "10.1201/9781420058772", "10.1126/science.1078008", "10.1146/annurev.physiol.70.113006.100434", "10.1017/CBO9780511818202", "10.1162/105474603763835314", "10.1007/978-3-540-89639-5_86", "10.1117/12.795210", "10.1016/j.resp.2010.03.013", "10.1242/jeb.019877", "10.1201/9781420058772", "10.1126/science.1078008", "10.1146/annurev.physiol.70.113006.100434"]}, "10.1109/TVCG.2014.33": {"doi": "10.1109/TVCG.2014.33", "author": ["K. Johnsen", "S. J. Ahn", "J. Moore", "S. Brown", "T. P. Robertson", "A. Marable", "A. Basu"], "title": "Mixed Reality Virtual Pets to Reduce Childhood Obesity", "year": "2014", "abstract": "Novel approaches are needed to reduce the high rates of childhood obesity in the developed world. While multifactorial in cause, a major factor is an increasingly sedentary lifestyle of children. Our research shows that a mixed reality system that is of interest to children can be a powerful motivator of healthy activity. We designed and constructed a mixed reality system that allowed children to exercise, play with, and train a virtual pet using their own physical activity as input. The health, happiness, and intelligence of each virtual pet grew as its associated child owner exercised more, reached goals, and interacted with their pet. We report results of a research study involving 61 children from a local summer camp that shows a large increase in recorded and observed activity, alongside observational evidence that the virtual pet was responsible for that change. These results, and the ease at which the system integrated into the camp environment, demonstrate the practical potential to impact the exercise behaviors of children with mixed reality.", "keywords": ["human computer interaction", "medical computing", "virtual reality", "mixed reality virtual pets", "childhood obesity reduction", "physical activity", "local summer camp", "mixed reality system", "Positron emission tomography", "Games", "Monitoring", "Pediatrics", "Obesity", "Avatars", "Virtual reality", " user studies", " field studies", " gestural input", "Animal Assisted Therapy", "Animals", "Child", "Exercise Therapy", "Female", "Health Promotion", "Humans", "Male", "Pediatric Obesity", "Pets", "Therapy, Computer-Assisted", "User-Computer Interface", "Video Games"], "referenced_by": ["IKEY:7460028", "IKEY:8079757", "IKEY:7495418", "IKEY:8336833", "IKEY:8442093", "IKEY:8460418", "IKEY:8809588", "IKEY:8943625", "IKEY:8951890", "IKEY:9090664", "10.1145/2702613.2732807", "10.1002/9781118952788.ch13", "10.1007/978-3-319-40238-3_29", "10.1016/j.beem.2015.04.003", "10.4018/978-1-5225-2182-2.ch010", "10.4018/978-1-5225-5469-1.ch072", "10.1093/jpepsy/jsy108", "10.1007/978-3-030-16187-3_11", "10.1007/s10916-019-1293-6", "10.4018/978-1-5225-9679-0.ch008", "10.1590/1982-0194201900063", "10.1089/cyber.2019.0491", "10.1080/10447318.2020.1801172", "10.33166/AETiC.2020.04.005"], "referencing": ["IKEY:5440158", "IKEY:5440158", "IKEY:5440158", "10.1145/1873951.1874316", "10.1145/1873951.1874316", "10.1145/1873951.1874316", "10.1056/NEJM199709253371301", "10.1161/01.CIR.0000161369.71722.10", "10.1056/NEJMoa072515", "10.1377/hlthaff.28.5.w822", "10.1038/sj.ijo.0803064", "10.1089/g4h.2013.0025", "10.1055/s-2005-872964", "10.1542/peds.2008-2357", "10.1007/11853565_16", "10.1111/j.1439-0396.2007.00680_9.x", "10.1038/oby.2006.203", "10.1159/000345963", "10.1080/15213260802669474", "10.1162/PRES_a_00111", "10.1056/NEJM199709253371301", "10.1161/01.CIR.0000161369.71722.10", "10.1056/NEJMoa072515", "10.1377/hlthaff.28.5.w822", "10.1038/sj.ijo.0803064", "10.1089/g4h.2013.0025", "10.1055/s-2005-872964", "10.1542/peds.2008-2357", "10.1007/11853565_16", "10.1111/j.1439-0396.2007.00680_9.x", "10.1038/oby.2006.203", "10.1159/000345963", "10.1080/15213260802669474", "10.1162/PRES_a_00111", "10.1056/NEJM199709253371301", "10.1161/01.CIR.0000161369.71722.10", "10.1056/NEJMoa072515", "10.1377/hlthaff.28.5.w822", "10.1038/sj.ijo.0803064", "10.1089/g4h.2013.0025", "10.1055/s-2005-872964", "10.1542/peds.2008-2357", "10.1007/11853565_16", "10.1111/j.1439-0396.2007.00680_9.x", "10.1038/oby.2006.203", "10.1159/000345963", "10.1080/15213260802669474", "10.1162/PRES_a_00111"]}, "10.1109/TVCG.2014.27": {"doi": "10.1109/TVCG.2014.27", "author": ["J. Ventura", "C. Arth", "G. Reitmayr", "D. Schmalstieg"], "title": "Global Localization from Monocular SLAM on a Mobile Phone", "year": "2014", "abstract": "We propose the combination of a keyframe-based monocular SLAM system and a global localization method. The SLAM system runs locally on a camera-equipped mobile client and provides continuous, relative 6DoF pose estimation as well as keyframe images with computed camera locations. As the local map expands, a server process localizes the keyframes with a pre-made, globally-registered map and returns the global registration correction to the mobile client. The localization result is updated each time a keyframe is added, and observations of global anchor points are added to the client-side bundle adjustment process to further refine the SLAM map registration and limit drift. The end result is a 6DoF tracking and mapping system which provides globally registered tracking in real-time on a mobile device, overcomes the difficulties of localization with a narrow field-of-view mobile phone camera, and is not limited to tracking only in areas covered by the offline reconstruction.", "keywords": ["image sensors", "pose estimation", "SLAM (robots)", "smart phones", "monocular SLAM", "global localization method", "SLAM system", "mobile client", "6DoF pose estimation", "keyframe images", "camera locations", "server process", "SLAM map registration", "mobile device", "field-of-view mobile phone camera", "Simultaneous localization and mapping", "Cameras", "Servers", "Real-time systems", "Global Positioning System", "Feature extraction", "Mobile handsets", "Image-based localization", " monocular SLAM", " real-time tracking", " global positioning", " mobile augmented reality"], "referenced_by": ["IKEY:6909455", "IKEY:7410637", "IKEY:8237522", "IKEY:8265282", "IKEY:7177440", "IKEY:7989741", "IKEY:7877846", "IKEY:7571859", "IKEY:7353802", "IKEY:7328080", "IKEY:7804440", "IKEY:7426273", "IKEY:7375310", "IKEY:6912003", "IKEY:6777462", "IKEY:7164332", "IKEY:7523411", "IKEY:7223374", "IKEY:7223387", "IKEY:7045976", "IKEY:8324772", "IKEY:7517247", "IKEY:7453420", "IKEY:7353722", "IKEY:7328079", "IKEY:8533680", "IKEY:8540426", "IKEY:8559868", "IKEY:8569120", "IKEY:8567574", "10.1007/978-3-319-54427-4_11", "10.1007/s00138-016-0808-0", "10.1007/s12555-016-0816-x", "10.1016/j.cag.2016.02.002", "10.1016/j.cviu.2016.02.014", "10.1016/j.eswa.2015.10.045", "10.1016/j.neucom.2015.11.117", "10.1155/2017/8037607", "10.1186/s13640-016-0146-1", "10.3169/mta.4.169", "10.3390/ijgi7020046", "10.3390/s151229847", "10.3390/s16010017", "10.1117/12.2291635", "10.1186/s42492-018-0008-z", "10.1016/j.envsoft.2018.05.012", "10.1002/navi.254", "10.1155/2019/8176489", "10.3390/s19040953", "10.1007/978-3-319-13969-2_31", "10.1007/978-3-030-23525-3_73", "10.1007/978-981-32-9050-1_40", "10.1007/978-3-030-34110-7_1", "10.1007/s11277-020-07487-9", "10.1177/0278364920931151", "10.1007/978-3-030-58465-8_23", "10.1007/s11263-020-01399-8", "10.1007/978-3-658-30889-6_16"], "referencing": ["IKEY:6162870", "IKEY:5336494", "IKEY:5995610", "IKEY:5336495", "IKEY:6130230", "IKEY:5722962", "IKEY:6162870", "IKEY:5336494", "IKEY:5995610", "IKEY:5336495", "IKEY:6130230", "IKEY:5722962", "IKEY:6162870", "IKEY:5336494", "IKEY:5995610", "IKEY:5336495", "IKEY:6130230", "IKEY:5722962", "10.1145/358669.358692", "10.1145/1141911.1141964", "10.1145/1460096.1460165", "10.1145/358669.358692", "10.1145/1141911.1141964", "10.1145/1460096.1460165", "10.1145/358669.358692", "10.1145/1141911.1141964", "10.1145/1460096.1460165", "10.1016/j.imavis.2011.05.002", "10.1177/0278364908090961", "10.1177/0278364910385483", "10.5244/C.22.6", "10.1007/BF01682023", "10.1017/CBO9780511811685", "10.1364/JOSAA.4.000629", "10.1007/978-3-642-33718-5_2", "10.1007/978-3-642-15552-9_57", "10.1023/B:VISI.0000029664.99615.94", "10.1016/j.imavis.2011.05.002", "10.1177/0278364908090961", "10.1177/0278364910385483", "10.5244/C.22.6", "10.1007/BF01682023", "10.1017/CBO9780511811685", "10.1364/JOSAA.4.000629", "10.1007/978-3-642-33718-5_2", "10.1007/978-3-642-15552-9_57", "10.1023/B:VISI.0000029664.99615.94", "10.1016/j.imavis.2011.05.002", "10.1177/0278364908090961", "10.1177/0278364910385483", "10.5244/C.22.6", "10.1007/BF01682023", "10.1017/CBO9780511811685", "10.1364/JOSAA.4.000629", "10.1007/978-3-642-33718-5_2", "10.1007/978-3-642-15552-9_57", "10.1023/B:VISI.0000029664.99615.94"]}, "10.1109/TVCG.2014.25": {"doi": "10.1109/TVCG.2014.25", "author": ["Y. Fujimoto", "R. T. Smith", "T. Taketomi", "G. Yamamoto", "J. Miyazaki", "H. Kato", "B. H. Thomas"], "title": "Geometrically-Correct Projection-Based Texture Mapping onto a Deformable Object", "year": "2014", "abstract": "Projection-based Augmented Reality commonly employs a rigid substrate as the projection surface and does not support scenarios where the substrate can be reshaped. This investigation presents a projection-based AR system that supports deformable substrates that can be bent, twisted or folded. We demonstrate a new invisible marker embedded into a deformable substrate and an algorithm that identifies deformations to project geometrically correct textures onto the deformable object. The geometrically correct projection-based texture mapping onto a deformable marker is conducted using the measurement of the 3D shape through the detection of the retro-reflective marker on the surface. In order to achieve accurate texture mapping, we propose a marker pattern that can be partially recognized and can be registered to an object's surface. The outcome of this work addresses a fundamental vision recognition challenge that allows the underlying material to change shape and be recognized by the system. Our evaluation demonstrated the system achieved geometrically correct projection under extreme deformation conditions. We envisage the techniques presented are useful for domains including prototype development, design, entertainment and information based AR systems.", "keywords": ["augmented reality", "image registration", "image texture", "object detection", "object recognition", "geometrically-correct projection-based texture mapping", "deformable object", "projection-based augmented reality", "projection surface", "projection-based AR system", "deformable substrates", "invisible marker", "3D shape measurement", "deformable marker", "retro-reflective marker detection", "marker pattern", "object surface registration", "fundamental vision recognition", "extreme deformation conditions", "information based AR systems", "Cameras", "Shape", "Substrates", "Surface treatment", "Three-dimensional displays", "Pattern recognition", "Projection-based augmented reality", " deformable marker", " product design support"], "referenced_by": ["IKEY:7516689", "IKEY:7328091", "10.1007/s10055-014-0256-y", "10.1080/10496491.2018.1448323", "10.1162/PRES_a_00275", "10.1080/10641734.2018.1500321", "10.1117/12.2284359", "10.1108/JRIM-01-2018-0027", "10.1007/978-3-030-13940-7_2", "10.1117/1.JEI.28.6.063008", "10.3169/itej.74.208", "10.1515/aot-2016-0047", "10.1016/j.cag.2020.07.008", "10.1007/978-3-030-62655-6_12", "10.3390/en13236442"], "referencing": ["IKEY:1544683", "IKEY:803809", "IKEY:6402533", "IKEY:6193074", "IKEY:4476588", "IKEY:6162896", "IKEY:44402", "IKEY:1544683", "IKEY:803809", "IKEY:6402533", "IKEY:6193074", "IKEY:4476588", "IKEY:6162896", "IKEY:44402", "IKEY:1544683", "IKEY:803809", "IKEY:6402533", "IKEY:6193074", "IKEY:4476588", "IKEY:6162896", "IKEY:44402", "10.1145/1349026.1349037", "10.1145/2047196.2047270", "10.1145/1753326.1753572", "10.1145/513867.513889", "10.1145/1517664.1517733", "10.1145/1450579.1450592", "10.1145/2381876.2381879", "10.1145/1349026.1349037", "10.1145/2047196.2047270", "10.1145/1753326.1753572", "10.1145/513867.513889", "10.1145/1517664.1517733", "10.1145/1450579.1450592", "10.1145/2381876.2381879", "10.1145/1349026.1349037", "10.1145/2047196.2047270", "10.1145/1753326.1753572", "10.1145/513867.513889", "10.1145/1517664.1517733", "10.1145/1450579.1450592", "10.1145/2381876.2381879", "10.1201/b10624", "10.1007/978-1-4614-0064-6_10", "10.1587/transinf.E95.D.256", "10.1007/11669487_48", "10.1007/s11263-006-0017-9", "10.1201/b10624", "10.1007/978-1-4614-0064-6_10", "10.1587/transinf.E95.D.256", "10.1007/11669487_48", "10.1007/s11263-006-0017-9", "10.1201/b10624", "10.1007/978-1-4614-0064-6_10", "10.1587/transinf.E95.D.256", "10.1007/11669487_48", "10.1007/s11263-006-0017-9"]}, "10.1109/TVCG.2014.24": {"doi": "10.1109/TVCG.2014.24", "author": ["S. Zollmann", "C. Hoppe", "T. Langlotz", "G. Reitmayr"], "title": "FlyAR: Augmented Reality Supported Micro Aerial Vehicle Navigation", "year": "2014", "abstract": "Micro aerial vehicles equipped with high-resolution cameras can be used to create aerial reconstructions of an area of interest. In that context automatic flight path planning and autonomous flying is often applied but so far cannot fully replace the human in the loop, supervising the flight on-site to assure that there are no collisions with obstacles. Unfortunately, this workflow yields several issues, such as the need to mentally transfer the aerial vehicle's position between 2D map positions and the physical environment, and the complicated depth perception of objects flying in the distance. Augmented Reality can address these issues by bringing the flight planning process on-site and visualizing the spatial relationship between the planned or current positions of the vehicle and the physical environment. In this paper, we present Augmented Reality supported navigation and flight planning of micro aerial vehicles by augmenting the user's view with relevant information for flight planning and live feedback for flight supervision. Furthermore, we introduce additional depth hints supporting the user in understanding the spatial relationship of virtual waypoints in the physical world and investigate the effect of these visualization techniques on the spatial understanding.", "keywords": ["aerospace computing", "augmented reality", "collision avoidance", "image sensors", "space vehicles", "FlyAR", "augmented reality", "micro aerial vehicle navigation", "high resolution cameras", "aerial reconstructions", "automatic flight path planning", "autonomous flying", "aerial vehicle position", "2D map positions", "physical environment", "flight planning process", "flight planning", "spatial relationship", "virtual waypoints", "visualization techniques", "Vehicles", "Cameras", "Three-dimensional displays", "Visualization", "Navigation", "Data visualization", "Robots", "Augmented reality", " Micro aerial vehicles", " Visualization", "Aircraft", "Depth Perception", "Humans", "Imaging, Three-Dimensional", "Man-Machine Systems", "Miniaturization", "Orientation", "User-Computer Interface"], "referenced_by": ["IKEY:7152395", "IKEY:7502588", "IKEY:8115410", "IKEY:7844371", "IKEY:7027835", "IKEY:8699275", "IKEY:8709267", "10.1145/3232232", "10.1007/978-3-319-61382-6_19", "10.1007/978-3-319-64027-3_23", "10.1007/978-3-319-67380-6_65", "10.3390/s17020297", "10.3390/s17102234", "10.7746/jkros.2018.13.2.113", "10.1007/978-3-030-30033-3_33", "10.1002/jsid.840", "10.1016/B978-0-12-815503-5.00005-X", "10.1016/j.daach.2020.e00140", "10.1007/978-3-030-49695-1_22", "10.3390/app10165436", "10.1007/978-3-030-58465-8_22", "10.1108/IJILT-06-2020-0108"], "referencing": ["IKEY:6777443", "IKEY:4079270", "IKEY:1550792", "IKEY:6777443", "IKEY:4079270", "IKEY:1550792", "IKEY:6777443", "IKEY:4079270", "IKEY:1550792", "10.1145/2460625.2460661", "10.1145/1811158.1811164", "10.1145/2460625.2460661", "10.1145/1811158.1811164", "10.1145/2460625.2460661", "10.1145/1811158.1811164", "10.1111/1467-8659.1530011", "10.1162/pres.18.3.171", "10.3758/BF03200563", "10.1016/B978-012240530-3/50005-5", "10.5244/C.27.94", "10.5244/C.26.70", "10.1007/978-3-642-03658-3_52", "10.1111/j.1467-8659.2009.01530.x", "10.1007/s10055-010-0179-1", "10.1007/978-3-642-33179-4_64", "10.1111/1467-8659.1530011", "10.1162/pres.18.3.171", "10.3758/BF03200563", "10.1016/B978-012240530-3/50005-5", "10.5244/C.27.94", "10.5244/C.26.70", "10.1007/978-3-642-03658-3_52", "10.1111/j.1467-8659.2009.01530.x", "10.1007/s10055-010-0179-1", "10.1007/978-3-642-33179-4_64", "10.1111/1467-8659.1530011", "10.1162/pres.18.3.171", "10.3758/BF03200563", "10.1016/B978-012240530-3/50005-5", "10.5244/C.27.94", "10.5244/C.26.70", "10.1007/978-3-642-03658-3_52", "10.1111/j.1467-8659.2009.01530.x", "10.1007/s10055-010-0179-1", "10.1007/978-3-642-33179-4_64"]}, "10.1109/TVCG.2014.21": {"doi": "10.1109/TVCG.2014.21", "author": ["N. C. Nilsson", "S. Serafin", "R. Nordahl"], "title": "Establishing the Range of Perceptually Natural Visual Walking Speeds for Virtual Walking-In-Place Locomotion", "year": "2014", "abstract": "Walking-In-Place (WIP) techniques make it possible to facilitate relatively natural locomotion within immersive virtual environments that are larger than the physical interaction space. However, in order to facilitate natural walking experiences one needs to know how to map steps in place to virtual motion. This paper describes two within-subjects studies performed with the intention of establishing the range of perceptually natural walking speeds for WIP locomotion. In both studies, subjects performed a series of virtual walks while exposed to visual gains (optic flow multipliers) ranging from 1.0 to 3.0. Thus, the slowest speed was equal to an estimate of the subjects normal walking speed, while the highest speed was three times greater. The perceived naturalness of the visual speed was assessed using self-reports. The first study compared four different types of movement, namely, no leg movement, walking on a treadmill, and two forms of gestural input for WIP locomotion. The results suggest that WIP locomotion is accompanied by a perceptual distortion of the speed of optic flow. The second study was performed using a 4\u00d72 factorial design and compared four different display field-of-views (FOVs) and two types of movement, walking on a treadmill and WIP locomotion. The results revealed significant main effects of both movement type and field of view, but no significant interaction between the two variables. Particularly, they suggest that the size of the display FOV is inversely proportional to the degree of underestimation of the virtual speeds for both treadmill-mediated virtual walking and WIP locomotion. Combined, the results constitute a first attempt at establishing a set of guidelines specifying what virtual walking speeds WIP gestures should produce in order to facilitate a natural walking experience.", "keywords": ["virtual reality", "natural visual walking speeds", "virtual walking-in-place locomotion", "WIP techniques", "immersive virtual environments", "physical interaction space", "virtual motion", "optic flow multipliers", "leg movement", "WIP locomotion", "field-of-views", "FOV", "immersive virtual reality", "IVR systems", "Legged locomotion", "Visualization", "Optical distortion", "Optical feedback", "Adaptive optics", "Tracking", "Equations", "Virtual reality", " locomotion", " speed perception", " perceived naturalness", "Adult", "Aged", "Computer Graphics", "Female", "Gait", "Humans", "Male", "Middle Aged", "Motion Perception", "Physical Exertion", "Reproducibility of Results", "Sensitivity and Specificity", "Task Performance and Analysis", "User-Computer Interface", "Walking", "Young Adult"], "referenced_by": ["IKEY:6798850", "IKEY:7131742", "IKEY:7776347", "IKEY:7829423", "IKEY:7223328", "IKEY:7223389", "IKEY:7892236", "IKEY:7957710", "IKEY:7968669", "IKEY:8446216", "IKEY:8642384", "IKEY:8409318", "IKEY:8797751", "IKEY:8797975", "IKEY:8798258", "IKEY:8798251", "IKEY:8798300", "IKEY:8798209", "IKEY:8797756", "IKEY:8928223", "IKEY:9020416", "IKEY:8580399", "IKEY:8762207", "10.1145/2983631", "10.1145/2986416.2986429", "10.1145/3267782.3267787", "10.1145/2897824.2925883", "10.1007/978-3-319-08234-9_186-1", "10.1007/978-3-319-08234-9_245-1", "10.1016/j.chb.2017.10.037", "10.3390/mti1040024", "10.1016/j.trf.2018.09.012", "10.1007/978-3-319-17738-0_6", "10.1007/978-3-319-39516-6_4", "10.3389/fpsyg.2019.02344", "10.3389/fncir.2019.00068", "10.3390/app9214589", "10.1007/978-3-030-62655-6_2"], "referencing": ["IKEY:4476598", "IKEY:5784419", "IKEY:6479211", "IKEY:5072212", "IKEY:5620907", "IKEY:6180877", "IKEY:6165136", "IKEY:4476598", "IKEY:5784419", "IKEY:6479211", "IKEY:5072212", "IKEY:5620907", "IKEY:6180877", "IKEY:6165136", "IKEY:4476598", "IKEY:5784419", "IKEY:6479211", "IKEY:5072212", "IKEY:5620907", "IKEY:6180877", "IKEY:6165136", "10.1145/1027933.1027948", "10.1145/2338676.2338699", "10.1145/263407.263550", "10.1145/1227134.1227139", "10.1145/1836248.1836283", "10.1145/2522628.2522653", "10.1145/210079.210084", "10.1145/1476589.1476686", "10.1145/1889863.1889867", "10.1145/311535.311589", "10.1145/1012551.1012558", "10.1145/2010325.2010329", "10.1145/1027933.1027948", "10.1145/2338676.2338699", "10.1145/263407.263550", "10.1145/1227134.1227139", "10.1145/1836248.1836283", "10.1145/2522628.2522653", "10.1145/210079.210084", "10.1145/1476589.1476686", "10.1145/1889863.1889867", "10.1145/311535.311589", "10.1145/1012551.1012558", "10.1145/2010325.2010329", "10.1145/1027933.1027948", "10.1145/2338676.2338699", "10.1145/263407.263550", "10.1145/1227134.1227139", "10.1145/1836248.1836283", "10.1145/2522628.2522653", "10.1145/210079.210084", "10.1145/1476589.1476686", "10.1145/1889863.1889867", "10.1145/311535.311589", "10.1145/1012551.1012558", "10.1145/2010325.2010329", "10.1037/0096-1523.11.2.122", "10.1162/105474605774785262", "10.1007/BF00234474", "10.3758/BF03203301", "10.1068/p5144", "10.1080/00140136508930772", "10.1068/p5845", "10.1111/j.1467-8721.2009.01603.x", "10.1037/0096-1523.31.2.339", "10.1007/s100550200008", "10.1007/s002210000504", "10.1016/j.visres.2007.03.012", "10.1016/0042-6989(75)90083-8", "10.1068/p180657", "10.2174/1875934301003010019", "10.1068/p060365", "10.1162/1054746042545238", "10.1080/00222895.1994.9941678", "10.1177/154193120805202704", "10.1007/s00221-007-0917-0", "10.1111/j.1468-5884.2008.00363.x", "10.1016/0166-4328(90)90181-D", "10.1068/p170737", "10.1016/j.cag.2009.01.003", "10.1007/PL00005624", "10.1068/p160175", "10.1142/9789814350938_0005", "10.1162/1054746042545292", "10.1080/00140130701628329", "10.2466/PMS.105.7.1245-1256", "10.1146/annurev.ps.38.020187.000245", "10.1037/0096-1523.22.4.818", "10.1007/s002210000545", "10.1007/978-1-4419-8432-6_11", "10.1038/nature02350", "10.1037/0096-1523.11.2.122", "10.1162/105474605774785262", "10.1007/BF00234474", "10.3758/BF03203301", "10.1068/p5144", "10.1080/00140136508930772", "10.1068/p5845", "10.1111/j.1467-8721.2009.01603.x", "10.1037/0096-1523.31.2.339", "10.1007/s100550200008", "10.1007/s002210000504", "10.1016/j.visres.2007.03.012", "10.1016/0042-6989(75)90083-8", "10.1068/p180657", "10.2174/1875934301003010019", "10.1068/p060365", "10.1162/1054746042545238", "10.1080/00222895.1994.9941678", "10.1177/154193120805202704", "10.1007/s00221-007-0917-0", "10.1111/j.1468-5884.2008.00363.x", "10.1016/0166-4328(90)90181-D", "10.1068/p170737", "10.1016/j.cag.2009.01.003", "10.1007/PL00005624", "10.1068/p160175", "10.1142/9789814350938_0005", "10.1162/1054746042545292", "10.1080/00140130701628329", "10.2466/PMS.105.7.1245-1256", "10.1146/annurev.ps.38.020187.000245", "10.1037/0096-1523.22.4.818", "10.1007/s002210000545", "10.1007/978-1-4419-8432-6_11", "10.1038/nature02350", "10.1037/0096-1523.11.2.122", "10.1162/105474605774785262", "10.1007/BF00234474", "10.3758/BF03203301", "10.1068/p5144", "10.1080/00140136508930772", "10.1068/p5845", "10.1111/j.1467-8721.2009.01603.x", "10.1037/0096-1523.31.2.339", "10.1007/s100550200008", "10.1007/s002210000504", "10.1016/j.visres.2007.03.012", "10.1016/0042-6989(75)90083-8", "10.1068/p180657", "10.2174/1875934301003010019", "10.1068/p060365", "10.1162/1054746042545238", "10.1080/00222895.1994.9941678", "10.1177/154193120805202704", "10.1007/s00221-007-0917-0", "10.1111/j.1468-5884.2008.00363.x", "10.1016/0166-4328(90)90181-D", "10.1068/p170737", "10.1016/j.cag.2009.01.003", "10.1007/PL00005624", "10.1068/p160175", "10.1142/9789814350938_0005", "10.1162/1054746042545292", "10.1080/00140130701628329", "10.2466/PMS.105.7.1245-1256", "10.1146/annurev.ps.38.020187.000245", "10.1037/0096-1523.22.4.818", "10.1007/s002210000545", "10.1007/978-1-4419-8432-6_11", "10.1038/nature02350"]}, "10.1109/TVCG.2014.34": {"doi": "10.1109/TVCG.2014.34", "author": ["E. Hodgson", "E. Bachmann", "T. Thrash"], "title": "Performance of Redirected Walking Algorithms in a Constrained Virtual World", "year": "2014", "abstract": "Redirected walking algorithms imperceptibly rotate a virtual scene about users of immersive virtual environment systems in order to guide them away from tracking area boundaries. Ideally, these distortions permit users to explore large unbounded virtual worlds while walking naturally within a physically limited space. Many potential virtual worlds are composed of corridors, passageways, or aisles. Assuming users are not expected to walk through walls or other objects within the virtual world, these constrained worlds limit the directions of travel and as well as the number of opportunities to change direction. The resulting differences in user movement characteristics within the physical world have an impact on redirected walking algorithm performance. This work presents a comparison of generalized RDW algorithm performance within a constrained virtual world. In contrast to previous studies involving unconstrained virtual worlds, experimental results indicate that the steer-to-orbit keeps users in a smaller area than the steer-to-center algorithm. Moreover, in comparison to steer-to-center, steer-to-orbit is shown to reduce potential wall contacts by over 29%.", "keywords": ["virtual reality", "constrained virtual world", "generalized RDW algorithm", "immersive virtual reality", "unbounded virtual worlds", "corridors", "passageways", "aisles", "user movement characteristics", "physical world", "redirected walking algorithm performance", "steer-to-orbit algorithm", "steer-to-center algorithm", "Legged locomotion", "Navigation", "Orbits", "Rendering (computer graphics)", "Tracking", "Extraterrestrial measurements", "Virtual environments", "Virtual environments", " redirected walking", " navigation", " locomotion interface", " algorithm comparison", "Adolescent", "Algorithms", "Female", "Gait", "Humans", "Imaging, Three-Dimensional", "Male", "Orientation", "Psychomotor Performance", "User-Computer Interface", "Visual Perception", "Walking"], "referenced_by": ["IKEY:7833190", "IKEY:8255772", "IKEY:7384536", "IKEY:8446225", "IKEY:8645699", "IKEY:8645818", "IKEY:8797818", "IKEY:9003250", "IKEY:9019652", "IKEY:8580399", "IKEY:9212396", "IKEY:8762207", "IKEY:9284750", "10.1007/978-3-319-08234-9_253-1", "10.1038/s41598-018-36035-6", "10.1016/j.cag.2019.09.005"], "referencing": ["IKEY:576007", "IKEY:250911", "IKEY:391038", "IKEY:4663065", "IKEY:5072212", "IKEY:6200791", "IKEY:6479192", "IKEY:576007", "IKEY:250911", "IKEY:391038", "IKEY:4663065", "IKEY:5072212", "IKEY:6200791", "IKEY:6479192", "IKEY:576007", "IKEY:250911", "IKEY:391038", "IKEY:4663065", "IKEY:5072212", "IKEY:6200791", "IKEY:6479192", "10.1145/2043603.2043604", "10.1145/1450579.1450612", "10.1145/1450579.1450611", "10.1145/1394281.1394310", "10.1145/1450579.1450612", "10.1145/1394281.1394310", "10.1145/2043603.2043604", "10.1145/1450579.1450612", "10.1145/1450579.1450611", "10.1145/1394281.1394310", "10.1145/1450579.1450612", "10.1145/1394281.1394310", "10.1145/2043603.2043604", "10.1145/1450579.1450612", "10.1145/1450579.1450611", "10.1145/1394281.1394310", "10.1145/1450579.1450612", "10.1145/1394281.1394310", "10.1080/001401300184378", "10.2196/jmir.1051", "10.1002/j.2168-9830.2010.tb01059.x", "10.1016/S0097-8493(02)00113-9", "10.1016/j.cpr.2004.04.001", "10.3758/BF03200735", "10.1007/978-1-4419-8432-6", "10.1177/154193120805202704", "10.3758/BF03192976", "10.1016/j.cub.2009.07.053", "10.1007/s00221-004-2191-8", "10.1007/978-1-4419-8432-6_1", "10.1080/001401300184378", "10.2196/jmir.1051", "10.1002/j.2168-9830.2010.tb01059.x", "10.1016/S0097-8493(02)00113-9", "10.1016/j.cpr.2004.04.001", "10.3758/BF03200735", "10.1007/978-1-4419-8432-6", "10.1177/154193120805202704", "10.3758/BF03192976", "10.1016/j.cub.2009.07.053", "10.1007/s00221-004-2191-8", "10.1007/978-1-4419-8432-6_1", "10.1080/001401300184378", "10.2196/jmir.1051", "10.1002/j.2168-9830.2010.tb01059.x", "10.1016/S0097-8493(02)00113-9", "10.1016/j.cpr.2004.04.001", "10.3758/BF03200735", "10.1007/978-1-4419-8432-6", "10.1177/154193120805202704", "10.3758/BF03192976", "10.1016/j.cub.2009.07.053", "10.1007/s00221-004-2191-8", "10.1007/978-1-4419-8432-6_1"]}, "10.1109/TVCG.2014.36": {"doi": "10.1109/TVCG.2014.36", "author": ["J. W. Kelly", "W. W. Hammel", "Z. D. Siegel", "L. A. Sjolund"], "title": "Recalibration of Perceived Distance in Virtual Environments Occurs Rapidly and Transfers Asymmetrically Across Scale", "year": "2014", "abstract": "Distance in immersive virtual reality is commonly underperceived relative to intended distance, causing virtual environments to appear smaller than they actually are. However, a brief period of interaction by walking through the virtual environment with visual feedback can cause dramatic improvement in perceived distance. The goal of the current project was to determine how quickly improvement occurs as a result of walking interaction (Experiment 1) and whether improvement is specific to the distances experienced during interaction, or whether improvement transfers across scales of space (Experiment 2). The results show that five interaction trials resulted in a large improvement in perceived distance, and that subsequent walking interactions showed continued but diminished improvement. Furthermore, interaction with near objects (1-2 m) improved distance perception for near but not far (4-5 m) objects, whereas interaction with far objects broadly improved distance perception for both near and far objects. These results have practical implications for ameliorating distance underperception in immersive virtual reality, as well as theoretical implications for distinguishing between theories of how walking interaction influences perceived distance.", "keywords": ["calibration", "distance measurement", "virtual reality", "perceived distance recalibration", "virtual environments", "visual feedback", "walking interaction", "distance perception", "immersive virtual reality", "Legged locomotion", "Virtual environments", "Visualization", "Educational institutions", "Atmospheric measurements", "Particle measurements", "Distance perception", " virtual reality", " recalibration"], "referenced_by": ["IKEY:7131732", "IKEY:7517276", "IKEY:8267487", "IKEY:7223350", "IKEY:7892292", "IKEY:7892349", "IKEY:8446539", "IKEY:8642384", "IKEY:8643340", "IKEY:8798059", "IKEY:9089552", "10.1145/2983631", "10.1145/3106155", "10.1145/3165285", "10.1145/2820619.2820627", "10.1007/978-3-319-72323-5_8", "10.1016/bs.plm.2014.09.006", "10.1068/p7929", "10.3389/frobt.2017.00033", "10.3758/s13414-015-0948-8", "10.3758/s13414-016-1243-z", "10.1007/978-3-319-95282-6_48", "10.3389/fnhum.2018.00361", "10.3389/frobt.2019.00044", "10.1371/journal.pone.0224651", "10.3758/s13414-019-01929-8", "10.1007/s10055-020-00432-y", "10.1007/978-3-030-51064-0_29", "10.1177/0301006620951997"], "referencing": ["IKEY:6479211", "IKEY:4480794", "IKEY:1667620", "IKEY:4811024", "IKEY:6180929", "IKEY:6479211", "IKEY:4480794", "IKEY:1667620", "IKEY:4811024", "IKEY:6180929", "IKEY:6479211", "IKEY:4480794", "IKEY:1667620", "IKEY:4811024", "IKEY:6180929", "10.1145/1140491.1140493", "10.1145/1823738.1823744", "10.1145/508530.508549", "10.1145/2077451.2077457", "10.1145/1577755.1577762", "10.1145/1077399.1077403", "10.1145/1620993.1620998", "10.1145/1498700.1498702", "10.1145/1581073.1581091", "10.1145/1227134.1227138", "10.1145/1140491.1140493", "10.1145/1823738.1823744", "10.1145/508530.508549", "10.1145/2077451.2077457", "10.1145/1577755.1577762", "10.1145/1077399.1077403", "10.1145/1620993.1620998", "10.1145/1498700.1498702", "10.1145/1581073.1581091", "10.1145/1227134.1227138", "10.1145/1140491.1140493", "10.1145/1823738.1823744", "10.1145/508530.508549", "10.1145/2077451.2077457", "10.1145/1577755.1577762", "10.1145/1077399.1077403", "10.1145/1620993.1620998", "10.1145/1498700.1498702", "10.1145/1581073.1581091", "10.1145/1227134.1227138", "10.1037/1076-898X.14.1.61", "10.1007/978-1-4899-0038-8", "10.1002/acp.1140", "10.1518/001872007X200139", "10.1037/0096-1523.18.4.906", "10.3758/BF03211932", "10.1068/p190675", "10.3758/BF03208231", "10.1038/35102562", "10.1068/p190675", "10.1068/p5144", "10.1162/1054746041944786", "10.1162/1054746042545238", "10.1162/1054746042545292", "10.1162/pres.17.1.91", "10.1518/001872098779591340", "10.3758/APP.71.5.1096", "10.1162/pres.17.2.176", "10.1016/j.cag.2009.12.003", "10.3758/s13414-013-0503-4", "10.3758/BF03211868", "10.1037/0096-1523.31.3.398", "10.1037//0096-1523.21.3.480", "10.1037/0096-1523.22.2.379", "10.1073/pnas.93.9.3843", "10.1162/105474698565640", "10.3758/BF03211868", "10.1098/rspb.1999.0601", "10.1016/0042-6989(69)90049-2", "10.3758/BF03214141", "10.3758/BF03196423", "10.1037/1082-989X.4.1.44", "10.1037/1076-898X.14.1.61", "10.1007/978-1-4899-0038-8", "10.1002/acp.1140", "10.1518/001872007X200139", "10.1037/0096-1523.18.4.906", "10.3758/BF03211932", "10.1068/p190675", "10.3758/BF03208231", "10.1038/35102562", "10.1068/p190675", "10.1068/p5144", "10.1162/1054746041944786", "10.1162/1054746042545238", "10.1162/1054746042545292", "10.1162/pres.17.1.91", "10.1518/001872098779591340", "10.3758/APP.71.5.1096", "10.1162/pres.17.2.176", "10.1016/j.cag.2009.12.003", "10.3758/s13414-013-0503-4", "10.3758/BF03211868", "10.1037/0096-1523.31.3.398", "10.1037//0096-1523.21.3.480", "10.1037/0096-1523.22.2.379", "10.1073/pnas.93.9.3843", "10.1162/105474698565640", "10.3758/BF03211868", "10.1098/rspb.1999.0601", "10.1016/0042-6989(69)90049-2", "10.3758/BF03214141", "10.3758/BF03196423", "10.1037/1082-989X.4.1.44", "10.1037/1076-898X.14.1.61", "10.1007/978-1-4899-0038-8", "10.1002/acp.1140", "10.1518/001872007X200139", "10.1037/0096-1523.18.4.906", "10.3758/BF03211932", "10.1068/p190675", "10.3758/BF03208231", "10.1038/35102562", "10.1068/p190675", "10.1068/p5144", "10.1162/1054746041944786", "10.1162/1054746042545238", "10.1162/1054746042545292", "10.1162/pres.17.1.91", "10.1518/001872098779591340", "10.3758/APP.71.5.1096", "10.1162/pres.17.2.176", "10.1016/j.cag.2009.12.003", "10.3758/s13414-013-0503-4", "10.3758/BF03211868", "10.1037/0096-1523.31.3.398", "10.1037//0096-1523.21.3.480", "10.1037/0096-1523.22.2.379", "10.1073/pnas.93.9.3843", "10.1162/105474698565640", "10.3758/BF03211868", "10.1098/rspb.1999.0601", "10.1016/0042-6989(69)90049-2", "10.3758/BF03214141", "10.3758/BF03196423", "10.1037/1082-989X.4.1.44"]}, "10.1109/TVCG.2014.18": {"doi": "10.1109/TVCG.2014.18", "author": ["T. Y. Grechkin", "J. M. Plumert", "J. K. Kearney"], "title": "Dynamic Affordances in Embodied Interactive Systems: The Role of Display and Mode of Locomotion", "year": "2014", "abstract": "We investigated how the properties of interactive virtual reality systems affect user behavior in full-body embodied interactions. Our experiment compared four interactive virtual reality systems using different display types (CAVE vs. HMD) and modes of locomotion (walking vs. joystick). Participants performed a perceptual-motor coordination task, in which they had to choose among a series of opportunities to pass through a gate that cycled open and closed and then board a moving train. Mode of locomotion, but not type of display, affected how participants chose opportunities for action. Both mode of locomotion and display affected performance when participants acted on their choices. We conclude that technological properties of virtual reality system (both display and mode of locomotion) significantly affected opportunities for action available in the environment (affordances) and discuss implications for design and practical applications of immersive interactive systems.", "keywords": ["gait analysis", "helmet mounted displays", "virtual reality", "embodied interactive systems", "interactive virtual reality systems", "full-body embodied interactions", "user behavior", "locomotion mode", "CAVE", "HMD", "perceptual-motor coordination task", "head-mounted display", "Logic gates", "Legged locomotion", "Interactive systems", "Virtual environments", "Tracking", "Psychology", "Virtual reality", " embodied interaction", " affordances", " perceptual-motor coordination", " display type", " interaction technique", " mode of locomotion", "Cues", "Gait", "Humans", "Imaging, Three-Dimensional", "Orientation", "Psychomotor Performance", "Transportation", "User-Computer Interface", "Visual Perception"], "referenced_by": ["IKEY:7072561", "IKEY:8446189", "10.1145/2983631", "10.1007/s10055-015-0267-3", "10.1111/cdep.12089", "10.3390/mti1040024", "10.1016/j.ijhcs.2018.08.002", "10.1007/978-3-030-05129-7_2", "10.1155/2019/7626349", "10.1016/j.cag.2019.09.005", "10.1177/1071181319631221", "10.1007/s10055-020-00432-y", "10.1080/10407413.2020.1741323", "10.1016/j.aei.2020.101227"], "referencing": ["IKEY:6184191", "IKEY:6180926", "IKEY:6180929", "IKEY:6479211", "IKEY:6165144", "IKEY:5722949", "IKEY:6184191", "IKEY:6180926", "IKEY:6180929", "IKEY:6479211", "IKEY:6165144", "IKEY:5722949", "IKEY:6184191", "IKEY:6180926", "IKEY:6180929", "IKEY:6479211", "IKEY:6165144", "IKEY:5722949", "10.1145/2043603.2043606", "10.1145/1536513.1536527", "10.1145/2330667.2330687", "10.1145/1823738.1823744", "10.1145/1925820.1925826", "10.1145/1357054.1357089", "10.1145/1394281.1394283", "10.1145/1744161.1744163", "10.1145/1822348.1822369", "10.1145/1970378.1970384", "10.1145/1140491.1140495", "10.1145/2043603.2043606", "10.1145/1536513.1536527", "10.1145/2330667.2330687", "10.1145/1823738.1823744", "10.1145/1925820.1925826", "10.1145/1357054.1357089", "10.1145/1394281.1394283", "10.1145/1744161.1744163", "10.1145/1822348.1822369", "10.1145/1970378.1970384", "10.1145/1140491.1140495", "10.1145/2043603.2043606", "10.1145/1536513.1536527", "10.1145/2330667.2330687", "10.1145/1823738.1823744", "10.1145/1925820.1925826", "10.1145/1357054.1357089", "10.1145/1394281.1394283", "10.1145/1744161.1744163", "10.1145/1822348.1822369", "10.1145/1970378.1970384", "10.1145/1140491.1140495", "10.2466/PMS.70.1.35-45", "10.1504/IJART.2009.028927", "10.1177/154193120204602607", "10.1068/p170623", "10.3389/fnbeh.2013.00085", "10.1016/j.humov.2010.07.016", "10.1037/a0023510", "10.1007/s00779-011-0476-z", "10.1016/S0042-6989(97)00230-7", "10.1037/a0029716", "10.1121/1.385912", "10.3758/BF03194543", "10.1227/01.neu.0000279734.22931.21", "10.1080/17470210701712978", "10.1016/S0001-4575(97)00053-5", "10.1016/j.trf.2006.01.004", "10.1111/j.1467-8624.2004.00736.x", "10.1016/j.jecp.2010.07.005", "10.1007/s10055-012-0216-3", "10.1162/105474605774918750", "10.1186/1743-0003-8-36", "10.1038/nn948", "10.1037/0096-1523.10.5.683", "10.1037/0033-295X.113.2.358", "10.3389/fpsyg.2013.00058", "10.2466/PMS.70.1.35-45", "10.1504/IJART.2009.028927", "10.1177/154193120204602607", "10.1068/p170623", "10.3389/fnbeh.2013.00085", "10.1016/j.humov.2010.07.016", "10.1037/a0023510", "10.1007/s00779-011-0476-z", "10.1016/S0042-6989(97)00230-7", "10.1037/a0029716", "10.1121/1.385912", "10.3758/BF03194543", "10.1227/01.neu.0000279734.22931.21", "10.1080/17470210701712978", "10.1016/S0001-4575(97)00053-5", "10.1016/j.trf.2006.01.004", "10.1111/j.1467-8624.2004.00736.x", "10.1016/j.jecp.2010.07.005", "10.1007/s10055-012-0216-3", "10.1162/105474605774918750", "10.1186/1743-0003-8-36", "10.1038/nn948", "10.1037/0096-1523.10.5.683", "10.1037/0033-295X.113.2.358", "10.3389/fpsyg.2013.00058", "10.2466/PMS.70.1.35-45", "10.1504/IJART.2009.028927", "10.1177/154193120204602607", "10.1068/p170623", "10.3389/fnbeh.2013.00085", "10.1016/j.humov.2010.07.016", "10.1037/a0023510", "10.1007/s00779-011-0476-z", "10.1016/S0042-6989(97)00230-7", "10.1037/a0029716", "10.1121/1.385912", "10.3758/BF03194543", "10.1227/01.neu.0000279734.22931.21", "10.1080/17470210701712978", "10.1016/S0001-4575(97)00053-5", "10.1016/j.trf.2006.01.004", "10.1111/j.1467-8624.2004.00736.x", "10.1016/j.jecp.2010.07.005", "10.1007/s10055-012-0216-3", "10.1162/105474605774918750", "10.1186/1743-0003-8-36", "10.1038/nn948", "10.1037/0096-1523.10.5.683", "10.1037/0033-295X.113.2.358", "10.3389/fpsyg.2013.00058"]}, "10.1109/TVCG.2014.23": {"doi": "10.1109/TVCG.2014.23", "author": ["C. Stinson", "D. A. Bowman"], "title": "Feasibility of Training Athletes for High-Pressure Situations Using Virtual Reality", "year": "2014", "abstract": "Virtual reality (VR) has been successfully applied to a broad range of training domains; however, to date there is little research investigating its benefits for sport psychology training. We hypothesized that using high-fidelity VR systems to display realistic 3D sport environments could trigger anxiety, allowing resilience-training systems to prepare athletes for real-world, high-pressure situations. In this work we investigated the feasibility and usefulness of using VR for sport psychology training. We developed a virtual soccer goalkeeping application for the Virginia Tech Visionarium VisCube (a CAVE-like display system), in which users defend against simulated penalty kicks using their own bodies. Using the application, we ran a controlled, within-subjects experiment with three independent variables: known anxiety triggers, field of regard, and simulation fidelity. The results demonstrate that a VR sport-oriented system can induce increased anxiety (physiological and subjective measures) compared to a baseline condition. There were a number of main effects and interaction effects for all three independent variables in terms of the subjective measures of anxiety. Both known anxiety triggers and simulation fidelity had a direct relationship to anxiety, while field of regard had an inverse relationship. Overall, the results demonstrate great potential for VR sport psychology training systems; however, further research is needed to determine if training in a VR environment can lead to long-term reduction in sport-induced anxiety.", "keywords": ["computer based training", "psychology", "sport", "virtual reality", "training athletes", "high-pressure situations", "virtual reality", "VR", "sport psychology training", "high-fidelity VR systems", "realistic 3D sport environments", "resilience-training systems", "virtual soccer goalkeeping application", "Virginia Tech Visionarium VisCube", "CAVE-like display system", "simulated penalty kicks", "simulation fidelity", "known anxiety triggers", "field of regard", "VR sport-oriented system", "interaction effects", "independent variables", "sport-induced anxiety", "Training", "Psychology", "Solid modeling", "Heart rate variability", "Animation", "Three-dimensional displays", "Virtual reality", " sport training", " sport psychology", "Athletic Performance", "Computer Graphics", "Feasibility Studies", "Humans", "Soccer", "Stress, Psychological", "Task Performance and Analysis", "Therapy, Computer-Assisted", "User-Computer Interface", "Video Games"], "referenced_by": ["IKEY:8280423", "IKEY:7131720", "IKEY:8336833", "IKEY:8615164", "IKEY:8797705", "IKEY:8797889", "IKEY:9036756", "IKEY:9086000", "IKEY:9223333", "IKEY:9153042", "IKEY:9283022", "10.1145/2806173.2806178", "10.1007/978-3-319-39690-3_38", "10.1007/978-3-319-57987-0_17", "10.1007/s10055-017-0320-5", "10.1016/j.physbeh.2016.05.032", "10.1080/19420889.2015.1029689", "10.3389/fphys.2018.00128", "10.3389/fpsyg.2018.00058", "10.3390/mti1040030", "10.1123/cssep.2018-0002", "10.3390/su10103475", "10.1051/sm/2018031", "10.1007/978-3-319-08234-9_181-1", "10.1080/02640414.2019.1689807", "10.1007/s10055-020-00441-x", "10.5772/intechopen.91351", "10.3389/fspor.2020.00059", "10.1080/10494820.2020.1772837", "10.1080/02640414.2020.1823618", "10.1515/jirspa-2020-0002", "10.1016/j.micpro.2020.103646"], "referencing": ["IKEY:4909120", "IKEY:4909120", "IKEY:4909120", "10.1145/566570.566630", "10.1145/566570.566630", "10.1145/566570.566630", "10.1016/j.janxdis.2007.04.006", "10.1177/154193121005402709", "10.1155/2007/60803", "10.1016/0001-6918(59)90105-2", "10.1016/0191-8869(94)90226-7", "10.1080/10615806.2010.481331", "10.1016/S0079-6123(09)01304-1", "10.1080/17470210802557702", "10.1162/PRES_a_00003", "10.1007/978-1-4419-8432-6_13", "10.1243/17543371JSET33", "10.1162/PRES_a_00004", "10.5298/1081-5937-39.1.11", "10.1016/j.beth.2005.04.004", "10.1037//0022-006X.68.6.1020", "10.1016/j.cpr.2004.04.001", "10.1016/S0005-7967(01)00023-7", "10.1089/109493103769710497", "10.1016/S0005-7967(03)00139-6", "10.1080/07303084.1997.10604922", "10.1037/1040-3590.19.4.369", "10.1037/a0024648", "10.1016/j.janxdis.2007.04.006", "10.1177/154193121005402709", "10.1155/2007/60803", "10.1016/0001-6918(59)90105-2", "10.1016/0191-8869(94)90226-7", "10.1080/10615806.2010.481331", "10.1016/S0079-6123(09)01304-1", "10.1080/17470210802557702", "10.1162/PRES_a_00003", "10.1007/978-1-4419-8432-6_13", "10.1243/17543371JSET33", "10.1162/PRES_a_00004", "10.5298/1081-5937-39.1.11", "10.1016/j.beth.2005.04.004", "10.1037//0022-006X.68.6.1020", "10.1016/j.cpr.2004.04.001", "10.1016/S0005-7967(01)00023-7", "10.1089/109493103769710497", "10.1016/S0005-7967(03)00139-6", "10.1080/07303084.1997.10604922", "10.1037/1040-3590.19.4.369", "10.1037/a0024648", "10.1016/j.janxdis.2007.04.006", "10.1177/154193121005402709", "10.1155/2007/60803", "10.1016/0001-6918(59)90105-2", "10.1016/0191-8869(94)90226-7", "10.1080/10615806.2010.481331", "10.1016/S0079-6123(09)01304-1", "10.1080/17470210802557702", "10.1162/PRES_a_00003", "10.1007/978-1-4419-8432-6_13", "10.1243/17543371JSET33", "10.1162/PRES_a_00004", "10.5298/1081-5937-39.1.11", "10.1016/j.beth.2005.04.004", "10.1037//0022-006X.68.6.1020", "10.1016/j.cpr.2004.04.001", "10.1016/S0005-7967(01)00023-7", "10.1089/109493103769710497", "10.1016/S0005-7967(03)00139-6", "10.1080/07303084.1997.10604922", "10.1037/1040-3590.19.4.369", "10.1037/a0024648"]}, "10.1109/TVCG.2014.30": {"doi": "10.1109/TVCG.2014.30", "author": ["S. Friston", "A. Steed"], "title": "Measuring Latency in Virtual Environments", "year": "2014", "abstract": "Latency of interactive computer systems is a product of the processing, transport and synchronisation delays inherent to the components that create them. In a virtual environment (VE) system, latency is known to be detrimental to a user's sense of immersion, physical performance and comfort level. Accurately measuring the latency of a VE system for study or optimisation, is not straightforward. A number of authors have developed techniques for characterising latency, which have become progressively more accessible and easier to use. In this paper, we characterise these techniques. We describe a simple mechanical simulator designed to simulate a VE with various amounts of latency that can be finely controlled (to within 3ms). We develop a new latency measurement technique called Automated Frame Counting to assist in assessing latency using high speed video (to within 1ms). We use the mechanical simulator to measure the accuracy of Steed's and Di Luca's measurement techniques, proposing improvements where they may be made. We use the methods to measure latency of a number of interactive systems that may be of interest to the VE engineer, with a significant level of confidence. All techniques were found to be highly capable however Steed's Method is both accurate and easy to use without requiring specialised hardware.", "keywords": ["synchronisation", "virtual reality", "virtual environment system", "interactive computer systems", "synchronisation delays", "VE system", "comfort level", "mechanical simulator", "latency measurement technique", "high speed video", "automated frame counting", "Di Luca measurement techniques", "Steed measurement techniques", "Feature extraction", "Cameras", "Estimation", "Measurement techniques", "Target tracking", "Delays", "Latency", " measurement", "Computer Graphics", "Equipment Design", "Equipment Failure Analysis", "Information Storage and Retrieval", "Photic Stimulation", "Signal Processing, Computer-Assisted", "User-Computer Interface", "Video Recording"], "referenced_by": ["IKEY:7460064", "IKEY:7398383", "IKEY:7398427", "IKEY:8251892", "IKEY:7551584", "IKEY:7127051", "IKEY:7833188", "IKEY:7892244", "IKEY:7892261", "IKEY:7293974", "IKEY:7050364", "IKEY:8446195", "IKEY:8605315", "IKEY:8643417", "IKEY:8658185", "IKEY:8747365", "IKEY:8940869", "IKEY:8951925", "IKEY:9089584", "IKEY:9089661", "IKEY:9145075", "IKEY:9139304", "IKEY:9183433", "10.1145/3083187.3084019", "10.1145/3377353", "10.1093/cz/zow070", "10.3389/fict.2016.00034", "10.4018/IJACDT.2017070104", "10.1177/2331216518800871", "10.1007/978-3-030-03801-4_45", "10.1007/s10055-018-0374-z", "10.1007/978-3-030-34644-7_5", "10.1177/2331216520908704", "10.3389/frvir.2020.582204"], "referencing": ["IKEY:1191132", "IKEY:1191132", "IKEY:1191132", "10.1145/2072298.2071991", "10.1145/1275511.1275514", "10.1145/1394281.1394310", "10.1145/169059.169431", "10.1145/2087756.2087869", "10.1145/354401.354444", "10.1145/2072298.2071991", "10.1145/1275511.1275514", "10.1145/1394281.1394310", "10.1145/169059.169431", "10.1145/2087756.2087869", "10.1145/354401.354444", "10.1145/2072298.2071991", "10.1145/1275511.1275514", "10.1145/1394281.1394310", "10.1145/169059.169431", "10.1145/2087756.2087869", "10.1145/354401.354444", "10.1177/154193120304702001", "10.1177/0018720811428734", "10.1162/pres_a_00023", "10.1162/105474605323384663", "10.1023/A:1008045108935", "10.1561/0600000017", "10.1162/PRES_a_00131", "10.1177/154193120304702001", "10.1177/0018720811428734", "10.1162/pres_a_00023", "10.1162/105474605323384663", "10.1023/A:1008045108935", "10.1561/0600000017", "10.1162/PRES_a_00131", "10.1177/154193120304702001", "10.1177/0018720811428734", "10.1162/pres_a_00023", "10.1162/105474605323384663", "10.1023/A:1008045108935", "10.1561/0600000017", "10.1162/PRES_a_00131"]}, "10.1109/TVCG.2014.19": {"doi": "10.1109/TVCG.2014.19", "author": ["Y. Wu", "S. V. Babu", "R. Armstrong", "J. W. Bertrand", "J. Luo", "T. Roy", "S. B. Daily", "L. C. Dukes", "L. F. Hodges", "T. Fasolino"], "title": "Effects of Virtual Human Animation on Emotion Contagion in Simulated Inter-Personal Experiences", "year": "2014", "abstract": "We empirically examined the impact of virtual human animation on the emotional responses of participants in a medical virtual reality system for education in the signs and symptoms of patient deterioration. Participants were presented with one of two virtual human conditions in a between-subjects experiment, static (non-animated) and dynamic (animated). Our objective measures included the use of psycho-physical Electro Dermal Activity (EDA) sensors, and subjective measures inspired by social psychology research included the Differential Emotions Survey (DES IV) and Positive and Negative Affect Survey (PANAS). We analyzed the quantitative and qualitative measures associated with participants' emotional state at four distinct time-steps in the simulated interpersonal experience as the virtual patient's medical condition deteriorated. Results suggest that participants in the dynamic condition with animations exhibited a higher sense of co-presence and greater emotional response as compared to participants in the static condition, corresponding to the deterioration in the medical condition of the virtual patient. Negative affect of participants in the dynamic condition increased at a higher rate than for participants in the static condition. The virtual human animations elicited a stronger response in negative emotions such as anguish, fear, and anger as the virtual patient's medical condition worsened.", "keywords": ["behavioural sciences computing", "biomedical education", "computer aided instruction", "computer animation", "emotion recognition", "virtual reality", "virtual human animation effects", "emotion contagion", "simulated interpersonal experiences", "emotional responses", "medical virtual reality system", "patient deterioration", "virtual human conditions", "psycho physical electro dermal activity", "EDA sensors", "social psychology research", "differential emotions survey", "DES IV", "positive and negative affect survey", "PANAS", "virtual patient medical condition", "Animation", "Training", "Educational institutions", "Sensors", "Medical services", "Atmospheric measurements", "Particle measurements", "Virtual humans/digital characters", " simulation and behavior", " emotion contagion", " user studies", " medicine", "Adolescent", "Adult", "Affect", "Computer Graphics", "Facial Expression", "Female", "Humans", "Imaging, Three-Dimensional", "Interpersonal Relations", "Male", "Photic Stimulation", "User-Computer Interface", "Whole Body Imaging", "Young Adult"], "referenced_by": ["IKEY:7219412", "IKEY:7118232", "IKEY:7383334", "IKEY:8446364", "IKEY:9089573", "10.1007/978-3-319-39907-2_53", "10.1007/978-3-319-42108-7_39", "10.1007/s12369-018-0466-7", "10.1080/0144929X.2017.1386714", "10.2196/preprints.9611", "10.26634/jet.14.2.13716", "10.3389/fnhum.2016.00421", "10.2196/games.9611", "10.3389/frobt.2018.00114", "10.12720/jcm.12.2.111-117", "10.3389/fpsyg.2019.00186", "10.1002/cav.1881", "10.1016/j.chb.2020.106451", "10.3389/fpsyg.2020.566682"], "referencing": ["IKEY:5415607", "IKEY:1024750", "IKEY:6479207", "IKEY:5415607", "IKEY:1024750", "IKEY:6479207", "IKEY:5415607", "IKEY:1024750", "IKEY:6479207", "10.1145/2207676.2207777", "10.1145/2449396.2449447", "10.1145/1823738.1823740", "10.1145/2492494.2492500", "10.1145/1240624.1240861", "10.1145/2207676.2207777", "10.1145/2449396.2449447", "10.1145/1823738.1823740", "10.1145/2492494.2492500", "10.1145/1240624.1240861", "10.1145/2207676.2207777", "10.1145/2449396.2449447", "10.1145/1823738.1823740", "10.1145/2492494.2492500", "10.1145/1240624.1240861", "10.1177/0146167203029007002", "10.1007/978-3-642-40415-3_12", "10.1007/978-3-642-39351-8_45", "10.1080/10413200008404216", "10.1177/1073191109340382", "10.1007/978-3-642-33197-8_42", "10.1007/978-3-642-24571-8_6", "10.1016/j.ijhcs.2004.11.009", "10.1111/j.1525-1497.2006.00306.x", "10.1007/978-3-642-23974-8_42", "10.1007/978-3-642-33197-8_8", "10.1037/a0022582", "10.1037/0022-3514.54.6.1063", "10.1177/0146167203029007002", "10.1007/978-3-642-40415-3_12", "10.1007/978-3-642-39351-8_45", "10.1080/10413200008404216", "10.1177/1073191109340382", "10.1007/978-3-642-33197-8_42", "10.1007/978-3-642-24571-8_6", "10.1016/j.ijhcs.2004.11.009", "10.1111/j.1525-1497.2006.00306.x", "10.1007/978-3-642-23974-8_42", "10.1007/978-3-642-33197-8_8", "10.1037/a0022582", "10.1037/0022-3514.54.6.1063", "10.1177/0146167203029007002", "10.1007/978-3-642-40415-3_12", "10.1007/978-3-642-39351-8_45", "10.1080/10413200008404216", "10.1177/1073191109340382", "10.1007/978-3-642-33197-8_42", "10.1007/978-3-642-24571-8_6", "10.1016/j.ijhcs.2004.11.009", "10.1111/j.1525-1497.2006.00306.x", "10.1007/978-3-642-23974-8_42", "10.1007/978-3-642-33197-8_8", "10.1037/a0022582", "10.1037/0022-3514.54.6.1063"]}, "10.1109/TVCG.2014.26": {"doi": "10.1109/TVCG.2014.26", "author": ["D. Rivera-Gutierrez", "R. Ferdig", "J. Li", "B. Lok"], "title": "Getting the Point Across: Exploring the Effects of Dynamic Virtual Humans in an Interactive Museum Exhibit on User Perceptions", "year": "2014", "abstract": "We have created \u201cYou, M.D.\u201d, an interactive museum exhibit in which users learn about topics in public health literacy while interacting with virtual humans. You, M.D. is equipped with a weight sensor, a height sensor and a Microsoft Kinect that gather basic user information. Conceptually, You, M.D. could use this user information to dynamically select the appearance of the virtual humans in the interaction attempting to improve learning outcomes and user perception for each particular user. For this concept to be possible, a better understanding of how different elements of the visual appearance of a virtual human affects user perceptions is required. In this paper, we present the results of an initial user study with a large sample size (n =333) ran using You, M.D. The study measured users' reactions based on the user's gender and body-mass index (BMI) when facing virtual humans with BMI either concordant or discordant from the user's BMI. The results of the study indicate that concordance between the users' BMI and the virtual human's BMI affects male and female users differently. The results also show that female users rate virtual humans as more knowledgeable than male users rate the same virtual humans.", "keywords": ["health care", "interactive devices", "museums", "virtual reality", "dynamic virtual humans", "interactive museum exhibit", "user perceptions", "You, M.D", "public health literacy", "weight sensor", "height sensor", "Microsoft Kinect", "user information", "body-mass index", "Malignant tumors", "Visualization", "Public healthcare", "Avatars", "Educational institutions", "TV", "virtual humans", " museum exhibits", " user perceptions", "Adolescent", "Adult", "Computer Graphics", "Computer-Assisted Instruction", "Female", "Humans", "Male", "Middle Aged", "Museums", "User-Computer Interface", "Visual Perception", "Whole Body Imaging", "Young Adult"], "referenced_by": ["10.1007/978-3-030-22993-1_13"], "referencing": ["10.1145/1746259.1746261", "10.1145/1124772.1124945", "10.1145/1746259.1746261", "10.1145/1124772.1124945", "10.1145/1746259.1746261", "10.1145/1124772.1124945", "10.1162/105474605774785235", "10.1007/978-1-84882-825-4_14", "10.1093/oxfordjournals.aje.a008733", "10.1016/j.jaci.2008.04.024", "10.1097/MLR.0b013e318213c03f", "10.1016/S0025-6196(11)61175-0", "10.3322/canjclin.55.1.10", "10.1007/11550617_28", "10.1046/j.1467-789x.2001.00031.x", "10.1007/978-3-540-85483-8_24", "10.1063/1.881216", "10.1007/978-3-642-33197-8_25", "10.1111/j.1468-2958.2007.00299.x", "10.1177/0093650208330254", "10.1162/105474605774785235", "10.1007/978-1-84882-825-4_14", "10.1093/oxfordjournals.aje.a008733", "10.1016/j.jaci.2008.04.024", "10.1097/MLR.0b013e318213c03f", "10.1016/S0025-6196(11)61175-0", "10.3322/canjclin.55.1.10", "10.1007/11550617_28", "10.1046/j.1467-789x.2001.00031.x", "10.1007/978-3-540-85483-8_24", "10.1063/1.881216", "10.1007/978-3-642-33197-8_25", "10.1111/j.1468-2958.2007.00299.x", "10.1177/0093650208330254", "10.1162/105474605774785235", "10.1007/978-1-84882-825-4_14", "10.1093/oxfordjournals.aje.a008733", "10.1016/j.jaci.2008.04.024", "10.1097/MLR.0b013e318213c03f", "10.1016/S0025-6196(11)61175-0", "10.3322/canjclin.55.1.10", "10.1007/11550617_28", "10.1046/j.1467-789x.2001.00031.x", "10.1007/978-3-540-85483-8_24", "10.1063/1.881216", "10.1007/978-3-642-33197-8_25", "10.1111/j.1468-2958.2007.00299.x", "10.1177/0093650208330254"]}, "10.1109/TVCG.2014.22": {"doi": "10.1109/TVCG.2014.22", "author": ["T. Lopez", "R. Bouville", "E. Loup-escande", "F. Nouviale", "V. Gouranton", "B. Arnaldi"], "title": "Exchange of Avatars: Toward a Better Perception and Understanding", "year": "2014", "abstract": "The exchange of avatars, i.e. the actual fact of changing once avatar with another one, is a promising trend in multi-actor virtual environments. It provides new opportunities for users, such as controlling a different avatar for a specific action, retrieving knowledge belonging to a particular avatar, solving conflicts and deadlocks situations or even helping another user. Virtual Environments for Training are especially affected by this trend as a specific role derived from a scenario is usually assigned to a unique avatar. Despite the increasing use of avatar exchange, users' perception and understanding of this mechanism have not been studied. In this paper, we propose two complementary user-centered evaluations that aim at comparing several representations for the exchange of avatars; these are termed exchange metaphors. Our first experiment focuses on the perception of an exchange by a user who is not involved in the exchange, and the second experiment analyzes the perception of an exchange triggered by the user. Results show that the use of visual feedback globally aids better understanding of the exchange mechanism in both cases. Our first experiment suggests, however, that visual feedback is less efficient than a simple popup notification in terms of task duration. In addition, the second experiment shows that much simpler metaphors with no visual effect are generally preferred because of their efficiency.", "keywords": ["avatars", "multi-actor virtual environments", "deadlocks situations", "training", "avatar exchange", "complementary user-centered evaluations", "exchange metaphors", "visual feedback", "exchange mechanism", "popup notification", "task duration", "user perception", "user understanding", "Avatars", "Visualization", "Virtual environments", "Collaboration", "Image color analysis", "Engines", "Wheels", "Perception", " User-centered evaluations", " Virtual environments for training", " Multi-user virtual environments"], "referenced_by": ["IKEY:7160933", "IKEY:7829434", "IKEY:6802093", "10.1002/cav.1583"], "referencing": ["IKEY:4810879", "IKEY:1242005", "IKEY:4480756", "IKEY:4810879", "IKEY:1242005", "IKEY:4480756", "IKEY:4810879", "IKEY:1242005", "IKEY:4480756", "10.1145/375735.376332", "10.1145/375735.376332", "10.1145/375735.376332", "10.1007/BF01424340", "10.1080/01449290500330331", "10.1126/science.1143439", "10.3389/fnhum.2013.00083", "10.1371/journal.pone.0003832", "10.1016/0749-5978(89)90060-5", "10.1177/1059601195201003", "10.1371/journal.pone.0010564", "10.1007/BF01424340", "10.1080/01449290500330331", "10.1126/science.1143439", "10.3389/fnhum.2013.00083", "10.1371/journal.pone.0003832", "10.1016/0749-5978(89)90060-5", "10.1177/1059601195201003", "10.1371/journal.pone.0010564", "10.1007/BF01424340", "10.1080/01449290500330331", "10.1126/science.1143439", "10.3389/fnhum.2013.00083", "10.1371/journal.pone.0003832", "10.1016/0749-5978(89)90060-5", "10.1177/1059601195201003", "10.1371/journal.pone.0010564"]}, "10.1109/TVCG.2014.45": {"doi": "10.1109/TVCG.2014.45", "author": ["D. A. G. Jauregui", "F. Argelaguet", "A. Olivier", "M. Marchal", "F. Multon", "A. Lecuyer"], "title": "Toward \"Pseudo-Haptic Avatars\": Modifying the Visual Animation of Self-Avatar Can Simulate the Perception of Weight Lifting", "year": "2014", "abstract": "In this paper we study how the visual animation of a self-avatar can be artificially modified in real-time in order to generate different haptic perceptions. In our experimental setup, participants could watch their self-avatar in a virtual environment in mirror mode while performing a weight lifting task. Users could map their gestures on the self-animated avatar in real-time using a Kinect. We introduce three kinds of modification of the visual animation of the self-avatar according to the effort delivered by the virtual avatar: 1) changes on the spatial mapping between the user's gestures and the avatar, 2) different motion profiles of the animation, and 3) changes in the posture of the avatar (upper-body inclination). The experimental task consisted of a weight lifting task in which participants had to order four virtual dumbbells according to their virtual weight. The user had to lift each virtual dumbbells by means of a tangible stick, the animation of the avatar was modulated according to the virtual weight of the dumbbell. The results showed that the altering the spatial mapping delivered the best performance. Nevertheless, participants globally appreciated all the different visual effects. Our results pave the way to the exploitation of such novel techniques in various VR applications such as sport training, exercise games, or industrial training scenarios in single or collaborative mode.", "keywords": ["avatars", "computer animation", "haptic interfaces", "image sensors", "pseudo haptic avatars", "visual animation", "self avatar", "weight lifting perception", "haptic perceptions", "virtual environment", "Kinect", "virtual avatar", "virtual dumbbells", "virtual weight", "spatial mapping", "VR applications", "Avatars", "Animation", "Visualization", "Wrist", "Virtual environments", "Joints", "Visual effects", "Self-animated avatar", " avatar-based physical interaction", " pseudo-haptic feedback", " perception of motion dynamics"], "referenced_by": ["IKEY:7819390", "IKEY:7833030", "IKEY:7989967", "IKEY:8324666", "IKEY:8448285", "IKEY:8495673", "IKEY:8642446", "IKEY:8768499", "IKEY:8797716", "IKEY:8797785", "IKEY:8798300", "IKEY:9223704", "10.1002/9781119341031.ch5", "10.3389/fict.2016.00006", "10.1541/ieejeiss.138.1094", "10.1016/j.cag.2018.09.001", "10.1002/ecj.12152"], "referencing": ["IKEY:1492749", "IKEY:6479188", "IKEY:6180884", "IKEY:1492749", "IKEY:6479188", "IKEY:6180884", "IKEY:1492749", "IKEY:6479188", "IKEY:6180884", "10.1145/2470654.2470665", "10.1145/223904.223935", "10.1145/1959826.1959858", "10.1145/2470654.2470665", "10.1145/223904.223935", "10.1145/1959826.1959858", "10.1145/2470654.2470665", "10.1145/223904.223935", "10.1145/1959826.1959858", "10.1162/pres.19.3.230", "10.1016/j.jbiomech.2005.10.002", "10.1038/415429a", "10.3758/BF03206188", "10.1037/0096-3445.116.4.356", "10.1162/pres.18.1.39", "10.1371/journal.pone.0068594", "10.1016/j.ijhcs.2008.09.015", "10.1126/science.143.3606.594", "10.3389/neuro.09.006.2008", "10.3389/neuro.01.029.2009", "10.1016/j.jbiomech.2004.05.042", "10.1162/pres.19.3.230", "10.1016/j.jbiomech.2005.10.002", "10.1038/415429a", "10.3758/BF03206188", "10.1037/0096-3445.116.4.356", "10.1162/pres.18.1.39", "10.1371/journal.pone.0068594", "10.1016/j.ijhcs.2008.09.015", "10.1126/science.143.3606.594", "10.3389/neuro.09.006.2008", "10.3389/neuro.01.029.2009", "10.1016/j.jbiomech.2004.05.042", "10.1162/pres.19.3.230", "10.1016/j.jbiomech.2005.10.002", "10.1038/415429a", "10.3758/BF03206188", "10.1037/0096-3445.116.4.356", "10.1162/pres.18.1.39", "10.1371/journal.pone.0068594", "10.1016/j.ijhcs.2008.09.015", "10.1126/science.143.3606.594", "10.3389/neuro.09.006.2008", "10.3389/neuro.01.029.2009", "10.1016/j.jbiomech.2004.05.042"]}}