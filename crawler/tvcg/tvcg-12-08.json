{"10.1109/TVCG.2012.86": {"doi": "10.1109/TVCG.2012.86", "author": ["N. Chentanez", "M. Mueller-Fischer"], "title": "A Multigrid Fluid Pressure Solver Handling Separating Solid Boundary Conditions", "year": "2012", "abstract": "We present a multigrid method for solving the linear complementarity problem (LCP) resulting from discretizing the Poisson equation subject to separating solid boundary conditions in an Eulerian liquid simulation's pressure projection step. The method requires only a few small changes to a multigrid solver for linear systems. Our generalized solver is fast enough to handle 3D liquid simulations with separating boundary conditions in practical domain sizes. Previous methods could only handle relatively small 2D domains in reasonable time, because they used expensive quadratic programming (QP) solvers. We demonstrate our technique in several practical scenarios, including nonaxis-aligned containers and moving solids in which the omission of separating boundary conditions results in disturbing artifacts of liquid sticking to solids. Our measurements show, that the convergence rate of our LCP solver is close to that of a standard multigrid solver.", "keywords": ["computer graphics", "differential equations", "Poisson equation", "quadratic programming", "multigrid fluid pressure solver", "solid boundary conditions", "linear complementarity problem", "LCP", "Poisson equation", "Eulerian liquid simulation", "pressure projection step", "3D liquid simulations", "quadratic programming", "QP solvers", "Solids", "Boundary conditions", "Mathematical model", "Multigrid methods", "Equations", "Linear systems", "Solid modeling", "Multigrid", "boundary condition", "linear complementarity", "fluid simulation", "physics-based animation."], "referenced_by": ["10.1109/TVCG.2018.2873375", "10.1145/3092818", "10.1111/cgf.12489", "10.1111/cgf.12825", "10.1111/cgf.13048", "10.1111/cgf.13084", "10.1155/2014/580154", "10.1111/cgf.13909"], "referencing": ["10.1145/1276377.1276502", "10.1145/383259.383261", "10.1145/965400.965561", "10.1145/1028523.1028549", "10.1145/1882261.1866195", "10.1145/1141911.1142001", "10.1145/1731047.1731054", "10.1145/1281740.1281819", "10.1145/1833349.1778851", "10.1145/2010324.1964977", "10.1145/1186822.1073298", "10.1145/1360612.1360645", "10.1145/1276377.1276502", "10.1145/383259.383261", "10.1145/965400.965561", "10.1145/1028523.1028549", "10.1145/1882261.1866195", "10.1145/1141911.1142001", "10.1145/1731047.1731054", "10.1145/1281740.1281819", "10.1145/1833349.1778851", "10.1145/2010324.1964977", "10.1145/1186822.1073298", "10.1145/1360612.1360645", "10.1145/1276377.1276502", "10.1145/383259.383261", "10.1145/965400.965561", "10.1145/1028523.1028549", "10.1145/1882261.1866195", "10.1145/1141911.1142001", "10.1145/1731047.1731054", "10.1145/1281740.1281819", "10.1145/1833349.1778851", "10.1145/2010324.1964977", "10.1145/1186822.1073298", "10.1145/1360612.1360645", "10.1063/1.1761178", "10.1016/0021-9991(69)90019-9", "10.1006/gmip.1996.0039", "10.1007/s10589-005-4557-7", "10.1137/1.9781611971057", "10.1063/1.1761178", "10.1016/0021-9991(69)90019-9", "10.1006/gmip.1996.0039", "10.1007/s10589-005-4557-7", "10.1137/1.9781611971057", "10.1063/1.1761178", "10.1016/0021-9991(69)90019-9", "10.1006/gmip.1996.0039", "10.1007/s10589-005-4557-7", "10.1137/1.9781611971057"]}, "10.1109/TVCG.2012.87": {"doi": "10.1109/TVCG.2012.87", "author": ["R. Ando", "N. Thurey", "R. Tsuruno"], "title": "Preserving Fluid Sheets with Adaptively Sampled Anisotropic Particles", "year": "2012", "abstract": "This paper presents a particle-based model for preserving fluid sheets of animated liquids with an adaptively sampled Fluid-Implicit-Particle (FLIP) method. In our method, we preserve fluid sheets by filling the breaking sheets with particle splitting in the thin regions, and by collapsing them in the deep water. To identify the critically thin parts, we compute the anisotropy of the particle neighborhoods, and use this information as a resampling criterion to reconstruct thin liquid surfaces. Unlike previous approaches, our method does not suffer from diffusive surfaces or complex remeshing operations, and robustly handles topology changes with the use of a meshless representation. We extend the underlying FLIP model with an anisotropic position correction to improve the particle spacing, and adaptive sampling to efficiently perform simulations of larger volumes. Due to the Lagrangian nature of our method, it can be easily implemented and efficiently parallelized. The results show that our method can produce visually complex liquid animations with thin structures and vivid motions.", "keywords": ["computational fluid dynamics", "fluid sheets", "sampled anisotropic particles", "particle-based model", "animated liquids", "sampled fluid implicit particle method", "particle splitting", "deep water", "anisotropy", "particle neighborhoods", "resampling criterion", "complex remeshing operation", "topology change", "meshless representation", "FLIP model", "anisotropic position correction", "particle spacing", "adaptive sampling", "Lagrangian nature", "complex liquid animations", "thin structures", "vivid motions", "Computational modeling", "Surface reconstruction", "Adaptation models", "Interpolation", "Kernel", "Mathematical model", "Boundary conditions", "Physically based modeling", "liquid simulation", "fluid-implicit-particle method", "thin fluid sheets", "adaptive sampling."], "referenced_by": ["10.1109/TVCG.2015.2449303", "10.1109/TVCG.2017.2706289", "10.1109/TMM.2018.2825888", "10.1109/VR.2019.8797906", "10.1109/TVCG.2018.2886322", "10.1145/2560795", "10.1145/2682630", "10.1145/2751541", "10.1145/3072959.3073633", "10.1145/3130800.3130878", "10.1145/3130800.3130879", "10.1002/cav.1568", "10.1002/cav.1646", "10.1002/cav.1663", "10.1002/cav.1741", "10.1007/s00371-015-1080-4", "10.1007/s12650-016-0400-8", "10.1016/j.gmod.2017.09.001", "10.1016/j.jfluidstructs.2016.01.008", "10.1111/cgf.12324", "10.1111/cgf.12488", "10.1111/cgf.12489", "10.1111/cgf.12825", "10.1111/cgf.12941", "10.1137/140976911", "10.1142/S0219876218500615", "10.12677/OJNS.2016.42021", "10.1371/journal.pone.0175695", "10.1111/cgf.13522", "10.3390/sym10100502", "10.1016/j.cag.2018.10.007", "10.1007/s12650-018-0535-x", "10.1007/978-981-287-487-0_5", "10.1016/j.cag.2019.08.011", "10.15701/kcgs.2019.25.1.13"], "referencing": ["10.1109/TVCG.2008.37", "10.1109/PBG.2005.194073", "10.1145/1360612.1360646", "10.1145/1599470.1599501", "10.1145/1778765.1778784", "10.1145/1778765.1778787", "10.1145/37402.37422", "10.1145/1599470.1599502", "10.1145/1073204.1073298", "10.1145/1122501.1122503", "10.1145/1882262.1866198", "10.1145/383259.383261", "10.1145/1073204.1073299", "10.1145/1281740.1281819", "10.1145/1576246.1531382", "10.1145/1531326.1531346", "10.1145/1073204.1073296", "10.1145/1599470.1599488", "10.1145/357306.357310", "10.1145/1276377.1276437", "10.1145/2019406.2019411", "10.1145/1599470.1599500", "10.1145/1028523.1028549", "10.1145/2019406.2019408", "10.1145/1360612.1360646", "10.1145/1599470.1599501", "10.1145/1778765.1778784", "10.1145/1778765.1778787", "10.1145/37402.37422", "10.1145/1599470.1599502", "10.1145/1073204.1073298", "10.1145/1122501.1122503", "10.1145/1882262.1866198", "10.1145/383259.383261", "10.1145/1073204.1073299", "10.1145/1281740.1281819", "10.1145/1576246.1531382", "10.1145/1531326.1531346", "10.1145/1073204.1073296", "10.1145/1599470.1599488", "10.1145/357306.357310", "10.1145/1276377.1276437", "10.1145/2019406.2019411", "10.1145/1599470.1599500", "10.1145/1028523.1028549", "10.1145/2019406.2019408", "10.1145/1360612.1360646", "10.1145/1599470.1599501", "10.1145/1778765.1778784", "10.1145/1778765.1778787", "10.1145/37402.37422", "10.1145/1599470.1599502", "10.1145/1073204.1073298", "10.1145/1122501.1122503", "10.1145/1882262.1866198", "10.1145/383259.383261", "10.1145/1073204.1073299", "10.1145/1281740.1281819", "10.1145/1576246.1531382", "10.1145/1531326.1531346", "10.1145/1073204.1073296", "10.1145/1599470.1599488", "10.1145/357306.357310", "10.1145/1276377.1276437", "10.1145/2019406.2019411", "10.1145/1599470.1599500", "10.1145/1028523.1028549", "10.1145/2019406.2019408", "10.1002/cav.300", "10.1016/0021-9991(88)90002-2", "10.1006/jcph.2002.7166", "10.1016/j.jcp.2009.04.045", "10.1111/j.1467-8659.2007.01068.x", "10.1016/0021-9991(81)90145-5", "10.1007/BF00133570", "10.1137/S1064827595293600", "10.1006/jcph.2001.6726", "10.1137/080737617", "10.1111/1467-8659.00687", "10.1007/s00371-008-0234-z", "10.1016/0021-9991(86)90211-1", "10.1006/jcph.2001.6977", "10.1002/cav.300", "10.1016/0021-9991(88)90002-2", "10.1006/jcph.2002.7166", "10.1016/j.jcp.2009.04.045", "10.1111/j.1467-8659.2007.01068.x", "10.1016/0021-9991(81)90145-5", "10.1007/BF00133570", "10.1137/S1064827595293600", "10.1006/jcph.2001.6726", "10.1137/080737617", "10.1111/1467-8659.00687", "10.1007/s00371-008-0234-z", "10.1016/0021-9991(86)90211-1", "10.1006/jcph.2001.6977", "10.1002/cav.300", "10.1016/0021-9991(88)90002-2", "10.1006/jcph.2002.7166", "10.1016/j.jcp.2009.04.045", "10.1111/j.1467-8659.2007.01068.x", "10.1016/0021-9991(81)90145-5", "10.1007/BF00133570", "10.1137/S1064827595293600", "10.1006/jcph.2001.6726", "10.1137/080737617", "10.1111/1467-8659.00687", "10.1007/s00371-008-0234-z", "10.1016/0021-9991(86)90211-1", "10.1006/jcph.2001.6977"]}, "10.1109/TVCG.2012.88": {"doi": "10.1109/TVCG.2012.88", "author": ["H. Huang", "K. Yin", "L. Zhao", "Y. Qi", "Y. Yu", "X. Tong"], "title": "Detail-Preserving Controllable Deformation from Sparse Examples", "year": "2012", "abstract": "Recent advances in laser scanning technology have made it possible to faithfully scan a real object with tiny geometric details, such as pores and wrinkles. However, a faithful digital model should not only capture static details of the real counterpart but also be able to reproduce the deformed versions of such details. In this paper, we develop a data-driven model that has two components; the first accommodates smooth large-scale deformations and the second captures high-resolution details. Large-scale deformations are based on a nonlinear mapping between sparse control points and bone transformations. A global mapping, however, would fail to synthesize realistic geometries from sparse examples, for highly deformable models with a large range of motion. The key is to train a collection of mappings defined over regions locally in both the geometry and the pose space. Deformable fine-scale details are generated from a second nonlinear mapping between the control points and per-vertex displacements. We apply our modeling scheme to scanned human hand models, scanned face models, face models reconstructed from multiview video sequences, and manually constructed dinosaur models. Experiments show that our deformation models, learned from extremely sparse training data, are effective and robust in synthesizing highly deformable models with rich fine features, for keyframe animation as well as performance-driven animation. We also compare our results with those obtained by alternative techniques.", "keywords": ["computational geometry", "computer animation", "feature extraction", "image reconstruction", "image sequences", "solid modelling", "video signal processing", "detail-preserving controllable deformation sparse examples", "laser scanning technology", "tiny geometric details", "object pores", "object wrinkles", "faithful digital model", "static detail capture", "data-driven model", "smooth large-scale deformation", "high-resolution detail capture", "nonlinear mapping", "sparse control points", "bone transformation", "global mapping", "geometry", "pose space", "per-vertex displacement", "scanned human hand model", "scanned face model", "face model reconstruction", "multiview video sequence", "manually constructed dinosaur model", "keyframe animation", "performance-driven animation", "Deformable models", "Face", "Training", "Bones", "Data models", "Geometry", "Animation", "Detail-preserving deformation", "controllable skinning", "learning from sparse examples", "CCA regression.", "Adult", "Animals", "Artificial Intelligence", "Computer Graphics", "Computer Simulation", "Dinosaurs", "Face", "Hand", "Humans", "Image Processing, Computer-Assisted", "Male", "Models, Biological", "Regression Analysis", "Video Recording"], "referenced_by": ["10.1145/2890493", "10.1145/2897824.2925916", "10.1002/cav.1557", "10.1007/s00371-014-0960-3", "10.1007/s00371-018-1546-2", "10.1007/978-3-642-34710-8_4"], "referencing": ["10.1145/2019406.2019416", "10.1145/344779.344862", "10.1145/364338.364382", "10.1145/882262.882308", "10.1145/1276377.1276468", "10.1145/545261.545286", "10.1145/1028523.1028571", "10.1145/1401032.1401121", "10.1145/1073204.1073218", "10.1145/1141911.1142011", "10.1145/1360612.1360690", "10.1145/2010324.1964969", "10.1145/2010324.1964971", "10.1145/1409060.1409074", "10.1145/1360612.1360697", "10.1145/1778765.1778778", "10.1145/1360612.1360682", "10.1145/1015706.1015759", "10.1145/1179352.1141988", "10.1145/1141911.1141970", "10.1145/133994.134008", "10.1145/1015706.1015736", "10.1145/1186822.1073206", "10.1145/1230100.1230107", "10.1145/2019406.2019416", "10.1145/344779.344862", "10.1145/364338.364382", "10.1145/882262.882308", "10.1145/1276377.1276468", "10.1145/545261.545286", "10.1145/1028523.1028571", "10.1145/1401032.1401121", "10.1145/1073204.1073218", "10.1145/1141911.1142011", "10.1145/1360612.1360690", "10.1145/2010324.1964969", "10.1145/2010324.1964971", "10.1145/1409060.1409074", "10.1145/1360612.1360697", "10.1145/1778765.1778778", "10.1145/1360612.1360682", "10.1145/1015706.1015759", "10.1145/1179352.1141988", "10.1145/1141911.1141970", "10.1145/133994.134008", "10.1145/1015706.1015736", "10.1145/1186822.1073206", "10.1145/1230100.1230107", "10.1145/2019406.2019416", "10.1145/344779.344862", "10.1145/364338.364382", "10.1145/882262.882308", "10.1145/1276377.1276468", "10.1145/545261.545286", "10.1145/1028523.1028571", "10.1145/1401032.1401121", "10.1145/1073204.1073218", "10.1145/1141911.1142011", "10.1145/1360612.1360690", "10.1145/2010324.1964969", "10.1145/2010324.1964971", "10.1145/1409060.1409074", "10.1145/1360612.1360697", "10.1145/1778765.1778778", "10.1145/1360612.1360682", "10.1145/1015706.1015759", "10.1145/1179352.1141988", "10.1145/1141911.1141970", "10.1145/133994.134008", "10.1145/1015706.1015736", "10.1145/1186822.1073206", "10.1145/1230100.1230107", "10.1111/j.1467-8659.2007.01048.x", "10.1080/01621459.1988.10478639", "10.1080/2151237X.2005.10129202", "10.1111/j.1467-8659.2007.01048.x", "10.1080/01621459.1988.10478639", "10.1080/2151237X.2005.10129202", "10.1111/j.1467-8659.2007.01048.x", "10.1080/01621459.1988.10478639", "10.1080/2151237X.2005.10129202"]}, "10.1109/TVCG.2012.78": {"doi": "10.1109/TVCG.2012.78", "author": ["T. Kim", "D. L. James"], "title": "Physics-Based Character Skinning Using Multidomain Subspace Deformations", "year": "2012", "abstract": "In this extended version of our Symposium on Computer Animation paper, we describe a domain-decomposition method to simulate articulated deformable characters entirely within a subspace framework. We have added a parallelization and eigendecomposition performance analysis, and several additional examples to the original symposium version. The method supports quasistatic and dynamic deformations, nonlinear kinematics and materials, and can achieve interactive time-stepping rates. To avoid artificial rigidity, or \"locking,\u201d associated with coupling low-rank domain models together with hard constraints, we employ penalty-based coupling forces. The multidomain subspace integrator can simulate deformations efficiently, and exploits efficient subspace-only evaluation of constraint forces between rotated domains using a novel Fast Sandwich Transform (FST). Examples are presented for articulated characters with quasistatic and dynamic deformations, and interactive performance with hundreds of fully coupled modes. Using our method, we have observed speedups of between 3 and 4 orders of magnitude over full-rank, unreduced simulations.", "keywords": ["computer animation", "deformation", "eigenvalues and eigenfunctions", "interactive systems", "transforms", "physics-based character skinning", "multidomain subspace deformations", "domain-decomposition method", "articulated deformable character simulation", "eigendecomposition performance analysis", "computer animation", "quasistatic deformation", "dynamic deformation", "nonlinear kinematics", "interactive time-stepping rates", "low-rank domain model coupling", "hard constraints", "penalty-based coupling forces", "multidomain subspace integrator", "subspace-only evaluation", "constraint forces", "fast sandwich transform", "FST", "rotated domains", "full-rank unreduced simulations", "artificial rigidity avoidance", "parallelization performance analysis", "Deformable models", "Couplings", "Animation", "Force", "Computational modeling", "Springs", "Transforms", "Domain decomposition", "deformation", "subspace dynamics", "reduced-order modeling", "character animation", "parallelization.", "Algorithms", "Computer Graphics", "Computer Simulation", "Humans", "Image Processing, Computer-Assisted"], "referenced_by": ["10.1109/TVCG.2016.2620467", "10.1109/TVCG.2015.2453951", "10.1145/3203187", "10.1145/3306346.3322951", "10.1145/2897824.2925916", "10.1002/cav.1594", "10.1007/s00371-016-1221-4", "10.1007/s00371-017-1376-7", "10.1016/B978-0-12-804009-6.00023-7", "10.1016/j.cagd.2016.02.014", "10.1080/02564602.2016.1141075", "10.1007/s00466-018-1611-8", "10.1007/s11704-018-8081-1", "10.1111/cgf.14127"], "referencing": ["10.1109/TVCG.2005.13", "10.1109/38.20317", "10.1109/34.85659", "10.1145/2019406.2019415", "10.1145/344779.344862", "10.1145/1409625.1409627", "10.1145/364338.364382", "10.1145/545261.545286", "10.1145/1401032.1401121", "10.1145/882262.882308", "10.1145/1073204.1073206", "10.1145/1141911.1142011", "10.1145/545261.545283", "10.1145/1183287.1183294", "10.1145/566654.566621", "10.1145/1073204.1073300", "10.1145/1618452.1618465", "10.1145/37402.37427", "10.1145/142920.134085", "10.1145/1409060.1409117", "10.1145/1289603.1289608", "10.1145/566654.566622", "10.1145/311535.311542", "10.1145/1276377.1276480", "10.1145/1944846.1944855", "10.1145/1531326.1531345", "10.1145/1073368.1073394", "10.1145/1731047.1731054", "10.1145/1028523.1028541", "10.1145/1015706.1015735", "10.1145/1360612.1360628", "10.1145/2019406.2019415", "10.1145/344779.344862", "10.1145/1409625.1409627", "10.1145/364338.364382", "10.1145/545261.545286", "10.1145/1401032.1401121", "10.1145/882262.882308", "10.1145/1073204.1073206", "10.1145/1141911.1142011", "10.1145/545261.545283", "10.1145/1183287.1183294", "10.1145/566654.566621", "10.1145/1073204.1073300", "10.1145/1618452.1618465", "10.1145/37402.37427", "10.1145/142920.134085", "10.1145/1409060.1409117", "10.1145/1289603.1289608", "10.1145/566654.566622", "10.1145/311535.311542", "10.1145/1276377.1276480", "10.1145/1944846.1944855", "10.1145/1531326.1531345", "10.1145/1073368.1073394", "10.1145/1731047.1731054", "10.1145/1028523.1028541", "10.1145/1015706.1015735", "10.1145/1360612.1360628", "10.1145/2019406.2019415", "10.1145/344779.344862", "10.1145/1409625.1409627", "10.1145/364338.364382", "10.1145/545261.545286", "10.1145/1401032.1401121", "10.1145/882262.882308", "10.1145/1073204.1073206", "10.1145/1141911.1142011", "10.1145/545261.545283", "10.1145/1183287.1183294", "10.1145/566654.566621", "10.1145/1073204.1073300", "10.1145/1618452.1618465", "10.1145/37402.37427", "10.1145/142920.134085", "10.1145/1409060.1409117", "10.1145/1289603.1289608", "10.1145/566654.566622", "10.1145/311535.311542", "10.1145/1276377.1276480", "10.1145/1944846.1944855", "10.1145/1531326.1531345", "10.1145/1073368.1073394", "10.1145/1731047.1731054", "10.1145/1028523.1028541", "10.1145/1015706.1015735", "10.1145/1360612.1360628", "10.1002/nme.167", "10.1111/1467-8659.00152", "10.1017/CBO9780511610523", "10.1007/BF01908877", "10.1111/j.1467-8659.2007.01046.x", "10.1115/1.1590354", "10.1002/nme.76", "10.1137/S1064827502412887", "10.1016/j.cag.2006.08.014", "10.1142/S0129183108012303", "10.1007/978-3-642-86940-2", "10.1002/nme.167", "10.1111/1467-8659.00152", "10.1017/CBO9780511610523", "10.1007/BF01908877", "10.1111/j.1467-8659.2007.01046.x", "10.1115/1.1590354", "10.1002/nme.76", "10.1137/S1064827502412887", "10.1016/j.cag.2006.08.014", "10.1142/S0129183108012303", "10.1007/978-3-642-86940-2", "10.1002/nme.167", "10.1111/1467-8659.00152", "10.1017/CBO9780511610523", "10.1007/BF01908877", "10.1111/j.1467-8659.2007.01046.x", "10.1115/1.1590354", "10.1002/nme.76", "10.1137/S1064827502412887", "10.1016/j.cag.2006.08.014", "10.1142/S0129183108012303", "10.1007/978-3-642-86940-2"]}, "10.1109/TVCG.2011.151": {"doi": "10.1109/TVCG.2011.151", "author": ["J. Spillmann", "M. Harders"], "title": "Robust Interactive Collision Handling between Tools and Thin Volumetric Objects", "year": "2012", "abstract": "Treating the interactions of soft tissue with rigid user-guided tools is a difficult problem. This is particularly true if the soft tissue has a slender shape, i.e., resembling a thin shell, and if the underlying numerical time-integration scheme employs large time steps. In this case, large mutual displacements of both the tool and the soft tissue occur frequently, resulting in deep interpenetrations or breakthroughs. As a consequence, the computation of spatially and temporally coherent contact spaces turns out to be very challenging. In this paper, an approach is proposed that is tailored to these kinds of interactions. To solve this problem, a novel spatially reduced representation of the soft tissue geometry is employed where the dominant dimensions of the object are approximated by a 2D triangle surface, while the third dimension is given in terms of nodal radii. To construct a feasible, nonpenetrating configuration, a novel manifold projection scheme is presented where the colliding triangles are rasterized into a distance field in order to robustly estimate the contact spaces, even for large intersections. The method produces physically plausible results, albeit it is purely geometric, and the material parameters are neglected at the collision response stage. Various examples, including an interactive prototype arthroscopy simulator, underline the wide applicability of the approach.", "keywords": ["biological tissues", "computational geometry", "interactive systems", "medical computing", "surgery", "robust interactive collision handling", "thin volumetric objects", "rigid user guided tools", "numerical time-integration scheme", "mutual displacements", "temporally coherent contact spaces", "spatially coherent contact spaces", "spatially reduced representation", "soft tissue geometry", "2D triangle surface", "manifold projection scheme", "colliding triangles", "material parameters", "collision response stage", "interactive prototype arthroscopy simulator", "Geometry", "Computational modeling", "Deformable models", "Shape", "Biological tissues", "Manifolds", "Robustness", "Physically based simulation", "collision handling", "soft tissue", "distance fields", "Gauss-Seidel.", "Algorithms", "Arthroscopy", "Arthroscopy", "Computer Graphics", "Computer Simulation", "Humans", "Image Processing, Computer-Assisted", "Menisci, Tibial", "Surgery, Computer-Assisted"], "referenced_by": ["10.1145/2856317", "10.1111/cgf.12528", "10.3390/sym10010017", "10.1002/nla.2323"], "referencing": ["10.1109/TVCG.2006.13", "10.1109/HAPTIC.2003.1191285", "10.1109/TOH.2008.1", "10.1109/2945.764872", "10.1109/IROS.1995.525876", "10.1109/TVCG.2006.56", "10.1109/TUFFC.2004.1320828", "10.1145/1531326.1531358", "10.1145/258734.258878", "10.1145/1180495.1180555", "10.1145/1073204.1073295", "10.1145/882262.882357", "10.1145/1531326.1531393", "10.1145/566654.566623", "10.1145/1360612.1360622", "10.1145/311535.311600", "10.1145/1778765.1778819", "10.1145/1073204.1073216", "10.1145/1409060.1409117", "10.1145/1276377.1276438", "10.1145/1730804.1730806", "10.1145/545261.545269", "10.1007/978-3-642-11615-5_17", "10.1111/j.1467-8659.2007.00945.x", "10.1007/978-3-540-40899-4_66", "10.1111/j.1467-8659.2007.01046.x", "10.1007/978-3-540-75759-7_103", "10.1007/978-3-540-70521-5_17", "10.1111/j.1467-8659.2009.01396.x", "10.1007/978-3-642-11615-5_15", "10.1111/j.1467-8659.2008.01147.x", "10.1007/978-3-642-18993-7_57", "10.1007/11790273_5", "10.1016/j.jvcir.2007.01.005", "10.1007/s00276-005-0031-6"]}, "10.1109/TVCG.2011.263": {"doi": "10.1109/TVCG.2011.263", "author": ["K. Biggers", "J. Keyser"], "title": "Inference-Based Surface Reconstruction of Cluttered Environments", "year": "2012", "abstract": "We present an inference-based surface reconstruction algorithm that is capable of identifying objects of interest among a cluttered scene, and reconstructing solid model representations even in the presence of occluded surfaces. Our proposed approach incorporates a predictive modeling framework that uses a set of user-provided models for prior knowledge, and applies this knowledge to the iterative identification and construction process. Our approach uses a local to global construction process guided by rules for fitting high-quality surface patches obtained from these prior models. We demonstrate the application of this algorithm on several example data sets containing heavy clutter and occlusion.", "keywords": ["hidden feature removal", "solid modelling", "surface reconstruction", "surface reconstruction", "cluttered environments", "inference based surface reconstruction", "solid model representations", "occluded surfaces", "predictive modeling", "user provided models", "iterative identification", "construction process", "Surface reconstruction", "Object recognition", "Solid modeling", "Shape", "Surface treatment", "Solids", "Computational modeling", "Three-dimensional/stereo scene analysis", "object recognition", "segmentation", "surface fitting."], "referenced_by": [], "referencing": ["10.1109/CCV.1988.589995", "10.1109/34.765655", "10.1109/TPAMI.2006.213", "10.1109/TVCG.2003.1175093", "10.1109/CVPR.2006.276", "10.1109/34.121791", "10.1109/IM.2001.924423", "10.1109/SMI.2004.1314502", "10.1145/280814.280947", "10.1145/383259.383266", "10.1145/1360612.1360684", "10.1145/1118890.1118893", "10.1145/1064830.1064859", "10.1145/1015706.1015775", "10.1145/1122501.1122507", "10.1145/1360612.1360642", "10.1145/133994.134008", "10.1145/1015706.1015713", "10.1145/37401.37422", "10.1145/566570.566586", "10.1007/978-3-540-24672-5_18", "10.1111/j.1467-8659.2009.01389.x", "10.1006/cviu.2000.0889", "10.1007/s11263-009-0296-z", "10.1111/j.1467-8659.2007.01016.x", "10.1111/j.1467-8659.2009.01410.x", "10.1115/1.1345522", "10.1007/978-3-7091-6103-6_12"]}, "10.1109/TVCG.2011.267": {"doi": "10.1109/TVCG.2011.267", "author": ["T. Hou", "H. Qin"], "title": "Robust Dense Registration of Partial Nonrigid Shapes", "year": "2012", "abstract": "This paper presents a complete and robust solution for dense registration of partial nonrigid shapes. Its novel contributions are founded upon the newly proposed heat kernel coordinates (HKCs) that can accurately position points on the shape, and the priority-vicinity search that ensures geometric compatibility during the registration. HKCs index points by computing heat kernels from multiple sources, and their magnitudes serve as priorities of queuing points in registration. We start with shape features as the sources of heat kernels via feature detection and matching. Following the priority order of HKCs, the dense registration is progressively propagated from feature sources to all points. Our method has a superior indexing ability that can produce dense correspondences with fewer flips. The diffusion nature of HKCs, which can be interpreted as a random walk on a manifold, makes our method robust to noise and small holes avoiding surface surgery and repair. Our method searches correspondence only in a small vicinity of registered points, which significantly improves the time performance. Through comprehensive experiments, our new method has demonstrated its technical soundness and robustness by generating highly compatible dense correspondences.", "keywords": ["feature extraction", "geometry", "image matching", "image registration", "object detection", "random processes", "search problems", "shape recognition", "solid modelling", "robust dense registration", "partial nonrigid shape", "heat kernel coordinates", "priority-vicinity search", "geometric compatibility", "HKC index point", "magnitude", "queuing point", "shape feature", "feature detection", "feature matching", "feature source propagation", "random walk", "Shape", "Heating", "Kernel", "Manifolds", "Eigenvalues and eigenfunctions", "Feature extraction", "Robustness", "Dense registration", "partial nonrigid shape", "heat kernel coordinates."], "referenced_by": ["10.1109/ICVRV.2017.00060", "10.1007/s11390-013-1382-9", "10.1016/j.dam.2016.05.005", "10.1016/j.ins.2016.07.030", "10.1201/b17585-16"], "referencing": ["10.1109/ICCV.2007.4409084", "10.1109/SMI.2010.27", "10.1145/1531326.1531378", "10.1145/1073204.1073229", "10.1145/1276377.1276466", "10.1145/1073204.1073244", "10.1145/1122501.1122507", "10.1145/1778765.1778858", "10.1145/1015706.1015811", "10.1145/1015706.1015736", "10.1145/1015706.1015759", "10.1145/1360612.1360696", "10.1111/j.1467-8659.2008.01285.x", "10.1111/j.1467-8659.2010.01763.x", "10.1111/j.1467-8659.2010.01764.x", "10.1007/s11263-009-0250-0", "10.1111/j.1467-8659.2010.01762.x", "10.1016/j.cad.2005.10.011", "10.1007/978-3-642-15558-1_28", "10.1111/j.1467-8659.2009.01515.x", "10.1007/s11263-009-0301-6", "10.1016/j.cag.2011.03.030", "10.1111/j.1467-8659.2008.01286.x", "10.1142/S0218654307000968", "10.1016/j.cad.2009.02.007", "10.1073/pnas.0508601103", "10.1090/conm/398/07486", "10.1111/j.1467-8659.2007.01061.x", "10.1111/j.1467-8659.2008.01274.x", "10.1007/s11263-009-0278-1", "10.5802/aif.2480"]}, "10.1109/TVCG.2011.141": {"doi": "10.1109/TVCG.2011.141", "author": ["Y. Zhang", "H. Wang", "S. Wang", "Y. Tong", "K. Zhou"], "title": "A Deformable Surface Model for Real-Time Water Drop Animation", "year": "2012", "abstract": "A water drop behaves differently from a large water body because of its strong viscosity and surface tension under the small scale. Surface tension causes the motion of a water drop to be largely determined by its boundary surface. Meanwhile, viscosity makes the interior of a water drop less relevant to its motion, as the smooth velocity field can be well approximated by an interpolation of the velocity on the boundary. Consequently, we propose a fast deformable surface model to realistically animate water drops and their flowing behaviors on solid surfaces. Our system efficiently simulates water drop motions in a Lagrangian fashion, by reducing 3D fluid dynamics over the whole liquid volume to a deformable surface model. In each time step, the model uses an implicit mean curvature flow operator to produce surface tension effects, a contact angle operator to change droplet shapes on solid surfaces, and a set of mesh connectivity updates to handle topological changes and improve mesh quality over time. Our numerical experiments demonstrate a variety of physically plausible water drop phenomena at a real-time rate, including capillary waves when water drops collide, pinch-off of water jets, and droplets flowing over solid materials. The whole system performs orders-of-magnitude faster than existing simulation approaches that generate comparable water drop effects.", "keywords": ["approximation theory", "capillary waves", "computational fluid dynamics", "computer animation", "contact angle", "deformation", "drops", "flow simulation", "interpolation", "jets", "mesh generation", "surface tension", "two-phase flow", "viscosity", "water", "deformable surface model", "real-time water drop animation", "viscosity", "water drop motion", "boundary surface", "interpolation", "approximation theory", "Lagrangian theory", "3D fluid dynamics", "mean curvature flow operator", "surface tension effect", "contact angle operator", "solid surface", "mesh connectivity", "mesh quality over time", "water drop phenomena", "capillary wave", "pinch off", "water jet", "droplets", "solid material", "contact angle", "flow simulation", "Solids", "Surface tension", "Viscosity", "Force", "Deformable models", "Surface waves", "Numerical models", "Deformable surface model", "surface tension", "mean curvature flow", "water drop simulation."], "referenced_by": ["10.1109/CADGRAPHICS.2015.16", "10.1109/ChiCC.2015.7259699", "10.1109/ISEIM.2014.6870773", "10.1109/TDEI.2015.005266", "10.1109/TVCG.2016.2605083", "10.1109/TVCG.2017.2720672", "10.1109/TVCG.2017.2789203", "10.1145/2682630", "10.1145/3130800.3130835", "10.1145/2767003", "10.1145/2897824.2925899", "10.1145/2451236.2451243", "10.1145/2601097.2601201", "10.1145/3386569.3392405", "10.1145/3386569.3392487", "10.1145/3414685.3417799", "10.1002/cav.1497", "10.1002/cav.1640", "10.1007/s00371-016-1258-4", "10.1007/s11042-013-1683-6", "10.1016/j.cag.2013.08.004", "10.1016/j.cag.2016.10.001", "10.1111/cgf.12945", "10.3390/sym9040056"], "referencing": ["10.1109/TVCG.2008.37", "10.1145/1073204.1073284", "10.1145/1531326.1531382", "10.1145/1778765.1778787", "10.1145/1833349.1778785", "10.1145/1599470.1599501", "10.1145/97879.97884", "10.1145/311535.311548", "10.1145/383259.383261", "10.1145/566570.566645", "10.1145/1015706.1015745", "10.1145/1122501.1122503", "10.1145/1281500.1281681", "10.1145/1141911.1141961", "10.1145/1141911.1141959", "10.1145/1186223.1186311", "10.1145/1073204.1073283", "10.1145/311535.311576", "10.1145/166117.166119", "10.1145/882262.882357", "10.1006/gmip.1996.0039", "10.1115/FEDSM2003-45144", "10.1086/112164", "10.1093/mnras/181.3.375", "10.1137/080732122", "10.1137/080737617"]}, "10.1109/TVCG.2011.156": {"doi": "10.1109/TVCG.2011.156", "author": ["J. Cao", "X. Li", "Z. Chen", "H. Qin"], "title": "Spherical DCB-Spline Surfaces with Hierarchical and Adaptive Knot Insertion", "year": "2012", "abstract": "This paper develops a novel surface fitting scheme for automatically reconstructing a genus-0 object into a continuous parametric spline surface. A key contribution for making such a fitting method both practical and accurate is our spherical generalization of the Delaunay configuration B-spline (DCB-spline), a new non-tensor-product spline. In this framework, we efficiently compute Delaunay configurations on sphere by the union of two planar Delaunay configurations. Also, we develop a hierarchical and adaptive method that progressively improves the fitting quality by new knot-insertion strategies guided by surface geometry and fitting error. Within our framework, a genus-0 model can be converted to a single spherical spline representation whose root mean square error is tightly bounded within a user-specified tolerance. The reconstructed continuous representation has many attractive properties such as global smoothness and no auxiliary knots. We conduct several experiments to demonstrate the efficacy of our new approach for reverse engineering and shape modeling.", "keywords": ["computational geometry", "least mean squares methods", "mesh generation", "splines (mathematics)", "surface fitting", "tensors", "spherical DCB-spline surfaces", "adaptive knot insertion", "novel surface fitting scheme", "continuous parametric spline surface", "Delaunay configuration B-spline", "nontensor-product spline", "surface geometry", "genus-0 model", "spherical spline representation", "reconstructed continuous representation", "reverse engineering", "shape modeling", "root mean square error", "hierarchical knot insertion", "Splines (mathematics)", "Surface reconstruction", "Polynomials", "Approximation methods", "Surface treatment", "Electronic mail", "Image reconstruction", "Delaunay configurations", "spherical splines", "knot placement", "knot insertion", "non-tensor-product B-splines."], "referenced_by": ["10.1109/JIOT.2019.2960827", "10.1145/2668020", "10.1007/s11432-013-4992-5", "10.1016/j.cag.2016.05.010", "10.1016/j.cagd.2017.01.001", "10.1016/j.cam.2013.10.030", "10.1016/j.gmod.2014.04.006", "10.1080/16864360.2016.1257191", "10.3390/rs10071073"], "referencing": ["10.1109/SMI.2005.37", "10.1109/SCCG.2001.945339", "10.1109/SMI.2006.9", "10.1109/TIT.1982.1056489", "10.1109/TIT.1979.1056067", "10.1145/1236246.1236281", "10.1145/1060244.1060249", "10.1145/502122.502124", "10.1145/164360.164425", "10.1145/1201775.882276", "10.1145/1201775.882274", "10.1145/237170.237216", "10.1145/383259.383307", "10.1145/777792.777839", "10.1145/1559755.1559758", "10.1016/B978-044451104-1/50010-1", "10.1137/S1064827598344388", "10.1016/0167-8396(92)90030-S", "10.1137/040620722", "10.1016/0167-8396(95)00030-5", "10.1016/0377-0427(96)00034-9", "10.1016/0377-0427(96)00042-8", "10.1017/CBO9780511721588", "10.1016/0021-9045(72)90080-9", "10.1016/S0167-8396(96)00062-3", "10.1007/s11390-006-0232-4", "10.1007/978-3-642-03413-8_2", "10.1016/j.cag.2009.03.013", "10.1007/BF01228508", "10.1007/978-1-4612-1098-6", "10.1016/S0925-7721(02)00077-9", "10.1016/j.cad.2004.09.008", "10.1016/j.cad.2006.04.007", "10.1007/978-3-662-05105-4_2", "10.1137/S1064827501391576", "10.1111/j.1467-8659.2009.01521.x"]}, "10.1109/TVCG.2011.140": {"doi": "10.1109/TVCG.2011.140", "author": ["Y. Zheng", "C. Tai", "O. K. Au"], "title": "Dot Scissor: A Single-Click Interface for Mesh Segmentation", "year": "2012", "abstract": "This paper presents a very easy-to-use interactive tool, which we call dot scissor, for mesh segmentation. The user's effort is reduced to placing only a single click where a cut is desired. Such a simple interface is made possible by a directional search strategy supported by a concavity-aware harmonic field and a robust voting scheme that selects the best isoline as the cut. With a concavity-aware weighting scheme, the harmonic fields gather dense isolines along concave regions which are natural boundaries of semantic components. The voting scheme relies on an isoline-face scoring mechanism that considers both shape geometry and user intent. We show by extensive experiments and quantitative analysis that our tool advances the state-of-the-art segmentation methods in both simplicity of use and segmentation quality.", "keywords": ["computer graphics", "interactive systems", "mesh generation", "search problems", "user interfaces", "dot scissor", "single-click interface", "mesh segmentation", "easy-to-use interactive tool", "directional search strategy", "concavity-aware harmonic field", "robust voting scheme", "concavity-aware weighting scheme", "natural boundaries", "semantic components", "isoline-face scoring mechanism", "shape geometry", "quantitative analysis", "state-of-the-art segmentation methods", "segmentation quality", "Harmonic analysis", "Shape", "Brushes", "Robustness", "Geometry", "Humans", "Gold", "Interactive mesh segmentation", "dot scissor", "concavity aware", "harmonic fields", "voting."], "referenced_by": ["10.1109/ACCESS.2018.2802478", "10.1109/ISBB.2015.7344926", "10.1109/CISP-BMEI.2018.8633099", "10.1109/TVCG.2018.2839685", "10.1007/s00371-017-1434-1", "10.1016/j.cag.2013.05.021", "10.1016/j.compbiomed.2014.10.013", "10.1016/j.cviu.2014.12.008", "10.1016/j.gmod.2014.04.009", "10.1111/cgf.13323", "10.1155/2015/187173", "10.1155/2020/1394231", "10.1007/s00170-020-05299-6", "10.1016/j.gmod.2020.101071", "10.1016/j.cag.2020.05.022", "10.1007/s41095-020-0192-6", "10.1016/j.cad.2020.102985"], "referencing": ["10.1109/TVCG.2005.33", "10.1145/1409060.1409098", "10.1145/1833349.1778839", "10.1145/1015706.1015775", "10.1145/1531326.1531379", "10.1111/j.1467-8659.2009.01621.x", "10.1111/j.1467-8659.2009.01622.x", "10.1111/j.1467-8659.2006.00947.x", "10.1111/j.1467-8659.2011.01895.x", "10.1111/j.1467-8659.2007.01103.x", "10.1111/j.1467-8659.2005.00885.x", "10.1016/0031-3203(81)90009-1", "10.1111/j.1467-8659.2008.01286.x", "10.1016/0010-0277(84)90022-2", "10.1016/S0010-0277(96)00791-3", "10.1016/j.cag.2009.03.022", "10.3758/BF03205536", "10.1111/j.1467-8659.2009.01578.x"]}, "10.1109/TVCG.2011.144": {"doi": "10.1109/TVCG.2011.144", "author": ["H. Shiravi", "A. Shiravi", "A. A. Ghorbani"], "title": "A Survey of Visualization Systems for Network Security", "year": "2012", "abstract": "Security Visualization is a very young term. It expresses the idea that common visualization techniques have been designed for use cases that are not supportive of security-related data, demanding novel techniques fine tuned for the purpose of thorough analysis. Significant amount of work has been published in this area, but little work has been done to study this emerging visualization discipline. We offer a comprehensive review of network security visualization and provide a taxonomy in the form of five use-case classes encompassing nearly all recent works in this area. We outline the incorporated visualization techniques and data sources and provide an informative table to display our findings. From the analysis of these systems, we examine issues and concerns regarding network security visualization and provide guidelines and directions for future researchers and visual system developers.", "keywords": ["computer network security", "data visualisation", "network security visualization system", "security-related data", "taxonomy", "use-case classes", "data sources", "informative table", "information visualization", "Data visualization", "Security", "Servers", "Visualization", "Monitoring", "Feature extraction", "IP networks", "Information visualization", "network security visualization", "visualization techniques."], "referenced_by": ["10.1109/3PGCIC.2015.59", "10.1109/AINA.2017.24", "10.1109/ARES.2014.75", "10.1109/BigData.2017.8258128", "10.1109/CCC.2017.11", "10.1109/CCST.2017.8167804", "10.1109/CCWC.2017.7868417", "10.1109/COMST.2017.2745505", "10.1109/CVPRW.2014.127", "10.1109/CyberSA.2016.7503278", "10.1109/CyberSA.2017.8073388", "10.1109/CyberSA.2017.8073400", "10.1109/CyberSecurity.2012.9", "10.1109/ICAICT.2014.7035946", "10.1109/ICOIN.2014.6799724", "10.1109/ICSESS.2016.7883232", "10.1109/ICUMT.2012.6459796", "10.1109/ICVRV.2013.33", "10.1109/ICVRV.2013.39", "10.1109/ISCC.2016.7543793", "10.1109/ISI.2013.6578847", "10.1109/ISI.2015.7165932", "10.1109/IV.2013.15", "10.1109/TVCG.2017.2745105", "10.1109/VAST.2012.6400520", "10.1109/VAST.2015.7347661", "10.1109/VIZSEC.2015.7312763", "10.1109/VIZSEC.2015.7312768", "10.1109/VIZSEC.2016.7739577", "10.1109/VIZSEC.2016.7739579", "10.1145/2671491.2671493", "10.1145/2713579.2713583", "10.1002/sec.1147", "10.1007/978-3-319-44257-0_8", "10.1007/978-3-319-61152-5_3", "10.1007/978-981-10-1741-4_13", "10.1007/s00371-013-0892-3", "10.1007/s10586-017-1317-2", "10.1007/s11432-013-4891-9", "10.1007/s11432-016-0428-2", "10.1007/s12650-014-0213-6", "10.1007/s12650-015-0276-z", "10.1007/s12650-017-0431-9", "10.1016/j.csi.2015.03.001", "10.1016/j.diin.2015.01.005", "10.1016/j.future.2016.06.005", "10.1016/j.neucom.2014.09.099", "10.1108/ICS-07-2014-0049", "10.1111/cgf.13212", "10.1177/1541931215591233", "10.1177/1548512914552530", "10.1186/s13388-014-0006-4", "10.1587/transcom.2016PFI0017", "10.3923/itj.2014.1335.1340", "10.4018/978-1-5225-5191-1.ch059", "10.1117/12.2037790", "10.1007/978-3-319-94496-8_10", "10.1007/978-3-319-92624-7_16", "10.1016/j.ijinfomgt.2018.08.006", "10.1007/978-981-13-2203-7_45"], "referencing": ["10.1109/38.974517", "10.1109/VIZSEC.2005.1532068", "10.1109/VIZSEC.2005.1532061", "10.1109/VAST.2006.261438", "10.1109/VIZSEC.2005.1532074", "10.1109/VIZSEC.2005.1532065", "10.1109/SECPRI.2002.1004372", "10.1109/TDSC.2004.21", "10.1109/VIZSEC.2005.1532064", "10.1109/VIZSEC.2005.1532070", "10.1109/VIZSEC.2005.1532075", "10.1109/VIZSEC.2005.1532060", "10.1109/MCG.2006.49", "10.1109/MCG.2006.30", "10.1109/VAST.2006.261436", "10.1109/TVCG.2007.70522", "10.1109/VAST.2007.4389007", "10.1109/DSN.2005.57", "10.1109/TVCG.2006.108", "10.1109/MCG.2004.26", "10.1109/INFVIS.2002.1173156", "10.1109/TVCG.2006.184", "10.1109/VIZSEC.2009.5375538", "10.1109/TVCG.2006.122", "10.1109/INFVIS.2004.43", "10.1109/VIZSEC.2005.1532062", "10.1109/VIZSEC.2005.1532073", "10.1109/MCG.2003.1242376", "10.1145/1029208.1029219", "10.1145/1029208.1029217", "10.1145/1029208.1029214", "10.1145/990680.990699", "10.1145/1029208.1029220", "10.1145/1029208.1029232", "10.1145/1179576.1179582", "10.1145/1850795.1850799", "10.1145/1029208.1029215", "10.1145/1179576.1179593", "10.1145/1179576.1179592", "10.1145/365024.365309", "10.1145/503411.503413", "10.1145/505202.505233", "10.1145/505231.505234", "10.1145/863993.863994", "10.1007/978-3-540-78243-8_9", "10.1007/978-3-540-78243-8_13", "10.1007/978-3-540-78243-8_7", "10.1007/978-3-540-85933-8_16", "10.1007/3-540-36084-0_7", "10.1007/978-3-540-28651-6_38", "10.1016/j.cose.2006.10.001", "10.1007/978-3-540-85933-8_11", "10.1007/978-3-642-17650-0_31", "10.7155/jgaa.00102", "10.1518/001872095779049543", "10.1057/ivs.2010.5", "10.1117/12.649625", "10.1006/ijhc.2000.0417", "10.1007/3-540-44702-4_10", "10.1016/S1389-1286(00)00134-1", "10.1007/978-0-387-35259-6_13", "10.1007/978-3-540-78243-8_4"]}, "10.1109/TVCG.2011.128": {"doi": "10.1109/TVCG.2011.128", "author": ["K. Feng", "C. Wang", "H. Shen", "T. Lee"], "title": "Coherent Time-Varying Graph Drawing with Multifocus+Context Interaction", "year": "2012", "abstract": "We present a new approach for time-varying graph drawing that achieves both spatiotemporal coherence and multifocus+context visualization in a single framework. Our approach utilizes existing graph layout algorithms to produce the initial graph layout, and formulates the problem of generating coherent time-varying graph visualization with the focus+context capability as a specially tailored deformation optimization problem. We adopt the concept of the super graph to maintain spatiotemporal coherence and further balance the needs for aesthetic quality and dynamic stability when interacting with time-varying graphs through focus+context visualization. Our method is particularly useful for multifocus+context visualization of time-varying graphs where we can preserve the mental map by preventing nodes in the focus from undergoing abrupt changes in size and location in the time sequence. Experiments demonstrate that our method strikes a good balance between maintaining spatiotemporal coherence and accentuating visual foci, thus providing a more engaging viewing experience for the users.", "keywords": ["graph theory", "optimisation", "coherent time-varying graph drawing", "multifocus+context interaction", "spatiotemporal coherence", "multifocus+context visualization", "graph layout algorithms", "coherent time-varying graph visualization", "focus+context capability", "deformation optimization problem", "aesthetic quality", "dynamic stability", "focus+context visualization", "visual foci", "Layout", "Visualization", "Context", "Heuristic algorithms", "Coherence", "Data visualization", "Spatiotemporal phenomena", "Graph drawing", "time-varying graphs", "spatiotemporal coherence", "focus+context visualization."], "referenced_by": ["10.1109/BMEI.2015.7401585", "10.1109/CW.2016.24", "10.1109/EITT.2016.40", "10.1109/TVCG.2014.2299803", "10.1109/TVCG.2014.2346746", "10.1109/ICVRV.2014.5", "10.1109/ICCI-CC.2015.7259407", "10.1109/ICSESS.2017.8342958", "10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00156", "10.1007/s00371-013-0892-3", "10.1007/s11390-013-1383-8", "10.1111/cgf.12394", "10.1111/cgf.12791", "10.1177/1473871616630778", "10.1117/12.2074198", "10.1111/cgf.13723", "10.1016/j.ins.2019.07.097", "10.1631/FITEE.1900310", "10.1177/1473871620972339"], "referencing": ["10.1109/INFVIS.2004.66", "10.1109/TVCG.2006.193", "10.1109/TVCG.2008.140", "10.1109/TVCG.2008.132", "10.1109/TVCG.2010.34", "10.1145/22339.22342", "10.1145/1124772.1124921", "10.1145/142750.142763", "10.1145/168642.168650", "10.1145/1618452.1618473", "10.1007/3-540-44969-8_4", "10.1007/3-540-44969-8_9", "10.1080/17445760802337010", "10.1007/978-3-7091-6215-6_19", "10.1002/spe.4380211102", "10.7155/jgaa.00198", "10.1007/978-3-540-31843-9_25", "10.1007/978-3-540-31843-9_24", "10.1007/3-540-36151-0_20", "10.1016/0020-0190(89)90102-6", "10.1006/jvlc.1995.1010", "10.1007/978-3-540-24595-7_40", "10.1007/978-3-540-87730-1_9", "10.1007/BFb0014497", "10.1017/CBO9780511815478"]}, "10.1109/TVCG.2011.142": {"doi": "10.1109/TVCG.2011.142", "author": ["T. E. Gorochowski", "M. di Bernardo", "C. S. Grierson"], "title": "Using Aging to Visually Uncover Evolutionary Processes on Networks", "year": "2012", "abstract": "Networks are widely used to describe many natural and technological systems. Understanding how these evolve over time poses a challenge for existing visualization techniques originally developed for fixed network structures. We describe a method of incorporating the concept of aging into evolving networks, where nodes and edges store information related to the amount of local evolutionary change they have experienced. This property is used to generate visualizations that ensure stable substructures maintain relatively fixed spatial positions, allowing them to act as visual markers and providing context for evolutionary change elsewhere. By further supplementing these visualizations with color cues, the resultant animations enable a clearer portrayal of the underlying evolutionary process.", "keywords": ["computer animation", "data visualisation", "evolutionary computation", "network theory (graphs)", "network aging", "evolutionary process", "visualization techniques", "network structures", "visual marker", "color cues", "animation", "Layout", "Aging", "Visualization", "Data visualization", "Color", "Animation", "Stability analysis", "Network evolution", "information visualization", "graph layout.", "Algorithms", "Computer Communication Networks", "Computer Simulation", "Humans", "Models, Genetic", "Social Support", "Time Factors"], "referenced_by": ["10.1109/ICBDA.2017.8078754", "10.1109/ICVRV.2015.31", "10.1109/PACIFICVIS.2017.8031576", "10.1109/ICSESS.2017.8342958", "10.1109/DSC.2018.00120", "10.1109/ACCESS.2018.2870684", "10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00156", "10.1109/TVCG.2018.2886901", "10.1109/ICCICC46617.2019.9146098", "10.1145/3006299.3006302", "10.1007/978-3-319-73915-1_31", "10.1007/978-981-10-5287-3_2", "10.1111/cgf.12791", "10.1007/978-3-030-05414-4_5", "10.1007/978-3-319-27261-0_2", "10.1016/j.ins.2019.07.097", "10.1177/1473871620972339"], "referencing": ["10.1109/TVCG.2008.11", "10.1109/TVCG.2006.193", "10.1109/TVCG.2006.122", "10.1109/TVCG.2007.70580", "10.1145/345513.345353", "10.1145/234535.234538", "10.1038/nature08480", "10.1038/nature05670", "10.1093/acprof:oso/9780198515906.001.0001", "10.1016/S0378-4371(02)00736-7", "10.1002/spe.4380211102", "10.1016/0020-0190(89)90102-6", "10.1006/ijhc.2002.1017", "10.1037/13156-000", "10.1103/PhysRevE.81.056212", "10.1057/palgrave.ivs.9500037", "10.7155/jgaa.00057", "10.1006/jvlc.1995.1010", "10.1287/isre.1080.0191", "10.1086/421509", "10.1007/3-540-44541-2_17", "10.1086/338779", "10.1007/978-3-540-70904-6_19", "10.1007/978-3-540-87730-1_9"]}, "10.1109/TVCG.2011.155": {"doi": "10.1109/TVCG.2011.155", "author": ["H. Yu", "C. Wang", "C. Shene", "J. H. Chen"], "title": "Hierarchical Streamline Bundles", "year": "2012", "abstract": "Effective 3D streamline placement and visualization play an essential role in many science and engineering disciplines. The main challenge for effective streamline visualization lies in seed placement, i.e., where to drop seeds and how many seeds should be placed. Seeding too many or too few streamlines may not reveal flow features and patterns either because it easily leads to visual clutter in rendering or it conveys little information about the flow field. Not only does the number of streamlines placed matter, their spatial relationships also play a key role in understanding the flow field. Therefore, effective flow visualization requires the streamlines to be placed in the right place and in the right amount. This paper introduces hierarchical streamline bundles, a novel approach to simplifying and visualizing 3D flow fields defined on regular grids. By placing seeds and generating streamlines according to flow saliency, we produce a set of streamlines that captures important flow features near critical points without enforcing the dense seeding condition. We group spatially neighboring and geometrically similar streamlines to construct a hierarchy from which we extract streamline bundles at different levels of detail. Streamline bundles highlight multiscale flow features and patterns through clustered yet not cluttered display. This selective visualization strategy effectively reduces visual clutter while accentuating visual foci, and therefore is able to convey the desired insight into the flow data.", "keywords": ["critical points", "flow visualisation", "pattern clustering", "pattern formation", "rendering (computer graphics)", "hierarchical streamline bundles", "3D streamline placement", "3D streamline visualization", "seed placement", "rendering", "spatial relationships", "3D flow field visualization", "spatially neighboring streamlines", "geometrically similar streamlines", "streamline bundle extraction", "multiscale flow features", "multiscale flow patterns", "visual clutter reduction", "visual foci accentuation", "flow data", "flow saliency", "streamline seeding", "critical points", "Three dimensional displays", "Streaming media", "Feature extraction", "Data visualization", "Clustering algorithms", "Visualization", "Diffusion tensor imaging", "Streamline bundles", "flow saliency", "seed placement", "hierarchical clustering", "level-of-detail", "flow visualization."], "referenced_by": ["10.1109/CADGRAPHICS.2015.48", "10.1109/PacificVis.2013.6596150", "10.1109/PacificVis.2013.6596153", "10.1109/TVCG.2012.150", "10.1109/TVCG.2012.169", "10.1109/TVCG.2013.2297914", "10.1109/TVCG.2013.236", "10.1109/TVCG.2014.2312009", "10.1109/TVCG.2014.2346455", "10.1109/TVCG.2015.2403323", "10.1109/TVCG.2015.2467203", "10.1109/TVCG.2015.2467204", "10.1109/TVCG.2016.2582174", "10.1109/TVCG.2017.2744338", "10.1109/TVCG.2017.2719684", "10.1109/PacificVis.2019.00031", "10.1109/ACCESS.2019.2935461", "10.1109/TVCG.2019.2934806", "10.1109/TVCG.2018.2880207", "10.1109/PacificVis48177.2020.1718", "10.1109/TVCG.2019.2915222", "10.1145/2461912.2461930", "10.1007/978-3-319-44684-4_11", "10.1007/s12650-014-0237-y", "10.1007/s12650-015-0293-y", "10.1007/s12650-015-0336-4", "10.1007/s12650-017-0447-1", "10.1016/B978-0-12-415873-3.00035-3", "10.1016/j.cag.2015.06.003", "10.1016/j.cag.2016.08.001", "10.1016/j.cag.2017.07.014", "10.1111/cgf.12335", "10.1111/cgf.13115", "10.3390/ijgi7070266", "10.3390/e20090625", "10.1007/s12650-018-0516-0", "10.1007/s12650-019-00592-3", "10.1016/j.cag.2019.09.004", "10.3390/a13120316"], "referencing": ["10.1109/TVCG.2007.70595", "10.1109/VISUAL.2004.32", "10.1109/VISUAL.1999.809863", "10.1109/TVCG.2006.147", "10.1109/34.730558", "10.1109/TVCG.2009.141", "10.1109/PACIFICVIS.2008.4475462", "10.1109/TVCG.2006.116", "10.1109/TVCG.2003.1196000", "10.1109/TVCG.2010.212", "10.1109/VISUAL.2005.1532832", "10.1109/VISUAL.2005.1532779", "10.1109/PACIFICVIS.2009.4906832", "10.1109/TVCG.2006.104", "10.1109/VISUAL.1999.809865", "10.1109/TVCG.2008.52", "10.1145/375663.375668", "10.1145/258734.258796", "10.1145/331499.331504", "10.1145/1073204.1073244", "10.1145/237170.237285", "10.1145/1148493.1148510", "10.1111/j.1467-8659.2008.01227.x", "10.1111/j.1467-8659.2008.01244.x", "10.1007/978-3-7091-6876-9_5", "10.1111/j.1467-8659.2004.00753.x", "10.1007/978-3-540-70823-0_1", "10.1111/j.1467-8659.2010.01650.x", "10.1111/j.1467-8659.2003.00723.x", "10.2307/2284239", "10.1111/j.1467-8659.2009.01352.x", "10.1016/B978-012387582-2/50014-9"]}, "10.1109/TVCG.2012.33": {"doi": "10.1109/TVCG.2012.33", "author": ["s. barakat", "C. Garth", "X. Tricoche"], "title": "Interactive Computation and Rendering of Finite-Time Lyapunov Exponent Fields", "year": "2012", "abstract": "In this paper, we present a novel technique that allows for the coupled computation and visualization of salient flow structures at interactive frame rates. Our approach is built upon a hierarchical representation of the Finite-time Lyapunov Exponent (FTLE) field, which is adaptively sampled and rendered to meet the need of the current visual setting. The performance of our method allows the user to explore large and complex data sets across scales and to inspect their features at arbitrary resolution. The paper discusses an efficient implementation of this strategy on graphics hardware and provides results for an analytical flow and several CFD simulation data sets.", "keywords": ["computational fluid dynamics", "flow visualisation", "Lyapunov methods", "interactive computation", "finite time Lyapunov exponent fields", "coupled computation", "salient flow structures visualization", "hierarchical representation", "graphics hardware", "simulation data sets", "Octrees", "Rendering (computer graphics)", "Graphics processing unit", "Visualization", "Transient analysis", "Three dimensional displays", "Flow visualization", "vector field data", "GPU and multicore architectures", "interactive", "FTLE", "streaming data."], "referenced_by": ["10.1109/ICVRV.2016.89", "10.1109/TVCG.2013.128", "10.1109/TVCG.2015.2476795", "10.1109/TVCG.2016.2599016", "10.1109/TVCG.2017.2674918", "10.1109/TVCG.2019.2934313", "10.1109/PacificVis48177.2020.1718", "10.1007/s11071-013-0823-x", "10.1111/cgf.12914", "10.1146/annurev-fluid-010313-141322", "10.2514/1.J057094"], "referencing": ["10.1109/TVCG.2007.70551", "10.1109/TVCG.2008.133", "10.1109/TVCG.2010.227", "10.1109/TVCG.2004.47", "10.1109/TVCG.2007.70554", "10.1109/TVCG.2008.183", "10.1109/TVCG.2005.68", "10.1145/1507149.1507152", "10.1145/1187112.1187129", "10.1007/PL00013406", "10.1063/1.3270044", "10.1007/978-3-540-88606-8_1", "10.1017/S0022112006003648", "10.1016/S0167-2789(00)00199-8", "10.1063/1.1403336", "10.1063/1.1477449", "10.1111/j.1467-8659.2004.00753.x", "10.1063/1.3278516", "10.1063/1.3270049", "10.1111/j.1467-8659.2003.00723.x", "10.1063/1.2189885", "10.1016/j.physd.2005.10.007", "10.1016/S0097-8493(02)00056-0", "10.1103/PhysRevLett.88.254501"]}}