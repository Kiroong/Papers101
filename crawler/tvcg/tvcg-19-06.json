{"10.1109/TVCG.2019.2905484": {"doi": "10.1109/TVCG.2019.2905484", "author": ["R. Maciejewski", "J. Seo", "R. Westermann"], "title": "Guest Editors' Introduction: Special Section on IEEE PacificVis 2019", "year": "2019", "abstract": "The papers in this special issue were presented at the 2019 IEEE Pacific Visualization Symposium (IEEE PacificVis 2019), which was held in Bangkok, Thailand from April 23 to 26, 2019 hosted by Chulalongkorn University. The IEEE Pacific Visualization Symposium, sponsored by the IEEE Visualization and Graphics Technical Committee (VGTC), aims to foster greater exchange between visualization researchers and practitioners especially in the Asia-Pacific region. ", "keywords": ["Special issues and sections", "Meetings", "Visualization"], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2019.2903942": {"doi": "10.1109/TVCG.2019.2903942", "author": ["F. Heinrich", "F. Joeres", "K. Lawonn", "C. Hansen"], "title": "Comparison of Projective Augmented Reality Concepts to Support Medical Needle Insertion", "year": "2019", "abstract": "Augmented reality (AR) is a promising tool to improve instrument navigation in needle-based interventions. Limited research has been conducted regarding suitable navigation visualizations. In this work, three navigation concepts based on existing approaches were compared in a user study using a projective AR setup. Each concept was implemented with three different scales for accuracy-to-color mapping and two methods of navigation indicator scaling. Participants were asked to perform simulated needle insertion tasks with each of the resulting 18 prototypes. Insertion angle and insertion depth accuracies were measured and analyzed, as well as task completion time and participants' subjectively perceived task difficulty. Results show a clear ranking of visualization concepts across variables. Less consistent results were obtained for the color and indicator scaling factors. Results suggest that logarithmic indicator scaling achieved better accuracy, but participants perceived it to be more difficult than linear scaling. With specific results for angle and depth accuracy, our study contributes to the future composition of improved navigation support and systems for precise needle insertion or similar applications.", "keywords": ["augmented reality", "data visualisation", "medical computing", "needles", "projective augmented reality", "medical needle insertion", "instrument navigation", "needle-based interventions", "projective AR setup", "accuracy-to-color mapping", "navigation indicator scaling", "visualization concepts", "indicator scaling factors", "logarithmic indicator scaling", "navigation visualizations", "Needles", "Visualization", "Navigation", "Instruments", "Task analysis", "Monitoring", "Computed tomography", "Visualization", "augmented reality", "evaluation", "medical navigation systems", "instrument guidance", "needle placement", "Adult", "Augmented Reality", "Female", "Humans", "Male", "Needles", "Phantoms, Imaging", "Surgery, Computer-Assisted", "Young Adult"], "referenced_by": ["IKEY:9211732", "IKEY:9284729", "IKEY:9284793", "10.1049/htl.2019.0062"], "referencing": ["IKEY:8425736", "IKEY:7328052", "IKEY:6064981", "IKEY:6571221", "IKEY:5643530", "IKEY:8425736", "IKEY:7328052", "IKEY:6064981", "IKEY:6571221", "IKEY:5643530", "IKEY:8425736", "IKEY:7328052", "IKEY:6064981", "IKEY:6571221", "IKEY:5643530", "10.1145/3009977.3010023", "10.1145/3009977.3010023", "10.1145/3009977.3010023", "10.3109/10929088.2011.578367", "10.1007/s00270-010-9836-8", "10.2214/AJR.15.15803", "10.1007/s11548-013-0816-8", "10.3109/10929088.2011.597566", "10.1002/rcs.261", "10.1002/rcs.1466", "10.1007/s11548-011-0660-7", "10.1007/s11548-015-1156-7", "10.1148/radiol.2401040018", "10.2214/AJR.11.6918", "10.1117/12.2293671", "10.1148/radiol.2382041441", "10.1016/j.ijrobp.2007.10.048", "10.1111/cgf.13311", "10.1049/htl.2018.5076", "10.1117/12.707896", "10.1007/s10439-014-1203-5", "10.3109/10929088.2011.578367", "10.1007/s00270-010-9836-8", "10.2214/AJR.15.15803", "10.1007/s11548-013-0816-8", "10.3109/10929088.2011.597566", "10.1002/rcs.261", "10.1002/rcs.1466", "10.1007/s11548-011-0660-7", "10.1007/s11548-015-1156-7", "10.1148/radiol.2401040018", "10.2214/AJR.11.6918", "10.1117/12.2293671", "10.1148/radiol.2382041441", "10.1016/j.ijrobp.2007.10.048", "10.1111/cgf.13311", "10.1049/htl.2018.5076", "10.1117/12.707896", "10.1007/s10439-014-1203-5", "10.3109/10929088.2011.578367", "10.1007/s00270-010-9836-8", "10.2214/AJR.15.15803", "10.1007/s11548-013-0816-8", "10.3109/10929088.2011.597566", "10.1002/rcs.261", "10.1002/rcs.1466", "10.1007/s11548-011-0660-7", "10.1007/s11548-015-1156-7", "10.1148/radiol.2401040018", "10.2214/AJR.11.6918", "10.1117/12.2293671", "10.1148/radiol.2382041441", "10.1016/j.ijrobp.2007.10.048", "10.1111/cgf.13311", "10.1049/htl.2018.5076", "10.1117/12.707896", "10.1007/s10439-014-1203-5"]}, "10.1109/TVCG.2019.2903943": {"doi": "10.1109/TVCG.2019.2903943", "author": ["J. Wang", "L. Gou", "W. Zhang", "H. Yang", "H. Shen"], "title": "DeepVID: Deep Visual Interpretation and Diagnosis for Image Classifiers via Knowledge Distillation", "year": "2019", "abstract": "Deep Neural Networks (DNNs) have been extensively used in multiple disciplines due to their superior performance. However, in most cases, DNNs are considered as black-boxes and the interpretation of their internal working mechanism is usually challenging. Given that model trust is often built on the understanding of how a model works, the interpretation of DNNs becomes more important, especially in safety-critical applications (e.g., medical diagnosis, autonomous driving). In this paper, we propose DeepVID, a Deep learning approach to Visually Interpret and Diagnose DNN models, especially image classifiers. In detail, we train a small locally-faithful model to mimic the behavior of an original cumbersome DNN around a particular data instance of interest, and the local model is sufficiently simple such that it can be visually interpreted (e.g., a linear model). Knowledge distillation is used to transfer the knowledge from the cumbersome DNN to the small model, and a deep generative model (i.e., variational auto-encoder) is used to generate neighbors around the instance of interest. Those neighbors, which come with small feature variances and semantic meanings, can effectively probe the DNN's behaviors around the interested instance and help the small model to learn those behaviors. Through comprehensive evaluations, as well as case studies conducted together with deep learning experts, we validate the effectiveness of DeepVID.", "keywords": ["image classification", "learning (artificial intelligence)", "neural nets", "DeepVID", "image classifiers", "knowledge distillation", "Deep Neural Networks", "safety-critical applications", "deep generative model", "deep learning experts", "DNN", "deep visual interpretation", "deep visual diagnosis", "Data models", "Visual analytics", "Deep learning", "Analytical models", "Neural networks", "Semantics", "Training", "Deep neural networks", "model interpretation", "knowledge distillation", "generative model", "visual analytics"], "referenced_by": ["IKEY:8805421", "IKEY:8944065", "IKEY:9086289", "IKEY:9115491", "IKEY:9196460", "IKEY:9195219"], "referencing": ["IKEY:97458", "IKEY:7780459", "IKEY:8578273", "IKEY:7780688", "IKEY:8237633", "IKEY:8440091", "IKEY:8237336", "IKEY:7536654", "IKEY:8019861", "IKEY:8022871", "IKEY:8320546", "IKEY:8454905", "IKEY:726791", "IKEY:7410782", "IKEY:7926714", "IKEY:97458", "IKEY:7780459", "IKEY:8578273", "IKEY:7780688", "IKEY:8237633", "IKEY:8440091", "IKEY:8237336", "IKEY:7536654", "IKEY:8019861", "IKEY:8022871", "IKEY:8320546", "IKEY:8454905", "IKEY:726791", "IKEY:7410782", "IKEY:7926714", "IKEY:97458", "IKEY:7780459", "IKEY:8578273", "IKEY:7780688", "IKEY:8237633", "IKEY:8440091", "IKEY:8237336", "IKEY:7536654", "IKEY:8019861", "IKEY:8022871", "IKEY:8320546", "IKEY:8454905", "IKEY:726791", "IKEY:7410782", "IKEY:7926714", "10.1145/2939672.2939778", "10.1145/2858036.2858111", "10.1145/2939672.2939778", "10.1145/2858036.2858111", "10.1145/2939672.2939778", "10.1145/2858036.2858111", "10.1007/BF00994018", "10.1371/journal.pone.0130140", "10.1016/j.patcog.2016.11.008", "10.1007/978-3-319-27857-5_77", "10.1007/BF00994018", "10.1371/journal.pone.0130140", "10.1016/j.patcog.2016.11.008", "10.1007/978-3-319-27857-5_77", "10.1007/BF00994018", "10.1371/journal.pone.0130140", "10.1016/j.patcog.2016.11.008", "10.1007/978-3-319-27857-5_77"]}, "10.1109/TVCG.2019.2903946": {"doi": "10.1109/TVCG.2019.2903946", "author": ["X. Ji", "H. -W. Shen", "A. Ritter", "R. Machiraju", "P. -Y. Yen"], "title": "Visual Exploration of Neural Document Embedding in Information Retrieval: Semantics and Feature Selection", "year": "2019", "abstract": "Neural embeddings are widely used in language modeling and feature generation with superior computational power. Particularly, neural document embedding - converting texts of variable-length to semantic vector representations - has shown to benefit widespread downstream applications, e.g., information retrieval (IR). However, the black-box nature makes it difficult to understand how the semantics are encoded and employed. We propose visual exploration of neural document embedding to gain insights into the underlying embedding space, and promote the utilization in prevalent IR applications. In this study, we take an IR application-driven view, which is further motivated by biomedical IR in healthcare decision-making, and collaborate with domain experts to design and develop a visual analytics system. This system visualizes neural document embeddings as a configurable document map and enables guidance and reasoning; facilitates to explore the neural embedding space and identify salient neural dimensions (semantic features) per task and domain interest; and supports advisable feature selection (semantic analysis) along with instant visual feedback to promote IR performance. We demonstrate the usefulness and effectiveness of this system and present inspiring findings in use cases. This work will help designers/developers of downstream applications gain insights and confidence in neural document embedding, and exploit that to achieve more favorable performance in application domains.", "keywords": ["data analysis", "data visualisation", "health care", "information retrieval", "neural nets", "text analysis", "visual analytics system", "healthcare decision-making", "biomedical IR", "IR application-driven view", "semantic vector representations", "text conversion", "feature selection", "salient neural dimensions", "neural embedding space", "information retrieval", "neural document embedding", "visual exploration", "Semantics", "Analytical models", "Visual analytics", "Medical services", "Task analysis", "Feature extraction", "Neural document embedding", "information retrieval", "semantic analysis", "feature selection", "Cluster Analysis", "Humans", "Information Storage and Retrieval", "Machine Learning", "Natural Language Processing", "Semantics"], "referenced_by": ["IKEY:9308101", "IKEY:9308101", "10.1186/s41182-019-0189-y", "10.1016/j.jbi.2020.103374", "10.1016/j.visinf.2020.04.001", "10.1016/j.visinf.2020.04.003", "10.1007/s10489-020-01922-x", "10.1007/s41095-020-0191-7"], "referencing": ["IKEY:7536654", "IKEY:7539329", "IKEY:8017583", "IKEY:7389336", "IKEY:8019864", "IKEY:8494828", "IKEY:8440842", "IKEY:8022871", "IKEY:7883507", "IKEY:7539597", "IKEY:4677350", "IKEY:7536217", "IKEY:7192671", "IKEY:6400486", "IKEY:5290709", "IKEY:7536654", "IKEY:7539329", "IKEY:8017583", "IKEY:7389336", "IKEY:8019864", "IKEY:8494828", "IKEY:8440842", "IKEY:8022871", "IKEY:7883507", "IKEY:7539597", "IKEY:4677350", "IKEY:7536217", "IKEY:7192671", "IKEY:6400486", "IKEY:5290709", "IKEY:7536654", "IKEY:7539329", "IKEY:8017583", "IKEY:7389336", "IKEY:8019864", "IKEY:8494828", "IKEY:8440842", "IKEY:8022871", "IKEY:7883507", "IKEY:7539597", "IKEY:4677350", "IKEY:7536217", "IKEY:7192671", "IKEY:6400486", "IKEY:5290709", "10.1145/3018661.3022755", "10.1145/3018661.3022755", "10.1145/3018661.3022755", "10.18653/v1/N16-1162", "10.2352/ISSN.2470-1173.2017.1.VDA-388", "10.1197/jamia.M1929", "10.1007/978-3-319-43862-7_8", "10.1002/9780470689646.ch1", "10.1111/gwat.12804", "10.1177/1473871617733996", "10.18653/v1/N16-1162", "10.2352/ISSN.2470-1173.2017.1.VDA-388", "10.1197/jamia.M1929", "10.1007/978-3-319-43862-7_8", "10.1002/9780470689646.ch1", "10.1111/gwat.12804", "10.1177/1473871617733996", "10.18653/v1/N16-1162", "10.2352/ISSN.2470-1173.2017.1.VDA-388", "10.1197/jamia.M1929", "10.1007/978-3-319-43862-7_8", "10.1002/9780470689646.ch1", "10.1111/gwat.12804", "10.1177/1473871617733996"]}, "10.1109/TVCG.2019.2903945": {"doi": "10.1109/TVCG.2019.2903945", "author": ["J. G\u00f6rtler", "M. Spicker", "C. Schulz", "D. Weiskopf", "O. Deussen"], "title": "Stippling of 2D Scalar Fields", "year": "2019", "abstract": "We propose a technique to represent two-dimensional data using stipples. While stippling is often regarded as an illustrative method, we argue that it is worth investigating its suitability for the visualization domain. For this purpose, we generalize the Linde-Buzo-Gray stippling algorithm for information visualization purposes to encode continuous and discrete 2D data. Our proposed modifications provide more control over the resulting distribution of stipples for encoding additional information into the representation, such as contours. We show different approaches to depict contours in stipple drawings based on locally adjusting the stipple distribution. Combining stipple-based gradients and contours allows for simultaneous assessment of the overall structure of the data while preserving important local details. We discuss the applicability of our technique using datasets from different domains and conduct observation-validating studies to assess the perception of stippled representations.", "keywords": ["data visualisation", "gradient methods", "image coding", "image representation", "vector quantisation", "2D scalar fields", "two-dimensional data", "illustrative method", "visualization domain", "Linde-Buzo-Gray stippling algorithm", "information visualization purposes", "stipple drawings", "stipple distribution", "stippled representations", "stipple-based gradients", "Data visualization", "Image color analysis", "Visualization", "Two dimensional displays", "Rendering (computer graphics)", "Encoding", "Task analysis", "Stippling", "contours", "semiotics", "evaluation", "scalar field visualization", "abstraction", "sampling"], "referenced_by": [], "referencing": ["IKEY:1310205", "IKEY:7539585", "IKEY:5290709", "IKEY:6634173", "IKEY:8025425", "IKEY:6327281", "IKEY:6484065", "IKEY:5613427", "IKEY:6094044", "IKEY:1056489", "IKEY:841534", "IKEY:1208320", "IKEY:4376160", "IKEY:5290742", "IKEY:7305807", "IKEY:7760", "IKEY:8017604", "IKEY:4658159", "IKEY:6095544", "IKEY:6634108", "IKEY:1310205", "IKEY:7539585", "IKEY:5290709", "IKEY:6634173", "IKEY:8025425", "IKEY:6327281", "IKEY:6484065", "IKEY:5613427", "IKEY:6094044", "IKEY:1056489", "IKEY:841534", "IKEY:1208320", "IKEY:4376160", "IKEY:5290742", "IKEY:7305807", "IKEY:7760", "IKEY:8017604", "IKEY:4658159", "IKEY:6095544", "IKEY:6634108", "IKEY:1310205", "IKEY:7539585", "IKEY:5290709", "IKEY:6634173", "IKEY:8025425", "IKEY:6327281", "IKEY:6484065", "IKEY:5613427", "IKEY:6094044", "IKEY:1056489", "IKEY:841534", "IKEY:1208320", "IKEY:4376160", "IKEY:5290742", "IKEY:7305807", "IKEY:7760", "IKEY:8017604", "IKEY:4658159", "IKEY:6095544", "IKEY:6634108", "10.1145/508530.508537", "10.1145/3130800.3130819", "10.1145/1179352.1142016", "10.1145/344779.345074", "10.1145/1124728.1124741", "10.1145/383259.383327", "10.1145/3092919.3092923", "10.1145/2993901.2993907", "10.1145/508530.508537", "10.1145/3130800.3130819", "10.1145/1179352.1142016", "10.1145/344779.345074", "10.1145/1124728.1124741", "10.1145/383259.383327", "10.1145/3092919.3092923", "10.1145/2993901.2993907", "10.1145/508530.508537", "10.1145/3130800.3130819", "10.1145/1179352.1142016", "10.1145/344779.345074", "10.1145/1124728.1124741", "10.1145/383259.383327", "10.1145/3092919.3092923", "10.1145/2993901.2993907", "10.1364/JOSAA.9.001433", "10.1111/cgf.12932", "10.14714/CP29.672", "10.1016/j.comgeo.2003.07.005", "10.1016/j.cag.2017.05.001", "10.1111/1467-8659.00396", "10.1111/j.1467-8659.2008.01259.x", "10.1364/JOSA.32.000247", "10.1111/cgf.12379", "10.3758/s13423-016-1174-7", "10.1179/000870403235002042", "10.1007/978-3-319-66435-4", "10.1111/1467-8659.00699", "10.1007/s00453-009-9281-8", "10.1364/JOSAA.9.001433", "10.1111/cgf.12932", "10.14714/CP29.672", "10.1016/j.comgeo.2003.07.005", "10.1016/j.cag.2017.05.001", "10.1111/1467-8659.00396", "10.1111/j.1467-8659.2008.01259.x", "10.1364/JOSA.32.000247", "10.1111/cgf.12379", "10.3758/s13423-016-1174-7", "10.1179/000870403235002042", "10.1007/978-3-319-66435-4", "10.1111/1467-8659.00699", "10.1007/s00453-009-9281-8", "10.1364/JOSAA.9.001433", "10.1111/cgf.12932", "10.14714/CP29.672", "10.1016/j.comgeo.2003.07.005", "10.1016/j.cag.2017.05.001", "10.1111/1467-8659.00396", "10.1111/j.1467-8659.2008.01259.x", "10.1364/JOSA.32.000247", "10.1111/cgf.12379", "10.3758/s13423-016-1174-7", "10.1179/000870403235002042", "10.1007/978-3-319-66435-4", "10.1111/1467-8659.00699", "10.1007/s00453-009-9281-8"]}, "10.1109/TVCG.2019.2903956": {"doi": "10.1109/TVCG.2019.2903956", "author": ["R. G. Raidou", "M. E. Gr\u00f6ller", "M. Eisemann"], "title": "Relaxing Dense Scatter Plots with Pixel-Based Mappings", "year": "2019", "abstract": "Scatter plots are the most commonly employed technique for the visualization of bivariate data. Despite their versatility and expressiveness in showing data aspects, such as clusters, correlations, and outliers, scatter plots face a main problem. For large and dense data, the representation suffers from clutter due to overplotting. This is often partially solved with the use of density plots. Yet, data overlap may occur in certain regions of a scatter or density plot, while other regions may be partially, or even completely empty. Adequate pixel-based techniques can be employed for effectively filling the plotting space, giving an additional notion of the numerosity of data motifs or clusters. We propose the Pixel-Relaxed Scatter Plots, a new and simple variant, to improve the display of dense scatter plots, using pixel-based, space-filling mappings. Our Pixel-Relaxed Scatter Plots make better use of the plotting canvas, while avoiding data overplotting, and optimizing space coverage and insight in the presence and size of data motifs. We have employed different methods to map scatter plot points to pixels and to visually present this mapping. We demonstrate our approach on several synthetic and realistic datasets, and we discuss the suitability of our technique for different tasks. Our conducted user evaluation shows that our Pixel-Relaxed Scatter Plots can be a useful enhancement to traditional scatter plots.", "keywords": ["data structures", "data visualisation", "pattern clustering", "density plots", "plotting space", "data motifs", "Pixel-Relaxed Scatter Plots", "dense scatter plots", "plotting canvas", "data overplotting", "Pixel-based mappings", "bivariate data", "scatter plot points", "pixel-based techniques", "Data visualization", "Distortion", "Clutter", "Task analysis", "Visualization", "Estimation", "Correlation", "Scatter plots", "overplotting", "pixel-based technique", "space-filling technique"], "referenced_by": [], "referencing": ["IKEY:8017602", "IKEY:7864468", "IKEY:4376143", "IKEY:6875982", "IKEY:636789", "IKEY:1214971", "IKEY:4906843", "IKEY:1320190", "IKEY:5429604", "IKEY:974515", "IKEY:6484064", "IKEY:5290706", "IKEY:4376149", "IKEY:745301", "IKEY:1249018", "IKEY:5613442", "IKEY:175815", "IKEY:4658159", "IKEY:841121", "IKEY:485140", "IKEY:6634192", "IKEY:6095544", "IKEY:1532142", "IKEY:8017649", "IKEY:4015426", "IKEY:8017602", "IKEY:7864468", "IKEY:4376143", "IKEY:6875982", "IKEY:636789", "IKEY:1214971", "IKEY:4906843", "IKEY:1320190", "IKEY:5429604", "IKEY:974515", "IKEY:6484064", "IKEY:5290706", "IKEY:4376149", "IKEY:745301", "IKEY:1249018", "IKEY:5613442", "IKEY:175815", "IKEY:4658159", "IKEY:841121", "IKEY:485140", "IKEY:6634192", "IKEY:6095544", "IKEY:1532142", "IKEY:8017649", "IKEY:4015426", "IKEY:8017602", "IKEY:7864468", "IKEY:4376143", "IKEY:6875982", "IKEY:636789", "IKEY:1214971", "IKEY:4906843", "IKEY:1320190", "IKEY:5429604", "IKEY:974515", "IKEY:6484064", "IKEY:5290706", "IKEY:4376149", "IKEY:745301", "IKEY:1249018", "IKEY:5613442", "IKEY:175815", "IKEY:4658159", "IKEY:841121", "IKEY:485140", "IKEY:6634192", "IKEY:6095544", "IKEY:1532142", "IKEY:8017649", "IKEY:4015426", "10.1145/1056808.1056914", "10.1145/288392.288397", "10.1145/1753326.1753714", "10.1145/2702123.2702585", "10.1145/180171.180173", "10.1145/168642.168650", "10.1145/215585.215978", "10.1145/198366.198384", "10.1145/166117.166151", "10.1145/1056808.1056914", "10.1145/288392.288397", "10.1145/1753326.1753714", "10.1145/2702123.2702585", "10.1145/180171.180173", "10.1145/168642.168650", "10.1145/215585.215978", "10.1145/198366.198384", "10.1145/166117.166151", "10.1145/1056808.1056914", "10.1145/288392.288397", "10.1145/1753326.1753714", "10.1145/2702123.2702585", "10.1145/180171.180173", "10.1145/168642.168650", "10.1145/215585.215978", "10.1145/198366.198384", "10.1145/166117.166151", "10.1002/jhbs.20078", "10.1111/cgf.13446", "10.1057/palgrave.ivs.9500122", "10.1016/B978-155860915-0/50004-4", "10.1111/cgf.12877", "10.2307/2289444", "10.1080/01621459.1988.10478598", "10.1080/10095020.2016.1179441", "10.1057/ivs.2010.4", "10.17713/ajs.v33i3.441", "10.1006/ijhc.2000.0420", "10.1057/ivs.2009.34", "10.1007/978-3-540-71027-1_2", "10.1057/palgrave.ivs.9500003", "10.1016/B978-155860915-0/50034-2", "10.1002/nav.3800020109", "10.1111/j.1467-8659.2011.01938.x", "10.1016/j.jvlc.2016.07.003", "10.1111/j.1467-8659.2009.01450.x", "10.2307/2312726", "10.1057/ivs.2008.13", "10.1111/cgf.13444", "10.1002/jhbs.20078", "10.1111/cgf.13446", "10.1057/palgrave.ivs.9500122", "10.1016/B978-155860915-0/50004-4", "10.1111/cgf.12877", "10.2307/2289444", "10.1080/01621459.1988.10478598", "10.1080/10095020.2016.1179441", "10.1057/ivs.2010.4", "10.17713/ajs.v33i3.441", "10.1006/ijhc.2000.0420", "10.1057/ivs.2009.34", "10.1007/978-3-540-71027-1_2", "10.1057/palgrave.ivs.9500003", "10.1016/B978-155860915-0/50034-2", "10.1002/nav.3800020109", "10.1111/j.1467-8659.2011.01938.x", "10.1016/j.jvlc.2016.07.003", "10.1111/j.1467-8659.2009.01450.x", "10.2307/2312726", "10.1057/ivs.2008.13", "10.1111/cgf.13444", "10.1002/jhbs.20078", "10.1111/cgf.13446", "10.1057/palgrave.ivs.9500122", "10.1016/B978-155860915-0/50004-4", "10.1111/cgf.12877", "10.2307/2289444", "10.1080/01621459.1988.10478598", "10.1080/10095020.2016.1179441", "10.1057/ivs.2010.4", "10.17713/ajs.v33i3.441", "10.1006/ijhc.2000.0420", "10.1057/ivs.2009.34", "10.1007/978-3-540-71027-1_2", "10.1057/palgrave.ivs.9500003", "10.1016/B978-155860915-0/50034-2", "10.1002/nav.3800020109", "10.1111/j.1467-8659.2011.01938.x", "10.1016/j.jvlc.2016.07.003", "10.1111/j.1467-8659.2009.01450.x", "10.2307/2312726", "10.1057/ivs.2008.13", "10.1111/cgf.13444"]}, "10.1109/TVCG.2018.2832097": {"doi": "10.1109/TVCG.2018.2832097", "author": ["K. Yin", "H. Huang", "E. S. L. Ho", "H. Wang", "T. Komura", "D. Cohen-Or", "H. Zhang"], "title": "A Sampling Approach to Generating Closely Interacting 3D Pose-Pairs from 2D Annotations", "year": "2019", "abstract": "We introduce a data-driven method to generate a large number of plausible, closely interacting 3D human pose-pairs, for a given motion category, e.g., wrestling or salsa dance. With much difficulty in acquiring close interactions using 3D sensors, our approach utilizes abundant existing video data which cover many human activities. Instead of treating the data generation problem as one of reconstruction, either through 3D acquisition or direct 2D-to-3D data lifting from video annotations, we present a solution based on Markov Chain Monte Carlo (MCMC) sampling. Given a motion category and a set of video frames depicting the motion with the 2D pose-pair in each frame annotated, we start the sampling with one or few seed 3D pose-pairs which are manually created based on the target motion category. The initial set is then augmented by MCMC sampling around the seeds, via the Metropolis-Hastings algorithm and guided by a probability density function (PDF) that is defined by two terms to bias the sampling towards 3D pose-pairs that are physically valid and plausible for the motion category. With a focus on efficient sampling over the space of close interactions, rather than pose spaces, we develop a novel representation called interaction coordinates (IC) to encode both poses and their interactions in an integrated manner. Plausibility of a 3D pose-pair is then defined based on the IC and with respect to the annotated 2D pose-pairs from video. We show that our sampling-based approach is able to efficiently synthesize a large volume of plausible, closely interacting 3D pose-pairs which provide a good coverage of the input 2D pose-pairs.", "keywords": ["Bayes methods", "image annotation", "image motion analysis", "image reconstruction", "image representation", "image sampling", "Markov processes", "Monte Carlo methods", "pose estimation", "probability", "video signal processing", "sampling approach", "data-driven method", "3D human pose-pairs", "data generation problem", "2D pose-pair", "target motion category", "pose spaces", "video data", "Markov chain Monte Carlo sampling", "2D annotations", "motion category", "3D sensors", "3D acquisition", "2D-to-3D data", "MCMC sampling", "video frames", "seed 3D pose-pairs", "probability density function", "interaction coordinates", "input 2D pose-pairs", "Metropolis-Hastings algorithm", "Three-dimensional displays", "Two dimensional displays", "Probability density function", "Integrated circuits", "Databases", "Optical sensors", "Closely interacting 3D human poses", "data generation and augmentation", "MCMC sampling"], "referenced_by": [], "referencing": ["IKEY:5995316", "IKEY:855885", "IKEY:7298751", "IKEY:7299074", "IKEY:854758", "IKEY:990509", "IKEY:1467294", "IKEY:5995424", "IKEY:4102227", "IKEY:7780902", "IKEY:8099626", "IKEY:4441707", "IKEY:6515122", "IKEY:4731251", "IKEY:4767965", "IKEY:993558", "IKEY:5995316", "IKEY:855885", "IKEY:7298751", "IKEY:7299074", "IKEY:854758", "IKEY:990509", "IKEY:1467294", "IKEY:5995424", "IKEY:4102227", "IKEY:7780902", "IKEY:8099626", "IKEY:4441707", "IKEY:6515122", "IKEY:4731251", "IKEY:4767965", "IKEY:993558", "IKEY:5995316", "IKEY:855885", "IKEY:7298751", "IKEY:7299074", "IKEY:854758", "IKEY:990509", "IKEY:1467294", "IKEY:5995424", "IKEY:4102227", "IKEY:7780902", "IKEY:8099626", "IKEY:4441707", "IKEY:6515122", "IKEY:4731251", "IKEY:4767965", "IKEY:993558", "10.1145/1778765.1781155", "10.1145/2601097.2601117", "10.1145/2661229.2661230", "10.1145/2766914", "10.1145/2366145.2366207", "10.1145/1778765.1778779", "10.1145/2185520.2185523", "10.1145/2816795.2818013", "10.1145/2398356.2398381", "10.1145/2661229.2661286", "10.1145/2461912.2462000", "10.1145/1409060.1409067", "10.1145/1778765.1778770", "10.1145/1531326.1531385", "10.1145/2661229.2661271", "10.1145/1778765.1781155", "10.1145/2601097.2601117", "10.1145/2661229.2661230", "10.1145/2766914", "10.1145/2366145.2366207", "10.1145/1778765.1778779", "10.1145/2185520.2185523", "10.1145/2816795.2818013", "10.1145/2398356.2398381", "10.1145/2661229.2661286", "10.1145/2461912.2462000", "10.1145/1409060.1409067", "10.1145/1778765.1778770", "10.1145/1531326.1531385", "10.1145/2661229.2661271", "10.1145/1778765.1781155", "10.1145/2601097.2601117", "10.1145/2661229.2661230", "10.1145/2766914", "10.1145/2366145.2366207", "10.1145/1778765.1778779", "10.1145/2185520.2185523", "10.1145/2816795.2818013", "10.1145/2398356.2398381", "10.1145/2661229.2661286", "10.1145/2461912.2462000", "10.1145/1409060.1409067", "10.1145/1778765.1778770", "10.1145/1531326.1531385", "10.1145/2661229.2661271", "10.1007/978-3-7091-7486-9_14", "10.1007/978-3-642-33765-9_41", "10.1007/978-3-319-10590-1_12", "10.1007/978-1-4471-4640-7_5", "10.1007/978-3-642-33709-3_59", "10.1016/0021-9290(73)90029-8", "10.1111/j.1467-8659.2009.01369.x", "10.1111/cgf.12815", "10.1093/biomet/57.1.97", "10.1007/978-3-7091-7486-9_14", "10.1007/978-3-642-33765-9_41", "10.1007/978-3-319-10590-1_12", "10.1007/978-1-4471-4640-7_5", "10.1007/978-3-642-33709-3_59", "10.1016/0021-9290(73)90029-8", "10.1111/j.1467-8659.2009.01369.x", "10.1111/cgf.12815", "10.1093/biomet/57.1.97", "10.1007/978-3-7091-7486-9_14", "10.1007/978-3-642-33765-9_41", "10.1007/978-3-319-10590-1_12", "10.1007/978-1-4471-4640-7_5", "10.1007/978-3-642-33709-3_59", "10.1016/0021-9290(73)90029-8", "10.1111/j.1467-8659.2009.01369.x", "10.1111/cgf.12815", "10.1093/biomet/57.1.97"]}, "10.1109/TVCG.2018.2832633": {"doi": "10.1109/TVCG.2018.2832633", "author": ["J. L. Gabbard", "D. G. Mehra", "J. E. Swan"], "title": "Effects of AR Display Context Switching and Focal Distance Switching on Human Performance", "year": "2019", "abstract": "In augmented reality (AR) environments, information is often distributed between real world and virtual contexts, and often appears at different distances from the user. Therefore, to integrate the information, users must repeatedly switch context and refocus the eyes. To focus at different distances, the user's eyes must accommodate, which when done repeatedly can cause eyestrain and degrade task performance. An experiment was conducted that examined switching context and focal distance between a real and an AR environment, using a text-based visual search task and a monocular optical see-through AR display. Both context switching and focal distance switching resulted in significantly reduced performance. In addition, repeatedly performing the task caused visual fatigue to steadily increase. Performance was particularly poor for virtual text presented at optical infinity, and for target letters that participants tried to read before their eyes had completely accommodated to a new focal distance. The results show that context switching and focal distance switching are important AR user interface design issues.", "keywords": ["augmented reality", "data visualisation", "human factors", "user interfaces", "visual perception", "AR display context switching", "focal distance switching", "human performance", "augmented reality environments", "text-based visual search task", "monocular optical see-through AR display", "visual fatigue", "AR user interface design", "Visualization", "Optical switches", "Task analysis", "Fatigue", "Head-up displays", "Multimedia information systems\u2014artificial, augmented, and virtual realities", "User interfaces\u2014ergonomics, evaluation/methodology, screen design, style guides", "Accommodation, Ocular", "Adult", "Asthenopia", "Augmented Reality", "Computer Graphics", "Ergonomics", "Female", "Fixation, Ocular", "Humans", "Male", "Multimedia", "Task Performance and Analysis", "User-Computer Interface", "Young Adult"], "referenced_by": ["IKEY:8446058", "IKEY:8877757", "IKEY:8943689", "IKEY:9090479", "IKEY:9089640", "IKEY:9186694", "IKEY:9284796", "IKEY:9288417"], "referencing": ["IKEY:1528433", "IKEY:5336484", "IKEY:6788128", "IKEY:7274431", "IKEY:4122635", "IKEY:6704805", "IKEY:4637330", "IKEY:996521", "IKEY:6788180", "IKEY:4082053", "IKEY:6797341", "IKEY:1528433", "IKEY:5336484", "IKEY:6788128", "IKEY:7274431", "IKEY:4122635", "IKEY:6704805", "IKEY:4637330", "IKEY:996521", "IKEY:6788180", "IKEY:4082053", "IKEY:6797341", "IKEY:1528433", "IKEY:5336484", "IKEY:6788128", "IKEY:7274431", "IKEY:4122635", "IKEY:6704805", "IKEY:4637330", "IKEY:996521", "IKEY:6788180", "IKEY:4082053", "IKEY:6797341", "10.1145/2713168.2713171", "10.1145/1015706.1015804", "10.1145/1731047.1731057", "10.1145/2667317.2667329", "10.1145/1836248.1836255", "10.1145/2713168.2713171", "10.1145/1015706.1015804", "10.1145/1731047.1731057", "10.1145/2667317.2667329", "10.1145/1836248.1836255", "10.1145/2713168.2713171", "10.1145/1015706.1015804", "10.1145/1731047.1731057", "10.1145/2667317.2667329", "10.1145/1836248.1836255", "10.1007/978-1-4614-0064-6_31", "10.1007/s00464-016-4800-6", "10.1016/j.robot.2012.09.013", "10.2352/J.ImagingSci.Technol.2009.53.3.030201", "10.3758/BF03205906", "10.1016/0141-9382(85)90128-3", "10.1016/0141-9382(94)90059-0", "10.1177/001872088803000605", "10.1167/8.3.33", "10.1364/JOSA.69.000646", "10.1177/001872088502700601", "10.1177/001872087912210609", "10.1080/001401300184486", "10.1111/j.1475-1313.1990.tb00972.x", "10.1016/0042-6989(95)00018-U", "10.1117/1.JEI.21.1.011002", "10.1167/5.10.7", "10.1163/18784763-00002400", "10.1167/10.10.26", "10.1016/0141-9382(80)90052-9", "10.1068/i0566", "10.1364/JOSA.66.000138", "10.1177/154193129103502033", "10.4271/920600", "10.1177/154193128402800617", "10.1518/001872097778543840", "10.21236/AD0770993", "10.1016/0042-6989(82)90126-2", "10.1177/001872089103300106", "10.1177/001872088602800202", "10.21236/ADA108510", "10.1364/AO.49.000F79", "10.1113/jphysiol.1960.sp006438", "10.1016/j.visres.2005.11.012", "10.1007/978-1-4614-0064-6_31", "10.1007/s00464-016-4800-6", "10.1016/j.robot.2012.09.013", "10.2352/J.ImagingSci.Technol.2009.53.3.030201", "10.3758/BF03205906", "10.1016/0141-9382(85)90128-3", "10.1016/0141-9382(94)90059-0", "10.1177/001872088803000605", "10.1167/8.3.33", "10.1364/JOSA.69.000646", "10.1177/001872088502700601", "10.1177/001872087912210609", "10.1080/001401300184486", "10.1111/j.1475-1313.1990.tb00972.x", "10.1016/0042-6989(95)00018-U", "10.1117/1.JEI.21.1.011002", "10.1167/5.10.7", "10.1163/18784763-00002400", "10.1167/10.10.26", "10.1016/0141-9382(80)90052-9", "10.1068/i0566", "10.1364/JOSA.66.000138", "10.1177/154193129103502033", "10.4271/920600", "10.1177/154193128402800617", "10.1518/001872097778543840", "10.21236/AD0770993", "10.1016/0042-6989(82)90126-2", "10.1177/001872089103300106", "10.1177/001872088602800202", "10.21236/ADA108510", "10.1364/AO.49.000F79", "10.1113/jphysiol.1960.sp006438", "10.1016/j.visres.2005.11.012", "10.1007/978-1-4614-0064-6_31", "10.1007/s00464-016-4800-6", "10.1016/j.robot.2012.09.013", "10.2352/J.ImagingSci.Technol.2009.53.3.030201", "10.3758/BF03205906", "10.1016/0141-9382(85)90128-3", "10.1016/0141-9382(94)90059-0", "10.1177/001872088803000605", "10.1167/8.3.33", "10.1364/JOSA.69.000646", "10.1177/001872088502700601", "10.1177/001872087912210609", "10.1080/001401300184486", "10.1111/j.1475-1313.1990.tb00972.x", "10.1016/0042-6989(95)00018-U", "10.1117/1.JEI.21.1.011002", "10.1167/5.10.7", "10.1163/18784763-00002400", "10.1167/10.10.26", "10.1016/0141-9382(80)90052-9", "10.1068/i0566", "10.1364/JOSA.66.000138", "10.1177/154193129103502033", "10.4271/920600", "10.1177/154193128402800617", "10.1518/001872097778543840", "10.21236/AD0770993", "10.1016/0042-6989(82)90126-2", "10.1177/001872089103300106", "10.1177/001872088602800202", "10.21236/ADA108510", "10.1364/AO.49.000F79", "10.1113/jphysiol.1960.sp006438", "10.1016/j.visres.2005.11.012"]}, "10.1109/TVCG.2018.2828422": {"doi": "10.1109/TVCG.2018.2828422", "author": ["L. Wang", "X. Liang", "C. Meng", "V. Popescu"], "title": "Fast Ray-Scene Intersection for Interactive Shadow Rendering with Thousands of Dynamic Lights", "year": "2019", "abstract": "We present a method for the fast computation of the intersection between a ray and the geometry of a scene. The scene geometry is simplified with a 2D array of voxelizations computed from different directions, sampling the space of all possible directions. The 2D array of voxelizations is compressed using a vector quantization approach. The ray-scene intersection is approximated using the voxelization whose rows are most closely aligned with the ray. The voxelization row that contains the ray is looked up, the row is truncated to the extent of the ray using bit operations, and a truncated row with non-zero bits indicates that the ray intersects the scene. We support dynamic scenes with rigidly moving objects by building a separate 2D array of voxelizations for each type of object, and by using the same 2D array of voxelizations for all instances of an object type. We support complex dynamic scenes and scenes with deforming geometry by computing and rotating a single voxelization on the fly. We demonstrate the benefits of our method in the context of interactive rendering of scenes with thousands of moving lights, where we compare our method to ray tracing, to conventional shadow mapping, and to imperfect shadow maps.", "keywords": ["computational geometry", "interactive systems", "ray tracing", "rendering (computer graphics)", "fast ray-scene intersection", "interactive shadow rendering", "dynamic lights", "scene geometry", "voxelization row", "complex dynamic scenes", "vector quantization approach", "Geometry", "Light sources", "Ray tracing", "Acceleration", "Two dimensional displays", "Rendering (computer graphics)", "Lighting", "Real time rendering", "many lights", "visibility determination", "photorealism"], "referenced_by": ["10.1007/s11554-020-01022-6"], "referencing": ["IKEY:4392718", "IKEY:4392726", "IKEY:7429785", "IKEY:7539599", "IKEY:4392718", "IKEY:4392726", "IKEY:7429785", "IKEY:7539599", "IKEY:4392718", "IKEY:4392726", "IKEY:7429785", "IKEY:7539599", "10.1145/1409060.1409082", "10.1145/2556700.2556701", "10.1145/1275808.1276410", "10.1145/1882262.1866169", "10.1145/2508363.2508413", "10.1145/2816795.2818120", "10.1145/1618452.1618478", "10.1145/1944745.1944787", "10.1145/1073204.1073334", "10.1145/1073204.1073318", "10.1145/1409060.1409081", "10.1145/2185520.2185555", "10.1145/3023368.3023376", "10.1145/2018323.2018339", "10.1145/1882262.1866201", "10.1145/2897839.2927418", "10.1145/2018323.2018329", "10.1145/1576246.1531400", "10.1145/1409060.1409082", "10.1145/2556700.2556701", "10.1145/1275808.1276410", "10.1145/1882262.1866169", "10.1145/2508363.2508413", "10.1145/2816795.2818120", "10.1145/1618452.1618478", "10.1145/1944745.1944787", "10.1145/1073204.1073334", "10.1145/1073204.1073318", "10.1145/1409060.1409081", "10.1145/2185520.2185555", "10.1145/3023368.3023376", "10.1145/2018323.2018339", "10.1145/1882262.1866201", "10.1145/2897839.2927418", "10.1145/2018323.2018329", "10.1145/1576246.1531400", "10.1145/1409060.1409082", "10.1145/2556700.2556701", "10.1145/1275808.1276410", "10.1145/1882262.1866169", "10.1145/2508363.2508413", "10.1145/2816795.2818120", "10.1145/1618452.1618478", "10.1145/1944745.1944787", "10.1145/1073204.1073334", "10.1145/1073204.1073318", "10.1145/1409060.1409081", "10.1145/2185520.2185555", "10.1145/3023368.3023376", "10.1145/2018323.2018339", "10.1145/1882262.1866201", "10.1145/2897839.2927418", "10.1145/2018323.2018329", "10.1145/1576246.1531400", "10.1111/cgf.12256", "10.1111/j.1467-8659.2011.01982.x", "10.1111/j.1467-8659.2010.01723.x", "10.1111/1467-8659.00254", "10.1007/978-3-7091-6453-2_23", "10.1111/cgf.13224", "10.1111/cgf.12256", "10.1111/j.1467-8659.2011.01982.x", "10.1111/j.1467-8659.2010.01723.x", "10.1111/1467-8659.00254", "10.1007/978-3-7091-6453-2_23", "10.1111/cgf.13224", "10.1111/cgf.12256", "10.1111/j.1467-8659.2011.01982.x", "10.1111/j.1467-8659.2010.01723.x", "10.1111/1467-8659.00254", "10.1007/978-3-7091-6453-2_23", "10.1111/cgf.13224"]}, "10.1109/TVCG.2018.2832136": {"doi": "10.1109/TVCG.2018.2832136", "author": ["K. Li", "J. Yang", "Y. Lai", "D. Guo"], "title": "Robust Non-Rigid Registration with Reweighted Position and Transformation Sparsity", "year": "2019", "abstract": "Non-rigid registration is challenging because it is ill-posed with high degrees of freedom and is thus sensitive to noise and outliers. We propose a robust non-rigid registration method using reweighted sparsities on position and transformation to estimate the deformations between 3-D shapes. We formulate the energy function with position and transformation sparsity on both the data term and the smoothness term, and define the smoothness constraint using local rigidity. The double sparsity based non-rigid registration model is enhanced with a reweighting scheme, and solved by transferring the model into four alternately-optimized subproblems which have exact solutions and guaranteed convergence. Experimental results on both public datasets and real scanned datasets show that our method outperforms the state-of-the-art methods and is more robust to noise and outliers than conventional non-rigid registration methods.", "keywords": ["estimation theory", "image registration", "optimisation", "nonrigid registration model", "reweighting scheme", "nonrigid registration method", "reweighted position sparsity", "reweighted transformation sparsity", "alternately-optimized subproblems", "energy function", "deformations estimation", "smoothness constraint", "Shape", "Strain", "Robustness", "Three-dimensional displays", "Image reconstruction", "Position measurement", "Computational modeling", "Non-rigid registration", "noise and outliers", "deformation", "position sparsity", "transformation sparsity"], "referenced_by": ["IKEY:9157422", "10.1049/iet-ipr.2019.1527"], "referencing": ["IKEY:4270190", "IKEY:132043", "IKEY:7410710", "IKEY:6247673", "IKEY:5459161", "IKEY:6162880", "IKEY:7298631", "IKEY:7182717", "IKEY:5995632", "IKEY:6165146", "IKEY:4270190", "IKEY:132043", "IKEY:7410710", "IKEY:6247673", "IKEY:5459161", "IKEY:6162880", "IKEY:7298631", "IKEY:7182717", "IKEY:5995632", "IKEY:6165146", "IKEY:4270190", "IKEY:132043", "IKEY:7410710", "IKEY:6247673", "IKEY:5459161", "IKEY:6162880", "IKEY:7298631", "IKEY:7182717", "IKEY:5995632", "IKEY:6165146", "10.1145/566654.566626", "10.1145/882262.882311", "10.1145/2504435.2504456", "10.1145/2010324.1964974", "10.1145/1618452.1618521", "10.1145/1015706.1015736", "10.1145/2517967", "10.1145/1360612.1360696", "10.1145/1516522.1516526", "10.1145/2601097.2601165", "10.1145/566654.566626", "10.1145/882262.882311", "10.1145/2504435.2504456", "10.1145/2010324.1964974", "10.1145/1618452.1618521", "10.1145/1015706.1015736", "10.1145/2517967", "10.1145/1360612.1360696", "10.1145/1516522.1516526", "10.1145/2601097.2601165", "10.1145/566654.566626", "10.1145/882262.882311", "10.1145/2504435.2504456", "10.1145/2010324.1964974", "10.1145/1618452.1618521", "10.1145/1015706.1015736", "10.1145/2517967", "10.1145/1360612.1360696", "10.1145/1516522.1516526", "10.1145/2601097.2601165", "10.1016/j.cam.2010.11.003", "10.1111/cgf.12178", "10.1561/2200000016", "10.1007/s00041-008-9045-x", "10.1111/j.1467-8659.2009.01524.x", "10.1016/S1077-3142(03)00009-2", "10.1002/cpa.20045", "10.1111/j.1467-8659.2008.01282.x", "10.1111/j.1467-8659.2011.02023.x", "10.1111/j.1467-8659.2008.01137.x", "10.1007/s11263-006-5167-2", "10.1016/j.cviu.2004.04.002", "10.1016/0167-2789(92)90242-F", "10.1016/j.cviu.2014.04.011", "10.1111/j.1467-8659.2008.01287.x", "10.1111/cgf.12699", "10.1016/j.cam.2010.11.003", "10.1111/cgf.12178", "10.1561/2200000016", "10.1007/s00041-008-9045-x", "10.1111/j.1467-8659.2009.01524.x", "10.1016/S1077-3142(03)00009-2", "10.1002/cpa.20045", "10.1111/j.1467-8659.2008.01282.x", "10.1111/j.1467-8659.2011.02023.x", "10.1111/j.1467-8659.2008.01137.x", "10.1007/s11263-006-5167-2", "10.1016/j.cviu.2004.04.002", "10.1016/0167-2789(92)90242-F", "10.1016/j.cviu.2014.04.011", "10.1111/j.1467-8659.2008.01287.x", "10.1111/cgf.12699", "10.1016/j.cam.2010.11.003", "10.1111/cgf.12178", "10.1561/2200000016", "10.1007/s00041-008-9045-x", "10.1111/j.1467-8659.2009.01524.x", "10.1016/S1077-3142(03)00009-2", "10.1002/cpa.20045", "10.1111/j.1467-8659.2008.01282.x", "10.1111/j.1467-8659.2011.02023.x", "10.1111/j.1467-8659.2008.01137.x", "10.1007/s11263-006-5167-2", "10.1016/j.cviu.2004.04.002", "10.1016/0167-2789(92)90242-F", "10.1016/j.cviu.2014.04.011", "10.1111/j.1467-8659.2008.01287.x", "10.1111/cgf.12699"]}, "10.1109/TVCG.2018.2831233": {"doi": "10.1109/TVCG.2018.2831233", "author": ["A. Boukhayma", "E. Boyer"], "title": "Surface Motion Capture Animation Synthesis", "year": "2019", "abstract": "We propose to generate novel animations from a set of elementary examples of video-based surface motion capture, under user-specified constraints. 4D surface capture animation is motivated by the increasing demand from media production for highly realistic 3D content. To this aim, data driven strategies that consider video-based information can produce animation with real shapes, kinematics and appearances. Our animations rely on the combination and the interpolation of textured 3D mesh data, which requires examining two aspects: (1) Shape geometry and (2) appearance. First, we propose an animation synthesis structure for the shape geometry, the Essential graph, that outperforms standard Motion graphs in optimality with respect to quantitative criteria, and we extend optimized interpolated transition algorithms to mesh data. Second, we propose a compact view-independent representation for the shape appearance. This representation encodes subject appearance changes due to viewpoint and illumination, and due to inaccuracies in geometric modelling independently. Besides providing compact representations, such decompositions allow for additional applications such as interpolation for animation.", "keywords": ["computational geometry", "computer animation", "graph theory", "image capture", "image motion analysis", "image texture", "interpolation", "mesh generation", "solid modelling", "textured 3D mesh data", "optimized interpolated transition algorithms", "video-based surface motion capture", "4D surface capture animation", "shape geometry", "view-independent representation", "surface motion capture animation synthesis", "Animation", "Shape", "Geometry", "Interpolation", "Three-dimensional displays", "Pipelines", "Motion segmentation", "Character animation", "3D video", "multiview reconstruction", "video-based animation", "4D modeling", "4D performance capture"], "referenced_by": ["10.1049/iet-cvi.2019.0786"], "referencing": ["IKEY:4178157", "IKEY:7298631", "IKEY:4497206", "IKEY:7298623", "IKEY:6909591", "IKEY:4359478", "IKEY:7335517", "IKEY:5206626", "IKEY:4587703", "IKEY:6793549", "IKEY:927467", "IKEY:969116", "IKEY:4178157", "IKEY:6365634", "IKEY:1284395", "IKEY:8099862", "IKEY:8374584", "IKEY:4178157", "IKEY:7298631", "IKEY:4497206", "IKEY:7298623", "IKEY:6909591", "IKEY:4359478", "IKEY:7335517", "IKEY:5206626", "IKEY:4587703", "IKEY:6793549", "IKEY:927467", "IKEY:969116", "IKEY:4178157", "IKEY:6365634", "IKEY:1284395", "IKEY:8099862", "IKEY:8374584", "IKEY:4178157", "IKEY:7298631", "IKEY:4497206", "IKEY:7298623", "IKEY:6909591", "IKEY:4359478", "IKEY:7335517", "IKEY:5206626", "IKEY:4587703", "IKEY:6793549", "IKEY:927467", "IKEY:969116", "IKEY:4178157", "IKEY:6365634", "IKEY:1284395", "IKEY:8099862", "IKEY:8374584", "10.1145/2766945", "10.1145/2897824.2925969", "10.1145/1882261.1866161", "10.1145/1618452.1618520", "10.1145/566570.566590", "10.1145/2897824.2925967", "10.1145/566654.566605", "10.1145/566654.566607", "10.1145/566654.566606", "10.1145/1276377.1276510", "10.1145/1073368.1073375", "10.1145/1015706.1015760", "10.1145/2699643", "10.1145/2897824.2925975", "10.1145/3072959.3073663", "10.1145/1330511.1330512", "10.1145/1186562.1015766", "10.1145/1964921.1964927", "10.1145/311535.311556", "10.1145/1399504.1360696", "10.1145/1060244.1060274", "10.1145/2766945", "10.1145/2897824.2925969", "10.1145/1882261.1866161", "10.1145/1618452.1618520", "10.1145/566570.566590", "10.1145/2897824.2925967", "10.1145/566654.566605", "10.1145/566654.566607", "10.1145/566654.566606", "10.1145/1276377.1276510", "10.1145/1073368.1073375", "10.1145/1015706.1015760", "10.1145/2699643", "10.1145/2897824.2925975", "10.1145/3072959.3073663", "10.1145/1330511.1330512", "10.1145/1186562.1015766", "10.1145/1964921.1964927", "10.1145/311535.311556", "10.1145/1399504.1360696", "10.1145/1060244.1060274", "10.1145/2766945", "10.1145/2897824.2925969", "10.1145/1882261.1866161", "10.1145/1618452.1618520", "10.1145/566570.566590", "10.1145/2897824.2925967", "10.1145/566654.566605", "10.1145/566654.566607", "10.1145/566654.566606", "10.1145/1276377.1276510", "10.1145/1073368.1073375", "10.1145/1015706.1015760", "10.1145/2699643", "10.1145/2897824.2925975", "10.1145/3072959.3073663", "10.1145/1330511.1330512", "10.1145/1186562.1015766", "10.1145/1964921.1964927", "10.1145/311535.311556", "10.1145/1399504.1360696", "10.1145/1060244.1060274", "10.1007/978-3-319-46484-8_22", "10.1007/978-3-319-46478-7_17", "10.1007/978-3-319-46448-0_14", "10.1111/cgf.12296", "10.1111/j.1467-8659.2009.01624.x", "10.1111/j.1467-8659.2008.01138.x", "10.1007/s11263-013-0654-8", "10.5244/C.28.8", "10.1111/cgf.12756", "10.1007/s11263-010-0319-9", "10.1007/s10851-009-0161-2", "10.1214/009053607000000505", "10.1007/978-3-540-74048-3", "10.1007/s11263-012-0553-4", "10.5201/ipol.2013.26", "10.1007/978-3-319-46484-8_22", "10.1007/978-3-319-46478-7_17", "10.1007/978-3-319-46448-0_14", "10.1111/cgf.12296", "10.1111/j.1467-8659.2009.01624.x", "10.1111/j.1467-8659.2008.01138.x", "10.1007/s11263-013-0654-8", "10.5244/C.28.8", "10.1111/cgf.12756", "10.1007/s11263-010-0319-9", "10.1007/s10851-009-0161-2", "10.1214/009053607000000505", "10.1007/978-3-540-74048-3", "10.1007/s11263-012-0553-4", "10.5201/ipol.2013.26", "10.1007/978-3-319-46484-8_22", "10.1007/978-3-319-46478-7_17", "10.1007/978-3-319-46448-0_14", "10.1111/cgf.12296", "10.1111/j.1467-8659.2009.01624.x", "10.1111/j.1467-8659.2008.01138.x", "10.1007/s11263-013-0654-8", "10.5244/C.28.8", "10.1111/cgf.12756", "10.1007/s11263-010-0319-9", "10.1007/s10851-009-0161-2", "10.1214/009053607000000505", "10.1007/978-3-540-74048-3", "10.1007/s11263-012-0553-4", "10.5201/ipol.2013.26"]}, "10.1109/TVCG.2018.2832080": {"doi": "10.1109/TVCG.2018.2832080", "author": ["J. Bender", "D. Koschier", "T. Kugelstadt", "M. Weiler"], "title": "Turbulent Micropolar SPH Fluids with Foam", "year": "2019", "abstract": "In this paper we introduce a novel micropolar material model for the simulation of turbulent inviscid fluids. The governing equations are solved by using the concept of Smoothed Particle Hydrodynamics (SPH). As already investigated in previous works, SPH fluid simulations suffer from numerical diffusion which leads to a lower vorticity, a loss in turbulent details and finally in less realistic results. To solve this problem we propose a micropolar fluid model. The micropolar fluid model is a generalization of the classical Navier-Stokes equations, which are typically used in computer graphics to simulate fluids. In contrast to the classical Navier-Stokes model, micropolar fluids have a microstructure and therefore consider the rotational motion of fluid particles. In addition to the linear velocity field these fluids also have a field of microrotation which represents existing vortices and provides a source for new ones. However, classical micropolar materials are viscous and the translational and the rotational motion are coupled in a dissipative way. Since our goal is to simulate turbulent fluids, we introduce a novel modified micropolar material for inviscid fluids with a non-dissipative coupling. Our model can generate realistic turbulences, is linear and angular momentum conserving, can be easily integrated in existing SPH simulation methods and its computational overhead is negligible. Another important visual feature of turbulent liquids is foam. Therefore, we present a post-processing method which considers microrotation in the foam particle generation. It works completely automatic and requires only one user-defined parameter to control the amount of foam.", "keywords": ["computational fluid dynamics", "flow simulation", "foams", "geophysical fluid dynamics", "hydrodynamics", "Navier-Stokes equations", "turbulence", "vortices", "turbulent liquids", "foam particle generation", "turbulent micropolar SPH fluids", "novel micropolar material model", "turbulent inviscid fluids", "SPH fluid simulations", "micropolar fluid model", "classical Navier-Stokes equations", "classical Navier-Stokes model", "micropolar fluids", "rotational motion", "fluid particles", "classical micropolar materials", "turbulent fluids", "realistic turbulences", "user-defined parameter", "angular momentum", "micropolar materials", "linear velocity field", "microstructure", "computer graphics", "vorticity", "numerical diffusion", "micropolar material", "smoothed particle hydrodynamics", "SPH simulation methods", "Computational modeling", "Mathematical model", "Numerical models", "Visualization", "Fluids", "Smoothed particle hydrodynamics", "micropolar fluids", "turbulence", "incompressible fluids", "foam"], "referenced_by": ["IKEY:9090460", "IKEY:9089636", "IKEY:9136677", "IKEY:9123549", "10.1145/3355089.3356503", "10.1016/j.cag.2018.08.001", "10.1007/978-3-030-30949-7_29", "10.3390/w12010215", "10.1007/s00371-020-01914-5", "10.1002/cav.1973", "10.3390/w12071873", "10.1002/cav.1984"], "referencing": ["IKEY:6570475", "IKEY:7487018", "IKEY:4459322", "IKEY:8223531", "IKEY:8147897", "IKEY:6570475", "IKEY:7487018", "IKEY:4459322", "IKEY:8223531", "IKEY:8147897", "IKEY:6570475", "IKEY:7487018", "IKEY:4459322", "IKEY:8223531", "IKEY:8147897", "10.1145/2766901", "10.1145/383259.383260", "10.1145/1360612.1360647", "10.1145/2461912.2461984", "10.1145/1531326.1531346", "10.1145/2994258.2994282", "10.1145/2019406.2019419", "10.1145/2766982", "10.1145/1073368.1073406", "10.1145/1073204.1073282", "10.1145/1073368.1073380", "10.1145/2185520.2335463", "10.1145/2366145.2366167", "10.1145/2661229.2661261", "10.1145/1360612.1360649", "10.1145/1409060.1409119", "10.1145/2451236.2451241", "10.1145/2816795.2818115", "10.1145/2766996", "10.1145/3099564.3099578", "10.1145/2185520.2335413", "10.1145/2185520.2335412", "10.1145/3099564.3099565", "10.1145/2766901", "10.1145/383259.383260", "10.1145/1360612.1360647", "10.1145/2461912.2461984", "10.1145/1531326.1531346", "10.1145/2994258.2994282", "10.1145/2019406.2019419", "10.1145/2766982", "10.1145/1073368.1073406", "10.1145/1073204.1073282", "10.1145/1073368.1073380", "10.1145/2185520.2335463", "10.1145/2366145.2366167", "10.1145/2661229.2661261", "10.1145/1360612.1360649", "10.1145/1409060.1409119", "10.1145/2451236.2451241", "10.1145/2816795.2818115", "10.1145/2766996", "10.1145/3099564.3099578", "10.1145/2185520.2335413", "10.1145/2185520.2335412", "10.1145/3099564.3099565", "10.1145/2766901", "10.1145/383259.383260", "10.1145/1360612.1360647", "10.1145/2461912.2461984", "10.1145/1531326.1531346", "10.1145/2994258.2994282", "10.1145/2019406.2019419", "10.1145/2766982", "10.1145/1073368.1073406", "10.1145/1073204.1073282", "10.1145/1073368.1073380", "10.1145/2185520.2335463", "10.1145/2366145.2366167", "10.1145/2661229.2661261", "10.1145/1360612.1360649", "10.1145/1409060.1409119", "10.1145/2451236.2451241", "10.1145/2816795.2818115", "10.1145/2766996", "10.1145/3099564.3099578", "10.1145/2185520.2335413", "10.1145/2185520.2335412", "10.1145/3099564.3099565", "10.2312/egst.20141034", "10.1111/cgf.12324", "10.1007/978-1-4612-0641-5", "10.1007/s00371-012-0697-9", "10.1111/1467-8659.00687", "10.1007/s00371-010-0487-1", "10.1111/j.1467-8659.2010.01809.x", "10.1007/s00371-011-0626-3", "10.1002/cav.1607", "10.1512/iumj.1967.16.16001", "10.1016/0020-7225(69)90036-6", "10.1063/1.1676782", "10.1016/0020-7225(74)90059-7", "10.1080/10402008908981874", "10.21236/ADA479067", "10.1111/1467-8659.00686", "10.1007/s00371-013-0849-6", "10.1111/j.1467-8659.2009.01362.x", "10.1115/1.483244", "10.1111/j.1467-8659.2010.01734.x", "10.1177/1740349911400132", "10.1146/annurev.aa.30.090192.002551", "10.1088/0034-4885/68/8/R01", "10.1111/cgf.13349", "10.1016/0021-9991(89)90032-6", "10.1111/j.1467-8659.2010.01832.x", "10.1016/0021-9991(82)90058-4", "10.1006/jcph.1999.6246", "10.1002/cav.1614", "10.2312/egst.20141034", "10.1111/cgf.12324", "10.1007/978-1-4612-0641-5", "10.1007/s00371-012-0697-9", "10.1111/1467-8659.00687", "10.1007/s00371-010-0487-1", "10.1111/j.1467-8659.2010.01809.x", "10.1007/s00371-011-0626-3", "10.1002/cav.1607", "10.1512/iumj.1967.16.16001", "10.1016/0020-7225(69)90036-6", "10.1063/1.1676782", "10.1016/0020-7225(74)90059-7", "10.1080/10402008908981874", "10.21236/ADA479067", "10.1111/1467-8659.00686", "10.1007/s00371-013-0849-6", "10.1111/j.1467-8659.2009.01362.x", "10.1115/1.483244", "10.1111/j.1467-8659.2010.01734.x", "10.1177/1740349911400132", "10.1146/annurev.aa.30.090192.002551", "10.1088/0034-4885/68/8/R01", "10.1111/cgf.13349", "10.1016/0021-9991(89)90032-6", "10.1111/j.1467-8659.2010.01832.x", "10.1016/0021-9991(82)90058-4", "10.1006/jcph.1999.6246", "10.1002/cav.1614", "10.2312/egst.20141034", "10.1111/cgf.12324", "10.1007/978-1-4612-0641-5", "10.1007/s00371-012-0697-9", "10.1111/1467-8659.00687", "10.1007/s00371-010-0487-1", "10.1111/j.1467-8659.2010.01809.x", "10.1007/s00371-011-0626-3", "10.1002/cav.1607", "10.1512/iumj.1967.16.16001", "10.1016/0020-7225(69)90036-6", "10.1063/1.1676782", "10.1016/0020-7225(74)90059-7", "10.1080/10402008908981874", "10.21236/ADA479067", "10.1111/1467-8659.00686", "10.1007/s00371-013-0849-6", "10.1111/j.1467-8659.2009.01362.x", "10.1115/1.483244", "10.1111/j.1467-8659.2010.01734.x", "10.1177/1740349911400132", "10.1146/annurev.aa.30.090192.002551", "10.1088/0034-4885/68/8/R01", "10.1111/cgf.13349", "10.1016/0021-9991(89)90032-6", "10.1111/j.1467-8659.2010.01832.x", "10.1016/0021-9991(82)90058-4", "10.1006/jcph.1999.6246", "10.1002/cav.1614"]}, "10.1109/TVCG.2018.2831220": {"doi": "10.1109/TVCG.2018.2831220", "author": ["W. Li", "H. Gong", "R. Yang"], "title": "Fast Texture Mapping Adjustment via Local/Global Optimization", "year": "2019", "abstract": "This paper deals with the texture mapping of a triangular mesh model given a set of calibrated images. Different from the traditional approach of applying projective texture mapping with model parameterizations, we develop an image-space texture optimization scheme that aims to reduce visible seams or misalignment at texture or depth boundaries. Our novel scheme starts with an efficient local (and parallel) texture adjustment scheme at these boundaries, followed by a global correction step to rectify potential texture distortions caused by the local movement. Our phased optimization scheme achieves 50~100 times speed up on GPU (or 6\u00d7 on CPU) compared to previous state-of-the-art methods. Experiments on a variety of models showed that we achieve this significant speedup without sacrificing texture quality. Our approach significantly improves resilience to modeling and calibration errors, thereby allowing fast and fully automatic creation of textured models using commodity depth sensors by untrained users.", "keywords": ["calibration", "image texture", "mesh generation", "optimisation", "fast texture mapping adjustment", "triangular mesh model", "calibrated images", "projective texture mapping", "model parameterizations", "image-space texture optimization scheme", "texture adjustment scheme", "global correction step", "phased optimization scheme", "texture quality", "texture distortions", "calibration errors", "local-global optimization", "depth boundaries", "commodity depth sensors", "Optimization", "Three-dimensional displays", "Solid modeling", "Computational modeling", "Image color analysis", "Cameras", "Sensors", "Texture mapping", "parameterization", "texture optimization"], "referenced_by": ["IKEY:9060898", "IKEY:9225004"], "referencing": ["IKEY:6162880", "IKEY:7298631", "IKEY:4270103", "IKEY:7025407", "IKEY:4563095", "IKEY:6162880", "IKEY:7298631", "IKEY:4270103", "IKEY:7025407", "IKEY:4563095", "IKEY:6162880", "IKEY:7298631", "IKEY:4270103", "IKEY:7025407", "IKEY:4563095", "10.1145/2047196.2047270", "10.1145/3054739", "10.1145/566654.566635", "10.1145/2601097.2601134", "10.1145/1073204.1073325", "10.1145/1141911.1141930", "10.1145/1531326.1531351", "10.1145/882262.882271", "10.1145/383259.383307", "10.1145/882262.882269", "10.1145/2047196.2047270", "10.1145/3054739", "10.1145/566654.566635", "10.1145/2601097.2601134", "10.1145/1073204.1073325", "10.1145/1141911.1141930", "10.1145/1531326.1531351", "10.1145/882262.882271", "10.1145/383259.383307", "10.1145/882262.882269", "10.1145/2047196.2047270", "10.1145/3054739", "10.1145/566654.566635", "10.1145/2601097.2601134", "10.1145/1073204.1073325", "10.1145/1141911.1141930", "10.1145/1531326.1531351", "10.1145/882262.882271", "10.1145/383259.383307", "10.1145/882262.882269", "10.1007/978-3-319-46484-8_22", "10.1007/978-3-319-10602-1_54", "10.1111/j.1467-8659.2009.01617.x", "10.5244/C.16.38", "10.1007/978-3-7091-6809-7_12", "10.1111/j.1467-8659.2008.01138.x", "10.1007/s11263-011-0437-z", "10.1007/978-3-319-46484-8_22", "10.1007/978-3-319-10602-1_54", "10.1111/j.1467-8659.2009.01617.x", "10.5244/C.16.38", "10.1007/978-3-7091-6809-7_12", "10.1111/j.1467-8659.2008.01138.x", "10.1007/s11263-011-0437-z", "10.1007/978-3-319-46484-8_22", "10.1007/978-3-319-10602-1_54", "10.1111/j.1467-8659.2009.01617.x", "10.5244/C.16.38", "10.1007/978-3-7091-6809-7_12", "10.1111/j.1467-8659.2008.01138.x", "10.1007/s11263-011-0437-z"]}, "10.1109/TVCG.2018.2828818": {"doi": "10.1109/TVCG.2018.2828818", "author": ["S. K. Yadav", "U. Reitebuch", "K. Polthier"], "title": "Robust and High Fidelity Mesh Denoising", "year": "2019", "abstract": "This paper presents a simple and effective two-stage mesh denoising algorithm, where in the first stage, face normal filtering is done by using bilateral normal filtering in a robust statistics framework. Tukey's bi-weight function is used as similarity function in the bilateral weighting, which is a robust estimator and stops the diffusion at sharp edges to retain features and removes noise from flat regions effectively. In the second stage, an edge-weighted Laplace operator is introduced to compute a differential coordinate. This differential coordinate helps the algorithm to produce a high-quality mesh without any face normal flips and makes the method robust against high-intensity noise.", "keywords": ["estimation theory", "image denoising", "image filtering", "mesh generation", "face normal filtering", "bilateral normal filtering", "robust statistics framework", "similarity function", "bilateral weighting", "robust estimator", "sharp edges", "edge-weighted Laplace operator", "high-quality mesh", "high fidelity mesh denoising", "two-stage mesh denoising", "Tukey bi-weight function", "differential coordinate", "Face", "Robustness", "Noise reduction", "Noise measurement", "Geometry", "Surface treatment", "Smoothing methods", "Robust statistics", "face normal processing", "tukey's bi-weight function", "high fidelity mesh", "differential coordinate"], "referenced_by": ["IKEY:8614304", "IKEY:8824104", "IKEY:9200581", "IKEY:9253344"], "referencing": ["IKEY:1388228", "IKEY:710815", "IKEY:1008390", "IKEY:661192", "IKEY:5128905", "IKEY:5674028", "IKEY:6822598", "IKEY:7467494", "IKEY:7328329", "IKEY:4276075", "IKEY:1388228", "IKEY:710815", "IKEY:1008390", "IKEY:661192", "IKEY:5128905", "IKEY:5674028", "IKEY:6822598", "IKEY:7467494", "IKEY:7328329", "IKEY:4276075", "IKEY:1388228", "IKEY:710815", "IKEY:1008390", "IKEY:661192", "IKEY:5128905", "IKEY:5674028", "IKEY:6822598", "IKEY:7467494", "IKEY:7328329", "IKEY:4276075", "10.1145/1174429.1174494", "10.1145/566570.566574", "10.1145/1201775.882368", "10.1145/882262.882367", "10.1145/1276377.1276497", "10.1145/2980179.2980232", "10.1145/2461912.2461965", "10.1145/2557449", "10.1145/1174429.1174494", "10.1145/566570.566574", "10.1145/1201775.882368", "10.1145/882262.882367", "10.1145/1276377.1276497", "10.1145/2980179.2980232", "10.1145/2461912.2461965", "10.1145/2557449", "10.1145/1174429.1174494", "10.1145/566570.566574", "10.1145/1201775.882368", "10.1145/882262.882367", "10.1145/1276377.1276497", "10.1145/2980179.2980232", "10.1145/2461912.2461965", "10.1145/2557449", "10.1111/j.1467-8659.2006.00999.x", "10.1201/b10688", "10.1364/BOE.8.004181", "10.1142/S0218654305000724", "10.1111/j.1467-8659.2004.00770.x", "10.1111/cgf.12742", "10.1111/cgf.12743", "10.1016/j.cagd.2017.02.011", "10.1111/j.1467-8659.2006.00999.x", "10.1201/b10688", "10.1364/BOE.8.004181", "10.1142/S0218654305000724", "10.1111/j.1467-8659.2004.00770.x", "10.1111/cgf.12742", "10.1111/cgf.12743", "10.1016/j.cagd.2017.02.011", "10.1111/j.1467-8659.2006.00999.x", "10.1201/b10688", "10.1364/BOE.8.004181", "10.1142/S0218654305000724", "10.1111/j.1467-8659.2004.00770.x", "10.1111/cgf.12742", "10.1111/cgf.12743", "10.1016/j.cagd.2017.02.011"]}, "10.1109/TVCG.2018.2830759": {"doi": "10.1109/TVCG.2018.2830759", "author": ["F. Windhager", "P. Federico", "G. Schreder", "K. Glinka", "M. D\u00f6rk", "S. Miksch", "E. Mayr"], "title": "Visualization of Cultural Heritage Collection Data: State of the Art and Future Challenges", "year": "2019", "abstract": "After decades of digitization, large cultural heritage collections have emerged on the web, which contain massive stocks of content from galleries, libraries, archives, and museums. This increase in digital cultural heritage data promises new modes of analysis and increased levels of access for academic scholars and casual users alike. Going beyond the standard representations of search-centric and grid-based interfaces, a multitude of approaches has recently started to enable visual access to cultural collections, and to explore them as complex and comprehensive information spaces by the means of interactive visualizations. In contrast to conventional web interfaces, we witness a widening spectrum of innovative visualization types specially designed for rich collections from the cultural heritage sector. This new class of information visualizations gives rise to a notable diversity of interaction and representation techniques while lending currency and urgency to a discussion about principles such as serendipity, generosity, and criticality in connection with visualization design. With this survey, we review information visualization approaches to digital cultural heritage collections and reflect on the state of the art in techniques and design choices. We contextualize our survey with humanist perspectives on the field and point out opportunities for future research.", "keywords": ["data visualisation", "history", "interactive systems", "user interfaces", "grid-based interfaces", "interactive visualizations", "information visualization", "representation techniques", "visualization design", "digital cultural heritage collections", "interaction techniques", "digital cultural heritage data visualization", "search-centric interfaces", "Cultural differences", "Data visualization", "Libraries", "Visualization", "Art", "Prototypes", "Tools", "Information visualization", "introductory and survey", "digital libraries", "arts and humanities"], "referenced_by": [], "referencing": ["10.1145/2207676.2208607", "10.1145/2499149.2499159", "10.1145/1978942.1979124", "10.1145/2598153.2598159", "10.1145/3105971.3105989", "10.1145/2254556.2254658", "10.1145/1141753.1141755", "10.1145/3025171.3025226", "10.1145/1413634.1413659", "10.1145/1998076.1998169", "10.1145/996350.996426", "10.1145/3105971.3105989", "10.1145/2595188.2595215", "10.1145/2468356.2468458", "10.1145/2468356.2468739", "10.1145/2858036.2858549", "10.1145/2207676.2208607", "10.1145/2499149.2499159", "10.1145/1978942.1979124", "10.1145/2598153.2598159", "10.1145/3105971.3105989", "10.1145/2254556.2254658", "10.1145/1141753.1141755", "10.1145/3025171.3025226", "10.1145/1413634.1413659", "10.1145/1998076.1998169", "10.1145/996350.996426", "10.1145/3105971.3105989", "10.1145/2595188.2595215", "10.1145/2468356.2468458", "10.1145/2468356.2468739", "10.1145/2858036.2858549", "10.1145/2207676.2208607", "10.1145/2499149.2499159", "10.1145/1978942.1979124", "10.1145/2598153.2598159", "10.1145/3105971.3105989", "10.1145/2254556.2254658", "10.1145/1141753.1141755", "10.1145/3025171.3025226", "10.1145/1413634.1413659", "10.1145/1998076.1998169", "10.1145/996350.996426", "10.1145/3105971.3105989", "10.1145/2595188.2595215", "10.1145/2468356.2468458", "10.1145/2468356.2468739", "10.1145/2858036.2858549", "10.1002/evan.10110", "10.7551/mitpress/9780262033534.001.0001", "10.4324/9780203937884", "10.4324/9780203347485", "10.1080/13527250600604639", "10.1007/978-1-4471-5406-8_3", "10.1177/1473871612473590", "10.1126/science.1240064", "10.1007/978-3-642-38241-3_11", "10.1016/j.cag.2013.11.002", "10.1016/j.websem.2015.06.003", "10.1007/s11042-008-0253-9", "10.1016/j.cag.2016.03.009", "10.1179/174327909X441153", "10.1045/november2012-algee", "10.1093/llc/fqt043", "10.1002/(SICI)1097-4571(2000)51:4&lt;380::AID-ASI7&gt;3.0.CO;2-5", "10.1108/eb024320", "10.1007/978-0-85729-079-3", "10.5220/0005585801860194", "10.4108/icst.intetain.2015.259506", "10.1162/LEON_a_01230", "10.1016/j.is.2011.09.009", "10.1080/07317131.2015.972871", "10.1016/j.jasrep.2016.10.013", "10.1007/978-3-642-02115-2_3", "10.1108/00220410310472518", "10.1002/asi.23200", "10.1007/978-3-642-04346-8_20", "10.7559/citarj.v8i2.182", "10.1146/annurev.an.22.100193.001221", "10.14236/ewic/EVA2016.44", "10.1057/palgrave.ivs.9500173", "10.1016/j.culher.2010.04.001", "10.1007/978-1-4471-6497-5_1", "10.1111/cgf.12873", "10.1007/978-3-642-38288-8_40", "10.29379/jedem.v8i2.436", "10.1515/9783110330496.137", "10.1002/evan.10110", "10.7551/mitpress/9780262033534.001.0001", "10.4324/9780203937884", "10.4324/9780203347485", "10.1080/13527250600604639", "10.1007/978-1-4471-5406-8_3", "10.1177/1473871612473590", "10.1126/science.1240064", "10.1007/978-3-642-38241-3_11", "10.1016/j.cag.2013.11.002", "10.1016/j.websem.2015.06.003", "10.1007/s11042-008-0253-9", "10.1016/j.cag.2016.03.009", "10.1179/174327909X441153", "10.1045/november2012-algee", "10.1093/llc/fqt043", "10.1002/(SICI)1097-4571(2000)51:4&lt;380::AID-ASI7&gt;3.0.CO;2-5", "10.1108/eb024320", "10.1007/978-0-85729-079-3", "10.5220/0005585801860194", "10.4108/icst.intetain.2015.259506", "10.1162/LEON_a_01230", "10.1016/j.is.2011.09.009", "10.1080/07317131.2015.972871", "10.1016/j.jasrep.2016.10.013", "10.1007/978-3-642-02115-2_3", "10.1108/00220410310472518", "10.1002/asi.23200", "10.1007/978-3-642-04346-8_20", "10.7559/citarj.v8i2.182", "10.1146/annurev.an.22.100193.001221", "10.14236/ewic/EVA2016.44", "10.1057/palgrave.ivs.9500173", "10.1016/j.culher.2010.04.001", "10.1007/978-1-4471-6497-5_1", "10.1111/cgf.12873", "10.1007/978-3-642-38288-8_40", "10.29379/jedem.v8i2.436", "10.1515/9783110330496.137", "10.1002/evan.10110", "10.7551/mitpress/9780262033534.001.0001", "10.4324/9780203937884", "10.4324/9780203347485", "10.1080/13527250600604639", "10.1007/978-1-4471-5406-8_3", "10.1177/1473871612473590", "10.1126/science.1240064", "10.1007/978-3-642-38241-3_11", "10.1016/j.cag.2013.11.002", "10.1016/j.websem.2015.06.003", "10.1007/s11042-008-0253-9", "10.1016/j.cag.2016.03.009", "10.1179/174327909X441153", "10.1045/november2012-algee", "10.1093/llc/fqt043", "10.1002/(SICI)1097-4571(2000)51:4&lt;380::AID-ASI7&gt;3.0.CO;2-5", "10.1108/eb024320", "10.1007/978-0-85729-079-3", "10.5220/0005585801860194", "10.4108/icst.intetain.2015.259506", "10.1162/LEON_a_01230", "10.1016/j.is.2011.09.009", "10.1080/07317131.2015.972871", "10.1016/j.jasrep.2016.10.013", "10.1007/978-3-642-02115-2_3", "10.1108/00220410310472518", "10.1002/asi.23200", "10.1007/978-3-642-04346-8_20", "10.7559/citarj.v8i2.182", "10.1146/annurev.an.22.100193.001221", "10.14236/ewic/EVA2016.44", "10.1057/palgrave.ivs.9500173", "10.1016/j.culher.2010.04.001", "10.1007/978-1-4471-6497-5_1", "10.1111/cgf.12873", "10.1007/978-3-642-38288-8_40", "10.29379/jedem.v8i2.436", "10.1515/9783110330496.137"]}, "10.1109/TVCG.2019.2905056": {"doi": "10.1109/TVCG.2019.2905056", "author": [""], "title": "2018 Reviewers List", "year": "2019", "abstract": "Presents a listing of reviewers who contributed to this publication in 2018.", "keywords": ["IEEE publishing"], "referenced_by": [], "referencing": []}}