{"10.1109/TVCG.2013.252": {"doi": "10.1109/TVCG.2013.252", "author": ["C. Pontonnier", "A. Samani", "M. Badawi", "P. Madeleine", "G. Dumont"], "title": "Assessing the Ability of a VR-Based Assembly Task Simulation to Evaluate PhysicalRisk Factors", "year": "2014", "abstract": "Nowadays the process of workstation design tends to include assessment steps in a virtual environment (VE) to evaluate the ergonomic features. These approaches are cost-effective and convenient since working directly on the digital mock-up in a VE is preferable to constructing a real physical mock-up in a real environment (RE). This study aimed at understanding the ability of a VR-based assembly tasks simulator to evaluate physical risk factors in ergonomics. Sixteen subjects performed simplified assembly tasks in RE and VE. Motion of the upper body and five muscle electromyographic activities were recorded to compute normalized and averaged objective indicators of discomfort, that is, rapid upper limb assessment score, averaged muscle activations, and total task time. Rated perceived exertion (RPE) and a questionnaire were used as subjective indicators of discomfort. The timing regime and complexity of the assembly tasks were investigated as within-subject factors. The results revealed significant differences between measured indicators in RE and VE. While objective measures indicated lower activity and exposure in VE, the subjects experienced more discomfort than in RE. Fairly good correlation levels were found between RE and VE for six of the objective indicators. This study clearly demonstrates that ergonomic studies of assembly tasks using VR are still challenging. Indeed, objective and subjective measurements of discomfort that are usually used in ergonomics to minimize the risks of work-related musculoskeletal disorders development exhibit opposite trends in RE and VE. Nevertheless, the high level of correlation found during this study indicates that the VR-based simulator can be used for such assessments.", "keywords": ["bone", "digital simulation", "electromyography", "ergonomics", "medical computing", "medical disorders", "muscle", "occupational health", "virtual reality", "VR-based assembly task simulation ability assessment", "physical risk factor evaluation", "workstation design", "virtual environment", "ergonomic feature evaluation", "digital mock-up", "real physical mock-up", "real environment", "RE", "upper body motion", "muscle electromyographic activities", "normalized objective indicators", "averaged objective indicators", "rapid upper limb assessment score", "averaged muscle activations", "total task time", "rated perceived exertion", "subjective discomfort indicators", "discomfort measurements", "work-related musculoskeletal disorder development risks", "Ergonomics", "Assembly", "Muscles", "Complexity theory", "Electromyography", "Haptic interfaces", "Fidelity", "ergonomics", "motion capture", "emg", "assembly task", "user study"], "referenced_by": ["IKEY:8346271", "IKEY:8525738", "10.1145/3134301", "10.1007/978-3-319-41694-6_92", "10.1007/978-3-319-72323-5_6", "10.1007/s12008-015-0289-9", "10.3390/computers5040026", "10.1016/j.mechatronics.2018.02.009", "10.1371/journal.pone.0116211", "10.1007/s12193-016-0231-x", "10.1016/j.apergo.2019.04.001", "10.1007/s12193-013-0138-8", "10.1007/978-3-319-41627-4_16", "10.1007/978-3-030-51064-0_29", "10.1061/(ASCE)CO.1943-7862.0001997"], "referencing": ["IKEY:6165144", "IKEY:6421988", "IKEY:6788121", "IKEY:6787863", "IKEY:1371525", "IKEY:6788002", "IKEY:6165144", "IKEY:6421988", "IKEY:6788121", "IKEY:6787863", "IKEY:1371525", "IKEY:6788002", "IKEY:6165144", "IKEY:6421988", "IKEY:6788121", "IKEY:6787863", "IKEY:1371525", "IKEY:6788002", "10.1097/SLA.0b013e3180f61b09", "10.1504/IJMR.2007.014645", "10.5271/sjweh.1815", "10.1016/j.jelekin.2010.07.004", "10.1089/109493101300210222", "10.1016/S0003-6870(99)00039-3", "10.1016/j.ergon.2010.10.001", "10.1016/j.compind.2005.12.005", "10.1016/j.apergo.2011.06.002", "10.1007/s00421-002-0655-8", "10.1016/j.apergo.2008.12.006", "10.1007/978-3-540-73321-8_106", "10.1016/0003-6870(93)90080-S", "10.1007/978-0-387-49864-5_60", "10.1115/ESDA2012-82254", "10.1007/s12008-009-0078-4", "10.1080/17452759.2010.504082", "10.1177/0018720812465006", "10.1023/A:1008278929841", "10.1037//0022-006X.68.6.1020", "10.1201/9781410608888.ch6", "10.1016/j.humov.2011.02.001", "10.1007/s00464-008-0298-x", "10.1016/S0003-6870(98)00040-4", "10.1097/SLA.0b013e3180f61b09", "10.1504/IJMR.2007.014645", "10.5271/sjweh.1815", "10.1016/j.jelekin.2010.07.004", "10.1089/109493101300210222", "10.1016/S0003-6870(99)00039-3", "10.1016/j.ergon.2010.10.001", "10.1016/j.compind.2005.12.005", "10.1016/j.apergo.2011.06.002", "10.1007/s00421-002-0655-8", "10.1016/j.apergo.2008.12.006", "10.1007/978-3-540-73321-8_106", "10.1016/0003-6870(93)90080-S", "10.1007/978-0-387-49864-5_60", "10.1115/ESDA2012-82254", "10.1007/s12008-009-0078-4", "10.1080/17452759.2010.504082", "10.1177/0018720812465006", "10.1023/A:1008278929841", "10.1037//0022-006X.68.6.1020", "10.1201/9781410608888.ch6", "10.1016/j.humov.2011.02.001", "10.1007/s00464-008-0298-x", "10.1016/S0003-6870(98)00040-4", "10.1097/SLA.0b013e3180f61b09", "10.1504/IJMR.2007.014645", "10.5271/sjweh.1815", "10.1016/j.jelekin.2010.07.004", "10.1089/109493101300210222", "10.1016/S0003-6870(99)00039-3", "10.1016/j.ergon.2010.10.001", "10.1016/j.compind.2005.12.005", "10.1016/j.apergo.2011.06.002", "10.1007/s00421-002-0655-8", "10.1016/j.apergo.2008.12.006", "10.1007/978-3-540-73321-8_106", "10.1016/0003-6870(93)90080-S", "10.1007/978-0-387-49864-5_60", "10.1115/ESDA2012-82254", "10.1007/s12008-009-0078-4", "10.1080/17452759.2010.504082", "10.1177/0018720812465006", "10.1023/A:1008278929841", "10.1037//0022-006X.68.6.1020", "10.1201/9781410608888.ch6", "10.1016/j.humov.2011.02.001", "10.1007/s00464-008-0298-x", "10.1016/S0003-6870(98)00040-4"]}, "10.1109/TVCG.2013.267": {"doi": "10.1109/TVCG.2013.267", "author": ["Z. Ji", "W. Ma", "X. Sun"], "title": "Bas-Relief Modeling from Normal Images with Intuitive Styles", "year": "2014", "abstract": "Traditional 3D model-based bas-relief modeling methods are often limited to model-dependent and monotonic relief styles. This paper presents a novel method for digital bas-relief modeling with intuitive style control. Given a composite normal image, the problem discussed in this paper involves generating a discontinuity-free depth field with high compression of depth data while preserving or even enhancing fine details. In our framework, several layers of normal images are composed into a single normal image. The original normal image on each layer is usually generated from 3D models or through other techniques as described in this paper. The bas-relief style is controlled by choosing a parameter and setting a targeted height for them. Bas-relief modeling and stylization are achieved simultaneously by solving a sparse linear system. Different from previous work, our method can be used to freely design bas-reliefs in normal image space instead of in object space, which makes it possible to use any popular image editing tools for bas-relief modeling. Experiments with a wide range of 3D models and scenes show that our method can effectively generate digital bas-reliefs.", "keywords": ["computational geometry", "image coding", "image enhancement", "3D model-based digital bas-relief modeling methods", "model-dependent monotonic relief styles", "intuitive style control", "composite normal image", "discontinuity-free depth field generation", "depth data compression", "fine detail enhancement", "fine detail preservation", "normal image layers", "image stylization", "sparse linear system", "image editing tools", "Three-dimensional displays", "Solid modeling", "Laplace equations", "Image coding", "Computational modeling", "Shape", "Optimization", "Bas-relief", "normal image", "relief style", "feature preserving", "layer-based"], "referenced_by": ["IKEY:6975236", "IKEY:8322258", "IKEY:9017978", "IKEY:8611145", "IKEY:9206834", "10.1145/2661229.2661267", "10.1007/s41095-018-0111-2", "10.1016/j.compag.2016.07.023", "10.1016/j.rard.2016.11.003", "10.3901/CJME.2016.0720.084", "10.1111/cgf.12433", "10.1111/cgf.12781", "10.1111/cgf.13327", "10.1016/j.gmod.2019.01.002", "10.1088/1361-6501/ab02d1", "10.1016/j.gmod.2019.101025", "10.1016/j.cad.2019.05.036", "10.1111/cgf.13655", "10.1111/cgf.13754", "10.1111/cgf.13028", "10.1088/1361-6501/ab4e50", "10.1016/j.cagd.2020.101860", "10.1111/cgf.14016", "10.1016/j.cagd.2020.101913", "10.1016/j.cad.2020.102928", "10.1016/j.neucom.2020.06.130", "10.1111/cgf.14124"], "referencing": ["IKEY:5170176", "IKEY:4273383", "IKEY:4760139", "IKEY:5708141", "IKEY:784284", "IKEY:710815", "IKEY:5170176", "IKEY:4273383", "IKEY:4760139", "IKEY:5708141", "IKEY:784284", "IKEY:710815", "IKEY:5170176", "IKEY:4273383", "IKEY:4760139", "IKEY:5708141", "IKEY:784284", "IKEY:710815", "10.1145/566570.566573", "10.1145/1276377.1276417", "10.1145/1778765.1778797", "10.1145/1275808.1276432", "10.1145/1462173.1462176", "10.1145/566570.566573", "10.1145/1276377.1276417", "10.1145/1778765.1778797", "10.1145/1275808.1276432", "10.1145/1462173.1462176", "10.1145/566570.566573", "10.1145/1276377.1276417", "10.1145/1778765.1778797", "10.1145/1275808.1276432", "10.1145/1462173.1462176", "10.1111/j.1467-8659.2012.03185.x", "10.1023/A:1008154927611", "10.1080/10867651.1997.10487476", "10.1016/j.cagd.2011.03.003", "10.1016/j.cad.2012.11.002", "10.1111/j.1467-8659.2012.03185.x", "10.1023/A:1008154927611", "10.1080/10867651.1997.10487476", "10.1016/j.cagd.2011.03.003", "10.1016/j.cad.2012.11.002", "10.1111/j.1467-8659.2012.03185.x", "10.1023/A:1008154927611", "10.1080/10867651.1997.10487476", "10.1016/j.cagd.2011.03.003", "10.1016/j.cad.2012.11.002"]}, "10.1109/TVCG.2013.2297914": {"doi": "10.1109/TVCG.2013.2297914", "author": ["S. Oeltze", "D. J. Lehmann", "A. Kuhn", "G. Janiga", "H. Theisel", "B. Preim"], "title": "Blood Flow Clustering and Applications inVirtual Stenting of Intracranial Aneurysms", "year": "2014", "abstract": "Understanding the hemodynamics of blood flow in vascular pathologies such as intracranial aneurysms is essential for both their diagnosis and treatment. Computational fluid dynamics (CFD) simulations of blood flow based on patient-individual data are performed to better understand aneurysm initiation and progression and more recently, for predicting treatment success. In virtual stenting, a flow-diverting mesh tube (stent) is modeled inside the reconstructed vasculature and integrated in the simulation. We focus on steady-state simulation and the resulting complex multiparameter data. The blood flow pattern captured therein is assumed to be related to the success of stenting. It is often visualized by a dense and cluttered set of streamlines.We present a fully automatic approach for reducing visual clutter and exposing characteristic flow structures by clustering streamlines and computing cluster representatives. While individual clustering techniques have been applied before to streamlines in 3D flow fields, we contribute a general quantitative and a domain-specific qualitative evaluation of three state-of-the-art techniques. We show that clustering based on streamline geometry as well as on domain-specific streamline attributes contributes to comparing and evaluating different virtual stenting strategies. With our work, we aim at supporting CFD engineers and interventional neuroradiologists.", "keywords": ["computational fluid dynamics", "digital simulation", "flow simulation", "haemodynamics", "medical computing", "patient treatment", "pattern clustering", "pipe flow", "stents", "blood flow clustering", "virtual stenting", "intracranial aneurysms", "blood flow hemodynamics", "vascular pathologies", "computational fluid dynamics simulations", "patient-individual data", "treatment success", "flow-diverting mesh tube", "reconstructed vasculature", "steady-state simulation", "complex multiparameter data", "visual clutter", "characteristic flow structures", "computing cluster representatives", "3D flow fields", "domain-specific qualitative evaluation", "streamline geometry", "domain-specific streamline attributes", "virtual stenting strategies", "CFD engineers", "interventional neuroradiologists", "Aneurysm", "Blood", "Visualization", "Computational fluid dynamics", "Hemodynamics", "Vectors", "Clutter", "Blood flow", "aneurysm", "virtual stenting", "clustering", "evaluation", "Blood Flow Velocity", "Blood Vessel Prosthesis", "Computer Simulation", "Humans", "Imaging, Three-Dimensional", "Intracranial Aneurysm", "Models, Cardiovascular", "Shear Strength", "Stents", "Stress, Mechanical", "Therapy, Computer-Assisted"], "referenced_by": ["IKEY:7954963", "IKEY:7192675", "IKEY:7331662", "IKEY:7539321", "IKEY:7539342", "IKEY:8019883", "IKEY:8322888", "IKEY:7192711", "IKEY:8457259", "IKEY:8440052", "IKEY:8630911", "IKEY:8359417", "IKEY:8801825", "IKEY:8805433", "IKEY:8532319", "IKEY:9086231", "10.1016/B978-0-12-811018-8.00013-8", "10.1016/j.cag.2016.05.024", "10.1016/j.cag.2016.08.001", "10.1016/j.cag.2018.01.012", "10.1016/j.compbiomed.2017.01.020", "10.1111/cgf.13411", "10.1111/cgf.13412", "10.1002/cnm.3202", "10.1007/978-3-662-49465-3_33", "10.1111/cgf.13806", "10.1111/cgf.12911", "10.1111/cgf.12898", "10.1016/j.cag.2019.09.004", "10.1111/cgf.13422", "10.1111/cgf.13891"], "referencing": ["IKEY:6025348", "IKEY:5753894", "IKEY:6231627", "IKEY:6064983", "IKEY:1703379", "IKEY:6183580", "IKEY:6183581", "IKEY:6064980", "IKEY:6327222", "IKEY:4359056", "IKEY:1532779", "IKEY:4479455", "IKEY:1398545", "IKEY:5290742", "IKEY:6025348", "IKEY:5753894", "IKEY:6231627", "IKEY:6064983", "IKEY:1703379", "IKEY:6183580", "IKEY:6183581", "IKEY:6064980", "IKEY:6327222", "IKEY:4359056", "IKEY:1532779", "IKEY:4479455", "IKEY:1398545", "IKEY:5290742", "IKEY:6025348", "IKEY:5753894", "IKEY:6231627", "IKEY:6064983", "IKEY:1703379", "IKEY:6183580", "IKEY:6183581", "IKEY:6064980", "IKEY:6327222", "IKEY:4359056", "IKEY:1532779", "IKEY:4479455", "IKEY:1398545", "IKEY:5290742", "10.3171/JNS/2008/108/6/1132", "10.3174/ajnr.A3288", "10.1007/s10439-010-0065-8", "10.3174/ajnr.A2274", "10.1016/j.cma.2009.01.017", "10.1227/01.neu.0000306110.55174.30", "10.1016/j.jbiomech.2009.02.029", "10.1111/j.1467-8659.2011.02064.x", "10.3171/JNS/2008/108/6/1163", "10.1016/j.jbiomech.2012.08.047", "10.1115/1.4004410", "10.1007/s007910050004", "10.1111/j.1467-8659.2011.01953.x", "10.1111/j.1467-8659.2003.00723.x", "10.1111/j.1467-8659.2012.03099.x", "10.1007/978-3-540-88606-8_6", "10.1016/j.neuroimage.2008.12.023", "10.1007/s11222-007-9033-z", "10.1093/bioinformatics/bti517", "10.1080/03610910903168603", "10.1007/BF01908075", "10.1117/12.706242", "10.1007/s10439-008-9449-4", "10.3171/JNS/2008/108/6/1132", "10.3174/ajnr.A3288", "10.1007/s10439-010-0065-8", "10.3174/ajnr.A2274", "10.1016/j.cma.2009.01.017", "10.1227/01.neu.0000306110.55174.30", "10.1016/j.jbiomech.2009.02.029", "10.1111/j.1467-8659.2011.02064.x", "10.3171/JNS/2008/108/6/1163", "10.1016/j.jbiomech.2012.08.047", "10.1115/1.4004410", "10.1007/s007910050004", "10.1111/j.1467-8659.2011.01953.x", "10.1111/j.1467-8659.2003.00723.x", "10.1111/j.1467-8659.2012.03099.x", "10.1007/978-3-540-88606-8_6", "10.1016/j.neuroimage.2008.12.023", "10.1007/s11222-007-9033-z", "10.1093/bioinformatics/bti517", "10.1080/03610910903168603", "10.1007/BF01908075", "10.1117/12.706242", "10.1007/s10439-008-9449-4", "10.3171/JNS/2008/108/6/1132", "10.3174/ajnr.A3288", "10.1007/s10439-010-0065-8", "10.3174/ajnr.A2274", "10.1016/j.cma.2009.01.017", "10.1227/01.neu.0000306110.55174.30", "10.1016/j.jbiomech.2009.02.029", "10.1111/j.1467-8659.2011.02064.x", "10.3171/JNS/2008/108/6/1163", "10.1016/j.jbiomech.2012.08.047", "10.1115/1.4004410", "10.1007/s007910050004", "10.1111/j.1467-8659.2011.01953.x", "10.1111/j.1467-8659.2003.00723.x", "10.1111/j.1467-8659.2012.03099.x", "10.1007/978-3-540-88606-8_6", "10.1016/j.neuroimage.2008.12.023", "10.1007/s11222-007-9033-z", "10.1093/bioinformatics/bti517", "10.1080/03610910903168603", "10.1007/BF01908075", "10.1117/12.706242", "10.1007/s10439-008-9449-4"]}, "10.1109/TVCG.2014.2299803": {"doi": "10.1109/TVCG.2014.2299803", "author": ["W. Lu", "Y. Wang", "W. Lin"], "title": "Chess Evolution Visualization", "year": "2014", "abstract": "We present a chess visualization to convey the changes in a game over successive generations. It contains a score chart, an evolution graph and a chess board, such that users can understand a game from global to local viewpoints. Unlike current graphical chess tools, which focus only on highlighting pieces that are under attack and require sequential investigation, our visualization shows potential outcomes after a piece is moved and indicates how much tactical advantage the player can have over the opponent. Users can first glance at the score chart to roughly obtain the growth and decline of advantages from both sides, and then examine the position relations and the piece placements, to know how the pieces are controlled and how the strategy works. To achieve this visualization, we compute the decision tree using artificial intelligence to analyze a game, in which each node represents a chess position and each edge connects two positions that are one-move different. We then merge nodes representing the same chess position, and shorten branches where nodes on them contain only two neighbors, in order to achieve readability. During the graph rendering, the nodes containing events such as draws, effective checks and checkmates, are highlighted because they show how a game is ended. As a result, our visualization helps players understand a chess game so that they can efficiently learn strategies and tactics. The presented results, evaluations, and the conducted user studies demonstrate the feasibility of our visualization design.", "keywords": ["artificial intelligence", "computer games", "data visualisation", "decision trees", "graph theory", "rendering (computer graphics)", "chess evolution visualization", "successive generations", "score chart", "evolution graph", "chess board", "graphical chess tools", "position relations", "piece placements", "tactical advantage", "decision tree", "artificial intelligence", "graph rendering", "checkmates", "visualization design", "Games", "Visualization", "Data visualization", "Decision trees", "Artificial intelligence", "Licenses", "Market research", "Chess visualization", "graph"], "referenced_by": ["10.1016/j.cose.2017.11.014", "10.1016/j.softx.2018.12.004"], "referencing": ["IKEY:801859", "IKEY:5473227", "IKEY:1173151", "IKEY:6102453", "IKEY:87055", "IKEY:841119", "IKEY:4515862", "IKEY:1382896", "IKEY:4015433", "IKEY:5963661", "IKEY:6065008", "IKEY:221135", "IKEY:801859", "IKEY:5473227", "IKEY:1173151", "IKEY:6102453", "IKEY:87055", "IKEY:841119", "IKEY:4515862", "IKEY:1382896", "IKEY:4015433", "IKEY:5963661", "IKEY:6065008", "IKEY:221135", "IKEY:801859", "IKEY:5473227", "IKEY:1173151", "IKEY:6102453", "IKEY:87055", "IKEY:841119", "IKEY:4515862", "IKEY:1382896", "IKEY:4015433", "IKEY:5963661", "IKEY:6065008", "IKEY:221135", "10.1145/356893.356895", "10.1145/288392.288579", "10.1145/1842993.1843035", "10.1145/1879211.1879219", "10.1145/356893.356895", "10.1145/288392.288579", "10.1145/1842993.1843035", "10.1145/1879211.1879219", "10.1145/356893.356895", "10.1145/288392.288579", "10.1145/1842993.1843035", "10.1145/1879211.1879219", "10.1147/rd.24.0320", "10.1007/978-1-4613-9080-0_9", "10.1007/11618058_26", "10.1111/j.1467-8659.2011.01955.x", "10.1147/rd.24.0320", "10.1007/978-1-4613-9080-0_9", "10.1007/11618058_26", "10.1111/j.1467-8659.2011.01955.x", "10.1147/rd.24.0320", "10.1007/978-1-4613-9080-0_9", "10.1007/11618058_26", "10.1111/j.1467-8659.2011.01955.x"]}, "10.1109/TVCG.2013.268": {"doi": "10.1109/TVCG.2013.268", "author": ["F. Liu", "Y. J. Kim"], "title": "Exact and Adaptive Signed Distance FieldsComputation for Rigid and DeformableModels on GPUs", "year": "2014", "abstract": "Most techniques for real-time construction of a signed distance field, whether on a CPU or GPU, involve approximate distances. We use a GPU to build an exact adaptive distance field, constructed from an octree by using the Morton code. We use rectangle-swept spheres to construct a bounding volume hierarchy (BVH) around a triangulated model. To speed up BVH construction, we can use a multi-BVH structure to improve the workload balance between GPU processors. An upper bound on distance to the model provided by the octree itself allows us to reduce the number of BVHs involved in determining the distances from the centers of octree nodes at successively lower levels, prior to an exact distance query involving the remaining BVHs. Distance fields can be constructed 35-64 times as fast as a serial CPU implementation of a similar algorithm, allowing us to simulate a piece of fabric interacting with the Stanford Bunny at 20 frames per second.", "keywords": ["computer graphics", "octrees", "real-time construction", "signed distance field", "GPU", "adaptive distance field", "Morton code", "rectangle-swept spheres", "bounding volume hierarchy", "BVH construction", "exact distance query", "serial CPU", "octree", "Octrees", "Graphics processing units", "Computational modeling", "Adaptation models", "Instruction sets", "Parallel processing", "Vectors", "Distance fields", "GPU", "Octree", "bounding volume hierarchies", "physics simulation"], "referenced_by": ["IKEY:8031592", "10.1145/3197517.3201349", "10.1002/cav.1689", "10.1007/s00371-015-1111-1", "10.1016/j.cad.2017.01.002", "10.1016/j.cag.2017.05.024", "10.1111/cgf.12561", "10.1016/j.cag.2018.02.002", "10.1016/j.jcde.2015.04.001", "10.1016/j.cag.2017.07.015", "10.1186/s13640-018-0318-2"], "referencing": ["IKEY:845311", "IKEY:1250358", "IKEY:1634323", "IKEY:5577893", "IKEY:4547967", "IKEY:5473223", "IKEY:675649", "IKEY:1407857", "IKEY:845311", "IKEY:1250358", "IKEY:1634323", "IKEY:5577893", "IKEY:4547967", "IKEY:5473223", "IKEY:675649", "IKEY:1407857", "IKEY:845311", "IKEY:1250358", "IKEY:1634323", "IKEY:5577893", "IKEY:4547967", "IKEY:5473223", "IKEY:675649", "IKEY:1407857", "10.1145/882262.882358", "10.1145/311535.311567", "10.1145/321356.321357", "10.1145/1730804.1730818", "10.1145/344779.344899", "10.1145/1141911.1141926", "10.1145/1409060.1409079", "10.1145/237170.237244", "10.1145/253607.253888", "10.1145/2018323.2018333", "10.1145/882262.882358", "10.1145/311535.311567", "10.1145/321356.321357", "10.1145/1730804.1730818", "10.1145/344779.344899", "10.1145/1141911.1141926", "10.1145/1409060.1409079", "10.1145/237170.237244", "10.1145/253607.253888", "10.1145/2018323.2018333", "10.1145/882262.882358", "10.1145/311535.311567", "10.1145/321356.321357", "10.1145/1730804.1730818", "10.1145/344779.344899", "10.1145/1141911.1141926", "10.1145/1409060.1409079", "10.1145/237170.237244", "10.1145/253607.253888", "10.1145/2018323.2018333", "10.1111/j.1467-8659.2008.01183.x", "10.1007/978-3-7091-6240-8_10", "10.1016/j.gmod.2005.11.003", "10.1111/j.1467-8659.2004.00787.x", "10.1016/0167-8655(92)90118-J", "10.1117/12.131088", "10.1006/cviu.1996.0065", "10.1016/0146-664X(80)90054-4", "10.1016/1049-9652(92)90072-6", "10.1006/cviu.2001.0915", "10.1073/pnas.93.4.1591", "10.1090/S0025-5718-04-01678-3", "10.1111/j.1467-8659.2008.01210.x", "10.1111/j.1467-8659.2009.01377.x", "10.1111/1467-8659.1530387", "10.1111/j.1467-8659.2009.01611.x", "10.1111/j.1467-8659.2008.01183.x", "10.1007/978-3-7091-6240-8_10", "10.1016/j.gmod.2005.11.003", "10.1111/j.1467-8659.2004.00787.x", "10.1016/0167-8655(92)90118-J", "10.1117/12.131088", "10.1006/cviu.1996.0065", "10.1016/0146-664X(80)90054-4", "10.1016/1049-9652(92)90072-6", "10.1006/cviu.2001.0915", "10.1073/pnas.93.4.1591", "10.1090/S0025-5718-04-01678-3", "10.1111/j.1467-8659.2008.01210.x", "10.1111/j.1467-8659.2009.01377.x", "10.1111/1467-8659.1530387", "10.1111/j.1467-8659.2009.01611.x", "10.1111/j.1467-8659.2008.01183.x", "10.1007/978-3-7091-6240-8_10", "10.1016/j.gmod.2005.11.003", "10.1111/j.1467-8659.2004.00787.x", "10.1016/0167-8655(92)90118-J", "10.1117/12.131088", "10.1006/cviu.1996.0065", "10.1016/0146-664X(80)90054-4", "10.1016/1049-9652(92)90072-6", "10.1006/cviu.2001.0915", "10.1073/pnas.93.4.1591", "10.1090/S0025-5718-04-01678-3", "10.1111/j.1467-8659.2008.01210.x", "10.1111/j.1467-8659.2009.01377.x", "10.1111/1467-8659.1530387", "10.1111/j.1467-8659.2009.01611.x"]}, "10.1109/TVCG.2013.271": {"doi": "10.1109/TVCG.2013.271", "author": ["H. Song", "J. Yun", "B. Kim", "J. Seo"], "title": "GazeVis: Interactive 3D Gaze Visualization for Contiguous Cross-Sectional Medical Images", "year": "2014", "abstract": "Gaze visualization has been used to understand the results from gaze tracking studies in a wide range of fields. In the medical field, diagnoses of medical images have been studied with gaze tracking technology to understand how radiologists read medical images. While prior work were mainly based on diagnosis with a single image, recent work focused on diagnosis with consecutive cross-sectional medical images acquired from preoperative computed tomography (CT) or magnetic resonance imaging (MRI). In the diagnosis, radiologists scroll through a stack of images to get a 3D cognition of organs and lesions. Thus, it is important to understand radiologists' gaze patterns three dimensionally across such contiguous cross-sectional images. However, little has been done to visualize more complicated gaze patterns from the contiguous cross-sectional medical images. To address this problem, we present an interactive 3D gaze visualization tool, GazeVis, where InfoVis and SciVis techniques are harmonized to show the abstract gaze data along with a realistic 3D rendering of the visual stimuli (i.e., organs and lesions). We present case studies with 12 radiologists who use GazeVis to investigate gaze patterns of their colleagues with different levels of expertise, providing empirical evidences about the competence of our gaze visualization system.", "keywords": ["biomedical MRI", "computerised tomography", "gaze tracking", "interactive systems", "medical image processing", "GazeVis", "interactive 3D gaze visualization", "contiguous cross-sectional medical images", "gaze tracking technology", "consecutive cross-sectional medical images", "preoperative computed tomography", "magnetic resonance imaging", "CT", "MRI", "SciVis techniques", "InfoVis techniques", "realistic 3D rendering", "Three-dimensional displays", "Data visualization", "Medical diagnostic imaging", "Rendering (computer graphics)", "Visualization", "Computed tomography", "Eye tracking", "gaze visualization", "volume rendering", "medical images", "interaction technique", "Algorithms", "Attention", "Depth Perception", "Fixation, Ocular", "Humans", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Reproducibility of Results", "Sensitivity and Specificity", "Software", "User-Computer Interface", "Visual Perception"], "referenced_by": ["IKEY:7467405", "IKEY:7539334", "10.1177/1473871615609787", "10.1111/cgf.13079", "10.1016/B978-0-12-816034-3.00017-1", "10.1093/jcde/qwaa019", "10.1007/978-981-15-5784-2_1", "10.1016/j.visinf.2020.10.002"], "referencing": ["IKEY:1097737", "IKEY:4658153", "IKEY:4658123", "IKEY:1021579", "IKEY:5613494", "IKEY:511", "IKEY:1319526", "IKEY:1320141", "IKEY:1608018", "IKEY:545307", "IKEY:1242376", "IKEY:963291", "IKEY:1260759", "IKEY:1541995", "IKEY:5613432", "IKEY:1097737", "IKEY:4658153", "IKEY:4658123", "IKEY:1021579", "IKEY:5613494", "IKEY:511", "IKEY:1319526", "IKEY:1320141", "IKEY:1608018", "IKEY:545307", "IKEY:1242376", "IKEY:963291", "IKEY:1260759", "IKEY:1541995", "IKEY:5613432", "IKEY:1097737", "IKEY:4658153", "IKEY:4658123", "IKEY:1021579", "IKEY:5613494", "IKEY:511", "IKEY:1319526", "IKEY:1320141", "IKEY:1608018", "IKEY:545307", "IKEY:1242376", "IKEY:963291", "IKEY:1260759", "IKEY:1541995", "IKEY:5613432", "10.1145/365024.365309", "10.1145/503411.503413", "10.1145/54852.378484", "10.1145/2168556.2168558", "10.1145/1743666.1743717", "10.1145/355017.355025", "10.1145/108844.108870", "10.1145/108844.108883", "10.1145/288392.288596", "10.1145/355017.355028", "10.1145/1168149.1168158", "10.1145/1842993.1843058", "10.1145/1743666.1743693", "10.1145/507072.507078", "10.1145/234526.234532", "10.1145/365024.365309", "10.1145/503411.503413", "10.1145/54852.378484", "10.1145/2168556.2168558", "10.1145/1743666.1743717", "10.1145/355017.355025", "10.1145/108844.108870", "10.1145/108844.108883", "10.1145/288392.288596", "10.1145/355017.355028", "10.1145/1168149.1168158", "10.1145/1842993.1843058", "10.1145/1743666.1743693", "10.1145/507072.507078", "10.1145/234526.234532", "10.1145/365024.365309", "10.1145/503411.503413", "10.1145/54852.378484", "10.1145/2168556.2168558", "10.1145/1743666.1743717", "10.1145/355017.355025", "10.1145/108844.108870", "10.1145/108844.108883", "10.1145/288392.288596", "10.1145/355017.355028", "10.1145/1168149.1168158", "10.1145/1842993.1843058", "10.1145/1743666.1743693", "10.1145/507072.507078", "10.1145/234526.234532", "10.1007/s10278-008-9140-1", "10.1117/12.707533", "10.1148/103.3.523", "10.1148/radiol.2422051997", "10.1016/S1076-6332(99)80252-9", "10.1148/radiol.2211001507", "10.1117/12.595365", "10.1117/12.790424", "10.1007/11555261_76", "10.1148/radiol.10101090", "10.1006/ijhc.2000.0413", "10.1007/978-1-4471-3588-3_6", "10.1007/s10278-008-9140-1", "10.1117/12.707533", "10.1148/103.3.523", "10.1148/radiol.2422051997", "10.1016/S1076-6332(99)80252-9", "10.1148/radiol.2211001507", "10.1117/12.595365", "10.1117/12.790424", "10.1007/11555261_76", "10.1148/radiol.10101090", "10.1006/ijhc.2000.0413", "10.1007/978-1-4471-3588-3_6", "10.1007/s10278-008-9140-1", "10.1117/12.707533", "10.1148/103.3.523", "10.1148/radiol.2422051997", "10.1016/S1076-6332(99)80252-9", "10.1148/radiol.2211001507", "10.1117/12.595365", "10.1117/12.790424", "10.1007/11555261_76", "10.1148/radiol.10101090", "10.1006/ijhc.2000.0413", "10.1007/978-1-4471-3588-3_6"]}, "10.1109/TVCG.2013.254": {"doi": "10.1109/TVCG.2013.254", "author": ["B. Bach", "E. Pietriga", "J. Fekete"], "title": "GraphDiaries: Animated Transitions andTemporal Navigation for Dynamic Networks", "year": "2014", "abstract": "Identifying, tracking and understanding changes in dynamic networks are complex and cognitively demanding tasks. We present GraphDiaries, a visual interface designed to improve support for these tasks in any node-link based graph visualization system. GraphDiaries relies on animated transitions that highlight changes in the network between time steps, thus helping users identify and understand those changes. To better understand the tasks related to the exploration of dynamic networks, we first introduce a task taxonomy, that informs the design of GraphDiaries, presented afterwards. We then report on a user study, based on representative tasks identified through the taxonomy, and that compares GraphDiaries to existing techniques for temporal navigation in dynamic networks, showing that it outperforms them in terms of both task time and errors for several of these tasks.", "keywords": ["computer animation", "data visualisation", "graph theory", "graphical user interfaces", "network theory (graphs)", "GraphDiaries", "animated transitions", "dynamic networks", "visual interface", "node-link-based graph visualization system", "time steps", "task taxonomy", "temporal navigation", "task time", "task errors", "Visualization", "Layout", "Animation", "Taxonomy", "Navigation", "Topology", "Complexity theory", "Dynamic networks", "graph visualization", "temporal navigation", "user experiment"], "referenced_by": ["IKEY:7529559", "IKEY:7938243", "IKEY:7426283", "IKEY:7465246", "IKEY:8031576", "IKEY:7091028", "IKEY:7374750", "IKEY:7516722", "IKEY:7570239", "IKEY:7581076", "IKEY:8017593", "IKEY:7011313", "IKEY:7883511", "IKEY:7780168", "IKEY:7312770", "IKEY:7192732", "IKEY:7192725", "IKEY:7192717", "IKEY:6980225", "IKEY:7953527", "IKEY:8017630", "IKEY:8466814", "IKEY:8585487", "IKEY:8267097", "IKEY:8622099", "IKEY:8802415", "IKEY:8805428", "IKEY:8809834", "IKEY:8933748", "IKEY:8580402", "10.1145/2670444.2670461", "10.1145/2702123.2702476", "10.1145/2858036.2858387", "10.1016/j.jvlc.2017.03.003", "10.1111/cgf.12791", "10.1111/cgf.12872", "10.1111/cgf.12901", "10.1111/cgf.12920", "10.1111/cgf.13264", "10.1177/1473871615576758", "10.2200/S00651ED1V01Y201506VIS003", "10.2200/S00688ED1V01Y201512VIS006", "10.4028/www.scientific.net/AMM.869.234", "10.1016/j.ins.2015.04.017", "10.1007/s12650-017-0430-x", "10.1007/978-3-319-73915-1_20", "10.1007/978-3-319-50106-2_43", "10.1177/1473871616630778", "10.1111/cgf.13401", "10.1111/cgf.13435", "10.1016/j.jvlc.2018.06.006", "10.1007/978-3-030-00668-6_9", "10.1016/j.jnca.2018.09.016", "10.1016/j.visinf.2018.12.002", "10.1016/j.visinf.2018.12.006", "10.1007/978-3-319-27261-0_2", "10.1111/cgf.13723", "10.1111/cgf.13668", "10.5194/npg-22-545-2015", "10.1111/cgf.13882"], "referencing": ["IKEY:5190876", "IKEY:6425766", "IKEY:1028770", "IKEY:4376146", "IKEY:1173148", "IKEY:4035741", "IKEY:4658146", "IKEY:5473226", "IKEY:801854", "IKEY:1532136", "IKEY:4658123", "IKEY:1509498", "IKEY:5190876", "IKEY:6425766", "IKEY:1028770", "IKEY:4376146", "IKEY:1173148", "IKEY:4035741", "IKEY:4658146", "IKEY:5473226", "IKEY:801854", "IKEY:1532136", "IKEY:4658123", "IKEY:1509498", "IKEY:5190876", "IKEY:6425766", "IKEY:1028770", "IKEY:4376146", "IKEY:1173148", "IKEY:4035741", "IKEY:4658146", "IKEY:5473226", "IKEY:801854", "IKEY:1532136", "IKEY:4658123", "IKEY:1509498", "10.1145/1385569.1385636", "10.1145/2024288.2024344", "10.1145/2470654.2470724", "10.1145/774841.774844", "10.1145/1830252.1830262", "10.1145/1385569.1385642", "10.1145/1753326.1753427", "10.1145/2254556.2254653", "10.1145/989863.989941", "10.1145/2110192.2110201", "10.1145/1168149.1168168", "10.1145/1385569.1385636", "10.1145/2024288.2024344", "10.1145/2470654.2470724", "10.1145/774841.774844", "10.1145/1830252.1830262", "10.1145/1385569.1385642", "10.1145/1753326.1753427", "10.1145/2254556.2254653", "10.1145/989863.989941", "10.1145/2110192.2110201", "10.1145/1168149.1168168", "10.1145/1385569.1385636", "10.1145/2024288.2024344", "10.1145/2470654.2470724", "10.1145/774841.774844", "10.1145/1830252.1830262", "10.1145/1385569.1385642", "10.1145/1753326.1753427", "10.1145/2254556.2254653", "10.1145/989863.989941", "10.1145/2110192.2110201", "10.1145/1168149.1168168", "10.1006/ijhc.2002.1017", "10.1057/palgrave.ivs.9500037", "10.1111/j.1467-8659.2009.01687.x", "10.7155/jgaa.00029", "10.1007/3-540-44541-2_37", "10.7155/jgaa.00057", "10.1007/978-3-642-18469-7_5", "10.1007/978-3-642-19656-0_43", "10.1007/978-3-540-87730-1_9", "10.1007/978-3-642-36763-2_42", "10.1111/j.1467-8659.2012.03113.x", "10.1111/j.1467-8306.1994.tb01869.x", "10.1016/0004-3702(84)90008-0", "10.1002/spe.4380211102", "10.1006/ijhc.2002.1017", "10.1057/palgrave.ivs.9500037", "10.1111/j.1467-8659.2009.01687.x", "10.7155/jgaa.00029", "10.1007/3-540-44541-2_37", "10.7155/jgaa.00057", "10.1007/978-3-642-18469-7_5", "10.1007/978-3-642-19656-0_43", "10.1007/978-3-540-87730-1_9", "10.1007/978-3-642-36763-2_42", "10.1111/j.1467-8659.2012.03113.x", "10.1111/j.1467-8306.1994.tb01869.x", "10.1016/0004-3702(84)90008-0", "10.1002/spe.4380211102", "10.1006/ijhc.2002.1017", "10.1057/palgrave.ivs.9500037", "10.1111/j.1467-8659.2009.01687.x", "10.7155/jgaa.00029", "10.1007/3-540-44541-2_37", "10.7155/jgaa.00057", "10.1007/978-3-642-18469-7_5", "10.1007/978-3-642-19656-0_43", "10.1007/978-3-540-87730-1_9", "10.1007/978-3-642-36763-2_42", "10.1111/j.1467-8659.2012.03113.x", "10.1111/j.1467-8306.1994.tb01869.x", "10.1016/0004-3702(84)90008-0", "10.1002/spe.4380211102"]}, "10.1109/TVCG.2013.266": {"doi": "10.1109/TVCG.2013.266", "author": ["M. Tang", "D. Manocha", "Y. J. Kim"], "title": "Hierarchical and Controlled Advancement for Continuous Collision Detectionof Rigid and Articulated Models", "year": "2014", "abstract": "We present fast CCD algorithm for general rigid and articulated models based on conservative advancement. We have implemented the CCD algorithm with two different acceleration techniques which can handle rigid models, and have extended one of them to articulated models. The resulting algorithms take a few milliseconds for rigid models with tens of thousands of triangles, and a few milliseconds for articulated models with tens of links. We show that the performance of our algorithms is much faster than existing CCD algorithms for polygon-soup models and it is also comparable to competing CCD algorithms that are limited to manifold models. The preliminary version of this paper appeared in .", "keywords": ["computational geometry", "continuous collision detection", "rigid model", "articulated model", "CCD algorithm", "acceleration techniques", "articulated models", "polygon-soup models", "manifold models", "conservative advancement", "hierarchical controlled advancement", "Charge coupled devices", "Computational modeling", "Solid modeling", "Trajectory", "Vectors", "Planning", "Mathematical model", "Continuous collision detection", "conservative advancement", "distance computation"], "referenced_by": ["IKEY:8880469", "10.1145/2699276.2699286", "10.1007/978-94-007-7194-9_26-1", "10.1016/j.rcim.2017.05.013", "10.1007/s11390-015-1541-2", "10.1007/978-94-007-6046-2_26", "10.1007/978-3-319-08234-9_332-1", "10.1088/1742-6596/1358/1/012083"], "referencing": ["IKEY:1310064", "IKEY:4767773", "IKEY:1618737", "IKEY:722297", "IKEY:6225337", "IKEY:1310064", "IKEY:4767773", "IKEY:1618737", "IKEY:722297", "IKEY:6225337", "IKEY:1310064", "IKEY:4767773", "IKEY:1618737", "IKEY:722297", "IKEY:6225337", "10.1145/1275808.1276396", "10.1145/781606.781612", "10.1145/336154.336219", "10.1145/237170.237244", "10.1145/1364901.1364908", "10.1145/2185520.2185594", "10.1145/2019627.2019630", "10.1145/1275808.1276396", "10.1145/781606.781612", "10.1145/336154.336219", "10.1145/237170.237244", "10.1145/1364901.1364908", "10.1145/2185520.2185594", "10.1145/2019627.2019630", "10.1145/1275808.1276396", "10.1145/781606.781612", "10.1145/336154.336219", "10.1145/237170.237244", "10.1145/1364901.1364908", "10.1145/2185520.2185594", "10.1145/2019627.2019630", "10.1007/978-3-642-17452-0_14", "10.1111/1467-8659.t01-1-00587", "10.1007/s00371-006-0060-0", "10.1142/S0218654306000858", "10.15607/RSS.2011.VII.032", "10.1007/978-3-642-17452-0_14", "10.1111/1467-8659.t01-1-00587", "10.1007/s00371-006-0060-0", "10.1142/S0218654306000858", "10.15607/RSS.2011.VII.032", "10.1007/978-3-642-17452-0_14", "10.1111/1467-8659.t01-1-00587", "10.1007/s00371-006-0060-0", "10.1142/S0218654306000858", "10.15607/RSS.2011.VII.032"]}, "10.1109/TVCG.2014.2303092": {"doi": "10.1109/TVCG.2014.2303092", "author": ["G. Tamm", "J. Kr\u00fcger"], "title": "Hybrid Rendering with Scheduling under Uncertainty", "year": "2014", "abstract": "As scientific data of increasing size is generated by today's simulations and measurements, utilizing dedicated server resources to process the visualization pipeline becomes necessary. In a purely server-based approach, requirements on the client-side are minimal as the client only displays results received from the server. However, the client may have a considerable amount of hardware available, which is left idle. Further, the visualization is put at the whim of possibly unreliable server and network conditions. Server load, bandwidth and latency may substantially affect the response time on the client. In this paper, we describe a hybrid method, where visualization workload is assigned to server and client. A capable client can produce images independently. The goal is to determine a workload schedule that enables a synergy between the two sides to provide rendering results to the user as fast as possible. The schedule is determined based on processing and transfer timings obtained at runtime. Our probabilistic scheduler adapts to changing conditions by shifting workload between server and client, and accounts for the performance variability in the dynamic system.", "keywords": ["data visualisation", "rendering (computer graphics)", "hybrid rendering", "visualization pipeline", "purely server-based approach", "capable client", "workload schedule", "probabilistic scheduler", "Servers", "Rendering (computer graphics)", "Timing", "Schedules", "Data visualization", "Hardware", "Probabilistic logic", "Remote/hybrid rendering", "client/server systems", "uncertainty", "probabilistic scheduling"], "referenced_by": ["IKEY:8614334", "10.1007/978-3-319-47099-3_6"], "referencing": ["IKEY:6176007", "IKEY:4015496", "IKEY:1309247", "IKEY:1372216", "IKEY:4302731", "IKEY:6176007", "IKEY:4015496", "IKEY:1309247", "IKEY:1372216", "IKEY:4302731", "IKEY:6176007", "IKEY:4015496", "IKEY:1309247", "IKEY:1372216", "IKEY:4302731", "10.1145/1329469.1329489", "10.1145/237170.237216", "10.1145/1329469.1329489", "10.1145/237170.237216", "10.1145/1329469.1329489", "10.1145/237170.237216", "10.1023/A:1020958815308", "10.1007/978-0-387-88617-6_3", "10.1016/j.compchemeng.2006.05.035", "10.1016/j.compchemeng.2007.03.001", "10.1007/s11263-010-0383-1", "10.1016/S0098-1354(00)00647-5", "10.1023/A:1020958815308", "10.1007/978-0-387-88617-6_3", "10.1016/j.compchemeng.2006.05.035", "10.1016/j.compchemeng.2007.03.001", "10.1007/s11263-010-0383-1", "10.1016/S0098-1354(00)00647-5", "10.1023/A:1020958815308", "10.1007/978-0-387-88617-6_3", "10.1016/j.compchemeng.2006.05.035", "10.1016/j.compchemeng.2007.03.001", "10.1007/s11263-010-0383-1", "10.1016/S0098-1354(00)00647-5"]}, "10.1109/TVCG.2013.257": {"doi": "10.1109/TVCG.2013.257", "author": ["L. Wang", "A. E. Kaufman"], "title": "Importance-Driven Accessory Lights Designfor Enhancing Local Shapes", "year": "2014", "abstract": "We introduce a semi-automatic lighting design method that deploys per-voxel accessory lights (fill and detail lights) to enhance local shapes, as well as to increase the perceptibility and visual saliency of an object. Our approach allows the user to manually design arbitrary lights in a scene for creating the desired feeling of emotion. The user designed lights are used as key lights and our approach automatically configures per-voxel accessory lights that preserve the user designed feeling of emotion. Per-voxel fill lights brighten the shadows and thus increase the perceptibility and visual saliency. Per-voxel detail lights enhance the visual cues for the local shape perception. Moreover, the revealed local shapes are controlled by the user employing an importance distribution. Similarly, the perceptibility and visual saliency are also controlled based on an importance distribution. Our perceptual measurement guarantees that the revealed local shapes are independent of the key lights. In addition, our method provides two control parameters, which adjust the fill and detail lights, to provide the user with additional flexibility in designing the expected lighting effect. The major contributions of this paper are the idea of using the importance distribution to control local shapes, the per-voxel accessory lights and the perceptual measurement.", "keywords": ["image enhancement", "object detection", "shape recognition", "importance driven accessory lights design", "local shape enhancement", "semiautomatic lighting design method", "per voxel accessory", "visual saliency", "local shape perception", "perceptual measurement", "Lighting", "Shape", "Visualization", "Shape measurement", "Rendering (computer graphics)", "Transfer functions", "Lighting design", "volume rendering", "ray-casting", "importance distribution", "accessory lights", "fill lights", "detail lights"], "referenced_by": ["IKEY:7470264", "IKEY:8052504"], "referencing": ["IKEY:1703375", "IKEY:4376160", "IKEY:5290740", "IKEY:1207441", "IKEY:1372208", "IKEY:1580454", "IKEY:1372209", "IKEY:6064956", "IKEY:6064942", "IKEY:1309213", "IKEY:4479459", "IKEY:6327242", "IKEY:4015449", "IKEY:1432686", "IKEY:4015403", "IKEY:4658174", "IKEY:6175015", "IKEY:1703375", "IKEY:4376160", "IKEY:5290740", "IKEY:1207441", "IKEY:1372208", "IKEY:1580454", "IKEY:1372209", "IKEY:6064956", "IKEY:6064942", "IKEY:1309213", "IKEY:4479459", "IKEY:6327242", "IKEY:4015449", "IKEY:1432686", "IKEY:4015403", "IKEY:4658174", "IKEY:6175015", "IKEY:1703375", "IKEY:4376160", "IKEY:5290740", "IKEY:1207441", "IKEY:1372208", "IKEY:1580454", "IKEY:1372209", "IKEY:6064956", "IKEY:6064942", "IKEY:1309213", "IKEY:4479459", "IKEY:6327242", "IKEY:4015449", "IKEY:1432686", "IKEY:4015403", "IKEY:4658174", "IKEY:6175015", "10.1145/280814.280950", "10.1145/258734.258887", "10.1145/566654.566617", "10.1145/1141911.1142015", "10.1145/1730804.1730827", "10.1145/1531326.1531331", "10.1145/280814.280950", "10.1145/258734.258887", "10.1145/566654.566617", "10.1145/1141911.1142015", "10.1145/1730804.1730827", "10.1145/1531326.1531331", "10.1145/280814.280950", "10.1145/258734.258887", "10.1145/566654.566617", "10.1145/1141911.1142015", "10.1145/1730804.1730827", "10.1145/1531326.1531331", "10.1068/p120411", "10.1111/j.1467-8659.2011.01975.x", "10.1002/col.10051", "10.1016/S0042-6989(01)00141-9", "10.1007/978-3-7091-6809-7_28", "10.1068/p230169", "10.1016/S1364-6613(98)01204-2", "10.1068/p5418", "10.1038/331163a0", "10.1111/1467-8659.00514", "10.1111/j.1467-8659.2007.00944.x", "10.1111/j.1467-8659.2012.03123.x", "10.1002/col.20230", "10.1068/p120411", "10.1111/j.1467-8659.2011.01975.x", "10.1002/col.10051", "10.1016/S0042-6989(01)00141-9", "10.1007/978-3-7091-6809-7_28", "10.1068/p230169", "10.1016/S1364-6613(98)01204-2", "10.1068/p5418", "10.1038/331163a0", "10.1111/1467-8659.00514", "10.1111/j.1467-8659.2007.00944.x", "10.1111/j.1467-8659.2012.03123.x", "10.1002/col.20230", "10.1068/p120411", "10.1111/j.1467-8659.2011.01975.x", "10.1002/col.10051", "10.1016/S0042-6989(01)00141-9", "10.1007/978-3-7091-6809-7_28", "10.1068/p230169", "10.1016/S1364-6613(98)01204-2", "10.1068/p5418", "10.1038/331163a0", "10.1111/1467-8659.00514", "10.1111/j.1467-8659.2007.00944.x", "10.1111/j.1467-8659.2012.03123.x", "10.1002/col.20230"]}, "10.1109/TVCG.2013.2297932": {"doi": "10.1109/TVCG.2013.2297932", "author": ["R. Ranon", "T. Urli"], "title": "Improving the Efficiency of Viewpoint Composition", "year": "2014", "abstract": "In this paper, we concentrate on the problem of finding the viewpoint that best satisfies a set of visual composition properties, often referred to as Virtual Camera or Viewpoint Composition. Previous approaches in the literature, which are based on general optimization solvers, are limited in their practical applicability because of unsuitable computation times and limited experimental analysis. To bring performances much closer to the needs of interactive applications, we introduce novel ways to define visual properties, evaluate their satisfaction, and initialize the search for optimal viewpoints, and test them in several problems under various time budgets, quantifying also, for the first time in the domain, the importance of tuning the parameters that control the behavior of the solving process. While our solver, as others in the literature, is based on Particle Swarm Optimization, our contributions could be applied to any stochastic search process that solves through many viewpoint evaluations, such as the genetic algorithms employed by other papers in the literature. The complete source code of our approach, together with the scenes and problems we have employed, can be downloaded from https://bitbucket.org/rranon/smart-viewpoint-computation-lib.", "keywords": ["computer graphics", "particle swarm optimisation", "viewpoint composition", "visual composition properties", "virtual camera", "interactive applications", "particle swarm optimization", "stochastic search process", "genetic algorithms", "Cameras", "TV", "Visualization", "Rendering (computer graphics)", "Search problems", "Accuracy", "Cognition", "Virtual camera control", "viewpoint computation", "virtual camera composition", "viewpoint composition"], "referenced_by": ["IKEY:7938224", "10.1145/2668064.2668104", "10.1145/3181975", "10.1145/3197517.3201284", "10.1145/2766965", "10.1145/3386569.3392427", "10.1016/j.cag.2015.03.005", "10.1007/978-3-319-46152-6_19", "10.1016/j.cag.2020.06.003"], "referencing": ["IKEY:7751", "IKEY:7751", "IKEY:7751", "10.1145/2072298.2072341", "10.1145/2019627.2019628", "10.1145/291080.291101", "10.1145/2072298.2072341", "10.1145/2019627.2019628", "10.1145/291080.291101", "10.1145/2072298.2072341", "10.1145/2019627.2019628", "10.1145/291080.291101", "10.1007/3-540-37620-8_18", "10.1111/j.1467-8659.2005.00849.x", "10.1007/978-3-540-85412-8_12", "10.1007/978-3-642-22571-0_2", "10.1007/978-3-642-13544-6_10", "10.1111/j.1467-8659.2003.00717.x", "10.1111/j.1467-8659.2004.00781.x", "10.1111/j.1467-8659.2008.01181.x", "10.1007/11795018_16", "10.1111/1467-8659.00265", "10.1007/978-3-642-13544-6_9", "10.1007/s10601-007-9026-8", "10.1007/978-3-642-29178-4_27", "10.1007/3-540-37620-8_18", "10.1111/j.1467-8659.2005.00849.x", "10.1007/978-3-540-85412-8_12", "10.1007/978-3-642-22571-0_2", "10.1007/978-3-642-13544-6_10", "10.1111/j.1467-8659.2003.00717.x", "10.1111/j.1467-8659.2004.00781.x", "10.1111/j.1467-8659.2008.01181.x", "10.1007/11795018_16", "10.1111/1467-8659.00265", "10.1007/978-3-642-13544-6_9", "10.1007/s10601-007-9026-8", "10.1007/978-3-642-29178-4_27", "10.1007/3-540-37620-8_18", "10.1111/j.1467-8659.2005.00849.x", "10.1007/978-3-540-85412-8_12", "10.1007/978-3-642-22571-0_2", "10.1007/978-3-642-13544-6_10", "10.1111/j.1467-8659.2003.00717.x", "10.1111/j.1467-8659.2004.00781.x", "10.1111/j.1467-8659.2008.01181.x", "10.1007/11795018_16", "10.1111/1467-8659.00265", "10.1007/978-3-642-13544-6_9", "10.1007/s10601-007-9026-8", "10.1007/978-3-642-29178-4_27"]}, "10.1109/TVCG.2013.2297933": {"doi": "10.1109/TVCG.2013.2297933", "author": ["M. Cho", "B. Kim", "H. Bae", "J. Seo"], "title": "Stroscope: Multi-Scale Visualization of Irregularly Measured Time-Series Data", "year": "2014", "abstract": "For irregularly measured time-series data, the measurement frequency or interval is as crucial information as measurements are. A well-known time-series visualization such as the line graph is good at showing an overall temporal pattern of change; however, it is not so effective in revealing the measurement frequency/interval while likely giving illusory confidence in values between measurements. In contrast, the bar graph is more effective in showing the frequency/interval, but less effective in showing an overall pattern than the line graph. We integrate the line graph and bar graph in a unified visualization model, called a ripple graph, to take the benefits of both of them with enhanced graphical integrity. Based on the ripple graph, we implemented an interactive time-series data visualization tool, called Stroscope, which facilitates multi-scale visualizations by providing users with a graphical widget to interactively control the integrated visualization model. We evaluated the visualization model (i.e., the ripple graph) through a controlled user study and Stroscope through long-term case studies with neurologists exploring large blood pressure measurement data of stroke patients. Results from our evaluations demonstrate that the ripple graph outperforms existing time-series visualizations, and that Stroscope has the efficacy and potential as an effective visual analysis tool for (irregularly) measured time-series data.", "keywords": ["blood pressure measurement", "data analysis", "data visualisation", "graph theory", "interactive systems", "medical administrative data processing", "time series", "Stroscope", "multiscale visualization", "irregularly measured time-series data", "measurement frequency", "measurement interval", "bar graph", "line graph", "unified visualization model", "ripple graph", "graphical integrity", "interactive time-series data visualization tool", "graphical widget", "integrated visualization model", "blood pressure measurement data", "stroke patients", "visual analysis tool", "Data visualization", "Frequency measurement", "Bars", "Blood pressure", "Visualization", "Time measurement", "Market research", "Irregularly measured time-series data", "frequency-aware visualization", "uncertainty visualization", "long-term case study"], "referenced_by": ["IKEY:7552532", "IKEY:8323992", "IKEY:8368315", "IKEY:8807351", "IKEY:8930535", "10.22237/jmasm/1556669220", "10.1016/j.engappai.2020.103857", "10.1016/j.visinf.2020.10.002"], "referencing": ["IKEY:5718616", "IKEY:1382913", "IKEY:5742371", "IKEY:5613429", "IKEY:5613426", "IKEY:6065010", "IKEY:6102435", "IKEY:1532144", "IKEY:5290731", "IKEY:801860", "IKEY:4271972", "IKEY:5290698", "IKEY:5290711", "IKEY:5332595", "IKEY:5718616", "IKEY:1382913", "IKEY:5742371", "IKEY:5613429", "IKEY:5613426", "IKEY:6065010", "IKEY:6102435", "IKEY:1532144", "IKEY:5290731", "IKEY:801860", "IKEY:4271972", "IKEY:5290698", "IKEY:5290711", "IKEY:5332595", "IKEY:5718616", "IKEY:1382913", "IKEY:5742371", "IKEY:5613429", "IKEY:5613426", "IKEY:6065010", "IKEY:6102435", "IKEY:1532144", "IKEY:5290731", "IKEY:801860", "IKEY:4271972", "IKEY:5290698", "IKEY:5290711", "IKEY:5332595", "10.1145/1294211.1294229", "10.1145/985692.985706", "10.1145/1518701.1518897", "10.1145/1133265.1133348", "10.1145/1357054.1357286", "10.1145/2470654.2466441", "10.1145/1978942.1979194", "10.1145/1168149.1168158", "10.1145/1357054.1357129", "10.1145/1978942.1979196", "10.1145/1978942.1979195", "10.1145/1294211.1294229", "10.1145/985692.985706", "10.1145/1518701.1518897", "10.1145/1133265.1133348", "10.1145/1357054.1357286", "10.1145/2470654.2466441", "10.1145/1978942.1979194", "10.1145/1168149.1168158", "10.1145/1357054.1357129", "10.1145/1978942.1979196", "10.1145/1978942.1979195", "10.1145/1294211.1294229", "10.1145/985692.985706", "10.1145/1518701.1518897", "10.1145/1133265.1133348", "10.1145/1357054.1357286", "10.1145/2470654.2466441", "10.1145/1978942.1979194", "10.1145/1168149.1168158", "10.1145/1357054.1357129", "10.1145/1978942.1979196", "10.1145/1978942.1979195", "10.1016/j.cag.2007.01.030", "10.1111/j.1467-8659.2010.01845.x", "10.1007/11555261_66", "10.1007/978-3-642-21716-6_15", "10.1007/978-3-642-25364-5_22", "10.1007/978-3-642-10520-3_89", "10.1016/j.cag.2007.01.030", "10.1111/j.1467-8659.2010.01845.x", "10.1007/11555261_66", "10.1007/978-3-642-21716-6_15", "10.1007/978-3-642-25364-5_22", "10.1007/978-3-642-10520-3_89", "10.1016/j.cag.2007.01.030", "10.1111/j.1467-8659.2010.01845.x", "10.1007/11555261_66", "10.1007/978-3-642-21716-6_15", "10.1007/978-3-642-25364-5_22", "10.1007/978-3-642-10520-3_89"]}}