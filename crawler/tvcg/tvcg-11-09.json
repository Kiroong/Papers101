{"10.1109/TVCG.2011.36": {"doi": "10.1109/TVCG.2011.36", "author": ["M. Moehring", "B. Froehlich"], "title": "Natural Interaction Metaphors for Functional Validations of Virtual Car Models", "year": "2011", "abstract": "Natural Interaction in virtual environments is a key requirement for the virtual validation of functional aspects in automotive product development processes. Natural Interaction is the metaphor people encounter in reality: the direct manipulation of objects by their hands. To enable this kind of Natural Interaction, we propose a pseudophysical metaphor that is both plausible enough to provide realistic interaction and robust enough to meet the needs of industrial applications. Our analysis of the most common types of objects in typical automotive scenarios guided the development of a set of refined grasping heuristics to support robust finger-based interaction of multiple hands and users. The objects' behavior in reaction to the users' finger motions is based on pseudophysical simulations, which also take various types of constrained objects into account. In dealing with real-world scenarios, we had to introduce the concept of Normal Proxies, which extend objects with appropriate normals for improved grasp detection and grasp stability. An expert review revealed that our interaction metaphors allow for an intuitive and reliable assessment of several functionalities of objects found in a car interior. Follow-up user studies showed that overall task performance and usability are similar for CAVE and HMD environments. For larger objects and more gross manipulation, using the CAVE without employing a virtual hand representation is preferred, but for more fine-grained manipulation and smaller objects, the HMD turns out to be beneficial.", "keywords": ["automotive components", "automotive engineering", "mechanical engineering computing", "product development", "virtual reality", "natural interaction metaphors", "functional validations", "virtual car models", "automotive product development processes", "direct object manipulation", "refined grasping heuristics", "finger-based interaction", "multiple hands", "object behavior", "pseudophysical simulations", "normal proxies", "car interior", "CAVE", "HMD", "virtual hand representation", "User interfaces", "Computer graphics", "Three dimensional displays", "User interfaces", "3D graphics and realism", "input/output devices", "systems and software."], "referenced_by": ["10.1109/3DUI.2013.6550204", "10.1109/3DUI.2013.6550205", "10.1109/3DUI.2015.7131734", "10.1109/3DUI.2015.7131736", "10.1109/AERO.2015.7118876", "10.1109/SVR.2014.13", "10.1109/SVR.2017.12", "10.1007/s11042-016-3959-0", "10.1007/978-3-030-22666-4_11", "10.1007/s10055-014-0246-0"], "referencing": ["10.1109/TVCG.2006.42", "10.1109/VR.2010.5444819", "10.1162/pres.2006.15.1.1", "10.1109/VR.2005.1492758", "10.1109/VR.2000.840357", "10.1109/VR.2000.840369", "10.1109/VR.2008.4480754", "10.1109/TVCG.2006.42", "10.1109/VR.2010.5444819", "10.1162/pres.2006.15.1.1", "10.1109/VR.2005.1492758", "10.1109/VR.2000.840357", "10.1109/VR.2000.840369", "10.1109/VR.2008.4480754", "10.1109/TVCG.2006.42", "10.1109/VR.2010.5444819", "10.1162/pres.2006.15.1.1", "10.1109/VR.2005.1492758", "10.1109/VR.2000.840357", "10.1109/VR.2000.840369", "10.1109/VR.2008.4480754", "10.1145/1140491.1140502", "10.1145/325334.325242", "10.1145/1450579.1450614", "10.1145/1140491.1140502", "10.1145/325334.325242", "10.1145/1450579.1450614", "10.1145/1140491.1140502", "10.1145/325334.325242", "10.1145/1450579.1450614", "10.1177/154193120204602607", "10.1177/154193120204602607", "10.1177/154193120204602607"]}, "10.1109/TVCG.2011.33": {"doi": "10.1109/TVCG.2011.33", "author": ["B. Sajadi", "A. Majumder"], "title": "Autocalibrating Tiled Projectors on Piecewise Smooth Vertically Extruded Surfaces", "year": "2011", "abstract": "In this paper, we present a novel technique to calibrate multiple casually aligned projectors on fiducial-free piecewise smooth vertically extruded surfaces using a single camera. Such surfaces include cylindrical displays and CAVEs, common in immersive virtual reality systems. We impose two priors to the display surface. We assume the surface is a piecewise smooth vertically extruded surface for which the aspect ratio of the rectangle formed by the four corners of the surface is known and the boundary is visible and segmentable. Using these priors, we can estimate the display's 3D geometry and camera extrinsic parameters using a nonlinear optimization technique from a single image without any explicit display to camera correspondences. Using the estimated camera and display properties, the intrinsic and extrinsic parameters of each projector are recovered using a single projected pattern seen by the camera. This in turn is used to register the images on the display from any arbitrary viewpoint making it appropriate for virtual reality systems. The fast convergence and robustness of this method is achieved via a novel dimension reduction technique for camera parameter estimation and a novel deterministic technique for projector property estimation. This simplicity, efficiency, and robustness of our method enable several coveted features for nonplanar projection-based displays. First, it allows fast recalibration in the face of projector, display or camera movements and even change in display shape. Second, this opens up, for the first time, the possibility of allowing multiple projectors to overlap on the corners of the CAVE-a popular immersive VR display system. Finally, this opens up the possibility of easily deploying multiprojector displays on aesthetic novel shapes for edutainment and digital signage applications", "keywords": ["cameras", "geometry", "image registration", "image segmentation", "optimisation", "parameter estimation", "solid modelling", "three-dimensional displays", "virtual reality", "fiducial-free piecewise smooth vertically extruded surface", "single camera", "cylindrical displays", "CAVE", "immersive virtual reality systems", "3D geometry", "camera extrinsic parameters", "nonlinear optimization technique", "image registration", "dimension reduction technique", "camera parameter estimation", "projector property estimation", "nonplanar projection based display", "VR display system", "edutainment", "digital signage applications", "Cameras", "Three dimensional displays", "Surface reconstruction", "Shape", "Optimization", "Calibration", "Registers", "Tiled displays", "autocalibration", "geometric registration", "cylindrical displays", "CAVES."], "referenced_by": ["10.1109/ICACCI.2017.8125945", "10.1109/ICVRV.2013.9", "10.1109/TVCG.2011.271", "10.1145/2782782.2792500", "10.1007/s10043-015-0123-4", "10.4218/etrij.13.0112.0597", "10.1117/12.2192662", "10.1117/1.JEI.28.1.013019", "10.1016/j.image.2019.03.006", "10.1049/iet-ipr.2018.5575"], "referencing": ["10.1109/TVCG.2005.27", "10.1109/VR.2010.5444797", "10.1109/TVCG.2004.1260769", "10.1109/VISUAL.1999.809883", "10.1109/ISMAR.2004.30", "10.1109/CVPR.2007.383460", "10.1109/VR.2009.4810996", "10.1109/CVPRW.2006.161", "10.1109/PCCGA.2002.1167859", "10.1109/TVCG.2009.166", "10.1109/ICPR.2004.1333994", "10.1109/VISUAL.2001.964508", "10.1109/TVCG.2007.70586", "10.1109/VISUAL.2002.1183793", "10.1109/TVCG.2006.121", "10.1109/CVPR.2008.4587709", "10.1109/TVCG.2005.27", "10.1109/VR.2010.5444797", "10.1109/TVCG.2004.1260769", "10.1109/VISUAL.1999.809883", "10.1109/ISMAR.2004.30", "10.1109/CVPR.2007.383460", "10.1109/VR.2009.4810996", "10.1109/CVPRW.2006.161", "10.1109/PCCGA.2002.1167859", "10.1109/TVCG.2009.166", "10.1109/ICPR.2004.1333994", "10.1109/VISUAL.2001.964508", "10.1109/TVCG.2007.70586", "10.1109/VISUAL.2002.1183793", "10.1109/TVCG.2006.121", "10.1109/CVPR.2008.4587709", "10.1109/TVCG.2005.27", "10.1109/VR.2010.5444797", "10.1109/TVCG.2004.1260769", "10.1109/VISUAL.1999.809883", "10.1109/ISMAR.2004.30", "10.1109/CVPR.2007.383460", "10.1109/VR.2009.4810996", "10.1109/CVPRW.2006.161", "10.1109/PCCGA.2002.1167859", "10.1109/TVCG.2009.166", "10.1109/ICPR.2004.1333994", "10.1109/VISUAL.2001.964508", "10.1109/TVCG.2007.70586", "10.1109/VISUAL.2002.1183793", "10.1109/TVCG.2006.121", "10.1109/CVPR.2008.4587709", "10.1145/1342250.1342258", "10.1145/1179352.1141964", "10.1145/1037957.1037964", "10.1145/1394622.1394626", "10.1145/1394622.1394624", "10.1145/882262.882349", "10.1145/1342250.1342258", "10.1145/1179352.1141964", "10.1145/1037957.1037964", "10.1145/1394622.1394626", "10.1145/1394622.1394624", "10.1145/882262.882349", "10.1145/1342250.1342258", "10.1145/1179352.1141964", "10.1145/1037957.1037964", "10.1145/1394622.1394626", "10.1145/1394622.1394624", "10.1145/882262.882349", "10.1111/j.1467-8659.2005.00895.x", "10.1111/j.1467-8659.2005.00895.x", "10.1111/j.1467-8659.2005.00895.x"]}, "10.1109/TVCG.2011.41": {"doi": "10.1109/TVCG.2011.41", "author": ["F. Steinicke", "G. Bruder", "K. Hinrichs", "P. Willemsen"], "title": "Change Blindness Phenomena for Virtual Reality Display Systems", "year": "2011", "abstract": "In visual perception, change blindness describes the phenomenon that persons viewing a visual scene may apparently fail to detect significant changes in that scene. These phenomena have been observed in both computer-generated imagery and real-world scenes. Several studies have demonstrated that change blindness effects occur primarily during visual disruptions such as blinks or saccadic eye movements. However, until now the influence of stereoscopic vision on change blindness has not been studied thoroughly in the context of visual perception research. In this paper, we introduce change blindness techniques for stereoscopic virtual reality (VR) systems, providing the ability to substantially modify a virtual scene in a manner that is difficult for observers to perceive. We evaluate techniques for semiimmersive VR systems, i.e., a passive and active stereoscopic projection system as well as an immersive VR system, i.e., a head-mounted display, and compare the results to those of monoscopic viewing conditions. For stereoscopic viewing conditions, we found that change blindness phenomena occur with the same magnitude as in monoscopic viewing conditions. Furthermore, we have evaluated the potential of the presented techniques for allowing abrupt, and yet significant, changes of a stereoscopically displayed virtual reality environment.", "keywords": ["natural scenes", "stereo image processing", "three-dimensional displays", "virtual reality", "vision defects", "visual perception", "change blindness", "virtual reality", "display systems", "visual perception", "visual scene", "computer-generated imagery", "visual disruptions", "stereoscopic vision", "monoscopic viewing conditions", "Blindness", "Visualization", "Virtual reality", "Observers", "Humans", "Context", "Visual perception", "Change blindness", "stereoscopic display", "virtual reality.", "Adult", "Computer Graphics", "Depth Perception", "Humans", "Male", "Task Performance and Analysis", "User-Computer Interface", "Visual Perception", "Young Adult"], "referenced_by": ["10.1145/3197517.3201335", "10.1117/12.2084842", "10.3389/fpsyg.2019.01688"], "referencing": ["10.1109/VR.2010.5444790", "10.1109/VR.2005.1492747", "10.1109/3DUI.2009.4811208", "10.1162/105474603322955950", "10.1109/TVCG.2009.62", "10.1109/TVCG.2007.1029", "10.1109/VR.2010.5444790", "10.1109/VR.2005.1492747", "10.1109/3DUI.2009.4811208", "10.1162/105474603322955950", "10.1109/TVCG.2009.62", "10.1109/TVCG.2007.1029", "10.1109/VR.2010.5444790", "10.1109/VR.2005.1492747", "10.1109/3DUI.2009.4811208", "10.1162/105474603322955950", "10.1109/TVCG.2009.62", "10.1109/TVCG.2007.1029", "10.1145/1152399.1152451", "10.1145/1450579.1450611", "10.1145/1152399.1152451", "10.1145/1450579.1450611", "10.1145/1152399.1152451", "10.1145/1450579.1450611", "10.1111/j.1467-9280.1997.tb00427.x", "10.1111/j.0963-7214.2005.00332.x", "10.3758/BF03208840", "10.1016/j.tics.2004.11.006", "10.1111/1467-9280.00183", "10.3758/BF03214339", "10.3758/BF03196330", "10.1111/1467-8721.01256", "10.1037//0096-1523.22.3.563", "10.1080/135062800394766", "10.3758/BF03210419", "10.1146/annurev.ne.13.030190.000325", "10.1080/135062800394720", "10.1037//0033-295X.95.1.15", "10.1016/B978-012443760-9/50010-6", "10.1111/j.1467-9280.1997.tb00427.x", "10.1111/j.0963-7214.2005.00332.x", "10.3758/BF03208840", "10.1016/j.tics.2004.11.006", "10.1111/1467-9280.00183", "10.3758/BF03214339", "10.3758/BF03196330", "10.1111/1467-8721.01256", "10.1037//0096-1523.22.3.563", "10.1080/135062800394766", "10.3758/BF03210419", "10.1146/annurev.ne.13.030190.000325", "10.1080/135062800394720", "10.1037//0033-295X.95.1.15", "10.1016/B978-012443760-9/50010-6", "10.1111/j.1467-9280.1997.tb00427.x", "10.1111/j.0963-7214.2005.00332.x", "10.3758/BF03208840", "10.1016/j.tics.2004.11.006", "10.1111/1467-9280.00183", "10.3758/BF03214339", "10.3758/BF03196330", "10.1111/1467-8721.01256", "10.1037//0096-1523.22.3.563", "10.1080/135062800394766", "10.3758/BF03210419", "10.1146/annurev.ne.13.030190.000325", "10.1080/135062800394720", "10.1037//0033-295X.95.1.15", "10.1016/B978-012443760-9/50010-6"]}, "10.1109/TVCG.2011.30": {"doi": "10.1109/TVCG.2011.30", "author": ["R. Nordahl", "L. Turchet", "S. Serafin"], "title": "Sound Synthesis and Evaluation of Interactive Footsteps and Environmental Sounds Rendering for Virtual Reality Applications", "year": "2011", "abstract": "We propose a system that affords real-time sound synthesis of footsteps on different materials. The system is based on microphones, which detect real footstep sounds from subjects, from which the ground reaction force (GRF) is estimated. Such GRF is used to control a sound synthesis engine based on physical models. Two experiments were conducted. In the first experiment, the ability of subjects to recognize the surface they were exposed to was assessed. In the second experiment, the sound synthesis engine was enhanced with environmental sounds. Results show that, in some conditions, adding a soundscape significantly improves the recognition of the simulated environment.", "keywords": ["audio signal processing", "microphones", "surface acoustic wave signal processing", "virtual reality", "interactive footsteps", "environmental sounds", "virtual reality applications", "real-time sound synthesis engine", "microphones", "ground reaction force", "soundscape rendering", "Legged locomotion", "Solid modeling", "Engines", "Materials", "Footwear", "Force", "Microphones", "Sound and music computing", "walking", "surface simulation", "soundscape rendering.", "Foot", "Humans", "Sound", "User-Computer Interface", "Video Games"], "referenced_by": ["10.1109/ICDSP.2013.6622706", "10.1109/ICDSP.2013.6622815", "10.1109/IGIC.2013.6659164", "10.1109/MMUL.2015.17", "10.1109/TOH.2012.51", "10.1109/MCG.2018.193142628", "10.1109/IISA.2015.7388078", "10.1109/ISMAR.2019.000-6", "10.1002/cav.1611", "10.1007/978-3-319-53088-8_4", "10.1016/j.ijhcs.2015.07.003", "10.1007/978-3-030-01692-0_28", "10.1007/978-3-642-45432-5_14", "10.3389/frobt.2020.00020"], "referencing": ["10.1109/TASL.2006.885924", "10.1109/VR.2010.5444796", "10.1162/105474600300040385", "10.1109/ICSENS.2003.1279111", "10.1109/TAC.2002.1000274", "10.1162/105474600566907", "10.1109/HAVE.2008.4685311", "10.1109/VR.2010.5444796", "10.1109/TASL.2006.885924", "10.1109/VR.2010.5444796", "10.1162/105474600300040385", "10.1109/ICSENS.2003.1279111", "10.1109/TAC.2002.1000274", "10.1162/105474600566907", "10.1109/HAVE.2008.4685311", "10.1109/VR.2010.5444796", "10.1109/TASL.2006.885924", "10.1109/VR.2010.5444796", "10.1162/105474600300040385", "10.1109/ICSENS.2003.1279111", "10.1109/TAC.2002.1000274", "10.1162/105474600566907", "10.1109/HAVE.2008.4685311", "10.1109/VR.2010.5444796", "10.1145/1111411.1111429", "10.1145/383259.383322", "10.1145/1111411.1111429", "10.1145/383259.383322", "10.1145/1111411.1111429", "10.1145/383259.383322", "10.3758/PP.70.1.13", "10.1007/978-3-642-15841-4_11", "10.1089/109493103321640374", "10.2307/3681012", "10.1207/s15326969eco0501_1", "10.1121/1.2149839", "10.1121/1.2934136", "10.1115/1.3423596", "10.1121/1.401778", "10.3758/PP.70.1.13", "10.1007/978-3-642-15841-4_11", "10.1089/109493103321640374", "10.2307/3681012", "10.1207/s15326969eco0501_1", "10.1121/1.2149839", "10.1121/1.2934136", "10.1115/1.3423596", "10.1121/1.401778", "10.3758/PP.70.1.13", "10.1007/978-3-642-15841-4_11", "10.1089/109493103321640374", "10.2307/3681012", "10.1207/s15326969eco0501_1", "10.1121/1.2149839", "10.1121/1.2934136", "10.1115/1.3423596", "10.1121/1.401778"]}, "10.1109/TVCG.2011.49": {"doi": "10.1109/TVCG.2011.49", "author": ["S. Lee", "H. Hua"], "title": "Effects of Viewing Conditions and Rotation Methods in a Collaborative Tabletop AR Environment", "year": "2011", "abstract": "We investigate the effects of viewing conditions and rotation methods on different types of collaborative tasks in a two-user colocated tabletop augmented reality (AR) environment. The viewing condition means how the manipulation of a tabletop world by one user is shown in the other users' views and the rotation method means what type of input devices is used to rotate the tabletop world for alternative orientations. Our experiment considered two viewing conditions (consistent view and inconsistent view), two rotation methods (direct turn and indirect turn), and two task types (synchronous and referring-strong type, and asynchronous and orientation-strong type). A 3D display environment called \"Stereoscopic Collaboration in Augmented and Projective Environments (SCAPE)\u201d was utilized as a test environment. According to the results, the viewing conditions had significant effects on several objective and subjective measurements. On task completion time, their effect for the synchronous and referring-strong type of task was opposite to that for the asynchronous and orientation-strong type of task. On the other hand, the rotation methods had significant effects only on the accumulated turn angle (for both task types) and the number of negotiation phrases (only in the inconsistent viewing condition for the asynchronous and orientation-strong type of task).", "keywords": ["augmented reality", "groupware", "three-dimensional displays", "rotation methods", "collaborative tabletop AR environment", "augmented reality", "3D display environment", "stereoscopic collaboration in augmented and projective environments", "SCAPE", "referring-strong type", "Collaboration", "Three dimensional displays", "Mice", "Turning", "Visualization", "Performance evaluation", "User interfaces", "Augmented reality", "collaborative computing", "evaluation", "human factors", "user interfaces."], "referenced_by": ["10.1109/VR.2018.8446311", "10.1109/VR.2018.8446311"], "referencing": ["10.1109/38.689665", "10.1109/VR.2010.5444794", "10.1109/ISMAR.2002.1115083", "10.1109/ICSMC.1999.816444", "10.1109/IV.2007.146", "10.1162/105474603322761261", "10.1109/ISMAR.2008.4637362", "10.1109/TABLETOP.2006.10", "10.1109/MCG.2004.1255811", "10.1162/1054746041382429", "10.1109/38.689665", "10.1109/VR.2010.5444794", "10.1109/ISMAR.2002.1115083", "10.1109/ICSMC.1999.816444", "10.1109/IV.2007.146", "10.1162/105474603322761261", "10.1109/ISMAR.2008.4637362", "10.1109/TABLETOP.2006.10", "10.1109/MCG.2004.1255811", "10.1162/1054746041382429", "10.1109/38.689665", "10.1109/VR.2010.5444794", "10.1109/ISMAR.2002.1115083", "10.1109/ICSMC.1999.816444", "10.1109/IV.2007.146", "10.1162/105474603322761261", "10.1109/ISMAR.2008.4637362", "10.1109/TABLETOP.2006.10", "10.1109/MCG.2004.1255811", "10.1162/1054746041382429", "10.1145/514236.514265", "10.1145/1240624.1240638", "10.1145/1268517.1268552", "10.1145/958160.958219", "10.1145/302979.303113", "10.1145/1255047.1255065", "10.1145/587078.587124", "10.1145/1460563.1460589", "10.1145/514236.514265", "10.1145/1240624.1240638", "10.1145/1268517.1268552", "10.1145/958160.958219", "10.1145/302979.303113", "10.1145/1255047.1255065", "10.1145/587078.587124", "10.1145/1460563.1460589", "10.1145/514236.514265", "10.1145/1240624.1240638", "10.1145/1268517.1268552", "10.1145/958160.958219", "10.1145/302979.303113", "10.1145/1255047.1255065", "10.1145/587078.587124", "10.1145/1460563.1460589", "10.1207/S15327590IJHC1603_2", "10.1007/978-3-642-03655-2_72", "10.1007/s100550200016", "10.1007/978-94-010-0068-0_9", "10.1016/S0097-8493(03)00028-1", "10.1016/j.destud.2009.11.001", "10.1016/j.autcon.2007.07.002", "10.1006/imms.1993.1085", "10.1364/AO.47.002888", "10.1007/978-3-642-03364-3_53", "10.1207/S15327051HCI1403_2", "10.1207/S15327590IJHC1603_2", "10.1007/978-3-642-03655-2_72", "10.1007/s100550200016", "10.1007/978-94-010-0068-0_9", "10.1016/S0097-8493(03)00028-1", "10.1016/j.destud.2009.11.001", "10.1016/j.autcon.2007.07.002", "10.1006/imms.1993.1085", "10.1364/AO.47.002888", "10.1007/978-3-642-03364-3_53", "10.1207/S15327051HCI1403_2", "10.1207/S15327590IJHC1603_2", "10.1007/978-3-642-03655-2_72", "10.1007/s100550200016", "10.1007/978-94-010-0068-0_9", "10.1016/S0097-8493(03)00028-1", "10.1016/j.destud.2009.11.001", "10.1016/j.autcon.2007.07.002", "10.1006/imms.1993.1085", "10.1364/AO.47.002888", "10.1007/978-3-642-03364-3_53", "10.1207/S15327051HCI1403_2"]}, "10.1109/TVCG.2011.38": {"doi": "10.1109/TVCG.2011.38", "author": ["C. W. Borst", "J. Tiesel", "E. Habib", "K. Das"], "title": "Single-Pass Composable 3D Lens Rendering and Spatiotemporal 3D Lenses", "year": "2011", "abstract": "We present a new 3D lens rendering technique and a new spatiotemporal lens. Interactive 3D lenses, often called volumetric lenses, provide users with alternative views of data sets within 3D lens boundaries while maintaining the surrounding overview (context). In contrast to previous multipass rendering work, we discuss the strengths, limitations, and performance costs of a single-pass technique especially suited to fragment-level lens effects, such as color mapping, lighting, and clipping. Some object-level effects, such as a data set selection lens, are also incorporated, with each object's geometry being processed once by the graphics pipeline. For a substantial range of effects, our approach supports several composable lenses at interactive frame rates without performance loss during increasing lens intersections or manipulation by a user. Other cases, for which this performance cannot be achieved, are also discussed. We illustrate possible applications of our lens system, including Time Warp lenses for exploring time-varying data sets.", "keywords": ["computational geometry", "lenses", "solid modelling", "time warp simulation", "single-pass composable 3D lens rendering technique", "spatiotemporal 3D lens technique", "interactive 3D lens", "volumetric lens", "performance cost", "fragment-level lens effect", "object-level effect", "data set selection lens", "object geometry", "graphics pipeline", "interactive frame rate", "time warp lens", "time varying data set", "Lenses", "Three dimensional displays", "Rendering (computer graphics)", "Geometry", "Graphics processing unit", "Shape", "Transforms", "Interaction styles", "virtual reality", "volumetric lens."], "referenced_by": ["10.1201/b17360-55"], "referencing": ["10.1109/VISUAL.1998.745317", "10.1109/ISMAR.2006.297816", "10.1109/TVCG.2007.70534", "10.1109/VISUAL.2005.1532818", "10.1109/TVCG.2009.89", "10.1109/VR.2008.4480772", "10.1109/VR.2010.5444782", "10.1109/VR.2009.4811060", "10.1109/3DUI.2009.4811199", "10.1162/105474601753272835", "10.1109/VISUAL.1998.745317", "10.1109/ISMAR.2006.297816", "10.1109/TVCG.2007.70534", "10.1109/VISUAL.2005.1532818", "10.1109/TVCG.2009.89", "10.1109/VR.2008.4480772", "10.1109/VR.2010.5444782", "10.1109/VR.2009.4811060", "10.1109/3DUI.2009.4811199", "10.1162/105474601753272835", "10.1109/VISUAL.1998.745317", "10.1109/ISMAR.2006.297816", "10.1109/TVCG.2007.70534", "10.1109/VISUAL.2005.1532818", "10.1109/TVCG.2009.89", "10.1109/VR.2008.4480772", "10.1109/VR.2010.5444782", "10.1109/VR.2009.4811060", "10.1109/3DUI.2009.4811199", "10.1162/105474601753272835", "10.1145/237091.237098", "10.1145/988834.988870", "10.1145/1449715.1449756", "10.1145/166117.166126", "10.1145/237091.237098", "10.1145/988834.988870", "10.1145/1449715.1449756", "10.1145/166117.166126", "10.1145/237091.237098", "10.1145/988834.988870", "10.1145/1449715.1449756", "10.1145/166117.166126", "10.1007/11555261_64", "10.1061/(ASCE)1084-0699(2008)13:12(1177)", "10.1007/11555261_64", "10.1061/(ASCE)1084-0699(2008)13:12(1177)", "10.1007/11555261_64", "10.1061/(ASCE)1084-0699(2008)13:12(1177)"]}, "10.1109/TVCG.2010.233": {"doi": "10.1109/TVCG.2010.233", "author": ["M. K. Johnson", "K. Dale", "S. Avidan", "H. Pfister", "W. T. Freeman", "W. Matusik"], "title": "CG2Real: Improving the Realism of Computer Generated Images Using a Large Collection of Photographs", "year": "2011", "abstract": "Computer-generated (CG) images have achieved high levels of realism. This realism, however, comes at the cost of long and expensive manual modeling, and often humans can still distinguish between CG and real images. We introduce a new data-driven approach for rendering realistic imagery that uses a large collection of photographs gathered from online repositories. Given a CG image, we retrieve a small number of real images with similar global structure. We identify corresponding regions between the CG and real images using a mean-shift cosegmentation algorithm. The user can then automatically transfer color, tone, and texture from matching regions to the CG image. Our system only uses image processing operations and does not require a 3D model of the scene, making it fast and easy to integrate into digital content creation workflows. Results of a user study show that our hybrid images appear more realistic than the originals.", "keywords": ["image colour analysis", "image matching", "image segmentation", "image texture", "photography", "realistic images", "rendering (computer graphics)", "CG2Real", "computer-generated image", "CG image", "realism", "rendering", "realistic imagery", "photograph", "mean-shift cosegmentation algorithm", "image color", "image tone", "image texture", "image matching", "hybrid image", "Image color analysis", "Pixel", "Image segmentation", "Databases", "Rendering (computer graphics)", "Histograms", "Computational modeling", "Image enhancement", "image databases", "image-based rendering."], "referenced_by": ["10.1109/ACCESS.2018.2796638", "10.1109/CAC.2017.8243966", "10.1109/CVPR.2014.375", "10.1109/CVPR.2017.241", "10.1109/CVPR.2017.299", "10.1109/ICCPhot.2012.6215221", "10.1109/ICCV.2015.449", "10.1109/ICVRV.2015.47", "10.1109/JPROC.2013.2260711", "10.1109/TIP.2013.2279315", "10.1109/TIP.2015.2414873", "10.1109/TMM.2013.2239629", "10.1109/TMM.2014.2299511", "10.1109/TMM.2016.2535727", "10.1109/TMM.2016.2631123", "10.1109/TVCG.2013.77", "10.1109/VR.2012.6180881", "10.1109/CVPR.2018.00918", "10.1109/CVPR.2019.00242", "10.1109/CVPR.2019.00861", "10.1145/2980179.2980249", "10.1145/2601097.2601101", "10.1145/2661229.2661278", "10.1145/2699641", "10.1145/3072959.3073683", "10.1145/2508363.2508381", "10.1145/2897824.2925942", "10.1145/2461912.2461939", "10.1007/978-981-10-3561-6_6", "10.1007/s00371-013-0818-0", "10.1007/s11042-016-3658-x", "10.1111/cgf.12678", "10.1111/cgf.13225", "10.1111/cgf.13261", "10.1111/j.1467-8659.2012.03005.x", "10.1007/s00371-013-0792-6", "10.1117/1.JEI.23.2.023010", "10.1111/j.1467-8659.2012.03022.x", "10.3389/fpsyg.2019.02390", "10.1101/866921", "10.1111/cgf.14022"], "referencing": ["10.1109/ICCV.1999.790383", "10.1109/TSP.2004.839896", "10.1109/ICCV.2007.4409107", "10.1109/CVPR.2007.383092", "10.1109/CVPR.2005.160", "10.1109/CVPR.2006.68", "10.1109/ICCV.2005.239", "10.1109/TIT.1975.1055330", "10.1109/CVPR.2007.383228", "10.1109/TCOM.1983.1095851", "10.1109/CVPR.2006.91", "10.1109/38.988747", "10.1109/ICCV.2003.1238384", "10.1109/38.946629", "10.1109/ICCV.2009.5459473", "10.1109/ICCV.1999.790383", "10.1109/TSP.2004.839896", "10.1109/ICCV.2007.4409107", "10.1109/CVPR.2007.383092", "10.1109/CVPR.2005.160", "10.1109/CVPR.2006.68", "10.1109/ICCV.2005.239", "10.1109/TIT.1975.1055330", "10.1109/CVPR.2007.383228", "10.1109/TCOM.1983.1095851", "10.1109/CVPR.2006.91", "10.1109/38.988747", "10.1109/ICCV.2003.1238384", "10.1109/38.946629", "10.1109/ICCV.2009.5459473", "10.1109/ICCV.1999.790383", "10.1109/TSP.2004.839896", "10.1109/ICCV.2007.4409107", "10.1109/CVPR.2007.383092", "10.1109/CVPR.2005.160", "10.1109/CVPR.2006.68", "10.1109/ICCV.2005.239", "10.1109/TIT.1975.1055330", "10.1109/CVPR.2007.383228", "10.1109/TCOM.1983.1095851", "10.1109/CVPR.2006.91", "10.1109/38.988747", "10.1109/ICCV.2003.1238384", "10.1109/38.946629", "10.1109/ICCV.2009.5459473", "10.1145/1276377.1276382", "10.1145/218380.218446", "10.1145/258734.258882", "10.1145/1618452.1618505", "10.1145/1275808.1276497", "10.1145/1073204.1073271", "10.1145/882262.882269", "10.1145/258734.258854", "10.1145/383259.383296", "10.1145/882262.882264", "10.1145/383259.383295", "10.1145/1141911.1141935", "10.1145/1409060.1409105", "10.1145/1276377.1276381", "10.1145/1276377.1276382", "10.1145/218380.218446", "10.1145/258734.258882", "10.1145/1618452.1618505", "10.1145/1275808.1276497", "10.1145/1073204.1073271", "10.1145/882262.882269", "10.1145/258734.258854", "10.1145/383259.383296", "10.1145/882262.882264", "10.1145/383259.383295", "10.1145/1141911.1141935", "10.1145/1409060.1409105", "10.1145/1276377.1276381", "10.1145/1276377.1276382", "10.1145/218380.218446", "10.1145/258734.258882", "10.1145/1618452.1618505", "10.1145/1275808.1276497", "10.1145/1073204.1073271", "10.1145/882262.882269", "10.1145/258734.258854", "10.1145/383259.383296", "10.1145/882262.882264", "10.1145/383259.383295", "10.1145/1141911.1141935", "10.1145/1409060.1409105", "10.1145/1276377.1276381", "10.1007/s11263-007-0090-8", "10.1111/j.1467-8659.2006.00960.x", "10.1007/s11263-006-9794-4", "10.1023/B:VISI.0000029664.99615.94", "10.1023/A:1011139631724", "10.1111/j.1467-8659.2008.01321.x", "10.1007/s11263-007-0090-8", "10.1111/j.1467-8659.2006.00960.x", "10.1007/s11263-006-9794-4", "10.1023/B:VISI.0000029664.99615.94", "10.1023/A:1011139631724", "10.1111/j.1467-8659.2008.01321.x", "10.1007/s11263-007-0090-8", "10.1111/j.1467-8659.2006.00960.x", "10.1007/s11263-006-9794-4", "10.1023/B:VISI.0000029664.99615.94", "10.1023/A:1011139631724", "10.1111/j.1467-8659.2008.01321.x"]}, "10.1109/TVCG.2010.228": {"doi": "10.1109/TVCG.2010.228", "author": ["H. Kim", "C. Yu", "L. Kim"], "title": "A Memory-Efficient Unified Early Z-Test", "year": "2011", "abstract": "The Unified Early Z-Test (U-EZT) is proposed to examine the visibility of pixels during tile-based rasterization in a mobile 3D graphics processor. U-EZT combines the advantages of the Z-max and Z-min EZT algorithms: the Z-max algorithm is improved by the independently updatable z-max tiles and the use of mask bits; and the Z-min algorithm is improved by reusing the mask bits from the z-max test to update the z-min tiles after tile rasterizing. As a result, storage requirements are reduced to 3 bits per pixel, and simulations suggest that U-EZT requires 20 percent to 57 percent less memory bandwidth than previous EZT algorithms.", "keywords": ["computer graphic equipment", "solid modelling", "storage management chips", "memory-efficient unified early Z-test", "tile-based rasterization", "mobile 3D graphics processor", "U-EZT", "Z-max EZT algorithm", "Z-min EZT algorithm", "Z-max test", "Z-min tile", "tile rasterizing", "memory bandwidth", "Classification algorithms", "Memory management", "System-on-a-chip", "Rendering (computer graphics)", "Computer graphics", "graphics processors", "visible line/surface algorithms", "z-test."], "referenced_by": ["10.1109/JSTARS.2015.2506268"], "referencing": ["10.1109/ISCAS.2002.1010972", "10.1109/ISCAS.2006.1693760", "10.1109/ISCAS.2003.1206023", "10.1109/JSSC.2005.859330", "10.1109/CGI.1998.694268", "10.1109/MC.2000.868692", "10.1109/38.656790", "10.1109/ISCAS.2002.1010972", "10.1109/ISCAS.2006.1693760", "10.1109/ISCAS.2003.1206023", "10.1109/JSSC.2005.859330", "10.1109/CGI.1998.694268", "10.1109/MC.2000.868692", "10.1109/38.656790", "10.1109/ISCAS.2002.1010972", "10.1109/ISCAS.2006.1693760", "10.1109/ISCAS.2003.1206023", "10.1109/JSSC.2005.859330", "10.1109/CGI.1998.694268", "10.1109/MC.2000.868692", "10.1109/38.656790", "10.1145/1201775.882348", "10.1145/262839.262847", "10.1145/122718.122725", "10.1145/258734.258781", "10.1145/166117.166147", "10.1145/1201775.882348", "10.1145/262839.262847", "10.1145/122718.122725", "10.1145/258734.258781", "10.1145/166117.166147", "10.1145/1201775.882348", "10.1145/262839.262847", "10.1145/122718.122725", "10.1145/258734.258781", "10.1145/166117.166147"]}, "10.1109/TVCG.2010.239": {"doi": "10.1109/TVCG.2010.239", "author": ["D. Xiang", "J. Tian", "F. Yang", "Q. Yang", "X. Zhang", "Q. Li", "X. Liu"], "title": "Skeleton Cuts\u2014An Efficient Segmentation Method for Volume Rendering", "year": "2011", "abstract": "Volume rendering has long been used as a key technique for volume data visualization, which works by using a transfer function to map color and opacity to each voxel. Many volume rendering approaches proposed so far for voxels classification have been limited in a single global transfer function, which is in general unable to properly visualize interested structures. In this paper, we propose a localized volume data visualization approach which regards volume visualization as a combination of two mutually related processes: the segmentation of interested structures and the visualization using a locally designed transfer function for each individual structure of interest. As shown in our work, a new interactive segmentation algorithm is advanced via skeletons to properly categorize interested structures. In addition, a localized transfer function is subsequently presented to assign optical parameters via interested information such as intensity, thickness and distance. As can be seen from the experimental results, the proposed techniques allow to appropriately visualize interested structures in highly complex volume medical data sets.", "keywords": ["bone", "data visualisation", "image classification", "image colour analysis", "image segmentation", "interactive systems", "medical image processing", "rendering (computer graphics)", "volume data visualization", "transfer function", "color mapping", "opacity mapping", "volume rendering", "voxel classification", "interactive segmentation algorithm", "localized transfer function", "visual parameters", "complex medical sets", "skeleton cuts", "Skeleton", "Transfer functions", "Rendering (computer graphics)", "Data visualization", "Euclidean distance", "Three dimensional displays", "Visualization", "Volume rendering", "classification", "segmentation", "skeleton cuts", "localized transfer function", "Abdomen", "Algorithms", "Brain", "Computer Graphics", "Diagnostic Imaging", "Heart", "Humans", "Image Processing, Computer-Assisted", "Mandible"], "referenced_by": ["10.1109/CGIV.2012.14", "10.1109/THMS.2013.2290011", "10.1109/TIP.2015.2481326", "10.1109/TVCG.2011.113", "10.1109/TBME.2015.2433397", "10.1109/TMI.2015.2474119", "10.1109/TVCG.2017.2784830", "10.1109/TVCG.2018.2856744", "10.1007/s11042-014-1994-2", "10.1016/j.media.2017.06.010", "10.1016/j.patcog.2012.10.005", "10.1088/0031-9155/60/13/5123", "10.1111/cgf.12934", "10.1111/cgf.12624", "10.1016/j.jvlc.2018.07.004", "10.1117/12.2216071", "10.1002/spe.2768"], "referencing": ["10.1109/TVCG.2006.100", "10.1109/TVCG.2006.39", "10.1109/TVCG.2008.23", "10.1109/38.511", "10.1109/SVV.1998.729588", "10.1109/TVCG.2005.38", "10.1109/34.56205", "10.1109/34.192473", "10.1109/TPAMI.2007.54", "10.1109/TPAMI.2004.60", "10.1109/ICCV.2005.13", "10.1109/VISUAL.2003.1250386", "10.1109/TITB.2008.926395", "10.1109/TVCG.2009.25", "10.1109/VISUAL.1997.663875", "10.1109/2945.856997", "10.1109/VISUAL.2003.1250414", "10.1109/TVCG.2006.148", "10.1109/TVCG.2002.1021579", "10.1109/TVCG.2008.162", "10.1109/TVCG.2009.189", "10.1109/TVCG.2008.169", "10.1109/TVCG.2008.147", "10.1109/TVCG.2007.47", "10.1109/VISUAL.1999.809932", "10.1109/PCCGA.2003.1238277", "10.1109/TVCG.2007.1051", "10.1109/TVCG.2006.100", "10.1109/TVCG.2006.39", "10.1109/TVCG.2008.23", "10.1109/38.511", "10.1109/SVV.1998.729588", "10.1109/TVCG.2005.38", "10.1109/34.56205", "10.1109/34.192473", "10.1109/TPAMI.2007.54", "10.1109/TPAMI.2004.60", "10.1109/ICCV.2005.13", "10.1109/VISUAL.2003.1250386", "10.1109/TITB.2008.926395", "10.1109/TVCG.2009.25", "10.1109/VISUAL.1997.663875", "10.1109/2945.856997", "10.1109/VISUAL.2003.1250414", "10.1109/TVCG.2006.148", "10.1109/TVCG.2002.1021579", "10.1109/TVCG.2008.162", "10.1109/TVCG.2009.189", "10.1109/TVCG.2008.169", "10.1109/TVCG.2008.147", "10.1109/TVCG.2007.47", "10.1109/VISUAL.1999.809932", "10.1109/PCCGA.2003.1238277", "10.1109/TVCG.2007.1051", "10.1109/TVCG.2006.100", "10.1109/TVCG.2006.39", "10.1109/TVCG.2008.23", "10.1109/38.511", "10.1109/SVV.1998.729588", "10.1109/TVCG.2005.38", "10.1109/34.56205", "10.1109/34.192473", "10.1109/TPAMI.2007.54", "10.1109/TPAMI.2004.60", "10.1109/ICCV.2005.13", "10.1109/VISUAL.2003.1250386", "10.1109/TITB.2008.926395", "10.1109/TVCG.2009.25", "10.1109/VISUAL.1997.663875", "10.1109/2945.856997", "10.1109/VISUAL.2003.1250414", "10.1109/TVCG.2006.148", "10.1109/TVCG.2002.1021579", "10.1109/TVCG.2008.162", "10.1109/TVCG.2009.189", "10.1109/TVCG.2008.169", "10.1109/TVCG.2008.147", "10.1109/TVCG.2007.47", "10.1109/VISUAL.1999.809932", "10.1109/PCCGA.2003.1238277", "10.1109/TVCG.2007.1051", "10.1145/1053427.1053445", "10.1145/258734.258887", "10.1145/1053427.1053445", "10.1145/258734.258887", "10.1145/1053427.1053445", "10.1145/258734.258887", "10.1016/S0925-7721(99)00050-4", "10.1007/s11263-006-7934-5", "10.2307/1932409", "10.1016/j.media.2009.07.011", "10.1007/978-3-540-39903-2_22", "10.1007/s00371-005-0330-2", "10.1016/S0925-7721(99)00050-4", "10.1007/s11263-006-7934-5", "10.2307/1932409", "10.1016/j.media.2009.07.011", "10.1007/978-3-540-39903-2_22", "10.1007/s00371-005-0330-2", "10.1016/S0925-7721(99)00050-4", "10.1007/s11263-006-7934-5", "10.2307/1932409", "10.1016/j.media.2009.07.011", "10.1007/978-3-540-39903-2_22", "10.1007/s00371-005-0330-2"]}, "10.1109/TVCG.2010.253": {"doi": "10.1109/TVCG.2010.253", "author": ["P. Bremer", "G. Weber", "J. Tierny", "V. Pascucci", "M. Day", "J. Bell"], "title": "Interactive Exploration and Analysis of Large-Scale Simulations Using Topology-Based Data Segmentation", "year": "2011", "abstract": "Large-scale simulations are increasingly being used to study complex scientific and engineering phenomena. As a result, advanced visualization and data analysis are also becoming an integral part of the scientific process. Often, a key step in extracting insight from these large simulations involves the definition, extraction, and evaluation of features in the space and time coordinates of the solution. However, in many applications, these features involve a range of parameters and decisions that will affect the quality and direction of the analysis. Examples include particular level sets of a specific scalar field, or local inequalities between derived quantities. A critical step in the analysis is to understand how these arbitrary parameters/decisions impact the statistical properties of the features, since such a characterization will help to evaluate the conclusions of the analysis as a whole. We present a new topological framework that in a single-pass extracts and encodes entire families of possible features definitions as well as their statistical properties. For each time step we construct a hierarchical merge tree a highly compact, yet flexible feature representation. While this data structure is more than two orders of magnitude smaller than the raw simulation data it allows us to extract a set of features for any given parameter selection in a postprocessing step. Furthermore, we augment the trees with additional attributes making it possible to gather a large number of useful global, local, as well as conditional statistic that would otherwise be extremely difficult to compile. We also use this representation to create tracking graphs that describe the temporal evolution of the features over time. Our system provides a linked-view interface to explore the time-evolution of the graph interactively alongside the segmentation, thus making it possible to perform extensive data analysis in a very efficient manner. We demonstrate our framework by extracting and analyzing burning cells from a large-scale turbulent combustion simulation. In particular, we show how the statistical analysis enabled by our techniques provides new insight into the combustion process.", "keywords": ["combustion", "data analysis", "digital simulation", "natural sciences computing", "statistical analysis", "large scale simulations", "topology based data segmentation", "data analysis", "scientific process", "single pass extracts", "hierarchical merge tree", "feature representation", "burning cells", "turbulent combustion simulation", "statistical analysis", "Fuels", "Feature extraction", "Combustion", "Computational modeling", "Data visualization", "Data structures", "Data models", "Topology", "Morse theory", "merge trees", "segmentation", "streaming algorithms", "combustion."], "referenced_by": ["10.1109/FiCloud.2014.84", "10.1109/ICNGIS.2016.7854016", "10.1109/IPDPS.2015.50", "10.1109/LDAV.2014.7013201", "10.1109/LDAV.2015.7348066", "10.1109/LDAV.2016.7874333", "10.1109/LDAV.2017.8231846", "10.1109/PACIFICVIS.2015.7156387", "10.1109/PACIFICVIS.2016.7465251", "10.1109/SC.2012.31", "10.1109/TPDS.2015.2417531", "10.1109/TVCG.2014.2346456", "10.1109/TVCG.2017.2743938", "10.1109/TVCG.2017.2692781", "10.1109/LDAV.2015.7348067", "10.1109/TVCG.2013.131", "10.1109/PacificVis.2018.00015", "10.1109/TVCG.2018.2864432", "10.1109/TVCG.2018.2864901", "10.1109/TVCG.2018.2810068", "10.1109/MLHPC.2018.8638633", "10.1109/LDAV.2018.8739196", "10.1109/TPDS.2019.2898436", "10.1109/TVCG.2019.2934256", "10.1109/TVCG.2019.2934257", "10.1109/TVCG.2019.2934312", "10.1109/TVCG.2019.2934258", "10.1109/TVCG.2019.2934368", "10.1109/UrgentHPC49580.2019.00007", "10.1145/2503210.2503303", "10.1145/2912152.2912157", "10.1145/2517327.2442526", "10.1007/978-3-319-44684-4_18", "10.1007/978-3-319-44684-4_2", "10.1007/978-3-319-44684-4_20", "10.1007/978-3-319-44684-4_5", "10.1007/s00454-017-9901-z", "10.1016/j.cag.2013.09.001", "10.1016/j.cag.2017.07.006", "10.1016/j.cag.2018.02.002", "10.1016/j.jksuci.2016.12.006", "10.1016/j.precisioneng.2016.12.005", "10.1111/cgf.12120", "10.1111/cgf.12596", "10.1111/cgf.12800", "10.1111/cgf.12930", "10.1111/cgf.12933", "10.1111/cgf.13164", "10.1111/cgf.13165", "10.1111/cgf.13336", "10.1201/b12985-19", "10.4028/www.scientific.net/AMM.869.9", "10.1007/978-1-4471-6497-5_18", "10.1007/978-3-030-02686-8_83", "10.1007/978-3-662-44900-4_4", "10.1007/s12650-019-00578-1", "10.1016/j.visinf.2019.08.002", "10.1007/978-981-10-2104-6_45", "10.1088/2051-672X/ab70e8", "10.1007/s12650-020-00654-x"], "referencing": ["10.1109/TVCG.2003.1207437", "10.1109/2945.489388", "10.1109/TVCG.2009.69", "10.1109/VISUAL.1995.480807", "10.1109/TVCG.2007.70519", "10.1109/2.299407", "10.1109/2945.597796", "10.1109/TVCG.2006.186", "10.1109/TVCG.2006.16", "10.1109/2945.485619", "10.1109/TVCG.2004.3", "10.1109/TVCG.2007.70552", "10.1109/VISUAL.2004.96", "10.1109/TVCG.2007.47", "10.1109/TVCG.2007.70603", "10.1109/TVCG.2009.119", "10.1109/TVCG.2003.1207437", "10.1109/2945.489388", "10.1109/TVCG.2009.69", "10.1109/VISUAL.1995.480807", "10.1109/TVCG.2007.70519", "10.1109/2.299407", "10.1109/2945.597796", "10.1109/TVCG.2006.186", "10.1109/TVCG.2006.16", "10.1109/2945.485619", "10.1109/TVCG.2004.3", "10.1109/TVCG.2007.70552", "10.1109/VISUAL.2004.96", "10.1109/TVCG.2007.47", "10.1109/TVCG.2007.70603", "10.1109/TVCG.2009.119", "10.1109/TVCG.2003.1207437", "10.1109/2945.489388", "10.1109/TVCG.2009.69", "10.1109/VISUAL.1995.480807", "10.1109/TVCG.2007.70519", "10.1109/2.299407", "10.1109/2945.597796", "10.1109/TVCG.2006.186", "10.1109/TVCG.2006.16", "10.1109/2945.485619", "10.1109/TVCG.2004.3", "10.1109/TVCG.2007.70552", "10.1109/VISUAL.2004.96", "10.1109/TVCG.2007.47", "10.1109/TVCG.2007.70603", "10.1109/TVCG.2009.119", "10.1145/37402.37422", "10.1145/1463822.1463869", "10.1145/262839.269238", "10.1145/345513.345271", "10.1145/37402.37422", "10.1145/1463822.1463869", "10.1145/262839.269238", "10.1145/345513.345271", "10.1145/37402.37422", "10.1145/1463822.1463869", "10.1145/262839.269238", "10.1145/345513.345271", "10.1016/0010-2180(94)00138-I", "10.1016/0010-2180(94)00196-Y", "10.1111/j.1467-8659.2003.00723.x", "10.1007/b106657_3", "10.1016/j.comgeo.2007.11.001", "10.1088/1742-6596/78/1/012007", "10.1016/S0925-7721(02)00093-7", "10.1007/s00453-003-1052-3", "10.1016/j.gmod.2003.08.002", "10.1007/s00454-003-2926-5", "10.1007/978-3-540-77704-5_15", "10.1088/1742-6596/46/1/001", "10.1364/AO.46.003928", "10.1016/j.proci.2006.08.038", "10.1016/j.expthermflusci.2007.11.012", "10.1088/1364-7830/4/4/309", "10.1007/978-3-540-88606-8_5", "10.1016/j.combustflame.2008.10.029", "10.1016/0010-2180(94)00138-I", "10.1016/0010-2180(94)00196-Y", "10.1111/j.1467-8659.2003.00723.x", "10.1007/b106657_3", "10.1016/j.comgeo.2007.11.001", "10.1088/1742-6596/78/1/012007", "10.1016/S0925-7721(02)00093-7", "10.1007/s00453-003-1052-3", "10.1016/j.gmod.2003.08.002", "10.1007/s00454-003-2926-5", "10.1007/978-3-540-77704-5_15", "10.1088/1742-6596/46/1/001", "10.1364/AO.46.003928", "10.1016/j.proci.2006.08.038", "10.1016/j.expthermflusci.2007.11.012", "10.1088/1364-7830/4/4/309", "10.1007/978-3-540-88606-8_5", "10.1016/j.combustflame.2008.10.029", "10.1016/0010-2180(94)00138-I", "10.1016/0010-2180(94)00196-Y", "10.1111/j.1467-8659.2003.00723.x", "10.1007/b106657_3", "10.1016/j.comgeo.2007.11.001", "10.1088/1742-6596/78/1/012007", "10.1016/S0925-7721(02)00093-7", "10.1007/s00453-003-1052-3", "10.1016/j.gmod.2003.08.002", "10.1007/s00454-003-2926-5", "10.1007/978-3-540-77704-5_15", "10.1088/1742-6596/46/1/001", "10.1364/AO.46.003928", "10.1016/j.proci.2006.08.038", "10.1016/j.expthermflusci.2007.11.012", "10.1088/1364-7830/4/4/309", "10.1007/978-3-540-88606-8_5", "10.1016/j.combustflame.2008.10.029"]}, "10.1109/TVCG.2010.246": {"doi": "10.1109/TVCG.2010.246", "author": ["A. J. Rueda", "F. R. Feito"], "title": "EL-REP: A New 2D Geometric Decomposition Scheme and Its Applications", "year": "2011", "abstract": "This work describes the EL-REP, a new 2D decomposition scheme with interesting properties and applications. The EL-REP can be computed for one or more simple polygons of any kind: convex or nonconvex, with or without holes and even with several shells. A method for constructing this decomposition is described in detail, together with several of its main applications: fast point-in-polygon inclusion test, 2D location, triangulation of polygons, and collision detection.", "keywords": ["computational geometry", "mesh generation", "solid modelling", "2D geometric decomposition scheme", "EL-REP", "polygons", "solid modeling", "Indexes", "Fans", "Generators", "Three dimensional displays", "Complexity theory", "Mesh generation", "Solid modeling", "2D decompositions", "solid modeling", "geometric algorithms."], "referenced_by": ["10.1016/j.cad.2017.02.001", "10.3390/sym10100477"], "referencing": ["10.1109/TVCG.2007.70407", "10.1109/TVCG.2007.70407", "10.1109/TVCG.2007.70407", "10.1145/357337.357341", "10.1145/357337.357341", "10.1145/357337.357341", "10.1016/B978-044482537-7/50007-3", "10.1142/9789812831699_0003", "10.1016/S0097-8493(02)00135-8", "10.1007/s00371-005-0302-6", "10.1016/j.cag.2005.03.001", "10.1016/j.cag.2006.08.015", "10.1016/0020-0190(79)90072-3", "10.1016/0020-0190(78)90062-5", "10.1201/b10644", "10.1016/0020-0190(72)90045-2", "10.1016/j.cag.2005.05.012", "10.1016/B978-044482537-7/50007-3", "10.1142/9789812831699_0003", "10.1016/S0097-8493(02)00135-8", "10.1007/s00371-005-0302-6", "10.1016/j.cag.2005.03.001", "10.1016/j.cag.2006.08.015", "10.1016/0020-0190(79)90072-3", "10.1016/0020-0190(78)90062-5", "10.1201/b10644", "10.1016/0020-0190(72)90045-2", "10.1016/j.cag.2005.05.012", "10.1016/B978-044482537-7/50007-3", "10.1142/9789812831699_0003", "10.1016/S0097-8493(02)00135-8", "10.1007/s00371-005-0302-6", "10.1016/j.cag.2005.03.001", "10.1016/j.cag.2006.08.015", "10.1016/0020-0190(79)90072-3", "10.1016/0020-0190(78)90062-5", "10.1201/b10644", "10.1016/0020-0190(72)90045-2", "10.1016/j.cag.2005.05.012"]}, "10.1109/TVCG.2010.232": {"doi": "10.1109/TVCG.2010.232", "author": ["J. Rossignac"], "title": "Ordered Boolean List (OBL): Reducing the Footprint for Evaluating Boolean Expressions", "year": "2011", "abstract": "An Expanded Boolean Expression (EBE) does not contain any XOR or EQUAL operators. The occurrence of each variable is a different literal. We provide a linear time algorithm that converts an EBE of n literals into a logically equivalent Ordered Boolean List (OBL) and show how to use the OBL to evaluate the EBE in n steps and O(log log n) space, if the values of the literals are each read once in the order prescribed by the OBL. (An evaluation workspace of 5 bits suffices for all EBEs of up to six billion literals.) The primary application is the SIMD architecture, where the same EBE is evaluated in parallel for different input vectors when rendering solid models on the GPU directly from their Constructive Solid Geometry (CSG) representation. We compare OBL to the Reduced Ordered Binary Decision Diagram (ROBDD) and suggest possible applications of OBL to logic verification and to circuit design.", "keywords": ["Boolean algebra", "computational complexity", "computer graphic equipment", "coprocessors", "parallel architectures", "rendering (computer graphics)", "solid modelling", "boolean expression evaluation", "expanded Boolean expression", "linear time algorithm", "logically equivalent ordered Boolean list", "SIMD architecture", "solid model rendering", "GPU", "constructive solid geometry representation", "reduced ordered binary decision diagram", "logic verification", "circuit design", "Switches", "Pixel", "Wiring", "Data structures", "Solids", "Weaving", "Boolean functions", "CSG", "Boolean expression evaluation cost", "OBDD."], "referenced_by": ["10.1145/3203198", "10.1016/j.cad.2012.10.012", "10.1016/j.cad.2015.06.013", "10.1016/j.gmod.2018.03.001"], "referencing": ["10.1109/PROC.1985.13108", "10.1109/TC.1986.1676819", "10.1109/ICCAD.1995.480018", "10.1109/ICCD.1991.139893", "10.1109/38.28107", "10.1109/MCG.1986.276544", "10.1109/TVCG.2007.70411", "10.1109/TCSI.2005.858767", "10.1109/TCSI.2004.840093", "10.1109/TC.1978.1675141", "10.1109/TC.1977.1674938", "10.1109/12.537122", "10.1109/PROC.1985.13108", "10.1109/TC.1986.1676819", "10.1109/ICCAD.1995.480018", "10.1109/ICCD.1991.139893", "10.1109/38.28107", "10.1109/MCG.1986.276544", "10.1109/TVCG.2007.70411", "10.1109/TCSI.2005.858767", "10.1109/TCSI.2004.840093", "10.1109/TC.1978.1675141", "10.1109/TC.1977.1674938", "10.1109/12.537122", "10.1109/PROC.1985.13108", "10.1109/TC.1986.1676819", "10.1109/ICCAD.1995.480018", "10.1109/ICCD.1991.139893", "10.1109/38.28107", "10.1109/MCG.1986.276544", "10.1109/TVCG.2007.70411", "10.1109/TCSI.2005.858767", "10.1109/TCSI.2004.840093", "10.1109/TC.1978.1675141", "10.1109/TC.1977.1674938", "10.1109/12.537122", "10.1145/356827.356833", "10.1145/285305.285308", "10.1145/142920.134092", "10.1145/321892.321901", "10.1145/240518.240637", "10.1145/362848.362859", "10.1145/321607.321620", "10.1145/321958.321970", "10.1145/192161.192196", "10.1145/112515.112548", "10.1145/15886.15898", "10.1145/1073204.1073306", "10.1145/383259.383280", "10.1145/641480.641513", "10.1145/97879.97887", "10.1145/882262.882320", "10.1145/99902.99904", "10.1145/49155.51123", "10.1145/136035.136043", "10.1145/225058.225098", "10.1145/363534.363549", "10.1145/263764.263784", "10.1145/356827.356833", "10.1145/285305.285308", "10.1145/142920.134092", "10.1145/321892.321901", "10.1145/240518.240637", "10.1145/362848.362859", "10.1145/321607.321620", "10.1145/321958.321970", "10.1145/192161.192196", "10.1145/112515.112548", "10.1145/15886.15898", "10.1145/1073204.1073306", "10.1145/383259.383280", "10.1145/641480.641513", "10.1145/97879.97887", "10.1145/882262.882320", "10.1145/99902.99904", "10.1145/49155.51123", "10.1145/136035.136043", "10.1145/225058.225098", "10.1145/363534.363549", "10.1145/263764.263784", "10.1145/356827.356833", "10.1145/285305.285308", "10.1145/142920.134092", "10.1145/321892.321901", "10.1145/240518.240637", "10.1145/362848.362859", "10.1145/321607.321620", "10.1145/321958.321970", "10.1145/192161.192196", "10.1145/112515.112548", "10.1145/15886.15898", "10.1145/1073204.1073306", "10.1145/383259.383280", "10.1145/641480.641513", "10.1145/97879.97887", "10.1145/882262.882320", "10.1145/99902.99904", "10.1145/49155.51123", "10.1145/136035.136043", "10.1145/225058.225098", "10.1145/363534.363549", "10.1145/263764.263784", "10.1111/1467-8659.1540205", "10.1016/0010-4485(88)90218-7", "10.1093/comjnl/40.9.555", "10.1007/978-3-642-76777-7_10", "10.1016/j.compeleceng.2002.10.001", "10.1016/0020-0255(80)90014-6", "10.1016/j.cag.2008.06.002", "10.1016/0304-3975(94)00181-H", "10.1111/1467-8659.1540205", "10.1016/0010-4485(88)90218-7", "10.1093/comjnl/40.9.555", "10.1007/978-3-642-76777-7_10", "10.1016/j.compeleceng.2002.10.001", "10.1016/0020-0255(80)90014-6", "10.1016/j.cag.2008.06.002", "10.1016/0304-3975(94)00181-H", "10.1111/1467-8659.1540205", "10.1016/0010-4485(88)90218-7", "10.1093/comjnl/40.9.555", "10.1007/978-3-642-76777-7_10", "10.1016/j.compeleceng.2002.10.001", "10.1016/0020-0255(80)90014-6", "10.1016/j.cag.2008.06.002", "10.1016/0304-3975(94)00181-H"]}}