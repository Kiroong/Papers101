{"10.1109/TVCG.2018.2865018": {"doi": "10.1109/TVCG.2018.2865018", "author": ["D. Liu", "P. Xu", "L. Ren"], "title": "TPFlow: Progressive Partition and Multidimensional Pattern Extraction for Large-Scale Spatio-Temporal Data Analysis", "year": "2019", "abstract": "Consider a multi-dimensional spatio-temporal (ST) dataset where each entry is a numerical measure defined by the corresponding temporal, spatial and other domain-specific dimensions. A typical approach to explore such data utilizes interactive visualizations with multiple coordinated views. Each view displays the aggregated measures along one or two dimensions. By brushing on the views, analysts can obtain detailed information. However, this approach often cannot provide sufficient guidance for analysts to identify patterns hidden within subsets of data. Without a priori hypotheses, analysts need to manually select and iterate through different slices to search for patterns, which can be a tedious and lengthy process. In this work, we model multidimensional ST data as tensors and propose a novel piecewise rank-one tensor decomposition algorithm which supports automatically slicing the data into homogeneous partitions and extracting the latent patterns in each partition for comparison and visual summarization. The algorithm optimizes a quantitative measure about how faithfully the extracted patterns visually represent the original data. Based on the algorithm we further propose a visual analytics framework that supports a top-down, progressive partitioning workflow for level-of-detail multidimensional ST data exploration. We demonstrate the general applicability and effectiveness of our technique on three datasets from different application domains: regional sales trend analysis, customer traffic analysis in department stores, and taxi trip analysis with origin-destination (OD) data. We further interview domain experts to verify the usability of the prototype.", "keywords": ["data analysis", "data mining", "data visualisation", "tensors", "multiple coordinated views", "model multidimensional ST data", "homogeneous partitions", "latent patterns", "visual summarization", "quantitative measure", "extracted patterns", "visual analytics framework", "progressive partitioning workflow", "level-of-detail multidimensional ST data exploration", "regional sales trend analysis", "customer traffic analysis", "taxi trip analysis", "origin-destination data", "interview domain experts", "progressive partition", "multidimensional pattern extraction", "large-scale spatio-temporal data analysis", "multidimensional spatio-temporal", "numerical measure", "domain-specific dimensions", "interactive visualizations", "Data visualization", "Tensile stress", "Partitioning algorithms", "Data mining", "Visualization", "Data models", "Data analysis", "Spatio-temporal data", "tensor decomposition", "interactive exploration", "automatic pattern discoveries"], "referenced_by": ["IKEY:8706292", "IKEY:8758808", "IKEY:9144543", "IKEY:9308627"], "referencing": ["IKEY:7891950", "IKEY:7587808", "IKEY:7539286", "IKEY:8022952", "IKEY:7120975", "IKEY:4015421", "IKEY:6876004", "IKEY:6634127", "IKEY:6816674", "IKEY:841121", "IKEY:6634137", "IKEY:7534856", "IKEY:7536654", "IKEY:7974891", "IKEY:7539326", "IKEY:8019867", "IKEY:7192701", "IKEY:6876049", "IKEY:801851", "IKEY:7192732", "IKEY:8456575", "IKEY:4376144", "IKEY:7506246", "IKEY:7891950", "IKEY:7587808", "IKEY:7539286", "IKEY:8022952", "IKEY:7120975", "IKEY:4015421", "IKEY:6876004", "IKEY:6634127", "IKEY:6816674", "IKEY:841121", "IKEY:6634137", "IKEY:7534856", "IKEY:7536654", "IKEY:7974891", "IKEY:7539326", "IKEY:8019867", "IKEY:7192701", "IKEY:6876049", "IKEY:801851", "IKEY:7192732", "IKEY:8456575", "IKEY:4376144", "IKEY:7506246", "IKEY:7891950", "IKEY:7587808", "IKEY:7539286", "IKEY:8022952", "IKEY:7120975", "IKEY:4015421", "IKEY:6876004", "IKEY:6634127", "IKEY:6816674", "IKEY:841121", "IKEY:6634137", "IKEY:7534856", "IKEY:7536654", "IKEY:7974891", "IKEY:7539326", "IKEY:8019867", "IKEY:7192701", "IKEY:6876049", "IKEY:801851", "IKEY:7192732", "IKEY:8456575", "IKEY:4376144", "IKEY:7506246", "10.1145/304181.304187", "10.1145/2632048.2636073", "10.1145/2254556.2254659", "10.1145/3173574.3173821", "10.1145/2629592", "10.1145/304181.304187", "10.1145/2632048.2636073", "10.1145/2254556.2254659", "10.1145/3173574.3173821", "10.1145/2629592", "10.1145/304181.304187", "10.1145/2632048.2636073", "10.1145/2254556.2254659", "10.1145/3173574.3173821", "10.1145/2629592", "10.1214/aoms/1177729580", "10.1111/j.1467-8659.2009.01664.x", "10.1016/S1045-926X(03)00046-6", "10.1111/cgf.13325", "10.1007/BF02310791", "10.1016/j.trc.2017.10.023", "10.2307/2669946", "10.1198/jcgs.2010.09051", "10.1007/s13177-014-0099-7", "10.1007/BF01908075", "10.1111/j.1467-8659.2012.03117.x", "10.1137/S0895479801387413", "10.1137/07070111X", "10.1177/1473871616667632", "10.1007/s00371-013-0892-3", "10.1111/cgf.12129", "10.1002/widm.1", "10.1201/b17511", "10.2307/3151680", "10.1016/B978-155860915-0/50046-9", "10.1111/cgf.12888", "10.1007/s12650-017-0463-1", "10.1007/978-1-4615-1177-9_14", "10.1137/S0895479899352045", "10.1057/PALGRAVE.IVS.9500184", "10.1214/aoms/1177729580", "10.1111/j.1467-8659.2009.01664.x", "10.1016/S1045-926X(03)00046-6", "10.1111/cgf.13325", "10.1007/BF02310791", "10.1016/j.trc.2017.10.023", "10.2307/2669946", "10.1198/jcgs.2010.09051", "10.1007/s13177-014-0099-7", "10.1007/BF01908075", "10.1111/j.1467-8659.2012.03117.x", "10.1137/S0895479801387413", "10.1137/07070111X", "10.1177/1473871616667632", "10.1007/s00371-013-0892-3", "10.1111/cgf.12129", "10.1002/widm.1", "10.1201/b17511", "10.2307/3151680", "10.1016/B978-155860915-0/50046-9", "10.1111/cgf.12888", "10.1007/s12650-017-0463-1", "10.1007/978-1-4615-1177-9_14", "10.1137/S0895479899352045", "10.1057/PALGRAVE.IVS.9500184", "10.1214/aoms/1177729580", "10.1111/j.1467-8659.2009.01664.x", "10.1016/S1045-926X(03)00046-6", "10.1111/cgf.13325", "10.1007/BF02310791", "10.1016/j.trc.2017.10.023", "10.2307/2669946", "10.1198/jcgs.2010.09051", "10.1007/s13177-014-0099-7", "10.1007/BF01908075", "10.1111/j.1467-8659.2012.03117.x", "10.1137/S0895479801387413", "10.1137/07070111X", "10.1177/1473871616667632", "10.1007/s00371-013-0892-3", "10.1111/cgf.12129", "10.1002/widm.1", "10.1201/b17511", "10.2307/3151680", "10.1016/B978-155860915-0/50046-9", "10.1111/cgf.12888", "10.1007/s12650-017-0463-1", "10.1007/978-1-4615-1177-9_14", "10.1137/S0895479899352045", "10.1057/PALGRAVE.IVS.9500184"]}, "10.1109/TVCG.2018.2865020": {"doi": "10.1109/TVCG.2018.2865020", "author": ["Y. Zhao", "F. Luo", "M. Chen", "Y. Wang", "J. Xia", "F. Zhou", "Y. Wang", "Y. Chen", "W. Chen"], "title": "Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters", "year": "2019", "abstract": "Fuzzy clustering assigns a probability of membership for a datum to a cluster, which veritably reflects real-world clustering scenarios but significantly increases the complexity of understanding fuzzy clusters. Many studies have demonstrated that visualization techniques for multi-dimensional data are beneficial to understand fuzzy clusters. However, no empirical evidence exists on the effectiveness and efficiency of these visualization techniques in solving analytical tasks featured by fuzzy clusters. In this paper, we conduct a controlled experiment to evaluate the ability of fuzzy clusters analysis to use four multi-dimensional visualization techniques, namely, parallel coordinate plot, scatterplot matrix, principal component analysis, and Radviz. First, we define the analytical tasks and their representative questions specific to fuzzy clusters analysis. Then, we design objective questionnaires to compare the accuracy, time, and satisfaction in using the four techniques to solve the questions. We also design subjective questionnaires to collect the experience of the volunteers with the four techniques in terms of ease of use, informativeness, and helpfulness. With a complete experiment process and a detailed result analysis, we test against four hypotheses that are formulated on the basis of our experience, and provide instructive guidance for analysts in selecting appropriate and efficient visualization techniques to analyze fuzzy clusters.", "keywords": ["data visualisation", "fuzzy set theory", "matrix algebra", "pattern clustering", "principal component analysis", "probability", "probability", "scatterplot matrix", "principal component analysis", "multidimensional visualization techniques", "fuzzy clusters analysis", "Data visualization", "Task analysis", "Principal component analysis", "Visualization", "Encoding", "Clustering algorithms", "Correlation", "Evaluation", "multi-dimensional visualization", "fuzzy clustering", "parallel coordinate plot", "scatterplot matrix", "principal component analysis", "radviz"], "referenced_by": ["IKEY:8736844", "IKEY:8801911", "IKEY:8805439", "IKEY:8807303", "IKEY:8794768", "IKEY:8807351", "IKEY:8993793", "IKEY:9308623"], "referencing": ["10.1145/3025453.3025882", "10.1145/1168149.1168169", "10.1145/2702123.2702293", "10.1145/133160.133216", "10.1145/3025453.3025882", "10.1145/1168149.1168169", "10.1145/2702123.2702293", "10.1145/133160.133216", "10.1145/3025453.3025882", "10.1145/1168149.1168169", "10.1145/2702123.2702293", "10.1145/133160.133216", "10.1016/0098-3004(84)90020-7", "10.1016/S0165-0114(98)00224-3", "10.1016/j.ins.2010.08.026", "10.1002/9780470061190", "10.5220/0005313400510062", "10.1007/s00500-006-0111-5", "10.1111/j.1467-8659.2011.01961.x", "10.1016/S0167-9473(02)00290-6", "10.1186/gb-2002-3-11-research0059", "10.1016/S0148-9062(98)00011-4", "10.1111/j.1467-8659.2009.01666.x", "10.1007/978-3-540-33037-0_25", "10.1007/978-1-4757-1904-8_7", "10.1007/978-1-4471-3744-3_7", "10.5244/C.8.19", "10.1111/j.1467-8659.2012.03129.x", "10.1016/S0377-2217(99)00118-6", "10.1057/ivs.2008.13", "10.1007/s00371-013-0892-3", "10.1016/S0933-3657(98)00069-4", "10.1016/S0305-0483(00)00042-6", "10.1016/S0925-2312(01)00653-1", "10.1016/j.patcog.2006.02.006", "10.1016/S0019-9958(69)90591-9", "10.5604/15084183.1197450", "10.1057/palgrave.ivs.9500099", "10.1080/01621459.1990.10474926", "10.1142/9789814261302_0021", "10.1016/0098-3004(84)90020-7", "10.1016/S0165-0114(98)00224-3", "10.1016/j.ins.2010.08.026", "10.1002/9780470061190", "10.5220/0005313400510062", "10.1007/s00500-006-0111-5", "10.1111/j.1467-8659.2011.01961.x", "10.1016/S0167-9473(02)00290-6", "10.1186/gb-2002-3-11-research0059", "10.1016/S0148-9062(98)00011-4", "10.1111/j.1467-8659.2009.01666.x", "10.1007/978-3-540-33037-0_25", "10.1007/978-1-4757-1904-8_7", "10.1007/978-1-4471-3744-3_7", "10.5244/C.8.19", "10.1111/j.1467-8659.2012.03129.x", "10.1016/S0377-2217(99)00118-6", "10.1057/ivs.2008.13", "10.1007/s00371-013-0892-3", "10.1016/S0933-3657(98)00069-4", "10.1016/S0305-0483(00)00042-6", "10.1016/S0925-2312(01)00653-1", "10.1016/j.patcog.2006.02.006", "10.1016/S0019-9958(69)90591-9", "10.5604/15084183.1197450", "10.1057/palgrave.ivs.9500099", "10.1080/01621459.1990.10474926", "10.1142/9789814261302_0021", "10.1016/0098-3004(84)90020-7", "10.1016/S0165-0114(98)00224-3", "10.1016/j.ins.2010.08.026", "10.1002/9780470061190", "10.5220/0005313400510062", "10.1007/s00500-006-0111-5", "10.1111/j.1467-8659.2011.01961.x", "10.1016/S0167-9473(02)00290-6", "10.1186/gb-2002-3-11-research0059", "10.1016/S0148-9062(98)00011-4", "10.1111/j.1467-8659.2009.01666.x", "10.1007/978-3-540-33037-0_25", "10.1007/978-1-4757-1904-8_7", "10.1007/978-1-4471-3744-3_7", "10.5244/C.8.19", "10.1111/j.1467-8659.2012.03129.x", "10.1016/S0377-2217(99)00118-6", "10.1057/ivs.2008.13", "10.1007/s00371-013-0892-3", "10.1016/S0933-3657(98)00069-4", "10.1016/S0305-0483(00)00042-6", "10.1016/S0925-2312(01)00653-1", "10.1016/j.patcog.2006.02.006", "10.1016/S0019-9958(69)90591-9", "10.5604/15084183.1197450", "10.1057/palgrave.ivs.9500099", "10.1080/01621459.1990.10474926", "10.1142/9789814261302_0021"]}, "10.1109/TVCG.2018.2865040": {"doi": "10.1109/TVCG.2018.2865040", "author": ["S. Alspaugh", "N. Zokaei", "A. Liu", "C. Jin", "M. A. Hearst"], "title": "Futzing and Moseying: Interviews with Professional Data Analysts on Exploration Practices", "year": "2019", "abstract": "We report the results of interviewing thirty professional data analysts working in a range of industrial, academic, and regulatory environments. This study focuses on participants' descriptions of exploratory activities and tool usage in these activities. Highlights of the findings include: distinctions between exploration as a precursor to more directed analysis versus truly open-ended exploration; confirmation that some analysts see \u201cfinding something interesting\u201d as a valid goal of data exploration while others explicitly disavow this goal; conflicting views about the role of intelligent tools in data exploration; and pervasive use of visualization for exploration, but with only a subset using direct manipulation interfaces. These findings provide guidelines for future tool development, as well as a better understanding of the meaning of the term \u201cdata exploration\u201d based on the words of practitioners \u201cin the wild\u201d.", "keywords": ["data analysis", "data visualisation", "information analysis", "personnel", "directed analysis", "intelligent tools", "direct manipulation interfaces", "futzing moseying", "exploration practices", "industrial environments", "regulatory environments", "openended information analysis", "visualization", "open-ended exploration", "academic environments", "professional data analysts", "data exploration", "Interviews", "Tools", "Data science", "Python", "Business intelligence", "Data visualization", "EDA", "exploratory data analysis", "interview study", "visual analytics tools"], "referenced_by": ["IKEY:8781587", "IKEY:8788592", "IKEY:8933542"], "referencing": ["IKEY:1385851", "IKEY:636793", "IKEY:6327298", "IKEY:6824680", "IKEY:7363784", "IKEY:6102438", "IKEY:4015419", "IKEY:7192728", "IKEY:1385851", "IKEY:636793", "IKEY:6327298", "IKEY:6824680", "IKEY:7363784", "IKEY:6102438", "IKEY:4015419", "IKEY:7192728", "IKEY:1385851", "IKEY:636793", "IKEY:6327298", "IKEY:6824680", "IKEY:7363784", "IKEY:6102438", "IKEY:4015419", "IKEY:7192728", "10.1145/2168931.2168943", "10.1145/2213836.2213931", "10.1145/2884781.2884783", "10.1145/169059.169365", "10.1145/1357054.1357101", "10.1145/2909132.2933287", "10.1145/1125451.1125708", "10.1145/259963.260433", "10.1145/1124772.1124890", "10.1145/2168931.2168943", "10.1145/2213836.2213931", "10.1145/2884781.2884783", "10.1145/169059.169365", "10.1145/1357054.1357101", "10.1145/2909132.2933287", "10.1145/1125451.1125708", "10.1145/259963.260433", "10.1145/1124772.1124890", "10.1145/2168931.2168943", "10.1145/2213836.2213931", "10.1145/2884781.2884783", "10.1145/169059.169365", "10.1145/1357054.1357101", "10.1145/2909132.2933287", "10.1145/1125451.1125708", "10.1145/259963.260433", "10.1145/1124772.1124890", "10.1057/ivs.2008.31", "10.11613/BM.2012.031", "10.1007/s10111-001-8004-y", "10.1057/ivs.2008.31", "10.11613/BM.2012.031", "10.1007/s10111-001-8004-y", "10.1057/ivs.2008.31", "10.11613/BM.2012.031", "10.1007/s10111-001-8004-y"]}, "10.1109/TVCG.2018.2865025": {"doi": "10.1109/TVCG.2018.2865025", "author": ["M. Chen", "K. Gaither", "N. W. John", "B. Mccann"], "title": "An Information-Theoretic Approach to the Cost-benefit Analysis of Visualization in Virtual Environments", "year": "2019", "abstract": "Visualization and virtual environments (VEs) have been two interconnected parallel strands in visual computing for decades. Some VEs have been purposely developed for visualization applications, while many visualization applications are exemplary showcases in general-purpose VEs. Because of the development and operation costs of VEs, the majority of visualization applications in practice have yet to benefit from the capacity of VEs. In this paper, we examine this status quo from an information-theoretic perspective. Our objectives are to conduct cost-benefit analysis on typical VE systems (including augmented and mixed reality, theater-based systems, and large powerwalls), to explain why some visualization applications benefit more from VEs than others, and to sketch out pathways for the future development of visualization applications in VEs. We support our theoretical propositions and analysis using theories and discoveries in the literature of cognitive sciences and the practical evidence reported in the literatures of visualization and VEs.", "keywords": ["cost-benefit analysis", "data visualisation", "user interfaces", "virtual reality", "visualization applications", "cost-benefit analysis", "information-theoretic approach", "virtual environments", "visual computing", "general-purpose VE", "Data visualization", "Visualization", "Virtual environments", "Augmented reality", "Guidelines", "Measurement", "Theory of visualization", "virtual environments", "virtual reality", "augmented reality", "mixed reality", "cost-benefit analysis", "information theory", "cognitive sciences", "visualization applications", "immersive analytics", "four levels of visualization"], "referenced_by": ["IKEY:8805439"], "referencing": ["10.1145/1240624.1240656", "10.1145/253284.253301", "10.1145/2330667.2330687", "10.1145/1180495.1180538", "10.1145/1978942.1979156", "10.1145/2556288.2557020", "10.1145/22949.22950", "10.1145/2702123.2702406", "10.1145/1240624.1240656", "10.1145/253284.253301", "10.1145/2330667.2330687", "10.1145/1180495.1180538", "10.1145/1978942.1979156", "10.1145/2556288.2557020", "10.1145/22949.22950", "10.1145/2702123.2702406", "10.1145/1240624.1240656", "10.1145/253284.253301", "10.1145/2330667.2330687", "10.1145/1180495.1180538", "10.1145/1978942.1979156", "10.1145/2556288.2557020", "10.1145/22949.22950", "10.1145/2702123.2702406", "10.1016/S0079-7421(08)60452-1", "10.1111/j.1467-8659.2005.00845.x", "10.1167/7.5.6", "10.1201/9781315369228", "10.1111/j.1467-8659.2012.03114.x", "10.1146/annurev.ne.18.030195.001205", "10.1007/978-1-4471-1011-8_15", "10.1016/0042-6989(84)90041-5", "10.1016/S0959-4388(98)80140-2", "10.1016/S0896-6273(02)01003-6", "10.1016/j.tics.2005.02.009", "10.1162/pres.1992.1.2.262", "10.1111/cgf.13169", "10.1016/S0042-6989(01)00102-X", "10.1111/j.1600-0412.2012.01482.x", "10.1067/mob.2002.127361", "10.1038/36846", "10.1037/a0033101", "10.1007/s00221-006-0804-0", "10.1016/j.cag.2012.04.007", "10.1007/978-3-662-43790-2_6", "10.1016/j.cag.2012.04.007", "10.1037/h0043158", "10.1038/nature03390", "10.1016/S0079-6123(06)55002-2", "10.1007/978-1-4471-3873-0", "10.1038/17953", "10.1007/s002210100745", "10.1037/0096-3445.109.2.160", "10.1146/annurev.psych.53.100901.135125", "10.1113/jphysiol.1964.sp007485", "10.1177/1473871613500978", "10.1523/JNEUROSCI.4319-03.2004", "10.1162/pres.1995.4.1.64", "10.1089/109493101300117884", "10.1523/JNEUROSCI.0647-08.2008", "10.1007/s00268-007-9307-9", "10.1162/pres.1992.1.1.120", "10.1016/S1364-6613(97)01080-2", "10.1037/a0029856", "10.1162/pres.1997.6.6.603", "10.1111/j.1460-2466.1992.tb00812.x", "10.1007/978-1-4471-1011-8_16", "10.1038/nn963", "10.1037/0033-295X.113.4.766", "10.1016/0010-0285(80)90005-5", "10.1364/JOSAA.20.001419", "10.1007/s11548-013-0929-0", "10.1016/0001-6918(67)90080-7", "10.3758/BF03200774", "10.1038/81497", "10.1097/SLA.0b013e318288c40b", "10.1016/S0079-7421(08)60452-1", "10.1111/j.1467-8659.2005.00845.x", "10.1167/7.5.6", "10.1201/9781315369228", "10.1111/j.1467-8659.2012.03114.x", "10.1146/annurev.ne.18.030195.001205", "10.1007/978-1-4471-1011-8_15", "10.1016/0042-6989(84)90041-5", "10.1016/S0959-4388(98)80140-2", "10.1016/S0896-6273(02)01003-6", "10.1016/j.tics.2005.02.009", "10.1162/pres.1992.1.2.262", "10.1111/cgf.13169", "10.1016/S0042-6989(01)00102-X", "10.1111/j.1600-0412.2012.01482.x", "10.1067/mob.2002.127361", "10.1038/36846", "10.1037/a0033101", "10.1007/s00221-006-0804-0", "10.1016/j.cag.2012.04.007", "10.1007/978-3-662-43790-2_6", "10.1016/j.cag.2012.04.007", "10.1037/h0043158", "10.1038/nature03390", "10.1016/S0079-6123(06)55002-2", "10.1007/978-1-4471-3873-0", "10.1038/17953", "10.1007/s002210100745", "10.1037/0096-3445.109.2.160", "10.1146/annurev.psych.53.100901.135125", "10.1113/jphysiol.1964.sp007485", "10.1177/1473871613500978", "10.1523/JNEUROSCI.4319-03.2004", "10.1162/pres.1995.4.1.64", "10.1089/109493101300117884", "10.1523/JNEUROSCI.0647-08.2008", "10.1007/s00268-007-9307-9", "10.1162/pres.1992.1.1.120", "10.1016/S1364-6613(97)01080-2", "10.1037/a0029856", "10.1162/pres.1997.6.6.603", "10.1111/j.1460-2466.1992.tb00812.x", "10.1007/978-1-4471-1011-8_16", "10.1038/nn963", "10.1037/0033-295X.113.4.766", "10.1016/0010-0285(80)90005-5", "10.1364/JOSAA.20.001419", "10.1007/s11548-013-0929-0", "10.1016/0001-6918(67)90080-7", "10.3758/BF03200774", "10.1038/81497", "10.1097/SLA.0b013e318288c40b", "10.1016/S0079-7421(08)60452-1", "10.1111/j.1467-8659.2005.00845.x", "10.1167/7.5.6", "10.1201/9781315369228", "10.1111/j.1467-8659.2012.03114.x", "10.1146/annurev.ne.18.030195.001205", "10.1007/978-1-4471-1011-8_15", "10.1016/0042-6989(84)90041-5", "10.1016/S0959-4388(98)80140-2", "10.1016/S0896-6273(02)01003-6", "10.1016/j.tics.2005.02.009", "10.1162/pres.1992.1.2.262", "10.1111/cgf.13169", "10.1016/S0042-6989(01)00102-X", "10.1111/j.1600-0412.2012.01482.x", "10.1067/mob.2002.127361", "10.1038/36846", "10.1037/a0033101", "10.1007/s00221-006-0804-0", "10.1016/j.cag.2012.04.007", "10.1007/978-3-662-43790-2_6", "10.1016/j.cag.2012.04.007", "10.1037/h0043158", "10.1038/nature03390", "10.1016/S0079-6123(06)55002-2", "10.1007/978-1-4471-3873-0", "10.1038/17953", "10.1007/s002210100745", "10.1037/0096-3445.109.2.160", "10.1146/annurev.psych.53.100901.135125", "10.1113/jphysiol.1964.sp007485", "10.1177/1473871613500978", "10.1523/JNEUROSCI.4319-03.2004", "10.1162/pres.1995.4.1.64", "10.1089/109493101300117884", "10.1523/JNEUROSCI.0647-08.2008", "10.1007/s00268-007-9307-9", "10.1162/pres.1992.1.1.120", "10.1016/S1364-6613(97)01080-2", "10.1037/a0029856", "10.1162/pres.1997.6.6.603", "10.1111/j.1460-2466.1992.tb00812.x", "10.1007/978-1-4471-1011-8_16", "10.1038/nn963", "10.1037/0033-295X.113.4.766", "10.1016/0010-0285(80)90005-5", "10.1364/JOSAA.20.001419", "10.1007/s11548-013-0929-0", "10.1016/0001-6918(67)90080-7", "10.3758/BF03200774", "10.1038/81497", "10.1097/SLA.0b013e318288c40b"]}, "10.1109/TVCG.2018.2864503": {"doi": "10.1109/TVCG.2018.2864503", "author": ["Z. Zhou", "L. Meng", "C. Tang", "Y. Zhao", "Z. Guo", "M. Hu", "W. Chen"], "title": "Visual Abstraction of Large Scale Geospatial Origin-Destination Movement Data", "year": "2019", "abstract": "A variety of human movement datasets are represented in an Origin-Destination(OD) form, such as taxi trips, mobile phone locations, etc. As a commonly-used method to visualize OD data, flow map always fails to discover patterns of human mobility, due to massive intersections and occlusions of lines on a 2D geographical map. A large number of techniques have been proposed to reduce visual clutter of flow maps, such as filtering, clustering and edge bundling, but the correlations of OD flows are often neglected, which makes the simplified OD flow map present little semantic information. In this paper, a characterization of OD flows is established based on an analogy between OD flows and natural language processing (NPL) terms. Then, an iterative multi-objective sampling scheme is designed to select OD flows in a vectorized representation space. To enhance the readability of sampled OD flows, a set of meaningful visual encodings are designed to present the interactions of OD flows. We design and implement a visual exploration system that supports visual inspection and quantitative evaluation from a variety of perspectives. Case studies based on real-world datasets and interviews with domain experts have demonstrated the effectiveness of our system in reducing the visual clutter and enhancing correlations of OD flows.", "keywords": ["data visualisation", "iterative methods", "natural language processing", "sampling methods", "2D geographical map", "visual clutter", "simplified OD flow map", "natural language processing terms", "iterative multiobjective sampling scheme", "sampled OD", "visual exploration system", "visual inspection", "visual abstraction", "human movement datasets", "mobile phone locations", "OD data", "human mobility", "massive intersections", "visual encodings", "origin-destination form", "large scale geospatial origin-destination movement data", "Visualization", "Data visualization", "Clutter", "Geospatial analysis", "Semantics", "Mobile handsets", "Correlation", "Visual abstraction", "human mobility", "origin-destination", "flow map", "representation learning"], "referenced_by": ["IKEY:8764395", "IKEY:8752446", "IKEY:8801911", "IKEY:8781856", "IKEY:8876625", "IKEY:8807303", "IKEY:8805421", "IKEY:8794768", "IKEY:8809845", "IKEY:8807351", "IKEY:8807233", "IKEY:8807274", "IKEY:9296350", "IKEY:9308623"], "referencing": ["IKEY:7790842", "IKEY:8017616", "IKEY:7587808", "IKEY:7539398", "IKEY:6065021", "IKEY:6875982", "IKEY:4658140", "IKEY:6065003", "IKEY:6634127", "IKEY:6875983", "IKEY:5742390", "IKEY:7819391", "IKEY:7563342", "IKEY:6183575", "IKEY:7192724", "IKEY:6876014", "IKEY:7539669", "IKEY:7790842", "IKEY:8017616", "IKEY:7587808", "IKEY:7539398", "IKEY:6065021", "IKEY:6875982", "IKEY:4658140", "IKEY:6065003", "IKEY:6634127", "IKEY:6875983", "IKEY:5742390", "IKEY:7819391", "IKEY:7563342", "IKEY:6183575", "IKEY:7192724", "IKEY:6876014", "IKEY:7539669", "IKEY:7790842", "IKEY:8017616", "IKEY:7587808", "IKEY:7539398", "IKEY:6065021", "IKEY:6875982", "IKEY:4658140", "IKEY:6065003", "IKEY:6634127", "IKEY:6875983", "IKEY:5742390", "IKEY:7819391", "IKEY:7563342", "IKEY:6183575", "IKEY:7192724", "IKEY:6876014", "IKEY:7539669", "10.1145/2684822.2685317", "10.1145/2939672.2939754", "10.1145/2487228.2487233", "10.1145/3072959.3119910", "10.1145/2461912.2462023", "10.1145/2516971.2516973", "10.1145/2684822.2685317", "10.1145/2939672.2939754", "10.1145/2487228.2487233", "10.1145/3072959.3119910", "10.1145/2461912.2462023", "10.1145/2516971.2516973", "10.1145/2684822.2685317", "10.1145/2939672.2939754", "10.1145/2487228.2487233", "10.1145/3072959.3119910", "10.1145/2461912.2462023", "10.1145/2516971.2516973", "10.1177/1473871612457601", "10.1088/1742-5468/2008/10/P10008", "10.1111/tgis.12042", "10.1080/13658810701349037", "10.2307/1791753", "10.14714/CP30.663", "10.3390/ijgi6110321", "10.1016/j.compenvurbsys.2009.01.007", "10.1080/03085696708592302", "10.1111/j.0033-0124.1981.00419.x", "10.1179/000870410X12658023467367", "10.3138/carto.46.4.239", "10.1111/tgis.12100", "10.1177/1473871612457601", "10.1088/1742-5468/2008/10/P10008", "10.1111/tgis.12042", "10.1080/13658810701349037", "10.2307/1791753", "10.14714/CP30.663", "10.3390/ijgi6110321", "10.1016/j.compenvurbsys.2009.01.007", "10.1080/03085696708592302", "10.1111/j.0033-0124.1981.00419.x", "10.1179/000870410X12658023467367", "10.3138/carto.46.4.239", "10.1111/tgis.12100", "10.1177/1473871612457601", "10.1088/1742-5468/2008/10/P10008", "10.1111/tgis.12042", "10.1080/13658810701349037", "10.2307/1791753", "10.14714/CP30.663", "10.3390/ijgi6110321", "10.1016/j.compenvurbsys.2009.01.007", "10.1080/03085696708592302", "10.1111/j.0033-0124.1981.00419.x", "10.1179/000870410X12658023467367", "10.3138/carto.46.4.239", "10.1111/tgis.12100"]}, "10.1109/TVCG.2018.2864811": {"doi": "10.1109/TVCG.2018.2864811", "author": ["N. Andrienko", "G. Andrienko", "J. M. C. Garcia", "D. Scarlatti"], "title": "Analysis of Flight Variability: a Systematic Approach", "year": "2019", "abstract": "In movement data analysis, there exists a problem of comparing multiple trajectories of moving objects to common or distinct reference trajectories. We introduce a general conceptual framework for comparative analysis of trajectories and an analytical procedure, which consists of (1) finding corresponding points in pairs of trajectories, (2) computation of pairwise difference measures, and (3) interactive visual analysis of the distributions of the differences with respect to space, time, set of moving objects, trajectory structures, and spatio-temporal context. We propose a combination of visualisation, interaction, and data transformation techniques supporting the analysis and demonstrate the use of our approach for solving a challenging problem from the aviation domain.", "keywords": ["data analysis", "data visualisation", "interactive systems", "pairwise difference measures", "moving objects", "trajectory structures", "spatio-temporal context", "data transformation techniques", "flight variability", "systematic approach", "movement data analysis", "multiple trajectories", "common reference trajectories", "distinct reference trajectories", "general conceptual framework", "comparative analysis", "interactive visual analysis", "aviation domain", "Trajectory", "Task analysis", "Data visualization", "Three-dimensional displays", "Heuristic algorithms", "Data analysis", "Visual analytics", "Visual analytics", "movement data", "flight trajectories"], "referenced_by": ["IKEY:8805439", "IKEY:8807274"], "referencing": ["IKEY:4677356", "IKEY:5653580", "IKEY:7891950", "IKEY:8017616", "IKEY:7587808", "IKEY:6361385", "IKEY:5432167", "IKEY:6634194", "IKEY:7192639", "IKEY:7464920", "IKEY:7120975", "IKEY:6065003", "IKEY:7777947", "IKEY:5742387", "IKEY:6327262", "IKEY:7192717", "IKEY:994784", "IKEY:1652919", "IKEY:4677356", "IKEY:5653580", "IKEY:7891950", "IKEY:8017616", "IKEY:7587808", "IKEY:6361385", "IKEY:5432167", "IKEY:6634194", "IKEY:7192639", "IKEY:7464920", "IKEY:7120975", "IKEY:6065003", "IKEY:7777947", "IKEY:5742387", "IKEY:6327262", "IKEY:7192717", "IKEY:994784", "IKEY:1652919", "IKEY:4677356", "IKEY:5653580", "IKEY:7891950", "IKEY:8017616", "IKEY:7587808", "IKEY:6361385", "IKEY:5432167", "IKEY:6634194", "IKEY:7192639", "IKEY:7464920", "IKEY:7120975", "IKEY:6065003", "IKEY:7777947", "IKEY:5742387", "IKEY:6327262", "IKEY:7192717", "IKEY:994784", "IKEY:1652919", "10.1145/1842993.1843034", "10.1145/2442968.2442971", "10.1145/1653771.1653820", "10.1145/3003965.3003970", "10.1145/2093973.2094060", "10.1145/2525314.2525360", "10.1145/1345448.1345454", "10.1145/2782759.2782767", "10.1145/1842993.1843034", "10.1145/2442968.2442971", "10.1145/1653771.1653820", "10.1145/3003965.3003970", "10.1145/2093973.2094060", "10.1145/2525314.2525360", "10.1145/1345448.1345454", "10.1145/2782759.2782767", "10.1145/1842993.1843034", "10.1145/2442968.2442971", "10.1145/1653771.1653820", "10.1145/3003965.3003970", "10.1145/2093973.2094060", "10.1145/2525314.2525360", "10.1145/1345448.1345454", "10.1145/2782759.2782767", "10.2514/6.2012-2540", "10.1007/978-3-642-37583-5", "10.1080/13658816.2011.556120", "10.1016/j.visinf.2017.01.004", "10.1177/1473871615581216", "10.1016/j.trc.2008.11.004", "10.1177/1473871611416549", "10.1559/152304000783547759", "10.2307/144477", "10.1080/13658810500105572", "10.1007/s10844-011-0159-2", "10.1007/978-1-4899-3324-9", "10.1111/j.1467-8659.2009.01440.x", "10.2514/6.2012-2540", "10.1007/978-3-642-37583-5", "10.1080/13658816.2011.556120", "10.1016/j.visinf.2017.01.004", "10.1177/1473871615581216", "10.1016/j.trc.2008.11.004", "10.1177/1473871611416549", "10.1559/152304000783547759", "10.2307/144477", "10.1080/13658810500105572", "10.1007/s10844-011-0159-2", "10.1007/978-1-4899-3324-9", "10.1111/j.1467-8659.2009.01440.x", "10.2514/6.2012-2540", "10.1007/978-3-642-37583-5", "10.1080/13658816.2011.556120", "10.1016/j.visinf.2017.01.004", "10.1177/1473871615581216", "10.1016/j.trc.2008.11.004", "10.1177/1473871611416549", "10.1559/152304000783547759", "10.2307/144477", "10.1080/13658810500105572", "10.1007/s10844-011-0159-2", "10.1007/978-1-4899-3324-9", "10.1111/j.1467-8659.2009.01440.x"]}, "10.1109/TVCG.2018.2865041": {"doi": "10.1109/TVCG.2018.2865041", "author": ["Y. Wu", "X. Xie", "J. Wang", "D. Deng", "H. Liang", "H. Zhang", "S. Cheng", "W. Chen"], "title": "ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer", "year": "2019", "abstract": "Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.", "keywords": ["data analysis", "data visualisation", "spatiotemporal phenomena", "sport", "team working", "soccer data", "ForVizor", "spatio-temporal team formations", "team performance", "soccer analysts", "spatio-temporal visual representation", "soccer tactic", "spatial information", "visual analytics system", "Games", "Data visualization", "Videos", "Visual analytics", "Tools", "Soccer data", "formation analysis", "spatio-temporal visualization"], "referenced_by": ["IKEY:8754444", "IKEY:8758808", "IKEY:8807264", "IKEY:8805439", "IKEY:8807233", "IKEY:9015569", "IKEY:9308628"], "referencing": ["IKEY:4677356", "IKEY:6595989", "IKEY:7022571", "IKEY:7023391", "IKEY:7577822", "IKEY:6065008", "IKEY:6875938", "IKEY:7042477", "IKEY:7536654", "IKEY:7360233", "IKEY:6634087", "IKEY:6876044", "IKEY:8100173", "IKEY:6004042", "IKEY:5571291", "IKEY:8237541", "IKEY:7579433", "IKEY:8019849", "IKEY:852338", "IKEY:1237851", "IKEY:6691503", "IKEY:8017600", "IKEY:4677356", "IKEY:6595989", "IKEY:7022571", "IKEY:7023391", "IKEY:7577822", "IKEY:6065008", "IKEY:6875938", "IKEY:7042477", "IKEY:7536654", "IKEY:7360233", "IKEY:6634087", "IKEY:6876044", "IKEY:8100173", "IKEY:6004042", "IKEY:5571291", "IKEY:8237541", "IKEY:7579433", "IKEY:8019849", "IKEY:852338", "IKEY:1237851", "IKEY:6691503", "IKEY:8017600", "IKEY:4677356", "IKEY:6595989", "IKEY:7022571", "IKEY:7023391", "IKEY:7577822", "IKEY:6065008", "IKEY:6875938", "IKEY:7042477", "IKEY:7536654", "IKEY:7360233", "IKEY:6634087", "IKEY:6876044", "IKEY:8100173", "IKEY:6004042", "IKEY:5571291", "IKEY:8237541", "IKEY:7579433", "IKEY:8019849", "IKEY:852338", "IKEY:1237851", "IKEY:6691503", "IKEY:8017600", "10.1145/3105576", "10.1145/2556288.2557379", "10.1145/3105576", "10.1145/2556288.2557379", "10.1145/3105576", "10.1145/2556288.2557379", "10.1007/s10618-017-0513-2", "10.1080/24748668.2013.11868691", "10.1016/j.humov.2012.04.006", "10.1080/02640414.2012.703783", "10.1002/scj.20254", "10.1016/j.humov.2011.02.008", "10.2352/ISSN.2470-1173.2016.1.VDA-486", "10.1002/nav.20053", "10.1016/j.cag.2017.08.006", "10.1080/02640414.2013.789920", "10.1007/978-3-319-24560-7_10", "10.1186/s40064-016-3108-2", "10.1111/cgf.13189", "10.2352/ISSN.2470-1173.2016.1.VDA-510", "10.3390/ijgi4042159", "10.1007/s10618-017-0513-2", "10.1080/24748668.2013.11868691", "10.1016/j.humov.2012.04.006", "10.1080/02640414.2012.703783", "10.1002/scj.20254", "10.1016/j.humov.2011.02.008", "10.2352/ISSN.2470-1173.2016.1.VDA-486", "10.1002/nav.20053", "10.1016/j.cag.2017.08.006", "10.1080/02640414.2013.789920", "10.1007/978-3-319-24560-7_10", "10.1186/s40064-016-3108-2", "10.1111/cgf.13189", "10.2352/ISSN.2470-1173.2016.1.VDA-510", "10.3390/ijgi4042159", "10.1007/s10618-017-0513-2", "10.1080/24748668.2013.11868691", "10.1016/j.humov.2012.04.006", "10.1080/02640414.2012.703783", "10.1002/scj.20254", "10.1016/j.humov.2011.02.008", "10.2352/ISSN.2470-1173.2016.1.VDA-486", "10.1002/nav.20053", "10.1016/j.cag.2017.08.006", "10.1080/02640414.2013.789920", "10.1007/978-3-319-24560-7_10", "10.1186/s40064-016-3108-2", "10.1111/cgf.13189", "10.2352/ISSN.2470-1173.2016.1.VDA-510", "10.3390/ijgi4042159"]}, "10.1109/TVCG.2018.2865049": {"doi": "10.1109/TVCG.2018.2865049", "author": ["J. Buchm\u00fcller", "D. J\u00e4ckle", "E. Cakmak", "U. Brandes", "D. A. Keim"], "title": "MotionRugs: Visualizing Collective Trends in Space and Time", "year": "2019", "abstract": "Understanding the movement patterns of collectives, such as flocks of birds or fish swarms, is an interesting open research question. The collectives are driven by mutual objectives or react to individual direction changes and external influence factors and stimuli. The challenge in visualizing collective movement data is to show space and time of hundreds of movements at the same time to enable the detection of spatiotemporal patterns. In this paper, we propose MotionRugs, a novel space efficient technique for visualizing moving groups of entities. Building upon established space-partitioning strategies, our approach reduces the spatial dimensions in each time step to a one-dimensional ordered representation of the individual entities. By design, MotionRugs provides an overlap-free, compact overview of the development of group movements over time and thus, enables analysts to visually identify and explore group-specific temporal patterns. We demonstrate the usefulness of our approach in the field of fish swarm analysis and report on initial feedback of domain experts from the field of collective behavior.", "keywords": ["data visualisation", "spatiotemporal phenomena", "spatial dimensions", "MotionRugs", "group-specific temporal patterns", "fish swarm analysis", "spatiotemporal patterns", "open research question", "space-partitioning strategies", "birds flocks", "Data visualization", "Visualization", "Trajectory", "Spatiotemporal phenomena", "Market research", "Tracking", "Image color analysis", "Spatio-Temporal Visualization", "Spatial Abstraction", "Spatial Index Structures", "Collective Movement"], "referenced_by": ["IKEY:8781586", "IKEY:8807296", "IKEY:8794520", "IKEY:8807274"], "referencing": ["IKEY:6634194", "IKEY:5473226", "IKEY:6065001", "IKEY:5332593", "IKEY:6787158", "IKEY:5290707", "IKEY:7042477", "IKEY:1250978", "IKEY:6787167", "IKEY:4015433", "IKEY:6634087", "IKEY:4658146", "IKEY:4577975", "IKEY:6327262", "IKEY:6674295", "IKEY:7072474", "IKEY:5473223", "IKEY:6634194", "IKEY:5473226", "IKEY:6065001", "IKEY:5332593", "IKEY:6787158", "IKEY:5290707", "IKEY:7042477", "IKEY:1250978", "IKEY:6787167", "IKEY:4015433", "IKEY:6634087", "IKEY:4658146", "IKEY:4577975", "IKEY:6327262", "IKEY:6674295", "IKEY:7072474", "IKEY:5473223", "IKEY:6634194", "IKEY:5473226", "IKEY:6065001", "IKEY:5332593", "IKEY:6787158", "IKEY:5290707", "IKEY:7042477", "IKEY:1250978", "IKEY:6787167", "IKEY:4015433", "IKEY:6634087", "IKEY:4658146", "IKEY:4577975", "IKEY:6327262", "IKEY:6674295", "IKEY:7072474", "IKEY:5473223", "10.1145/93597.98741", "10.1145/361002.361007", "10.1145/602259.602266", "10.1145/93597.98742", "10.1145/1376616.1376618", "10.1145/1520340.1520516", "10.1145/130881.130882", "10.1145/93597.98741", "10.1145/361002.361007", "10.1145/602259.602266", "10.1145/93597.98742", "10.1145/1376616.1376618", "10.1145/1520340.1520516", "10.1145/130881.130882", "10.1145/93597.98741", "10.1145/361002.361007", "10.1145/602259.602266", "10.1145/93597.98742", "10.1145/1376616.1376618", "10.1145/1520340.1520516", "10.1145/130881.130882", "10.1007/978-3-642-37583-5", "10.1016/S1045-926X(03)00046-6", "10.1177/1473871612457601", "10.1007/978-3-540-74553-2_1", "10.1080/13658816.2015.1081205", "10.1017/CBO9781139015165", "10.1007/BF00288933", "10.1007/s10844-006-9952-8", "10.5220/0005716900480059", "10.3138/carto.42.4.349", "10.1179/000870403235002042", "10.1007/BF01199431", "10.2307/2332226", "10.1080/13658816.2016.1199806", "10.1111/cgf.12653", "10.1007/978-3-319-10268-9", "10.1111/cgf.12654", "10.1016/0146-664X(82)90128-9", "10.1515/9781400837106", "10.1177/1473871613477851", "10.1111/j.1467-8659.2009.01440.x", "10.1179/000870410X12658023467367", "10.1007/978-3-642-37583-5", "10.1016/S1045-926X(03)00046-6", "10.1177/1473871612457601", "10.1007/978-3-540-74553-2_1", "10.1080/13658816.2015.1081205", "10.1017/CBO9781139015165", "10.1007/BF00288933", "10.1007/s10844-006-9952-8", "10.5220/0005716900480059", "10.3138/carto.42.4.349", "10.1179/000870403235002042", "10.1007/BF01199431", "10.2307/2332226", "10.1080/13658816.2016.1199806", "10.1111/cgf.12653", "10.1007/978-3-319-10268-9", "10.1111/cgf.12654", "10.1016/0146-664X(82)90128-9", "10.1515/9781400837106", "10.1177/1473871613477851", "10.1111/j.1467-8659.2009.01440.x", "10.1179/000870410X12658023467367", "10.1007/978-3-642-37583-5", "10.1016/S1045-926X(03)00046-6", "10.1177/1473871612457601", "10.1007/978-3-540-74553-2_1", "10.1080/13658816.2015.1081205", "10.1017/CBO9781139015165", "10.1007/BF00288933", "10.1007/s10844-006-9952-8", "10.5220/0005716900480059", "10.3138/carto.42.4.349", "10.1179/000870403235002042", "10.1007/BF01199431", "10.2307/2332226", "10.1080/13658816.2016.1199806", "10.1111/cgf.12653", "10.1007/978-3-319-10268-9", "10.1111/cgf.12654", "10.1016/0146-664X(82)90128-9", "10.1515/9781400837106", "10.1177/1473871613477851", "10.1111/j.1467-8659.2009.01440.x", "10.1179/000870410X12658023467367"]}, "10.1109/TVCG.2018.2865042": {"doi": "10.1109/TVCG.2018.2865042", "author": ["P. K. Muthumanickam", "K. Vrotsou", "A. Nordman", "J. Johansson", "M. Cooper"], "title": "Identification of Temporally Varying Areas of Interest in Long-Duration Eye-Tracking Data Sets", "year": "2019", "abstract": "Eye-tracking has become an invaluable tool for the analysis of working practices in many technological fields of activity. Typically studies focus on short tasks and use static expected areas of interest (AoI) in the display to explore subjects' behaviour, making the analyst's task quite straightforward. In long-duration studies, where the observations may last several hours over a complete work session, the AoIs may change over time in response to altering workload, emergencies or other variables making the analysis more difficult. This work puts forward a novel method to automatically identify spatial AoIs changing over time through a combination of clustering and cluster merging in the temporal domain. A visual analysis system based on the proposed methods is also presented. Finally, we illustrate our approach within the domain of air traffic control, a complex task sensitive to prevailing conditions over long durations, though it is applicable to other domains such as monitoring of complex systems.", "keywords": ["data visualisation", "gaze tracking", "inertial systems", "pattern clustering", "clustering", "temporal domain", "visual analysis system", "long-duration eye-tracking data", "static expected areas", "long-duration studies", "spatial AoIs", "Visualization", "Task analysis", "Monitoring", "Labeling", "Microsoft Windows", "Merging", "Vehicles", "Eye-tracking data", "areas of interest", "clustering", "minimum spanning tree", "temporal data", "spatio-temporal data"], "referenced_by": ["IKEY:8805439", "IKEY:8807274", "IKEY:9036879"], "referencing": ["IKEY:6327295", "IKEY:7344880", "IKEY:7314288", "IKEY:6596142", "IKEY:1000236", "IKEY:7018371", "IKEY:7194851", "IKEY:7539297", "IKEY:6634139", "IKEY:8017597", "IKEY:877520", "IKEY:5613432", "IKEY:5290698", "IKEY:1671676", "IKEY:6327295", "IKEY:7344880", "IKEY:7314288", "IKEY:6596142", "IKEY:1000236", "IKEY:7018371", "IKEY:7194851", "IKEY:7539297", "IKEY:6634139", "IKEY:8017597", "IKEY:877520", "IKEY:5613432", "IKEY:5290698", "IKEY:1671676", "IKEY:6327295", "IKEY:7344880", "IKEY:7314288", "IKEY:6596142", "IKEY:1000236", "IKEY:7018371", "IKEY:7194851", "IKEY:7539297", "IKEY:6634139", "IKEY:8017597", "IKEY:877520", "IKEY:5613432", "IKEY:5290698", "IKEY:1671676", "10.1145/2857491.2857524", "10.1145/2578153.2578175", "10.1145/1743666.1743719", "10.1145/2168556.2168558", "10.1145/1743666.1743721", "10.1145/1179622.1179836", "10.1145/2578153.2578158", "10.1145/2993901.2993905", "10.1145/355017.355028", "10.1145/968363.968368", "10.1145/2857491.2857512", "10.1145/2857491.2857524", "10.1145/2578153.2578175", "10.1145/1743666.1743719", "10.1145/2168556.2168558", "10.1145/1743666.1743721", "10.1145/1179622.1179836", "10.1145/2578153.2578158", "10.1145/2993901.2993905", "10.1145/355017.355028", "10.1145/968363.968368", "10.1145/2857491.2857512", "10.1145/2857491.2857524", "10.1145/2578153.2578175", "10.1145/1743666.1743719", "10.1145/2168556.2168558", "10.1145/1743666.1743721", "10.1145/1179622.1179836", "10.1145/2578153.2578158", "10.1145/2993901.2993905", "10.1145/355017.355028", "10.1145/968363.968368", "10.1145/2857491.2857512", "10.1111/cgf.13079", "10.1111/cgf.12115", "10.1016/j.cub.2004.09.041", "10.1016/j.compbiomed.2006.08.018", "10.1016/j.cag.2016.11.001", "10.1007/BF01936872", "10.1007/978-3-319-27707-3_28", "10.1007/978-3-642-15300-6_21", "10.1007/s12559-010-9074-z", "10.1007/978-3-319-50106-2_3", "10.1167/13.3.16", "10.1016/j.patcog.2007.10.010", "10.3758/BF03195481", "10.1111/cgf.13079", "10.1111/cgf.12115", "10.1016/j.cub.2004.09.041", "10.1016/j.compbiomed.2006.08.018", "10.1016/j.cag.2016.11.001", "10.1007/BF01936872", "10.1007/978-3-319-27707-3_28", "10.1007/978-3-642-15300-6_21", "10.1007/s12559-010-9074-z", "10.1007/978-3-319-50106-2_3", "10.1167/13.3.16", "10.1016/j.patcog.2007.10.010", "10.3758/BF03195481", "10.1111/cgf.13079", "10.1111/cgf.12115", "10.1016/j.cub.2004.09.041", "10.1016/j.compbiomed.2006.08.018", "10.1016/j.cag.2016.11.001", "10.1007/BF01936872", "10.1007/978-3-319-27707-3_28", "10.1007/978-3-642-15300-6_21", "10.1007/s12559-010-9074-z", "10.1007/978-3-319-50106-2_3", "10.1167/13.3.16", "10.1016/j.patcog.2007.10.010", "10.3758/BF03195481"]}, "10.1109/TVCG.2018.2864901": {"doi": "10.1109/TVCG.2018.2864901", "author": ["A. Kumpf", "M. Rautenhaus", "M. Riemer", "R. Westermann"], "title": "Visual Analysis of the Temporal Evolution of Ensemble Forecast Sensitivities", "year": "2019", "abstract": "Ensemble sensitivity analysis (ESA) has been established in the atmospheric sciences as a correlation-based approach to determine the sensitivity of a scalar forecast quantity computed by a numerical weather prediction model to changes in another model variable at a different model state. Its applications include determining the origin of forecast errors and placing targeted observations to improve future forecasts. We - a team of visualization scientists and meteorologists - present a visual analysis framework to improve upon current practice of ESA. We support the user in selecting regions to compute a meaningful target forecast quantity by embedding correlation-based grid-point clustering to obtain statistically coherent regions. The evolution of sensitivity features computed via ESA are then traced through time, by integrating a quantitative measure of feature matching into optical-flow-based feature assignment, and displayed by means of a swipe-path showing the geo-spatial evolution of the sensitivities. Visualization of the internal correlation structure of computed features guides the user towards those features robustly predicting a certain weather event. We demonstrate the use of our method by application to real-world 2D and 3D cases that occurred during the 2016 NAWDEX field campaign, showing the interactive generation of hypothesis chains to explore how atmospheric processes sensitive to each other are interrelated.", "keywords": ["data visualisation", "geophysics computing", "sensitivity analysis", "weather forecasting", "ESA", "correlation-based grid-point clustering", "statistically coherent regions", "sensitivity features", "optical-flow-based feature assignment", "geo-spatial evolution", "internal correlation structure", "weather event", "atmospheric processes", "temporal evolution", "ensemble forecast sensitivities", "ensemble sensitivity analysis", "atmospheric sciences", "correlation-based approach", "scalar forecast quantity", "numerical weather prediction model", "forecast errors", "visualization scientists", "meteorologists", "visual analysis framework", "Correlation", "Sensitivity", "Atmospheric modeling", "Weather forecasting", "Visualization", "Computational modeling", "Correlation", "clustering", "tracking", "ensemble visualization"], "referenced_by": [], "referencing": ["IKEY:5669296", "IKEY:5742369", "IKEY:6634109", "IKEY:6423276", "IKEY:7321821", "IKEY:1372239", "IKEY:8017585", "IKEY:8019883", "IKEY:4906833", "IKEY:299407", "IKEY:4015447", "IKEY:597796", "IKEY:1541996", "IKEY:4906852", "IKEY:6378962", "IKEY:7552532", "IKEY:5669296", "IKEY:5742369", "IKEY:6634109", "IKEY:6423276", "IKEY:7321821", "IKEY:1372239", "IKEY:8017585", "IKEY:8019883", "IKEY:4906833", "IKEY:299407", "IKEY:4015447", "IKEY:597796", "IKEY:1541996", "IKEY:4906852", "IKEY:6378962", "IKEY:7552532", "IKEY:5669296", "IKEY:5742369", "IKEY:6634109", "IKEY:6423276", "IKEY:7321821", "IKEY:1372239", "IKEY:8017585", "IKEY:8019883", "IKEY:4906833", "IKEY:299407", "IKEY:4015447", "IKEY:597796", "IKEY:1541996", "IKEY:4906852", "IKEY:6378962", "IKEY:7552532", "10.1145/1268517.1268563", "10.1145/1268517.1268563", "10.1145/1268517.1268563", "10.1175/2007MWR1904.1", "10.1023/B:MACH.0000033116.57574.95", "10.1175/MWR-D-17-0027.1", "10.1175/1520-0493(2000)129&lt;4071:LCCODC&gt;2.0.CO;2", "10.1002/qj.948", "10.1016/0004-3702(81)90024-2", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13396", "10.1002/qj.3072", "10.1175/BAMS-D-14-00259.1", "10.1111/j.1467-8659.2012.03095.x", "10.1615/Int.J.UncertaintyQuantification.2012003934", "10.5194/gmd-8-2329-2015", "10.1007/PL00013399", "10.1002/joc.4408", "10.1111/cgf.13163", "10.1175/BAMS-D-13-00191.1", "10.1175/2007MWR2132.1", "10.1175/MWR-D-14-00086.1", "10.1175/JAS3766.1", "10.1175/WAF-D-12-00132.1", "10.1175/2007MWR1904.1", "10.1023/B:MACH.0000033116.57574.95", "10.1175/MWR-D-17-0027.1", "10.1175/1520-0493(2000)129&lt;4071:LCCODC&gt;2.0.CO;2", "10.1002/qj.948", "10.1016/0004-3702(81)90024-2", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13396", "10.1002/qj.3072", "10.1175/BAMS-D-14-00259.1", "10.1111/j.1467-8659.2012.03095.x", "10.1615/Int.J.UncertaintyQuantification.2012003934", "10.5194/gmd-8-2329-2015", "10.1007/PL00013399", "10.1002/joc.4408", "10.1111/cgf.13163", "10.1175/BAMS-D-13-00191.1", "10.1175/2007MWR2132.1", "10.1175/MWR-D-14-00086.1", "10.1175/JAS3766.1", "10.1175/WAF-D-12-00132.1", "10.1175/2007MWR1904.1", "10.1023/B:MACH.0000033116.57574.95", "10.1175/MWR-D-17-0027.1", "10.1175/1520-0493(2000)129&lt;4071:LCCODC&gt;2.0.CO;2", "10.1002/qj.948", "10.1016/0004-3702(81)90024-2", "10.1016/j.jcp.2007.02.014", "10.1111/cgf.13396", "10.1002/qj.3072", "10.1175/BAMS-D-14-00259.1", "10.1111/j.1467-8659.2012.03095.x", "10.1615/Int.J.UncertaintyQuantification.2012003934", "10.5194/gmd-8-2329-2015", "10.1007/PL00013399", "10.1002/joc.4408", "10.1111/cgf.13163", "10.1175/BAMS-D-13-00191.1", "10.1175/2007MWR2132.1", "10.1175/MWR-D-14-00086.1", "10.1175/JAS3766.1", "10.1175/WAF-D-12-00132.1"]}, "10.1109/TVCG.2018.2864825": {"doi": "10.1109/TVCG.2018.2864825", "author": ["K. Xu", "M. Xia", "X. Mu", "Y. Wang", "N. Cao"], "title": "EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data", "year": "2019", "abstract": "The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts.", "keywords": ["data visualisation", "EnsembleLens", "visual exploration", "anomaly detection algorithms", "multidimensional data", "ensemble analysis techniques", "heterogeneous algorithms", "anomaly detectors", "ensemble analysis process", "ensemble processes", "interpretable data summaries", "visual analytic system", "Anomaly detection", "Correlation", "Data visualization", "Detectors", "Visual analytics", "Feature extraction", "Algorithm Evaluation", "Ensemble Analysis", "Anomaly Detection", "Visual Analysis", "Multidimensional Data"], "referenced_by": ["IKEY:8972081", "IKEY:8973379"], "referencing": ["10.1145/2481244.2481252", "10.1145/2830544.2830549", "10.1145/956755.956758", "10.1145/342009.335388", "10.1145/1541880.1541882", "10.1145/1961189.1961199", "10.1145/3097983.3098154", "10.1145/3063955.3063987", "10.1145/502512.502554", "10.1145/1401890.1401946", "10.1145/1772690.1772749", "10.1145/1081870.1081891", "10.1145/2890508", "10.1145/1518701.1518895", "10.1145/2481244.2481252", "10.1145/2830544.2830549", "10.1145/956755.956758", "10.1145/342009.335388", "10.1145/1541880.1541882", "10.1145/1961189.1961199", "10.1145/3097983.3098154", "10.1145/3063955.3063987", "10.1145/502512.502554", "10.1145/1401890.1401946", "10.1145/1772690.1772749", "10.1145/1081870.1081891", "10.1145/2890508", "10.1145/1518701.1518895", "10.1145/2481244.2481252", "10.1145/2830544.2830549", "10.1145/956755.956758", "10.1145/342009.335388", "10.1145/1541880.1541882", "10.1145/1961189.1961199", "10.1145/3097983.3098154", "10.1145/3063955.3063987", "10.1145/502512.502554", "10.1145/1401890.1401946", "10.1145/1772690.1772749", "10.1145/1081870.1081891", "10.1145/2890508", "10.1145/1518701.1518895", "10.1007/978-3-319-14142-8_8", "10.1007/3-540-45681-3_2", "10.1117/12.883535", "10.1111/1467-842X.00110", "10.1177/1473871616686635", "10.1111/cgf.13279", "10.1007/3-540-45014-9_1", "10.1007/978-1-4615-0953-0_4", "10.1002/sam.10008", "10.1111/cgf.12898", "10.1371/journal.pone.0152173", "10.1016/j.inffus.2005.01.008", "10.1007/3-540-46145-0_17", "10.1023/B:AIRE.0000045502.10941.a9", "10.2307/2332226", "10.1007/s007780050006", "10.1137/1.9781611972818.2", "10.1007/BF02289565", "10.1007/978-3-642-12026-8_29", "10.14778/1920841.1921021", "10.1098/rspl.1895.0041", "10.1111/cgf.12390", "10.1007/978-3-642-32677-6_15", "10.1007/s10115-007-0093-3", "10.1007/s10462-009-9124-7", "10.1137/1.9781611972825.90", "10.1007/s10618-012-0300-z", "10.1016/S0167-7152(98)00006-6", "10.2307/1412159", "10.1137/1.9781611972771.33", "10.1023/B:DAMI.0000023676.72185.7c", "10.1111/cgf.13173", "10.1002/sam.11161", "10.1007/978-3-319-14142-8_8", "10.1007/3-540-45681-3_2", "10.1117/12.883535", "10.1111/1467-842X.00110", "10.1177/1473871616686635", "10.1111/cgf.13279", "10.1007/3-540-45014-9_1", "10.1007/978-1-4615-0953-0_4", "10.1002/sam.10008", "10.1111/cgf.12898", "10.1371/journal.pone.0152173", "10.1016/j.inffus.2005.01.008", "10.1007/3-540-46145-0_17", "10.1023/B:AIRE.0000045502.10941.a9", "10.2307/2332226", "10.1007/s007780050006", "10.1137/1.9781611972818.2", "10.1007/BF02289565", "10.1007/978-3-642-12026-8_29", "10.14778/1920841.1921021", "10.1098/rspl.1895.0041", "10.1111/cgf.12390", "10.1007/978-3-642-32677-6_15", "10.1007/s10115-007-0093-3", "10.1007/s10462-009-9124-7", "10.1137/1.9781611972825.90", "10.1007/s10618-012-0300-z", "10.1016/S0167-7152(98)00006-6", "10.2307/1412159", "10.1137/1.9781611972771.33", "10.1023/B:DAMI.0000023676.72185.7c", "10.1111/cgf.13173", "10.1002/sam.11161", "10.1007/978-3-319-14142-8_8", "10.1007/3-540-45681-3_2", "10.1117/12.883535", "10.1111/1467-842X.00110", "10.1177/1473871616686635", "10.1111/cgf.13279", "10.1007/3-540-45014-9_1", "10.1007/978-1-4615-0953-0_4", "10.1002/sam.10008", "10.1111/cgf.12898", "10.1371/journal.pone.0152173", "10.1016/j.inffus.2005.01.008", "10.1007/3-540-46145-0_17", "10.1023/B:AIRE.0000045502.10941.a9", "10.2307/2332226", "10.1007/s007780050006", "10.1137/1.9781611972818.2", "10.1007/BF02289565", "10.1007/978-3-642-12026-8_29", "10.14778/1920841.1921021", "10.1098/rspl.1895.0041", "10.1111/cgf.12390", "10.1007/978-3-642-32677-6_15", "10.1007/s10115-007-0093-3", "10.1007/s10462-009-9124-7", "10.1137/1.9781611972825.90", "10.1007/s10618-012-0300-z", "10.1016/S0167-7152(98)00006-6", "10.2307/1412159", "10.1137/1.9781611972771.33", "10.1023/B:DAMI.0000023676.72185.7c", "10.1111/cgf.13173", "10.1002/sam.11161"]}, "10.1109/TVCG.2018.2865024": {"doi": "10.1109/TVCG.2018.2865024", "author": ["H. Stitz", "S. Gratzl", "H. Piringer", "T. Zichner", "M. Streit"], "title": "KnowledgePearls: Provenance-Based Visualization Retrieval", "year": "2019", "abstract": "Storing analytical provenance generates a knowledge base with a large potential for recalling previous results and guiding users in future analyses. However, without extensive manual creation of meta information and annotations by the users, search and retrieval of analysis states can become tedious. We present KnowledgePearls, a solution for efficient retrieval of analysis states that are structured as provenance graphs containing automatically recorded user interactions and visualizations. As a core component, we describe a visual interface for querying and exploring analysis states based on their similarity to a partial definition of a requested analysis state. Depending on the use case, this definition may be provided explicitly by the user by formulating a search query or inferred from given reference states. We explain our approach using the example of efficient retrieval of demographic analyses by Hans Rosling and discuss our implementation for a fast look-up of previous states. Our approach is independent of the underlying visualization framework. We discuss the applicability for visualizations which are based on the declarative grammar Vega and we use a Vega-based implementation of Gapminder as guiding example. We additionally present a biomedical case study to illustrate how KnowledgePearls facilitates the exploration process by recalling states from earlier analyses.", "keywords": ["data analysis", "data visualisation", "grammars", "graph theory", "knowledge based systems", "query processing", "meta information", "KnowledgePearls", "provenance graphs", "automatically recorded user interactions", "core component", "visual interface", "search query", "demographic analyses", "Vega-based implementation", "provenance-based visualization retrieval", "analytical provenance", "knowledge base", "analysis state", "reference states", "visualization framework", "manual creation", "meta annotations", "declarative grammar Vega", "Data visualization", "Visualization", "Indexes", "History", "Database languages", "Knowledge based systems", "Grammar", "Visualization provenance", "interaction provenance", "retrieval"], "referenced_by": ["IKEY:8807288", "IKEY:8809832", "IKEY:8585048"], "referencing": ["IKEY:6064985", "IKEY:4497516", "IKEY:6634189", "IKEY:5290712", "IKEY:5613439", "IKEY:5184827", "IKEY:4488060", "IKEY:6634146", "IKEY:4658129", "IKEY:1382890", "IKEY:6327266", "IKEY:211893", "IKEY:7536133", "IKEY:8017646", "IKEY:7192714", "IKEY:7539624", "IKEY:7192704", "IKEY:4015432", "IKEY:7369992", "IKEY:981851", "IKEY:5388055", "IKEY:6064985", "IKEY:4497516", "IKEY:6634189", "IKEY:5290712", "IKEY:5613439", "IKEY:5184827", "IKEY:4488060", "IKEY:6634146", "IKEY:4658129", "IKEY:1382890", "IKEY:6327266", "IKEY:211893", "IKEY:7536133", "IKEY:8017646", "IKEY:7192714", "IKEY:7539624", "IKEY:7192704", "IKEY:4015432", "IKEY:7369992", "IKEY:981851", "IKEY:5388055", "IKEY:6064985", "IKEY:4497516", "IKEY:6634189", "IKEY:5290712", "IKEY:5613439", "IKEY:5184827", "IKEY:4488060", "IKEY:6634146", "IKEY:4658129", "IKEY:1382890", "IKEY:6327266", "IKEY:211893", "IKEY:7536133", "IKEY:8017646", "IKEY:7192714", "IKEY:7539624", "IKEY:7192704", "IKEY:4015432", "IKEY:7369992", "IKEY:981851", "IKEY:5388055", "10.1145/245882.245893", "10.1145/361219.361220", "10.1145/2642918.2647360", "10.1145/142750.143082", "10.1145/1357054.1357247", "10.1145/775047.775064", "10.1145/245882.245893", "10.1145/361219.361220", "10.1145/2642918.2647360", "10.1145/142750.143082", "10.1145/1357054.1357247", "10.1145/775047.775064", "10.1145/245882.245893", "10.1145/361219.361220", "10.1145/2642918.2647360", "10.1145/142750.143082", "10.1145/1357054.1357247", "10.1145/775047.775064", "10.1093/bib/bbl022", "10.1002/cpe.1247", "10.1057/ivs.2008.31", "10.1111/cgf.12925", "10.1007/s00778-017-0486-1", "10.1016/j.aei.2016.04.003", "10.1111/cgf.13193", "10.1111/cgf.12924", "10.1093/bib/bbl022", "10.1002/cpe.1247", "10.1057/ivs.2008.31", "10.1111/cgf.12925", "10.1007/s00778-017-0486-1", "10.1016/j.aei.2016.04.003", "10.1111/cgf.13193", "10.1111/cgf.12924", "10.1093/bib/bbl022", "10.1002/cpe.1247", "10.1057/ivs.2008.31", "10.1111/cgf.12925", "10.1007/s00778-017-0486-1", "10.1016/j.aei.2016.04.003", "10.1111/cgf.13193", "10.1111/cgf.12924"]}, "10.1109/TVCG.2018.2865039": {"doi": "10.1109/TVCG.2018.2865039", "author": ["A. Camisetty", "C. Chandurkar", "M. Sun", "D. Koop"], "title": "Enhancing Web-based Analytics Applications through Provenance", "year": "2019", "abstract": "Visual analytics systems continue to integrate new technologies and leverage modern environments for exploration and collaboration, making tools and techniques available to a wide audience through web browsers. Many of these systems have been developed with rich interactions, offering users the opportunity to examine details and explore hypotheses that have not been directly encoded by a designer. Understanding is enhanced when users can replay and revisit the steps in the sensemaking process, and in collaborative settings, it is especially important to be able to review not only the current state but also what decisions were made along the way. Unfortunately, many web-based systems lack the ability to capture such reasoning, and the path to a result is transient, forgotten when a user moves to a new view. This paper explores the requirements to augment existing client-side web applications with support for capturing, reviewing, sharing, and reusing steps in the reasoning process. Furthermore, it considers situations where decisions are made with streaming data, and the insights gained from revisiting those choices when more data is available. It presents a proof of concept, the Shareable Interactive Manipulation Provenance framework (SIMProv.js), that addresses these requirements in a modern, client-side JavaScript library, and describes how it can be integrated with existing frameworks.", "keywords": ["data analysis", "data visualisation", "Internet", "reasoning process", "visual analytics systems", "collaborative settings", "Web-based systems", "Web browsers", "Web-based analytics applications", "client-side Web applications", "streaming data", "shareable interactive manipulation provenance framework", "client-side javascript library", "Collaboration", "History", "Tools", "Browsers", "Libraries", "Servers", "Visualization", "Collaboration", "provenance", "streaming data", "history", "web"], "referenced_by": [], "referencing": ["IKEY:398857", "IKEY:6102447", "IKEY:5652932", "IKEY:7994551", "IKEY:7534759", "IKEY:4488060", "IKEY:6634130", "IKEY:4658129", "IKEY:1185579", "IKEY:18020", "IKEY:4578449", "IKEY:6875986", "IKEY:7194834", "IKEY:7192714", "IKEY:6876049", "IKEY:4376132", "IKEY:7192728", "IKEY:7111922", "IKEY:8017596", "IKEY:398857", "IKEY:6102447", "IKEY:5652932", "IKEY:7994551", "IKEY:7534759", "IKEY:4488060", "IKEY:6634130", "IKEY:4658129", "IKEY:1185579", "IKEY:18020", "IKEY:4578449", "IKEY:6875986", "IKEY:7194834", "IKEY:7192714", "IKEY:6876049", "IKEY:4376132", "IKEY:7192728", "IKEY:7111922", "IKEY:8017596", "IKEY:398857", "IKEY:6102447", "IKEY:5652932", "IKEY:7994551", "IKEY:7534759", "IKEY:4488060", "IKEY:6634130", "IKEY:4658129", "IKEY:1185579", "IKEY:18020", "IKEY:4578449", "IKEY:6875986", "IKEY:7194834", "IKEY:7192714", "IKEY:6876049", "IKEY:4376132", "IKEY:7192728", "IKEY:7111922", "IKEY:8017596", "10.1145/2884781.2884864", "10.1145/2669485.2669518", "10.1145/2598153.2598168", "10.1145/2501988.2502050", "10.1145/67544.66963", "10.1145/2807442.2807468", "10.1145/2396636.2396673", "10.1145/2882903.2899392", "10.1145/215585.215706", "10.1145/1979742.1979570", "10.1145/1357054.1357247", "10.1145/1084805.1084812", "10.1145/1518701.1519008", "10.1145/2884781.2884864", "10.1145/2669485.2669518", "10.1145/2598153.2598168", "10.1145/2501988.2502050", "10.1145/67544.66963", "10.1145/2807442.2807468", "10.1145/2396636.2396673", "10.1145/2882903.2899392", "10.1145/215585.215706", "10.1145/1979742.1979570", "10.1145/1357054.1357247", "10.1145/1084805.1084812", "10.1145/1518701.1519008", "10.1145/2884781.2884864", "10.1145/2669485.2669518", "10.1145/2598153.2598168", "10.1145/2501988.2502050", "10.1145/67544.66963", "10.1145/2807442.2807468", "10.1145/2396636.2396673", "10.1145/2882903.2899392", "10.1145/215585.215706", "10.1145/1979742.1979570", "10.1145/1357054.1357247", "10.1145/1084805.1084812", "10.1145/1518701.1519008", "10.1111/j.1467-8659.2009.01687.x", "10.1016/S0950-7051(00)00101-5", "10.1007/11890850_2", "10.1057/ivs.2008.31", "10.1007/978-3-642-17819-1_34", "10.2218/ijdc.v7i1.213", "10.1057/palgrave.ivs.9500167", "10.1007/s00778-017-0486-1", "10.1111/cgf.12903", "10.1177/1473871611412817", "10.1007/978-3-319-40593-3_9", "10.1111/j.1467-8659.2009.01687.x", "10.1016/S0950-7051(00)00101-5", "10.1007/11890850_2", "10.1057/ivs.2008.31", "10.1007/978-3-642-17819-1_34", "10.2218/ijdc.v7i1.213", "10.1057/palgrave.ivs.9500167", "10.1007/s00778-017-0486-1", "10.1111/cgf.12903", "10.1177/1473871611412817", "10.1007/978-3-319-40593-3_9", "10.1111/j.1467-8659.2009.01687.x", "10.1016/S0950-7051(00)00101-5", "10.1007/11890850_2", "10.1057/ivs.2008.31", "10.1007/978-3-642-17819-1_34", "10.2218/ijdc.v7i1.213", "10.1057/palgrave.ivs.9500167", "10.1007/s00778-017-0486-1", "10.1111/cgf.12903", "10.1177/1473871611412817", "10.1007/978-3-319-40593-3_9"]}, "10.1109/TVCG.2018.2864905": {"doi": "10.1109/TVCG.2018.2864905", "author": ["N. Sultanum", "D. Singh", "M. Brudno", "F. Chevalier"], "title": "Doccurate: A Curation-Based Approach for Clinical Text Visualization", "year": "2019", "abstract": "Before seeing a patient, physicians seek to obtain an overview of the patient's medical history. Text plays a major role in this activity since it represents the bulk of the clinical documentation, but reviewing it quickly becomes onerous when patient charts grow too large. Text visualization methods have been widely explored to manage this large scale through visual summaries that rely on information retrieval algorithms to structure text and make it amenable to visualization. However, the integration with such automated approaches comes with a number of limitations, including significant error rates and the need for healthcare providers to fine-tune algorithms without expert knowledge of their inner mechanics. In addition, several of these approaches obscure or substitute the original clinical text and therefore fail to leverage qualitative and rhetorical flavours of the clinical notes. These drawbacks have limited the adoption of text visualization and other summarization technologies in clinical practice. In this work we present Doccurate, a novel system embodying a curation-based approach for the visualization of large clinical text datasets. Our approach offers automation auditing and customizability to physicians while also preserving and extensively linking to the original text. We discuss findings of a formal qualitative evaluation conducted with 6 domain experts, shedding light onto physicians' information needs, perceived strengths and limitations of automated tools, and the importance of customization while balancing efficiency. We also present use case scenarios to showcase Doccurate's envisioned usage in practice.", "keywords": ["data visualisation", "health care", "information retrieval", "medical information systems", "text analysis", "visual summaries", "information retrieval algorithms", "expert knowledge", "curation-based approach", "clinical text datasets", "automation auditing", "physicians", "clinical text visualization", "clinical documentation", "patient charts", "healthcare", "patient medical history", "fine-tune algorithms", "Doccurate envisioned usage", "Medical services", "Visualization", "Automation", "Data visualization", "Tools", "Task analysis", "Medical diagnostic imaging", "Visual Curation", "Clinical Text", "Text Visualization", "Medical Narrative"], "referenced_by": ["IKEY:8805439", "IKEY:8809711"], "referencing": ["IKEY:7042502", "IKEY:4267678", "IKEY:5613451", "IKEY:6400485", "IKEY:7192669", "IKEY:8019821", "IKEY:885098", "IKEY:6144740", "IKEY:6875959", "IKEY:6816054", "IKEY:8023823", "IKEY:7192716", "IKEY:7042502", "IKEY:4267678", "IKEY:5613451", "IKEY:6400485", "IKEY:7192669", "IKEY:8019821", "IKEY:885098", "IKEY:6144740", "IKEY:6875959", "IKEY:6816054", "IKEY:8023823", "IKEY:7192716", "IKEY:7042502", "IKEY:4267678", "IKEY:5613451", "IKEY:6400485", "IKEY:7192669", "IKEY:8019821", "IKEY:885098", "IKEY:6144740", "IKEY:6875959", "IKEY:6816054", "IKEY:8023823", "IKEY:7192716", "10.1145/2531602.2531620", "10.1145/1378773.1378785", "10.1145/2089094.2089101", "10.1145/286498.286513", "10.1145/238386.238493", "10.1145/2939672.2939778", "10.1145/3173574.3173996", "10.1145/2531602.2531620", "10.1145/1378773.1378785", "10.1145/2089094.2089101", "10.1145/286498.286513", "10.1145/238386.238493", "10.1145/2939672.2939778", "10.1145/3173574.3173996", "10.1145/2531602.2531620", "10.1145/1378773.1378785", "10.1145/2089094.2089101", "10.1145/286498.286513", "10.1145/238386.238493", "10.1145/2939672.2939778", "10.1145/3173574.3173996", "10.1016/j.cmpb.2015.10.014", "10.3122/jabfm.2011.06.100255", "10.1093/bioinformatics/btx228", "10.1136/amiajnl-2014-002945", "10.1038/sdata.2016.35", "10.1093/jamia/ocv069", "10.1007/978-0-85729-913-0_5", "10.1093/jamia/ocv032", "10.1016/S0140-6736(94)91406-0", "10.1561/1100000039", "10.1136/jamia.2009.001560", "10.1016/0020-7101(96)01178-6", "10.1093/jamia/ocx070", "10.1016/j.cmpb.2015.10.014", "10.3122/jabfm.2011.06.100255", "10.1093/bioinformatics/btx228", "10.1136/amiajnl-2014-002945", "10.1038/sdata.2016.35", "10.1093/jamia/ocv069", "10.1007/978-0-85729-913-0_5", "10.1093/jamia/ocv032", "10.1016/S0140-6736(94)91406-0", "10.1561/1100000039", "10.1136/jamia.2009.001560", "10.1016/0020-7101(96)01178-6", "10.1093/jamia/ocx070", "10.1016/j.cmpb.2015.10.014", "10.3122/jabfm.2011.06.100255", "10.1093/bioinformatics/btx228", "10.1136/amiajnl-2014-002945", "10.1038/sdata.2016.35", "10.1093/jamia/ocv069", "10.1007/978-0-85729-913-0_5", "10.1093/jamia/ocv032", "10.1016/S0140-6736(94)91406-0", "10.1561/1100000039", "10.1136/jamia.2009.001560", "10.1016/0020-7101(96)01178-6", "10.1093/jamia/ocx070"]}, "10.1109/TVCG.2018.2865022": {"doi": "10.1109/TVCG.2018.2865022", "author": ["S. Latif", "F. Beck"], "title": "VIS Author Profiles: Interactive Descriptions of Publication Records Combining Text and Visualization", "year": "2019", "abstract": "Publication records and collaboration networks are important for assessing the expertise and experience of researchers. Existing digital libraries show the raw publication lists in author profiles, whereas visualization techniques focus on specific subproblems. Instead, we look at publication records from various perspectives mixing low-level publication data with high-level abstractions and background information. This work presents VIS Author Profiles, a novel approach to generate integrated textual and visual descriptions to highlight patterns in publication records. We leverage template-based natural language generation to summarize notable publication statistics, evolution of research topics, and collaboration relationships. Seamlessly integrated visualizations augment the textual description and are interactively connected with each other and the text. The underlying publication data and detailed explanations of the analysis are available on demand. We compare our approach to existing systems by taking into account information needs of users and demonstrate its usefulness in two realistic application examples.", "keywords": ["data visualisation", "digital libraries", "groupware", "natural language processing", "statistical analysis", "text analysis", "interactive descriptions", "raw publication lists", "low-level publication data", "high-level abstractions", "integrated textual descriptions", "visual descriptions", "seamlessly integrated visualizations", "textual description", "underlying publication data", "publication records", "visualization techniques", "publication statistics", "VIS author profiles", "collaboration networks", "digital libraries", "author profiles", "template-based natural language generation", "collaboration relationships", "Data visualization", "Collaboration", "Libraries", "Computer science", "Natural languages", "Visual analytics", "Natural language generation", "document visualization", "interactive documents", "sparklines", "digital libraries"], "referenced_by": ["IKEY:8807243", "IKEY:8807349", "IKEY:8986934", "IKEY:8977320"], "referencing": ["IKEY:8114622", "IKEY:7192633", "IKEY:8091161", "IKEY:7864462", "IKEY:6327277", "IKEY:7570239", "IKEY:7465279", "IKEY:6875917", "IKEY:7938243", "IKEY:4376154", "IKEY:6824839", "IKEY:6991551", "IKEY:7192725", "IKEY:6634163", "IKEY:8114622", "IKEY:7192633", "IKEY:8091161", "IKEY:7864462", "IKEY:6327277", "IKEY:7570239", "IKEY:7465279", "IKEY:6875917", "IKEY:7938243", "IKEY:4376154", "IKEY:6824839", "IKEY:6991551", "IKEY:7192725", "IKEY:6634163", "IKEY:8114622", "IKEY:7192633", "IKEY:8091161", "IKEY:7864462", "IKEY:6327277", "IKEY:7570239", "IKEY:7465279", "IKEY:6875917", "IKEY:7938243", "IKEY:4376154", "IKEY:6824839", "IKEY:6991551", "IKEY:7192725", "IKEY:6634163", "10.1145/3025453.3025631", "10.1145/2470654.2481374", "10.1145/3173574.3174012", "10.1145/642611.642681", "10.1145/3025453.3025631", "10.1145/2470654.2481374", "10.1145/3173574.3174012", "10.1145/642611.642681", "10.1145/3025453.3025631", "10.1145/2470654.2481374", "10.1145/3173574.3174012", "10.1145/642611.642681", "10.1162/COLI_a_00091", "10.1057/palgrave.ivs.9500156", "10.1613/jair.5477", "10.3115/v1/W14-4423", "10.4304/jetwi.4.1.3-14", "10.3138/chr.694", "10.1002/int.21835", "10.1017/CBO9780511519857", "10.1016/0004-3702(93)90022-4", "10.1007/978-94-009-7798-3_15", "10.1162/COLI_a_00091", "10.1057/palgrave.ivs.9500156", "10.1613/jair.5477", "10.3115/v1/W14-4423", "10.4304/jetwi.4.1.3-14", "10.3138/chr.694", "10.1002/int.21835", "10.1017/CBO9780511519857", "10.1016/0004-3702(93)90022-4", "10.1007/978-94-009-7798-3_15", "10.1162/COLI_a_00091", "10.1057/palgrave.ivs.9500156", "10.1613/jair.5477", "10.3115/v1/W14-4423", "10.4304/jetwi.4.1.3-14", "10.3138/chr.694", "10.1002/int.21835", "10.1017/CBO9780511519857", "10.1016/0004-3702(93)90022-4", "10.1007/978-94-009-7798-3_15"]}, "10.1109/TVCG.2018.2864814": {"doi": "10.1109/TVCG.2018.2864814", "author": ["X. Yue", "X. Shu", "X. Zhu", "X. Du", "Z. Yu", "D. Papadopoulos", "S. Liu"], "title": "BitExTract: Interactive Visualization for Extracting Bitcoin Exchange Intelligence", "year": "2019", "abstract": "The emerging prosperity of cryptocurrencies, such as Bitcoin, has come into the spotlight during the past few years. Cryptocurrency exchanges, which act as the gateway to this world, now play a dominant role in the circulation of Bitcoin. Thus, delving into the analysis of the transaction patterns of exchanges can shed light on the evolution and trends in the Bitcoin market, and participants can gain hints for identifying credible exchanges as well. Not only Bitcoin practitioners but also researchers in the financial domains are interested in the business intelligence behind the curtain. However, the task of multiple exchanges exploration and comparisons has been limited owing to the lack of efficient tools. Previous methods of visualizing Bitcoin data have mainly concentrated on tracking suspicious transaction logs, but it is cumbersome to analyze exchanges and their relationships with existing tools and methods. In this paper, we present BitExTract, an interactive visual analytics system, which, to the best of our knowledge, is the first attempt to explore the evolutionary transaction patterns of Bitcoin exchanges from two perspectives, namely, exchange versus exchange and exchange versus client. In particular, BitExTract summarizes the evolution of the Bitcoin market by observing the transactions between exchanges over time via a massive sequence view. A node-link diagram with ego-centered views depicts the trading network of exchanges and their temporal transaction distribution. Moreover, BitExTract embeds multiple parallel bars on a timeline to examine and compare the evolution patterns of transactions between different exchanges. Three case studies with novel insights demonstrate the effectiveness and usability of our system.", "keywords": ["competitive intelligence", "data analysis", "data visualisation", "electronic money", "financial data processing", "transaction processing", "interactive visual analytics system", "evolutionary transaction patterns", "exchange versus exchange", "exchange versus client", "Bitcoin market", "interactive visualization", "bitcoin exchange intelligence", "cryptocurrency exchanges", "Bitcoin practitioners", "multiple exchanges exploration", "Bitcoin data visualization", "financial domains", "business intelligence", "BitExTract", "massive sequence view", "node-link diagram", "ego-centered views", "Bitcoin", "Data visualization", "Visualization", "Task analysis", "Tools", "Bitcoin exchange", "transaction data", "comparative analysis", "visual analytics", "FinTech"], "referenced_by": ["IKEY:8787562", "IKEY:8807302", "IKEY:9248197", "IKEY:9308622", "IKEY:9308621"], "referencing": ["IKEY:4658137", "IKEY:7312773", "IKEY:7163021", "IKEY:6064994", "IKEY:4389009", "IKEY:6805780", "IKEY:1333627", "IKEY:6113303", "IKEY:7423672", "IKEY:6876015", "IKEY:4658137", "IKEY:7312773", "IKEY:7163021", "IKEY:6064994", "IKEY:4389009", "IKEY:6805780", "IKEY:1333627", "IKEY:6113303", "IKEY:7423672", "IKEY:6876015", "IKEY:4658137", "IKEY:7312773", "IKEY:7163021", "IKEY:6064994", "IKEY:4389009", "IKEY:6805780", "IKEY:1333627", "IKEY:6113303", "IKEY:7423672", "IKEY:6876015", "10.1145/2504730.2504747", "10.1145/2504730.2504747", "10.1145/2504730.2504747", "10.1007/978-3-319-06793-3_8", "10.1111/cgf.12791", "10.1093/rfs/hhs091", "10.1371/journal.pone.0161197", "10.1111/cgf.12931", "10.1089/big.2015.0056", "10.1007/978-3-642-39884-1_3", "10.1007/978-3-319-70278-0_9", "10.1007/978-3-319-70278-0_16", "10.4135/9781412983907", "10.1177/1473871613487087", "10.1080/10447318.2010.516722", "10.1371/journal.pone.0163477", "10.1007/978-3-319-06793-3_8", "10.1111/cgf.12791", "10.1093/rfs/hhs091", "10.1371/journal.pone.0161197", "10.1111/cgf.12931", "10.1089/big.2015.0056", "10.1007/978-3-642-39884-1_3", "10.1007/978-3-319-70278-0_9", "10.1007/978-3-319-70278-0_16", "10.4135/9781412983907", "10.1177/1473871613487087", "10.1080/10447318.2010.516722", "10.1371/journal.pone.0163477", "10.1007/978-3-319-06793-3_8", "10.1111/cgf.12791", "10.1093/rfs/hhs091", "10.1371/journal.pone.0161197", "10.1111/cgf.12931", "10.1089/big.2015.0056", "10.1007/978-3-642-39884-1_3", "10.1007/978-3-319-70278-0_9", "10.1007/978-3-319-70278-0_16", "10.4135/9781412983907", "10.1177/1473871613487087", "10.1080/10447318.2010.516722", "10.1371/journal.pone.0163477"]}, "10.1109/TVCG.2018.2865047": {"doi": "10.1109/TVCG.2018.2865047", "author": ["M. Dowling", "J. Wenskovitch", "J. T. Fry", "S. Leman", "L. House", "C. North"], "title": "SIRIUS: Dual, Symmetric, Interactive Dimension Reductions", "year": "2019", "abstract": "Much research has been done regarding how to visualize and interact with observations and attributes of high-dimensional data for exploratory data analysis. From the analyst's perceptual and cognitive perspective, current visualization approaches typically treat the observations of the high-dimensional dataset very differently from the attributes. Often, the attributes are treated as inputs (e.g., sliders), and observations as outputs (e.g., projection plots), thus emphasizing investigation of the observations. However, there are many cases in which analysts wish to investigate both the observations and the attributes of the dataset, suggesting a symmetry between how analysts think about attributes and observations. To address this, we define SIRIUS (Symmetric Interactive Representations In a Unified System), a symmetric, dual projection technique to support exploratory data analysis of high-dimensional data. We provide an example implementation of SIRIUS and demonstrate how this symmetry affords additional insights.", "keywords": ["data analysis", "data mining", "data visualisation", "SIRIUS", "high-dimensional dataset", "symmetric projection technique", "dual projection technique", "data analysis", "visualization approaches", "cognitive perspective", "analysts perceptual", "symmetric interactive representations in a unified system", "symmetric interactive dimension reductions", "dual interactive dimension reductions", "Data visualization", "Task analysis", "Data analysis", "Animals", "Principal component analysis", "Visual analytics", "Image color analysis", "Dimension reduction", "semantic interaction", "exploratory data analysis", "observation projection", "attribute projection"], "referenced_by": [], "referencing": ["IKEY:6400493", "IKEY:5742382", "IKEY:7042492", "IKEY:6400486", "IKEY:7194836", "IKEY:5652443", "IKEY:5429600", "IKEY:8291905", "IKEY:6327294", "IKEY:6102449", "IKEY:6065024", "IKEY:7539597", "IKEY:7874305", "IKEY:7534876", "IKEY:7874310", "IKEY:4658161", "IKEY:329404", "IKEY:6065027", "IKEY:6327268", "IKEY:7534792", "IKEY:6634155", "IKEY:6400493", "IKEY:5742382", "IKEY:7042492", "IKEY:6400486", "IKEY:7194836", "IKEY:5652443", "IKEY:5429600", "IKEY:8291905", "IKEY:6327294", "IKEY:6102449", "IKEY:6065024", "IKEY:7539597", "IKEY:7874305", "IKEY:7534876", "IKEY:7874310", "IKEY:4658161", "IKEY:329404", "IKEY:6065027", "IKEY:6327268", "IKEY:7534792", "IKEY:6634155", "IKEY:6400493", "IKEY:5742382", "IKEY:7042492", "IKEY:6400486", "IKEY:7194836", "IKEY:5652443", "IKEY:5429600", "IKEY:8291905", "IKEY:6327294", "IKEY:6102449", "IKEY:6065024", "IKEY:7539597", "IKEY:7874305", "IKEY:7534876", "IKEY:7874310", "IKEY:4658161", "IKEY:329404", "IKEY:6065027", "IKEY:6327268", "IKEY:7534792", "IKEY:6634155", "10.1145/2207676.2207741", "10.1145/331770.331775", "10.1145/502512.502530", "10.1145/324133.324140", "10.1145/2505515.2505644", "10.1145/2939502.2939505", "10.1145/3077257.3077259", "10.1145/2207676.2207741", "10.1145/331770.331775", "10.1145/502512.502530", "10.1145/324133.324140", "10.1145/2505515.2505644", "10.1145/2939502.2939505", "10.1145/3077257.3077259", "10.1145/2207676.2207741", "10.1145/331770.331775", "10.1145/502512.502530", "10.1145/324133.324140", "10.1145/2505515.2505644", "10.1145/2939502.2939505", "10.1145/3077257.3077259", "10.2307/1942268", "10.1371/journal.pone.0038966", "10.1016/B978-155860915-0/50040-8", "10.2307/2528823", "10.1111/j.1467-8659.2009.01475.x", "10.1007/BF02289565", "10.4135/9781412985130", "10.1371/journal.pone.0050474", "10.1111/cgf.12129", "10.1016/0306-4573(93)90024-8", "10.1098/rspl.1895.0041", "10.1016/0169-7439(87)80084-9", "10.1016/j.patcog.2009.09.025", "10.1016/j.neucom.2010.06.028", "10.1016/j.cag.2016.08.007", "10.2307/1942268", "10.1371/journal.pone.0038966", "10.1016/B978-155860915-0/50040-8", "10.2307/2528823", "10.1111/j.1467-8659.2009.01475.x", "10.1007/BF02289565", "10.4135/9781412985130", "10.1371/journal.pone.0050474", "10.1111/cgf.12129", "10.1016/0306-4573(93)90024-8", "10.1098/rspl.1895.0041", "10.1016/0169-7439(87)80084-9", "10.1016/j.patcog.2009.09.025", "10.1016/j.neucom.2010.06.028", "10.1016/j.cag.2016.08.007", "10.2307/1942268", "10.1371/journal.pone.0038966", "10.1016/B978-155860915-0/50040-8", "10.2307/2528823", "10.1111/j.1467-8659.2009.01475.x", "10.1007/BF02289565", "10.4135/9781412985130", "10.1371/journal.pone.0050474", "10.1111/cgf.12129", "10.1016/0306-4573(93)90024-8", "10.1098/rspl.1895.0041", "10.1016/0169-7439(87)80084-9", "10.1016/j.patcog.2009.09.025", "10.1016/j.neucom.2010.06.028", "10.1016/j.cag.2016.08.007"]}, "10.1109/TVCG.2018.2865028": {"doi": "10.1109/TVCG.2018.2865028", "author": ["M. Angelini", "G. Blasilli", "T. Catarci", "S. Lenti", "G. Santucci"], "title": "Vulnus: Visual Vulnerability Analysis for Network Security", "year": "2019", "abstract": "Vulnerabilities represent one of the main weaknesses of IT systems and the availability of consolidated official data, like CVE (Common Vulnerabilities and Exposures), allows for using them to compute the paths an attacker is likely to follow. However, even if patches are available, business constraints or lack of resources create obstacles to their straightforward application. As a consequence, the security manager of a network needs to deal with a large number of vulnerabilities, making decisions on how to cope with them. This paper presents VULNUS (VULNerabilities visUal aSsessment), a visual analytics solution for dynamically inspecting the vulnerabilities spread on networks, allowing for a quick understanding of the network status and visually classifying nodes according to their vulnerabilities. Moreover, VULNUS computes the approximated optimal sequence of patches able to eliminate all the attack paths and allows for exploring sub-optimal patching strategies, simulating the effect of removing one or more vulnerabilities. VULNUS has been evaluated by domain experts using a lab-test experiment, investigating the effectiveness and efficiency of the proposed solution.", "keywords": ["computer network security", "data visualisation", "Internet", "business constraints", "visual analytics solution", "network status", "visually classifying nodes", "VULNUS", "visual vulnerability analysis", "network security", "consolidated official data", "vulnerabilities visual assessment", "lab-test experiment", "Security", "Bars", "Measurement", "Visual analytics", "Organizations", "Visual Analytics", "Network security", "Vulnerability analysis", "CVE", "CVSS", "Attack Graph", "Vulnerability triage and management"], "referenced_by": ["IKEY:8805439", "IKEY:8807351", "IKEY:8931883", "IKEY:9237998"], "referencing": ["IKEY:7312764", "IKEY:1290234", "IKEY:4376147", "IKEY:5168026", "IKEY:7166305", "IKEY:4641277", "IKEY:4376129", "IKEY:6007132", "IKEY:963283", "IKEY:7312764", "IKEY:1290234", "IKEY:4376147", "IKEY:5168026", "IKEY:7166305", "IKEY:4641277", "IKEY:4376129", "IKEY:6007132", "IKEY:963283", "IKEY:7312764", "IKEY:1290234", "IKEY:4376147", "IKEY:5168026", "IKEY:7166305", "IKEY:4641277", "IKEY:4376129", "IKEY:6007132", "IKEY:963283", "10.1145/1850795.1850798", "10.1145/3196884", "10.1145/1850795.1850800", "10.1145/2379690.2379694", "10.1145/582415.582418", "10.1145/1641587.1641590", "10.1145/1029208.1029225", "10.1145/310889.310919", "10.1145/3134600.3134633", "10.1145/1850795.1850798", "10.1145/3196884", "10.1145/1850795.1850800", "10.1145/2379690.2379694", "10.1145/582415.582418", "10.1145/1641587.1641590", "10.1145/1029208.1029225", "10.1145/310889.310919", "10.1145/3134600.3134633", "10.1145/1850795.1850798", "10.1145/3196884", "10.1145/1850795.1850800", "10.1145/2379690.2379694", "10.1145/582415.582418", "10.1145/1641587.1641590", "10.1145/1029208.1029225", "10.1145/310889.310919", "10.1145/3134600.3134633", "10.1007/978-1-4419-0140-8_1", "10.1007/978-3-319-61176-1_28", "10.1007/978-3-7091-6783-0_4", "10.1177/1473871613488573", "10.1007/978-3-319-66505-4_2", "10.1007/978-3-319-66505-4_1", "10.21236/ADA431826", "10.1155/2014/818957", "10.1007/978-3-540-78243-8_15", "10.1007/978-1-4419-0140-8_1", "10.1007/978-3-319-61176-1_28", "10.1007/978-3-7091-6783-0_4", "10.1177/1473871613488573", "10.1007/978-3-319-66505-4_2", "10.1007/978-3-319-66505-4_1", "10.21236/ADA431826", "10.1155/2014/818957", "10.1007/978-3-540-78243-8_15", "10.1007/978-1-4419-0140-8_1", "10.1007/978-3-319-61176-1_28", "10.1007/978-3-7091-6783-0_4", "10.1177/1473871613488573", "10.1007/978-3-319-66505-4_2", "10.1007/978-3-319-66505-4_1", "10.21236/ADA431826", "10.1155/2014/818957", "10.1007/978-3-540-78243-8_15"]}, "10.1109/TVCG.2018.2865021": {"doi": "10.1109/TVCG.2018.2865021", "author": ["X. Wang", "W. Chen", "J. Chou", "C. Bryan", "H. Guan", "W. Chen", "R. Pan", "K. Ma"], "title": "GraphProtector: A Visual Interface for Employing and Assessing Multiple Privacy Preserving Graph Algorithms", "year": "2019", "abstract": "Analyzing social networks reveals the relationships between individuals and groups in the data. However, such analysis can also lead to privacy exposure (whether intentionally or inadvertently): leaking the real-world identity of ostensibly anonymous individuals. Most sanitization strategies modify the graph's structure based on hypothesized tactics that an adversary would employ. While combining multiple anonymization schemes provides a more comprehensive privacy protection, deciding the appropriate set of techniques-along with evaluating how applying the strategies will affect the utility of the anonymized results-remains a significant challenge. To address this problem, we introduce GraphProtector, a visual interface that guides a user through a privacy preservation pipeline. GraphProtector enables multiple privacy protection schemes which can be simultaneously combined together as a hybrid approach. To demonstrate the effectiveness of GraphPro tector, we report several case studies and feedback collected from interviews with expert users in various scenarios.", "keywords": ["data privacy", "data visualisation", "graph theory", "social networking (online)", "visual interface", "graph algorithms", "social networks", "privacy exposure", "ostensibly anonymous individuals", "sanitization strategies", "hypothesized tactics", "GraphProtector", "privacy preservation pipeline", "privacy protection schemes", "anonymization schemes", "Privacy", "Data privacy", "Data visualization", "Pipelines", "Visualization", "Task analysis", "Measurement", "Graph privacy", "k-anonymity", "structural features", "privacy preservation"], "referenced_by": ["IKEY:8725773", "IKEY:9161608", "IKEY:9308625", "IKEY:9308621"], "referencing": ["IKEY:8031573", "IKEY:1323804", "IKEY:6064989", "IKEY:5742391", "IKEY:8126099", "IKEY:7218534", "IKEY:5207644", "IKEY:8019828", "IKEY:6876032", "IKEY:6482549", "IKEY:4497459", "IKEY:8031573", "IKEY:1323804", "IKEY:6064989", "IKEY:5742391", "IKEY:8126099", "IKEY:7218534", "IKEY:5207644", "IKEY:8019828", "IKEY:6876032", "IKEY:6482549", "IKEY:4497459", "IKEY:8031573", "IKEY:1323804", "IKEY:6064989", "IKEY:5742391", "IKEY:8126099", "IKEY:7218534", "IKEY:5207644", "IKEY:8019828", "IKEY:6876032", "IKEY:6482549", "IKEY:4497459", "10.1145/1242572.1242598", "10.1145/1807167.1807218", "10.1145/3002151.3002153", "10.1145/2339530.2339723", "10.1145/1376616.1376629", "10.1145/2660267.2660324", "10.1145/2068816.2068825", "10.1145/1533057.1533088", "10.1145/2623330.2623642", "10.1145/2433396.2433471", "10.1145/1242572.1242598", "10.1145/1807167.1807218", "10.1145/3002151.3002153", "10.1145/2339530.2339723", "10.1145/1376616.1376629", "10.1145/2660267.2660324", "10.1145/2068816.2068825", "10.1145/1533057.1533088", "10.1145/2623330.2623642", "10.1145/2433396.2433471", "10.1145/1242572.1242598", "10.1145/1807167.1807218", "10.1145/3002151.3002153", "10.1145/2339530.2339723", "10.1145/1376616.1376629", "10.1145/2660267.2660324", "10.1145/2068816.2068825", "10.1145/1533057.1533088", "10.1145/2623330.2623642", "10.1145/2433396.2433471", "10.1007/s13278-014-0205-5", "10.1086/228631", "10.1080/14697680400020325", "10.1086/421787", "10.1080/07468342.1988.11973088", "10.2307/3033543", "10.1016/0378-8733(78)90021-7", "10.1140/epjb/e2008-00237-3", "10.1073/pnas.122653799", "10.14778/1453856.1453873", "10.1016/j.eswa.2004.06.007", "10.1007/978-3-319-13257-0_14", "10.14778/2732269.2732274", "10.1111/j.1467-8659.2011.01912.x", "10.1016/j.tourman.2014.07.007", "10.1016/j.jtrangeo.2015.09.001", "10.7155/jgaa.00108", "10.1007/s11390-013-1383-8", "10.1142/S0218488502001648", "10.1111/j.1467-8659.2011.01898.x", "10.1007/978-1-4419-6045-0_14", "10.1137/1.9781611972788.67", "10.14778/1687627.1687734", "10.1007/s13278-014-0205-5", "10.1086/228631", "10.1080/14697680400020325", "10.1086/421787", "10.1080/07468342.1988.11973088", "10.2307/3033543", "10.1016/0378-8733(78)90021-7", "10.1140/epjb/e2008-00237-3", "10.1073/pnas.122653799", "10.14778/1453856.1453873", "10.1016/j.eswa.2004.06.007", "10.1007/978-3-319-13257-0_14", "10.14778/2732269.2732274", "10.1111/j.1467-8659.2011.01912.x", "10.1016/j.tourman.2014.07.007", "10.1016/j.jtrangeo.2015.09.001", "10.7155/jgaa.00108", "10.1007/s11390-013-1383-8", "10.1142/S0218488502001648", "10.1111/j.1467-8659.2011.01898.x", "10.1007/978-1-4419-6045-0_14", "10.1137/1.9781611972788.67", "10.14778/1687627.1687734", "10.1007/s13278-014-0205-5", "10.1086/228631", "10.1080/14697680400020325", "10.1086/421787", "10.1080/07468342.1988.11973088", "10.2307/3033543", "10.1016/0378-8733(78)90021-7", "10.1140/epjb/e2008-00237-3", "10.1073/pnas.122653799", "10.14778/1453856.1453873", "10.1016/j.eswa.2004.06.007", "10.1007/978-3-319-13257-0_14", "10.14778/2732269.2732274", "10.1111/j.1467-8659.2011.01912.x", "10.1016/j.tourman.2014.07.007", "10.1016/j.jtrangeo.2015.09.001", "10.7155/jgaa.00108", "10.1007/s11390-013-1383-8", "10.1142/S0218488502001648", "10.1111/j.1467-8659.2011.01898.x", "10.1007/978-1-4419-6045-0_14", "10.1137/1.9781611972788.67", "10.14778/1687627.1687734"]}, "10.1109/TVCG.2018.2865029": {"doi": "10.1109/TVCG.2018.2865029", "author": ["J. R. Goodall", "E. D. Ragan", "C. A. Steed", "J. W. Reed", "G. D. Richardson", "K. M. T. Huffer", "R. A. Bridges", "J. A. Laska"], "title": "Situ: Identifying and Explaining Suspicious Behavior in Networks", "year": "2019", "abstract": "Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major financial damages. Anomaly detection methods are beneficial for detecting new types of attacks and abnormal network activity, but such algorithms can be difficult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system's visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workflow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization's security operations center and present the results of expert reviews with professionals.", "keywords": ["computer network security", "data visualisation", "learning (artificial intelligence)", "scalable tools", "suspicious behavior", "security systems", "automated tool", "visual analytics system", "Situ platform", "operational network setting", "cyber security analysts", "networked computing assets", "anomaly detection methods", "abnormal network activity", "network operators", "information visualization", "anomalous events", "IP addresses", "machine learning", "Data visualization", "Network security", "Machine learning", "Anomaly detection", "Visual analytics", "Network security", "situational awareness", "privacy and security", "streaming data", "machine learning", "visualization"], "referenced_by": ["IKEY:8805421", "IKEY:8807351", "IKEY:8924439", "IKEY:8999281", "IKEY:9272175", "IKEY:9165817", "IKEY:9291520", "IKEY:9296846"], "referencing": ["IKEY:4215661", "IKEY:8258031", "IKEY:7307098", "IKEY:5949386", "IKEY:6406752", "IKEY:5375542", "IKEY:1607924", "IKEY:5168026", "IKEY:4804444", "IKEY:5210817", "IKEY:7943487", "IKEY:5945360", "IKEY:7813926", "IKEY:1673246", "IKEY:4376132", "IKEY:4024522", "IKEY:4215661", "IKEY:8258031", "IKEY:7307098", "IKEY:5949386", "IKEY:6406752", "IKEY:5375542", "IKEY:1607924", "IKEY:5168026", "IKEY:4804444", "IKEY:5210817", "IKEY:7943487", "IKEY:5945360", "IKEY:7813926", "IKEY:1673246", "IKEY:4376132", "IKEY:4024522", "IKEY:4215661", "IKEY:8258031", "IKEY:7307098", "IKEY:5949386", "IKEY:6406752", "IKEY:5375542", "IKEY:1607924", "IKEY:5168026", "IKEY:4804444", "IKEY:5210817", "IKEY:7943487", "IKEY:5945360", "IKEY:7813926", "IKEY:1673246", "IKEY:4376132", "IKEY:4024522", "10.1145/1029208.1029217", "10.1145/1850795.1850805", "10.1145/1921168.1921179", "10.1145/1031607.1031663", "10.1145/1898147.1898149", "10.1145/2897795.2897806", "10.1145/3064814.3064828", "10.1145/3064814.3064828", "10.1145/508791.508835", "10.1145/1357054.1357286", "10.1145/2663887.2663899", "10.1145/586143.586146", "10.1145/1029208.1029217", "10.1145/1850795.1850805", "10.1145/1921168.1921179", "10.1145/1031607.1031663", "10.1145/1898147.1898149", "10.1145/2897795.2897806", "10.1145/3064814.3064828", "10.1145/3064814.3064828", "10.1145/508791.508835", "10.1145/1357054.1357286", "10.1145/2663887.2663899", "10.1145/586143.586146", "10.1145/1029208.1029217", "10.1145/1850795.1850805", "10.1145/1921168.1921179", "10.1145/1031607.1031663", "10.1145/1898147.1898149", "10.1145/2897795.2897806", "10.1145/3064814.3064828", "10.1145/3064814.3064828", "10.1145/508791.508835", "10.1145/1357054.1357286", "10.1145/2663887.2663899", "10.1145/586143.586146", "10.1177/154193120504900304", "10.1518/001872095779049543", "10.1007/978-1-4615-0953-0_4", "10.1016/j.cose.2014.05.011", "10.1108/09593840910962186", "10.1111/j.1467-8659.2008.01222.x", "10.20532/cit.2016.1002701", "10.1108/09685221011035241", "10.1016/j.knosys.2016.10.030", "10.1177/154193120504900304", "10.1518/001872095779049543", "10.1007/978-1-4615-0953-0_4", "10.1016/j.cose.2014.05.011", "10.1108/09593840910962186", "10.1111/j.1467-8659.2008.01222.x", "10.20532/cit.2016.1002701", "10.1108/09685221011035241", "10.1016/j.knosys.2016.10.030", "10.1177/154193120504900304", "10.1518/001872095779049543", "10.1007/978-1-4615-0953-0_4", "10.1016/j.cose.2014.05.011", "10.1108/09593840910962186", "10.1111/j.1467-8659.2008.01222.x", "10.20532/cit.2016.1002701", "10.1108/09685221011035241", "10.1016/j.knosys.2016.10.030"]}, "10.1109/TVCG.2018.2865026": {"doi": "10.1109/TVCG.2018.2865026", "author": ["C. Xie", "W. Xu", "K. Mueller"], "title": "A Visual Analytics Framework for the Detection of Anomalous Call Stack Trees in High Performance Computing Applications", "year": "2019", "abstract": "Anomalous runtime behavior detection is one of the most important tasks for performance diagnosis in High Performance Computing (HPC). Most of the existing methods find anomalous executions based on the properties of individual functions, such as execution time. However, it is insufficient to identify abnormal behavior without taking into account the context of the executions, such as the invocations of children functions and the communications with other HPC nodes. We improve upon the existing anomaly detection approaches by utilizing the call stack structures of the executions, which record rich temporal and contextual information. With our call stack tree (CSTree) representation of the executions, we formulate the anomaly detection problem as finding anomalous tree structures in a call stack forest. The CSTrees are converted to vector representations using our proposed stack2vec embedding. Structural and temporal visualizations of CSTrees are provided to support users in the identification and verification of the anomalies during an active anomaly detection process. Three case studies of real-world HPC applications demonstrate the capabilities of our approach.", "keywords": ["data analysis", "data visualisation", "parallel processing", "security of data", "trees (mathematics)", "unsupervised learning", "call stack structures", "contextual information", "call stack tree representation", "CSTree", "anomaly detection problem", "anomalous tree structures", "call stack forest", "vector representations", "stack2vec embedding", "structural visualizations", "temporal visualizations", "active anomaly detection process", "visual analytics framework", "anomalous call stack trees", "anomalous runtime behavior detection", "performance diagnosis", "execution time", "children functions", "HPC nodes", "HPC applications", "high performance computing applications", "Vegetation", "Anomaly detection", "Labeling", "Runtime", "Forestry", "Visualization", "Kernel", "Call Stack", "Performance Visualization", "Representation Learning", "Active Learning", "Anomaly Detection"], "referenced_by": ["IKEY:8473686", "IKEY:8807232", "IKEY:8805421", "IKEY:8805439", "IKEY:8805426", "IKEY:8986943", "IKEY:9086288"], "referencing": ["IKEY:4227982", "IKEY:1565664", "IKEY:7156390", "IKEY:7194836", "IKEY:5713169", "IKEY:6327290", "IKEY:6650534", "IKEY:7422127", "IKEY:7836553", "IKEY:6569821", "IKEY:7536610", "IKEY:4227982", "IKEY:1565664", "IKEY:7156390", "IKEY:7194836", "IKEY:5713169", "IKEY:6327290", "IKEY:6650534", "IKEY:7422127", "IKEY:7836553", "IKEY:6569821", "IKEY:7536610", "IKEY:4227982", "IKEY:1565664", "IKEY:7156390", "IKEY:7194836", "IKEY:5713169", "IKEY:6327290", "IKEY:6650534", "IKEY:7422127", "IKEY:7836553", "IKEY:6569821", "IKEY:7536610", "10.1145/1150402.1150459", "10.1145/335191.335388", "10.1145/1541880.1541882", "10.1145/1141277.1141421", "10.1145/2939672.2939754", "10.1145/1879211.1879228", "10.1145/2623330.2623732", "10.1145/2783258.2783417", "10.1145/1150402.1150459", "10.1145/335191.335388", "10.1145/1541880.1541882", "10.1145/1141277.1141421", "10.1145/2939672.2939754", "10.1145/1879211.1879228", "10.1145/2623330.2623732", "10.1145/2783258.2783417", "10.1145/1150402.1150459", "10.1145/335191.335388", "10.1145/1541880.1541882", "10.1145/1141277.1141421", "10.1145/2939672.2939754", "10.1145/1879211.1879228", "10.1145/2623330.2623732", "10.1145/2783258.2783417", "10.1016/j.patcog.2008.07.004", "10.1002/cpe.4068", "10.1002/spe.4380211102", "10.1002/cpe.1556", "10.1613/jair.3623", "10.1016/S0167-8655(03)00003-5", "10.1016/j.cag.2013.10.006", "10.1007/978-3-540-68564-7_9", "10.1007/978-3-642-31476-6_7", "10.1007/BF02289565", "10.1006/jcph.1995.1039", "10.1016/0022-0000(88)90010-4", "10.1177/1094342006064482", "10.1007/978-3-319-58667-0_19", "10.1016/j.cpc.2010.04.018", "10.1177/109434209901300310", "10.1016/j.patcog.2008.07.004", "10.1002/cpe.4068", "10.1002/spe.4380211102", "10.1002/cpe.1556", "10.1613/jair.3623", "10.1016/S0167-8655(03)00003-5", "10.1016/j.cag.2013.10.006", "10.1007/978-3-540-68564-7_9", "10.1007/978-3-642-31476-6_7", "10.1007/BF02289565", "10.1006/jcph.1995.1039", "10.1016/0022-0000(88)90010-4", "10.1177/1094342006064482", "10.1007/978-3-319-58667-0_19", "10.1016/j.cpc.2010.04.018", "10.1177/109434209901300310", "10.1016/j.patcog.2008.07.004", "10.1002/cpe.4068", "10.1002/spe.4380211102", "10.1002/cpe.1556", "10.1613/jair.3623", "10.1016/S0167-8655(03)00003-5", "10.1016/j.cag.2013.10.006", "10.1007/978-3-540-68564-7_9", "10.1007/978-3-642-31476-6_7", "10.1007/BF02289565", "10.1006/jcph.1995.1039", "10.1016/0022-0000(88)90010-4", "10.1177/1094342006064482", "10.1007/978-3-319-58667-0_19", "10.1016/j.cpc.2010.04.018", "10.1177/109434209901300310"]}, "10.1109/TVCG.2018.2865023": {"doi": "10.1109/TVCG.2018.2865023", "author": ["J. Koven", "C. Felix", "H. Siadati", "M. Jakobsson", "E. Bertini"], "title": "Lessons Learned Developing a Visual Analytics Solution for Investigative Analysis of Scamming Activities", "year": "2019", "abstract": "The forensic investigation of communication datasets which contain unstructured text, social network information, and metadata is a complex task that is becoming more important due to the immense amount of data being collected. Currently there are limited approaches that allow an investigator to explore the network, text and metadata in a unified manner. We developed Beagle as a forensic tool for email datasets that allows investigators to flexibly form complex queries in order to discover important information in email data. Beagle was successfully deployed at a security firm which had a large email dataset that was difficult to properly investigate. We discuss our experience developing Beagle as well as the lessons we learned applying visual analytic techniques to a difficult real-world problem.", "keywords": ["data analysis", "data visualisation", "learning (artificial intelligence)", "meta data", "query processing", "security of data", "social networking (online)", "email dataset", "visual analytics solution", "investigative analysis", "scamming activities", "forensic investigation", "communication datasets", "unstructured text", "social network information", "metadata", "forensic tool", "complex queries", "email data", "security firm", "Electronic mail", "Visual analytics", "Forensics", "Data security", "Metadata", "Data visualization", "Query processing", "Visual Analytics", "Email Investigation", "Email Forensics"], "referenced_by": [], "referencing": ["IKEY:5652968", "IKEY:5482577", "IKEY:1249028", "IKEY:4053131", "IKEY:5290695", "IKEY:6875967", "IKEY:1703371", "IKEY:6327248", "IKEY:5652968", "IKEY:5482577", "IKEY:1249028", "IKEY:4053131", "IKEY:5290695", "IKEY:6875967", "IKEY:1703371", "IKEY:6327248", "IKEY:5652968", "IKEY:5482577", "IKEY:1249028", "IKEY:4053131", "IKEY:5290695", "IKEY:6875967", "IKEY:1703371", "IKEY:6327248", "10.1145/1134271.1134282", "10.1145/1134271.1134282", "10.1145/1134271.1134282", "10.1016/j.dss.2011.01.009", "10.1016/j.diin.2014.10.002", "10.1016/j.cose.2013.11.004", "10.1007/978-3-540-70904-6_37", "10.1108/IMCS-11-2013-0080", "10.4018/jdcf.2011070101", "10.1017/CBO9781139644082", "10.1057/palgrave.ivs.9500167", "10.1016/j.ijhcs.2011.02.007", "10.1016/B978-155860915-0/50046-9", "10.1016/j.dss.2011.01.009", "10.1016/j.diin.2014.10.002", "10.1016/j.cose.2013.11.004", "10.1007/978-3-540-70904-6_37", "10.1108/IMCS-11-2013-0080", "10.4018/jdcf.2011070101", "10.1017/CBO9781139644082", "10.1057/palgrave.ivs.9500167", "10.1016/j.ijhcs.2011.02.007", "10.1016/B978-155860915-0/50046-9", "10.1016/j.dss.2011.01.009", "10.1016/j.diin.2014.10.002", "10.1016/j.cose.2013.11.004", "10.1007/978-3-540-70904-6_37", "10.1108/IMCS-11-2013-0080", "10.4018/jdcf.2011070101", "10.1017/CBO9781139644082", "10.1057/palgrave.ivs.9500167", "10.1016/j.ijhcs.2011.02.007", "10.1016/B978-155860915-0/50046-9"]}, "10.1109/TVCG.2018.2864843": {"doi": "10.1109/TVCG.2018.2864843", "author": ["S. Liu", "C. Chen", "Y. Lu", "F. Ouyang", "B. Wang"], "title": "An Interactive Method to Improve Crowdsourced Annotations", "year": "2019", "abstract": "In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations.", "keywords": ["artificial intelligence", "belief networks", "interactive systems", "learning (artificial intelligence)", "pattern classification", "expert validation", "validation procedure", "interactive method", "uncertain instance labels", "unreliable workers", "worker reliability", "candidate instances", "relevant instances", "constrained projection method", "uncertain labels", "data validation", "validating improving crowdsourced annotations", "correct labels", "noisy crowdsourced annotations", "learning-from-crowd model", "Data visualization", "Labeling", "Data models", "Task analysis", "Visual analytics", "Reliability", "Crowdsourcing", "learning-from-crowds", "interactive visualization", "focus + context"], "referenced_by": ["IKEY:8805421", "IKEY:8805439", "IKEY:8973382", "IKEY:8798996", "IKEY:9263518", "IKEY:9308625"], "referencing": ["10.1145/2836034.2836035", "10.1145/2723372.2723731", "10.1145/775047.775126", "10.1145/1978942.1979444", "10.1145/2254556.2254659", "10.1145/2063576.2063860", "10.1145/2089094.2089101", "10.1145/2408736.2408740", "10.1145/1518701.1518895", "10.1145/2836034.2836035", "10.1145/2723372.2723731", "10.1145/775047.775126", "10.1145/1978942.1979444", "10.1145/2254556.2254659", "10.1145/2063576.2063860", "10.1145/2089094.2089101", "10.1145/2408736.2408740", "10.1145/1518701.1518895", "10.1145/2836034.2836035", "10.1145/2723372.2723731", "10.1145/775047.775126", "10.1145/1978942.1979444", "10.1145/2254556.2254659", "10.1145/2063576.2063860", "10.1145/2089094.2089101", "10.1145/2408736.2408740", "10.1145/1518701.1518895", "10.1093/bioinformatics/17.suppl_1.S22", "10.1111/cgf.12935", "10.1016/S0169-7552(98)00110-X", "10.1007/BF02288367", "10.1111/cgf.13092", "10.1111/j.1467-8659.2011.01918.x", "10.1111/j.1467-8659.2009.01450.x", "10.24963/ijcai.2017/324", "10.1007/s00371-013-0892-3", "10.1016/j.visinf.2017.01.006", "10.1007/s11263-015-0816-y", "10.1093/bioinformatics/17.suppl_1.S22", "10.1111/cgf.12935", "10.1016/S0169-7552(98)00110-X", "10.1007/BF02288367", "10.1111/cgf.13092", "10.1111/j.1467-8659.2011.01918.x", "10.1111/j.1467-8659.2009.01450.x", "10.24963/ijcai.2017/324", "10.1007/s00371-013-0892-3", "10.1016/j.visinf.2017.01.006", "10.1007/s11263-015-0816-y", "10.1093/bioinformatics/17.suppl_1.S22", "10.1111/cgf.12935", "10.1016/S0169-7552(98)00110-X", "10.1007/BF02288367", "10.1111/cgf.13092", "10.1111/j.1467-8659.2011.01918.x", "10.1111/j.1467-8659.2009.01450.x", "10.24963/ijcai.2017/324", "10.1007/s00371-013-0892-3", "10.1016/j.visinf.2017.01.006", "10.1007/s11263-015-0816-y"]}, "10.1109/TVCG.2018.2865043": {"doi": "10.1109/TVCG.2018.2865043", "author": ["D. Dingen", "M. van't Veer", "P. Houthuizen", "E. H. J. Mestrom", "E. H. H. M. Korsten", "A. R. A. Bouwman", "J. van Wijk"], "title": "RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis", "year": "2019", "abstract": "We present RegressionExplorer, a Visual Analytics tool for the interactive exploration of logistic regression models. Our application domain is Clinical Biostatistics, where models are derived from patient data with the aim to obtain clinically meaningful insights and consequences. Development and interpretation of a proper model requires domain expertise and insight into model characteristics. Because of time constraints, often a limited number of candidate models is evaluated. RegressionExplorer enables experts to quickly generate, evaluate, and compare many different models, taking the workflow for model development as starting point. Global patterns in parameter values of candidate models can be explored effectively. In addition, experts are enabled to compare candidate models across multiple subpopulations. The insights obtained can be used to formulate new hypotheses or to steer model development. The effectiveness of the tool is demonstrated for two uses cases: prediction of a cardiac conduction disorder in patients after receiving a heart valve implant and prediction of hypernatremia in critically ill patients.", "keywords": ["cardiology", "data analysis", "data visualisation", "diseases", "medical computing", "medical disorders", "prosthetics", "regression analysis", "RegressionExplorer", "interactive exploration", "logistic regression models", "hypernatremia prediction", "heart valve implant", "cardiac conduction disorder", "clinical biostatistics", "subgroup analysis", "visual analytics tool", "Analytical models", "Logistics", "Visual analytics", "Biological system modeling", "Mathematical model", "Data models", "Visual analytics", "Predictive visual analytics", "Exploratory data analysis", "Multivariate statistics", "Regression analysis", "Variable selection", "Subgroup analysis"], "referenced_by": ["IKEY:8933619", "IKEY:9070468", "IKEY:9086281", "IKEY:9308631"], "referencing": ["IKEY:7466736", "IKEY:6400537", "IKEY:7192713", "IKEY:6634169", "IKEY:6102453", "IKEY:7192729", "IKEY:7465261", "IKEY:6881685", "IKEY:7466736", "IKEY:6400537", "IKEY:7192713", "IKEY:6634169", "IKEY:6102453", "IKEY:7192729", "IKEY:7465261", "IKEY:6881685", "IKEY:7466736", "IKEY:6400537", "IKEY:7192713", "IKEY:6634169", "IKEY:6102453", "IKEY:7192729", "IKEY:7465261", "IKEY:6881685", "10.1145/2590349", "10.1145/2678025.2701407", "10.1145/2590349", "10.1145/2678025.2701407", "10.1145/2590349", "10.1145/2678025.2701407", "10.1093/jamia/ocv006", "10.1198/000313002533", "10.1002/9781118548387", "10.1007/s11704-016-6028-y", "10.1111/cgf.13210", "10.1111/j.1467-8659.2009.01684.x", "10.1561/1100000039", "10.1007/978-3-642-21716-6_15", "10.21037/jtd.2016.08.16", "10.1214/12-AOS1058", "10.1002/pds.4328", "10.1007/s11390-016-1663-1", "10.1093/jamia/ocv006", "10.1198/000313002533", "10.1002/9781118548387", "10.1007/s11704-016-6028-y", "10.1111/cgf.13210", "10.1111/j.1467-8659.2009.01684.x", "10.1561/1100000039", "10.1007/978-3-642-21716-6_15", "10.21037/jtd.2016.08.16", "10.1214/12-AOS1058", "10.1002/pds.4328", "10.1007/s11390-016-1663-1", "10.1093/jamia/ocv006", "10.1198/000313002533", "10.1002/9781118548387", "10.1007/s11704-016-6028-y", "10.1111/cgf.13210", "10.1111/j.1467-8659.2009.01684.x", "10.1561/1100000039", "10.1007/978-3-642-21716-6_15", "10.21037/jtd.2016.08.16", "10.1214/12-AOS1058", "10.1002/pds.4328", "10.1007/s11390-016-1663-1"]}, "10.1109/TVCG.2018.2865051": {"doi": "10.1109/TVCG.2018.2865051", "author": ["D. Orban", "D. F. Keefe", "A. Biswas", "J. Ahrens", "D. Rogers"], "title": "Drag and Track: A Direct Manipulation Interface for Contextualizing Data Instances within a Continuous Parameter Space", "year": "2019", "abstract": "We present a direct manipulation technique that allows material scientists to interactively highlight relevant parameterized simulation instances located in dimensionally reduced spaces, enabling a user-defined understanding of a continuous parameter space. Our goals are two-fold: first, to build a user-directed intuition of dimensionally reduced data, and second, to provide a mechanism for creatively exploring parameter relationships in parameterized simulation sets, called ensembles. We start by visualizing ensemble data instances in dimensionally reduced scatter plots. To understand these abstract views, we employ user-defined virtual data instances that, through direct manipulation, search an ensemble for similar instances. Users can create multiple of these direct manipulation queries to visually annotate the spaces with sets of highlighted ensemble data instances. User-defined goals are therefore translated into custom illustrations that are projected onto the dimensionally reduced spaces. Combined forward and inverse searches of the parameter space follow naturally allowing for continuous parameter space prediction and visual query comparison in the context of an ensemble. The potential for this visualization technique is confirmed via expert user feedback for a shock physics application and synthetic model analysis.", "keywords": ["data visualisation", "human computer interaction", "query processing", "user-defined virtual data instances", "highlighted ensemble data instances", "user-defined goals", "dimensionally reduced spaces", "continuous parameter space prediction", "visual query comparison", "visualization technique", "expert user feedback", "direct manipulation interface", "direct manipulation technique", "material scientists", "interactively highlight relevant parameterized simulation instances", "user-defined understanding", "user-directed intuition", "dimensionally reduced data", "creatively exploring parameter relationships", "parameterized simulation sets", "dimensionally reduced scatter plots", "Data visualization", "Visualization", "Electric shock", "Physics", "Navigation", "Data models", "Uncertainty", "Visual Parameter Space Analysis", "Ensemble Visualization", "Semantic Interaction", "Direct Manipulation", "Shock Physics"], "referenced_by": ["IKEY:8805421", "IKEY:8805439", "IKEY:8805426", "10.1111/cgf.14029"], "referencing": ["IKEY:7013022", "IKEY:6634187", "IKEY:7539581", "IKEY:6400486", "IKEY:5613488", "IKEY:6634138", "IKEY:6400489", "IKEY:7192664", "IKEY:6562729", "IKEY:7160906", "IKEY:6327294", "IKEY:6102449", "IKEY:545269", "IKEY:7192675", "IKEY:6634122", "IKEY:8019883", "IKEY:7563342", "IKEY:6875964", "IKEY:7352365", "IKEY:6813969", "IKEY:7536133", "IKEY:5360497", "IKEY:7536217", "IKEY:7539327", "IKEY:6876043", "IKEY:6064952", "IKEY:7862917", "IKEY:7539323", "IKEY:5613487", "IKEY:7013022", "IKEY:6634187", "IKEY:7539581", "IKEY:6400486", "IKEY:5613488", "IKEY:6634138", "IKEY:6400489", "IKEY:7192664", "IKEY:6562729", "IKEY:7160906", "IKEY:6327294", "IKEY:6102449", "IKEY:545269", "IKEY:7192675", "IKEY:6634122", "IKEY:8019883", "IKEY:7563342", "IKEY:6875964", "IKEY:7352365", "IKEY:6813969", "IKEY:7536133", "IKEY:5360497", "IKEY:7536217", "IKEY:7539327", "IKEY:6876043", "IKEY:6064952", "IKEY:7862917", "IKEY:7539323", "IKEY:5613487", "IKEY:7013022", "IKEY:6634187", "IKEY:7539581", "IKEY:6400486", "IKEY:5613488", "IKEY:6634138", "IKEY:6400489", "IKEY:7192664", "IKEY:6562729", "IKEY:7160906", "IKEY:6327294", "IKEY:6102449", "IKEY:545269", "IKEY:7192675", "IKEY:6634122", "IKEY:8019883", "IKEY:7563342", "IKEY:6875964", "IKEY:7352365", "IKEY:6813969", "IKEY:7536133", "IKEY:5360497", "IKEY:7536217", "IKEY:7539327", "IKEY:6876043", "IKEY:6064952", "IKEY:7862917", "IKEY:7539323", "IKEY:5613487", "10.1145/1357054.1357096", "10.1145/258734.258887", "10.1145/344779.344964", "10.1145/3072959.3073688", "10.1145/800186.810616", "10.1145/2766908", "10.1145/1357054.1357096", "10.1145/258734.258887", "10.1145/344779.344964", "10.1145/3072959.3073688", "10.1145/800186.810616", "10.1145/2766908", "10.1145/1357054.1357096", "10.1145/258734.258887", "10.1145/344779.344964", "10.1145/3072959.3073688", "10.1145/800186.810616", "10.1145/2766908", "10.1111/j.1467-8659.2011.01940.x", "10.1063/1.2336492", "10.1006/jcph.1998.6029", "10.1111/j.1467-8659.2009.01475.x", "10.1111/j.1467-8659.2011.01958.x", "10.1111/j.1467-8659.2009.01684.x", "10.1111/cgf.12396", "10.1137/1.9780898717921", "10.1111/j.1467-8659.2011.01940.x", "10.1063/1.2336492", "10.1006/jcph.1998.6029", "10.1111/j.1467-8659.2009.01475.x", "10.1111/j.1467-8659.2011.01958.x", "10.1111/j.1467-8659.2009.01684.x", "10.1111/cgf.12396", "10.1137/1.9780898717921", "10.1111/j.1467-8659.2011.01940.x", "10.1063/1.2336492", "10.1006/jcph.1998.6029", "10.1111/j.1467-8659.2009.01475.x", "10.1111/j.1467-8659.2011.01958.x", "10.1111/j.1467-8659.2009.01684.x", "10.1111/cgf.12396", "10.1137/1.9780898717921"]}, "10.1109/TVCG.2018.2864477": {"doi": "10.1109/TVCG.2018.2864477", "author": ["M. Cavallo", "\u00c7. Demiralp"], "title": "Clustrophile 2: Guided Visual Clustering Analysis", "year": "2019", "abstract": "Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce Clustrophile 2, a new interactive tool for guided clustering analysis. Clustrophile 2 guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, Clustrophile 2 contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate Clustrophile 2 through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson's disease patients. Results suggest that Clustrophile 2 improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.", "keywords": ["data analysis", "data visualisation", "diseases", "pattern clustering", "statistical analysis", "unsupervised learning", "clustering parameters", "data features", "user judgment", "clustering-based exploratory analysis", "user feedback", "user guidance", "user expectations", "guided visual clustering analysis", "data clustering", "high-dimensional data analysis", "interactive tools", "data scientists", "unsupervised learning method", "clustering tour", "clustrophile", "optimal solution", "iterative experimentation", "ground-truth labels", "Parkinson's disease patients dataset", "Tools", "Data visualization", "Visualization", "Clustering algorithms", "Data analysis", "Space exploration", "Dimensionality reduction", "Clustering tour", "Guided data analysis", "Exploratory data analysis", "Interactive clustering analysis", "Interpretability", "Explainability", "Visual data exploration recommendation", "Dimensionality reduction", "What-if analysis", "Clustrophile", "Unsupervised learning"], "referenced_by": ["IKEY:8836087", "IKEY:8827593", "IKEY:8933618", "IKEY:9064929", "IKEY:9260004"], "referencing": ["IKEY:6065026", "IKEY:1672644", "IKEY:6634182", "IKEY:6327298", "IKEY:8019866", "IKEY:5613440", "IKEY:5694060", "IKEY:6327256", "IKEY:8019867", "IKEY:868688", "IKEY:7192728", "IKEY:6065026", "IKEY:1672644", "IKEY:6634182", "IKEY:6327298", "IKEY:8019866", "IKEY:5613440", "IKEY:5694060", "IKEY:6327256", "IKEY:8019867", "IKEY:868688", "IKEY:7192728", "IKEY:6065026", "IKEY:1672644", "IKEY:6634182", "IKEY:6327298", "IKEY:8019866", "IKEY:5613440", "IKEY:5694060", "IKEY:6327256", "IKEY:8019867", "IKEY:868688", "IKEY:7192728", "10.1145/276304.276312", "10.1145/3025453.3025866", "10.1145/235968.233324", "10.1145/276304.276312", "10.1145/3025453.3025866", "10.1145/235968.233324", "10.1145/276304.276312", "10.1145/3025453.3025866", "10.1145/235968.233324", "10.1137/0906011", "10.1201/9781315139470", "10.1016/j.neucom.2014.09.062", "10.14778/3137765.3137813", "10.1023/A:1012487302797", "10.1007/BF02289565", "10.1111/j.1467-8659.2012.03110.x", "10.1186/1471-2105-16-S11-S5", "10.1101/cshperspect.a009282", "10.1093/nar/gkv468", "10.1016/0377-0427(87)90125-7", "10.1126/science.290.5500.2323", "10.1057/ivs.2008.29", "10.1186/1471-2105-15-S6-S4", "10.1126/science.290.5500.2319", "10.1111/1467-9868.00196", "10.1007/BF02288916", "10.14778/2831360.2831371", "10.1057/ivs.2008.27", "10.1117/12.810093", "10.1137/0906011", "10.1201/9781315139470", "10.1016/j.neucom.2014.09.062", "10.14778/3137765.3137813", "10.1023/A:1012487302797", "10.1007/BF02289565", "10.1111/j.1467-8659.2012.03110.x", "10.1186/1471-2105-16-S11-S5", "10.1101/cshperspect.a009282", "10.1093/nar/gkv468", "10.1016/0377-0427(87)90125-7", "10.1126/science.290.5500.2323", "10.1057/ivs.2008.29", "10.1186/1471-2105-15-S6-S4", "10.1126/science.290.5500.2319", "10.1111/1467-9868.00196", "10.1007/BF02288916", "10.14778/2831360.2831371", "10.1057/ivs.2008.27", "10.1117/12.810093", "10.1137/0906011", "10.1201/9781315139470", "10.1016/j.neucom.2014.09.062", "10.14778/3137765.3137813", "10.1023/A:1012487302797", "10.1007/BF02289565", "10.1111/j.1467-8659.2012.03110.x", "10.1186/1471-2105-16-S11-S5", "10.1101/cshperspect.a009282", "10.1093/nar/gkv468", "10.1016/0377-0427(87)90125-7", "10.1126/science.290.5500.2323", "10.1057/ivs.2008.29", "10.1186/1471-2105-15-S6-S4", "10.1126/science.290.5500.2319", "10.1111/1467-9868.00196", "10.1007/BF02288916", "10.14778/2831360.2831371", "10.1057/ivs.2008.27", "10.1117/12.810093"]}, "10.1109/TVCG.2018.2864887": {"doi": "10.1109/TVCG.2018.2864887", "author": ["Z. Lu", "M. Fan", "Y. Wang", "J. Zhao", "M. Annett", "D. Wigdor"], "title": "InkPlanner: Supporting Prewriting via Intelligent Visual Diagramming", "year": "2019", "abstract": "Prewriting is the process of generating and organizing ideas before drafting a document. Although often overlooked by novice writers and writing tool developers, prewriting is a critical process that improves the quality of a final document. To better understand current prewriting practices, we first conducted interviews with writing learners and experts. Based on the learners' needs and experts' recommendations, we then designed and developed InkPlanner, a novel pen and touch visualization tool that allows writers to utilize visual diagramming for ideation during prewriting. InkPlanner further allows writers to sort their ideas into a logical and sequential narrative by using a novel widget- NarrativeLine. Using a NarrativeLine, InkPlanner can automatically generate a document outline to guide later drafting exercises. Inkplanner is powered by machine-generated semantic and structural suggestions that are curated from various texts. To qualitatively review the tool and understand how writers use InkPlanner for prewriting, two writing experts were interviewed and a user study was conducted with university students. The results demonstrated that InkPlanner encouraged writers to generate more diverse ideas and also enabled them to think more strategically about how to organize their ideas for later drafting.", "keywords": ["computer aided instruction", "data visualisation", "educational institutions", "intelligent visual diagramming", "writing tool developers", "writing learners", "touch visualization tool", "document outline", "writing experts", "InkPlanner", "prewriting", "pen visualization tool", "recommendations", "logical narrative", "sequential narrative", "widget-NarrativeLine", "drafting", "machine-generated semantic suggestions", "structural suggestions", "university students", "Writing", "Data visualization", "Computer aided instruction", "Educational institutions", "Writing", "prewriting", "diagraming", "content and structure recommendation", "pen and touch interfaces"], "referenced_by": ["IKEY:8440040", "IKEY:8805421", "10.1007/s12650-020-00705-3"], "referencing": ["IKEY:6165258", "IKEY:5194339", "IKEY:7265356", "IKEY:4561736", "IKEY:6165258", "IKEY:5194339", "IKEY:7265356", "IKEY:4561736", "IKEY:6165258", "IKEY:5194339", "IKEY:7265356", "IKEY:4561736", "10.1145/1378773.1378814", "10.1145/2362456.2362494", "10.1145/2494188.2494216", "10.1145/2851581.2892384", "10.1145/2207676.2208548", "10.1145/2047196.2047245", "10.1145/1866029.1866036", "10.1145/1240624.1240666", "10.1145/354401.354412", "10.1145/2807442.2807455", "10.1145/2702123.2702383", "10.1145/2998181.2998208", "10.1145/2631925", "10.1145/800265.810742", "10.1145/1866029.1866035", "10.1145/1378773.1378814", "10.1145/2362456.2362494", "10.1145/2494188.2494216", "10.1145/2851581.2892384", "10.1145/2207676.2208548", "10.1145/2047196.2047245", "10.1145/1866029.1866036", "10.1145/1240624.1240666", "10.1145/354401.354412", "10.1145/2807442.2807455", "10.1145/2702123.2702383", "10.1145/2998181.2998208", "10.1145/2631925", "10.1145/800265.810742", "10.1145/1866029.1866035", "10.1145/1378773.1378814", "10.1145/2362456.2362494", "10.1145/2494188.2494216", "10.1145/2851581.2892384", "10.1145/2207676.2208548", "10.1145/2047196.2047245", "10.1145/1866029.1866036", "10.1145/1240624.1240666", "10.1145/354401.354412", "10.1145/2807442.2807455", "10.1145/2702123.2702383", "10.1145/2998181.2998208", "10.1145/2631925", "10.1145/800265.810742", "10.1145/1866029.1866035", "10.2307/819337", "10.4135/9781452230153", "10.1007/s10734-010-9387-6", "10.1016/j.tsc.2009.05.001", "10.2307/356095", "10.1057/palgrave.ivs.9500131", "10.2307/356600", "10.1080/00222895.1987.10735426", "10.1561/1100000013", "10.2307/1423213", "10.3115/v1/P14-2050", "10.1016/S8755-4615(04)00040-4", "10.3102/00028312028001117", "10.4018/jcini.2013010101", "10.2307/354885", "10.2307/819337", "10.4135/9781452230153", "10.1007/s10734-010-9387-6", "10.1016/j.tsc.2009.05.001", "10.2307/356095", "10.1057/palgrave.ivs.9500131", "10.2307/356600", "10.1080/00222895.1987.10735426", "10.1561/1100000013", "10.2307/1423213", "10.3115/v1/P14-2050", "10.1016/S8755-4615(04)00040-4", "10.3102/00028312028001117", "10.4018/jcini.2013010101", "10.2307/354885", "10.2307/819337", "10.4135/9781452230153", "10.1007/s10734-010-9387-6", "10.1016/j.tsc.2009.05.001", "10.2307/356095", "10.1057/palgrave.ivs.9500131", "10.2307/356600", "10.1080/00222895.1987.10735426", "10.1561/1100000013", "10.2307/1423213", "10.3115/v1/P14-2050", "10.1016/S8755-4615(04)00040-4", "10.3102/00028312028001117", "10.4018/jcini.2013010101", "10.2307/354885"]}, "10.1109/TVCG.2018.2864504": {"doi": "10.1109/TVCG.2018.2864504", "author": ["J. Wang", "L. Gou", "H. Shen", "H. Yang"], "title": "DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks", "year": "2019", "abstract": "Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent's experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models.", "keywords": ["computer games", "data visualisation", "learning (artificial intelligence)", "neural nets", "DQNViz", "deep Q-Network", "deep reinforcement learning model", "intelligent agent", "optimal actions", "professional human players", "superhuman performance", "sophisticated behaviors", "DQN agent", "visual analytics system", "blind training process", "experience space", "DQN models", "Atari games", "deep learning experts", "breakout game", "reward patterns", "action space", "model training process", "Training", "Games", "Visual analytics", "Data visualization", "Analytical models", "Learning (artificial intelligence)", "Machine learning", "Deep Q-Network (DQN)", "reinforcement learning", "model interpretation", "visual analytics"], "referenced_by": ["IKEY:8667661", "IKEY:8805439", "IKEY:8805421", "IKEY:8827593", "IKEY:8807299", "IKEY:8812988", "IKEY:8820172", "IKEY:8933677", "IKEY:9006128", "IKEY:9086289", "IKEY:9086290", "IKEY:9308631"], "referencing": ["IKEY:8103164", "IKEY:8103164", "IKEY:7042500", "IKEY:8017618", "IKEY:8402187", "IKEY:6875996", "IKEY:8017612", "IKEY:8022871", "IKEY:6065010", "IKEY:8019879", "IKEY:7536654", "IKEY:6634100", "IKEY:8019872", "IKEY:882407", "IKEY:8017583", "IKEY:8320546", "IKEY:8103164", "IKEY:8103164", "IKEY:7042500", "IKEY:8017618", "IKEY:8402187", "IKEY:6875996", "IKEY:8017612", "IKEY:8022871", "IKEY:6065010", "IKEY:8019879", "IKEY:7536654", "IKEY:6634100", "IKEY:8019872", "IKEY:882407", "IKEY:8017583", "IKEY:8320546", "IKEY:8103164", "IKEY:8103164", "IKEY:7042500", "IKEY:8017618", "IKEY:8402187", "IKEY:6875996", "IKEY:8017612", "IKEY:8022871", "IKEY:6065010", "IKEY:8019879", "IKEY:7536654", "IKEY:6634100", "IKEY:8019872", "IKEY:882407", "IKEY:8017583", "IKEY:8320546", "10.1145/238386.238493", "10.1145/363347.363387", "10.1145/1978942.1979196", "10.1145/2858036.2858488", "10.1145/2702123.2702419", "10.1145/238386.238493", "10.1145/363347.363387", "10.1145/1978942.1979196", "10.1145/2858036.2858488", "10.1145/2702123.2702419", "10.1145/238386.238493", "10.1145/363347.363387", "10.1145/1978942.1979196", "10.1145/2858036.2858488", "10.1145/2702123.2702419", "10.1016/j.neucom.2006.11.018", "10.1613/jair.3912", "10.1007/978-3-540-68677-4", "10.1137/S0363012901385691", "10.1016/j.visinf.2017.01.006", "10.18653/v1/D15-1166", "10.1038/nature14236", "10.1186/s13634-016-0355-x", "10.3233/IDA-2007-11508", "10.1038/nature16961", "10.1007/BF00992698", "10.1016/j.neucom.2006.11.018", "10.1613/jair.3912", "10.1007/978-3-540-68677-4", "10.1137/S0363012901385691", "10.1016/j.visinf.2017.01.006", "10.18653/v1/D15-1166", "10.1038/nature14236", "10.1186/s13634-016-0355-x", "10.3233/IDA-2007-11508", "10.1038/nature16961", "10.1007/BF00992698", "10.1016/j.neucom.2006.11.018", "10.1613/jair.3912", "10.1007/978-3-540-68677-4", "10.1137/S0363012901385691", "10.1016/j.visinf.2017.01.006", "10.18653/v1/D15-1166", "10.1038/nature14236", "10.1186/s13634-016-0355-x", "10.3233/IDA-2007-11508", "10.1038/nature16961", "10.1007/BF00992698"]}, "10.1109/TVCG.2018.2865027": {"doi": "10.1109/TVCG.2018.2865027", "author": ["B. C. Kwon", "M. Choi", "J. T. Kim", "E. Choi", "Y. B. Kim", "S. Kwon", "J. Sun", "J. Choo"], "title": "RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records", "year": "2019", "abstract": "We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.", "keywords": ["artificial intelligence", "data analysis", "data visualisation", "interactive systems", "medical information systems", "recurrent neural nets", "interactive RNN-based model", "EMR data", "prediction tasks", "RetainVis", "individual medical codes", "risk predictions", "temporal information", "increase interactivity", "interpretable analytics tool", "interpretable networks", "interactive recurrent neural networks", "electronic medical records", "black-box nature", "interactively leverage users", "design study", "visual analytics solution", "medical experts", "artificial intelligence scientists", "iterative design process", "newly improved RNN-based model", "RNN-based model", "visual analytic researchers", "interactive visual analytic tool", "Machine learning", "Medical diagnostic imaging", "Task analysis", "Predictive models", "Computational modeling", "Visual analytics", "Data models", "Interactive Artificial Intelligence", "XAI (Explainable Artificial Intelligence)", "Interpretable Deep Learning", "Healthcare"], "referenced_by": ["IKEY:8695354", "IKEY:8667702", "IKEY:8805457", "IKEY:8827944", "IKEY:8812988", "IKEY:8933677", "IKEY:8970777", "IKEY:9086238", "IKEY:9196460", "IKEY:9308631"], "referencing": ["10.1145/3097983.3097997", "10.1145/2783258.2783365", "10.1145/2939672.2939823", "10.1145/3097983.3098126", "10.1145/2939502.2939515", "10.1145/3027063.3053103", "10.1145/3097983.3098088", "10.1145/2939672.2939778", "10.1145/3097983.3097997", "10.1145/2783258.2783365", "10.1145/2939672.2939823", "10.1145/3097983.3098126", "10.1145/2939502.2939515", "10.1145/3027063.3053103", "10.1145/3097983.3098088", "10.1145/2939672.2939778", "10.1145/3097983.3097997", "10.1145/2783258.2783365", "10.1145/2939672.2939823", "10.1145/3097983.3098126", "10.1145/2939502.2939515", "10.1145/3027063.3053103", "10.1145/3097983.3098088", "10.1145/2939672.2939778", "10.1371/journal.pone.0177544", "10.1161/01.STR.17.4.648", "10.1016/j.imr.2017.07.002", "10.1016/S0002-8703(96)90537-2", "10.3115/v1/D14-1179", "10.1016/j.dsx.2013.08.003", "10.1007/s10618-014-0384-8", "10.1016/j.ahj.2004.03.010", "10.1016/S1071-9164(97)90013-0", "10.1016/j.ancard.2004.03.003", "10.18653/v1/P17-1106", "10.1214/aos/1013203451", "10.1038/s41598-017-04075-z", "10.1016/j.media.2016.05.004", "10.1016/j.media.2016.10.004", "10.1056/NEJM197210192871601", "10.1056/NEJMoa020245", "10.4178/epih/e2014008", "10.4332/KJHPA.2013.23.2.152", "10.1161/CIRCULATIONAHA.106.678326", "10.1111/j.1467-8659.2012.03108.x", "10.1016/j.ijhcs.2017.03.007", "10.1111/j.1467-8659.2010.01835.x", "10.1001/jama.1996.03530440037034", "10.18653/v1/D15-1166", "10.1016/j.ejcts.2003.11.038", "10.1016/j.neucom.2017.01.105", "10.1515/9781400881970-018", "10.1161/01.HYP.16.6.692", "10.1186/1471-2466-10-22", "10.4292/wjgpt.v5.i3.183", "10.1016/j.neunet.2017.09.007", "10.21437/Interspeech.2016-134", "10.1016/j.patrec.2016.09.014", "10.1007/978-3-319-46478-7_28", "10.1371/journal.pone.0177544", "10.1161/01.STR.17.4.648", "10.1016/j.imr.2017.07.002", "10.1016/S0002-8703(96)90537-2", "10.3115/v1/D14-1179", "10.1016/j.dsx.2013.08.003", "10.1007/s10618-014-0384-8", "10.1016/j.ahj.2004.03.010", "10.1016/S1071-9164(97)90013-0", "10.1016/j.ancard.2004.03.003", "10.18653/v1/P17-1106", "10.1214/aos/1013203451", "10.1038/s41598-017-04075-z", "10.1016/j.media.2016.05.004", "10.1016/j.media.2016.10.004", "10.1056/NEJM197210192871601", "10.1056/NEJMoa020245", "10.4178/epih/e2014008", "10.4332/KJHPA.2013.23.2.152", "10.1161/CIRCULATIONAHA.106.678326", "10.1111/j.1467-8659.2012.03108.x", "10.1016/j.ijhcs.2017.03.007", "10.1111/j.1467-8659.2010.01835.x", "10.1001/jama.1996.03530440037034", "10.18653/v1/D15-1166", "10.1016/j.ejcts.2003.11.038", "10.1016/j.neucom.2017.01.105", "10.1515/9781400881970-018", "10.1161/01.HYP.16.6.692", "10.1186/1471-2466-10-22", "10.4292/wjgpt.v5.i3.183", "10.1016/j.neunet.2017.09.007", "10.21437/Interspeech.2016-134", "10.1016/j.patrec.2016.09.014", "10.1007/978-3-319-46478-7_28", "10.1371/journal.pone.0177544", "10.1161/01.STR.17.4.648", "10.1016/j.imr.2017.07.002", "10.1016/S0002-8703(96)90537-2", "10.3115/v1/D14-1179", "10.1016/j.dsx.2013.08.003", "10.1007/s10618-014-0384-8", "10.1016/j.ahj.2004.03.010", "10.1016/S1071-9164(97)90013-0", "10.1016/j.ancard.2004.03.003", "10.18653/v1/P17-1106", "10.1214/aos/1013203451", "10.1038/s41598-017-04075-z", "10.1016/j.media.2016.05.004", "10.1016/j.media.2016.10.004", "10.1056/NEJM197210192871601", "10.1056/NEJMoa020245", "10.4178/epih/e2014008", "10.4332/KJHPA.2013.23.2.152", "10.1161/CIRCULATIONAHA.106.678326", "10.1111/j.1467-8659.2012.03108.x", "10.1016/j.ijhcs.2017.03.007", "10.1111/j.1467-8659.2010.01835.x", "10.1001/jama.1996.03530440037034", "10.18653/v1/D15-1166", "10.1016/j.ejcts.2003.11.038", "10.1016/j.neucom.2017.01.105", "10.1515/9781400881970-018", "10.1161/01.HYP.16.6.692", "10.1186/1471-2466-10-22", "10.4292/wjgpt.v5.i3.183", "10.1016/j.neunet.2017.09.007", "10.21437/Interspeech.2016-134", "10.1016/j.patrec.2016.09.014", "10.1007/978-3-319-46478-7_28"]}, "10.1109/TVCG.2018.2864500": {"doi": "10.1109/TVCG.2018.2864500", "author": ["M. Kahng", "N. Thorat", "D. H. Chau", "F. B. Vi\u00e9gas", "M. Wattenberg"], "title": "GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation", "year": "2019", "abstract": "Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process's intermediate results. GAN Lab tightly integrates an model overview graph that summarizes GAN's structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as step-by-step training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning.", "keywords": ["data visualisation", "interactive systems", "learning (artificial intelligence)", "network theory (graphs)", "online front-ends", "GAN Lab", "interactive visual experimentation", "interactive visualization tool", "complex deep learning models", "GAN structure", "Web browsers", "generative adversarial networks", "TensorFlow", "complex deep generative models", "Gallium nitride", "Machine learning", "Tools", "Generative adversarial networks", "Generators", "Training", "Data visualization", "Deep learning", "information visualization", "visual analytics", "generative adversarial networks", "machine learning", "interactive experimentation", "explorable explanations"], "referenced_by": ["IKEY:8877387", "IKEY:8805421", "IKEY:8827593", "IKEY:8812988", "IKEY:8807294", "IKEY:8933677", "IKEY:9196460", "IKEY:9308631"], "referencing": ["IKEY:4658159", "IKEY:8017618", "IKEY:8253599", "IKEY:8022871", "IKEY:61115", "IKEY:8019879", "IKEY:7536654", "IKEY:7784854", "IKEY:8237566", "IKEY:8019872", "IKEY:8017583", "IKEY:7298935", "IKEY:8320546", "IKEY:8019861", "IKEY:4658159", "IKEY:8017618", "IKEY:8253599", "IKEY:8022871", "IKEY:61115", "IKEY:8019879", "IKEY:7536654", "IKEY:7784854", "IKEY:8237566", "IKEY:8019872", "IKEY:8017583", "IKEY:7298935", "IKEY:8320546", "IKEY:8019861", "IKEY:4658159", "IKEY:8017618", "IKEY:8253599", "IKEY:8022871", "IKEY:61115", "IKEY:8019879", "IKEY:7536654", "IKEY:7784854", "IKEY:8237566", "IKEY:8019872", "IKEY:8017583", "IKEY:7298935", "IKEY:8320546", "IKEY:8019861", "10.1145/1067445.1067495", "10.1145/2445196.2445368", "10.1145/971300.971432", "10.1145/1227504.1227384", "10.1145/1821996.1821997", "10.1145/1067445.1067495", "10.1145/2445196.2445368", "10.1145/971300.971432", "10.1145/1227504.1227384", "10.1145/1821996.1821997", "10.1145/1067445.1067495", "10.1145/2445196.2445368", "10.1145/971300.971432", "10.1145/1227504.1227384", "10.1145/1821996.1821997", "10.23915/distill.00009", "10.23915/distill.00006", "10.1007/978-3-319-27857-5_77", "10.1016/j.jvlc.2006.03.002", "10.1006/jvlc.2002.0237", "10.1016/j.visinf.2017.01.006", "10.23915/distill.00005", "10.23915/distill.00002", "10.23915/distill.00009", "10.23915/distill.00006", "10.1007/978-3-319-27857-5_77", "10.1016/j.jvlc.2006.03.002", "10.1006/jvlc.2002.0237", "10.1016/j.visinf.2017.01.006", "10.23915/distill.00005", "10.23915/distill.00002", "10.23915/distill.00009", "10.23915/distill.00006", "10.1007/978-3-319-27857-5_77", "10.1016/j.jvlc.2006.03.002", "10.1006/jvlc.2002.0237", "10.1016/j.visinf.2017.01.006", "10.23915/distill.00005", "10.23915/distill.00002"]}, "10.1109/TVCG.2018.2864826": {"doi": "10.1109/TVCG.2018.2864826", "author": ["G. Y. Chan", "P. Xu", "Z. Dai", "L. Ren"], "title": "ViBr: Visualizing Bipartite Relations at Scale with the Minimum Description Length Principle", "year": "2019", "abstract": "Bipartite graphs model the key relations in many large scale real-world data: customers purchasing items, legislators voting for bills, people's affiliation with different social groups, faults occurring in vehicles, etc. However, it is challenging to visualize large scale bipartite graphs with tens of thousands or even more nodes or edges. In this paper, we propose a novel visual summarization technique for bipartite graphs based on the minimum description length (MDL) principle. The method simultaneously groups the two different set of nodes and constructs aggregated bipartite relations with balanced granularity and precision. It addresses the key trade-off that often occurs for visualizing large scale and noisy data: acquiring a clear and uncluttered overview while maximizing the information content in it. We formulate the visual summarization task as a co-clustering problem and propose an efficient algorithm based on locality sensitive hashing (LSH) that can easily scale to large graphs under reasonable interactive time constraints that previous related methods cannot satisfy. The method leads to the opportunity of introducing a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. In the framework, we also introduce a compact visual design inspired by adjacency list representation of graphs as the building block for a small multiples display to compare the bipartite relations for different subsets of data. We showcase the applicability and effectiveness of our approach by applying it on synthetic data with ground truth and performing case studies on real-world datasets from two application domains including roll-call vote record analysis and vehicle fault pattern analysis. Interviews with experts in the political science community and the automotive industry further highlight the benefits of our approach.", "keywords": ["data analysis", "data visualisation", "graph theory", "pattern clustering", "minimum description length principle", "bipartite graphs model", "balanced granularity", "visual analytics framework", "interactive data exploration", "synthetic data", "roll-call vote record analysis", "vehicle fault pattern analysis", "social groups", "visual design", "visual summarization technique", "people affiliation", "ViBr", "interactive time constraints", "bipartite relation visualization", "legislators voting", "MDL", "co-clustering problem", "locality sensitive hashing", "LSH", "political science community", "automotive industry", "customer purchasing items", "Data visualization", "Bipartite graph", "Visualization", "Clustering algorithms", "Complexity theory", "Data models", "Noise measurement", "Bipartite Graph", "Visual Summarization", "Minimum Description Length", "Information Theory"], "referenced_by": ["IKEY:8533894", "IKEY:8836662", "IKEY:8805439", "IKEY:8807233"], "referencing": ["IKEY:5613456", "IKEY:6327277", "IKEY:6583179", "IKEY:6634091", "IKEY:1382886", "IKEY:754967", "IKEY:6812198", "IKEY:8147308", "IKEY:7536654", "IKEY:6004018", "IKEY:5290695", "IKEY:7422136", "IKEY:6875988", "IKEY:1703364", "IKEY:4015424", "IKEY:7192715", "IKEY:6875974", "IKEY:7536174", "IKEY:7465248", "IKEY:1401887", "IKEY:5613456", "IKEY:6327277", "IKEY:6583179", "IKEY:6634091", "IKEY:1382886", "IKEY:754967", "IKEY:6812198", "IKEY:8147308", "IKEY:7536654", "IKEY:6004018", "IKEY:5290695", "IKEY:7422136", "IKEY:6875988", "IKEY:1703364", "IKEY:4015424", "IKEY:7192715", "IKEY:6875974", "IKEY:7536174", "IKEY:7465248", "IKEY:1401887", "IKEY:5613456", "IKEY:6327277", "IKEY:6583179", "IKEY:6634091", "IKEY:1382886", "IKEY:754967", "IKEY:6812198", "IKEY:8147308", "IKEY:7536654", "IKEY:6004018", "IKEY:5290695", "IKEY:7422136", "IKEY:6875988", "IKEY:1703364", "IKEY:4015424", "IKEY:7192715", "IKEY:6875974", "IKEY:7536174", "IKEY:7465248", "IKEY:1401887", "10.1145/1014052.1014064", "10.1145/3035918.3058741", "10.1145/2882903.2915245", "10.1145/502512.502550", "10.1145/2339530.2339725", "10.1145/1376616.1376661", "10.1145/2556288.2557337", "10.1145/2702123.2702419", "10.1145/1014052.1014064", "10.1145/3035918.3058741", "10.1145/2882903.2915245", "10.1145/502512.502550", "10.1145/2339530.2339725", "10.1145/1376616.1376661", "10.1145/2556288.2557337", "10.1145/2702123.2702419", "10.1145/1014052.1014064", "10.1145/3035918.3058741", "10.1145/2882903.2915245", "10.1145/502512.502550", "10.1145/2339530.2339725", "10.1145/1376616.1376661", "10.1145/2556288.2557337", "10.1145/2702123.2702419", "10.3162/036298008786403079", "10.1179/000870403235002042", "10.1017/CBO9780511763113", "10.1101/gr.648603", "10.1017/CBO9781139924801", "10.1007/s00371-013-0892-3", "10.1016/0005-1098(78)90005-5", "10.1057/palgrave.ivs.9500086", "10.1057/palgrave.ivs.9500180", "10.1186/1471-2105-15-S6-S4", "10.1007/978-3-540-30214-8_2", "10.3162/036298008786403079", "10.1179/000870403235002042", "10.1017/CBO9780511763113", "10.1101/gr.648603", "10.1017/CBO9781139924801", "10.1007/s00371-013-0892-3", "10.1016/0005-1098(78)90005-5", "10.1057/palgrave.ivs.9500086", "10.1057/palgrave.ivs.9500180", "10.1186/1471-2105-15-S6-S4", "10.1007/978-3-540-30214-8_2", "10.3162/036298008786403079", "10.1179/000870403235002042", "10.1017/CBO9780511763113", "10.1101/gr.648603", "10.1017/CBO9781139924801", "10.1007/s00371-013-0892-3", "10.1016/0005-1098(78)90005-5", "10.1057/palgrave.ivs.9500086", "10.1057/palgrave.ivs.9500180", "10.1186/1471-2105-15-S6-S4", "10.1007/978-3-540-30214-8_2"]}, "10.1109/TVCG.2018.2864844": {"doi": "10.1109/TVCG.2018.2864844", "author": ["H. Wang", "Y. Lu", "S. T. Shutters", "M. Steptoe", "F. Wang", "S. Landis", "R. Maciejewski"], "title": "A Visual Analytics Framework for Spatiotemporal Trade Network Analysis", "year": "2019", "abstract": "Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade.", "keywords": ["data analysis", "data visualisation", "economics", "financial data processing", "globalisation", "international trade", "time series", "regional instability measures", "international global trade", "visual analytics framework", "spatiotemporal trade network analysis", "economic globalization", "supply chains", "supply shocks", "network-induced vulnerability", "political science", "environmental studies", "global trade networks", "multivariate nature", "spatiotemporal nature", "network structure", "exploratory data analysis", "multiview framework", "network analytics", "spatiotemporal visualization methods", "visual encoding techniques", "trade goods", "Data visualization", "Visual analytics", "Correlation", "Anomaly detection", "Time series analysis", "Spatiotemporal phenomena", "Global trade network", "anomaly detection", "visual analytics"], "referenced_by": ["IKEY:8805439"], "referencing": ["10.1145/1541880.1541882", "10.1145/245882.245901", "10.1145/1809400.1809403", "10.1145/1541880.1541882", "10.1145/245882.245901", "10.1145/1809400.1809403", "10.1145/1541880.1541882", "10.1145/245882.245901", "10.1145/1809400.1809403", "10.1080/14697688.2014.968356", "10.1016/j.physa.2011.02.004", "10.1111/cgf.12791", "10.1111/j.1467-8659.2011.01946.x", "10.1007/978-3-642-25591-5_27", "10.1037/h0046049", "10.1073/pnas.1203176109", "10.1111/j.1467-9701.2011.01360.x", "10.1073/pnas.1109521108", "10.1371/journal.pone.0097331", "10.1007/s00191-009-0160-x", "10.1111/j.1467-9531.2007.00179.x", "10.1103/PhysRevLett.93.188701", "10.1016/j.physa.2005.02.075", "10.1140/epjb/e2007-00131-6", "10.2307/270703", "10.1111/j.1467-8659.2009.01450.x", "10.1038/nature10311", "10.1080/00224065.1986.11979014", "10.1142/9789812777638_0001", "10.1098/rsif.2009.0495", "10.1098/rsif.2009.0495", "10.1016/j.gloenvcha.2013.09.008", "10.1017/S1876404511200046", "10.1029/2010WR010307", "10.1007/BF01063907", "10.1371/journal.pone.0088666", "10.1093/biosci/biu225", "10.1007/3-540-44590-0_37", "10.1002/(SICI)1099-131X(199705)16:3&lt;147::AID-FOR652&gt;3.0.CO;2-X", "10.1126/science.1089167", "10.1016/j.compenvurbsys.2009.01.007", "10.1177/0022343310378914", "10.2139/ssrn.922059", "10.1080/13658816.2013.868466", "10.1371/journal.pone.0098247", "10.1371/journal.pone.0039756", "10.1126/science.1216556", "10.1029/2011GL046837", "10.1016/j.socnet.2010.06.001", "10.1559/152304087783875273", "10.1017/CBO9780511815478", "10.1371/journal.pone.0040337", "10.1179/000870410X12658023467367", "10.1016/j.ssresearch.2013.06.003", "10.1080/14697688.2014.968356", "10.1016/j.physa.2011.02.004", "10.1111/cgf.12791", "10.1111/j.1467-8659.2011.01946.x", "10.1007/978-3-642-25591-5_27", "10.1037/h0046049", "10.1073/pnas.1203176109", "10.1111/j.1467-9701.2011.01360.x", "10.1073/pnas.1109521108", "10.1371/journal.pone.0097331", "10.1007/s00191-009-0160-x", "10.1111/j.1467-9531.2007.00179.x", "10.1103/PhysRevLett.93.188701", "10.1016/j.physa.2005.02.075", "10.1140/epjb/e2007-00131-6", "10.2307/270703", "10.1111/j.1467-8659.2009.01450.x", "10.1038/nature10311", "10.1080/00224065.1986.11979014", "10.1142/9789812777638_0001", "10.1098/rsif.2009.0495", "10.1098/rsif.2009.0495", "10.1016/j.gloenvcha.2013.09.008", "10.1017/S1876404511200046", "10.1029/2010WR010307", "10.1007/BF01063907", "10.1371/journal.pone.0088666", "10.1093/biosci/biu225", "10.1007/3-540-44590-0_37", "10.1002/(SICI)1099-131X(199705)16:3&lt;147::AID-FOR652&gt;3.0.CO;2-X", "10.1126/science.1089167", "10.1016/j.compenvurbsys.2009.01.007", "10.1177/0022343310378914", "10.2139/ssrn.922059", "10.1080/13658816.2013.868466", "10.1371/journal.pone.0098247", "10.1371/journal.pone.0039756", "10.1126/science.1216556", "10.1029/2011GL046837", "10.1016/j.socnet.2010.06.001", "10.1559/152304087783875273", "10.1017/CBO9780511815478", "10.1371/journal.pone.0040337", "10.1179/000870410X12658023467367", "10.1016/j.ssresearch.2013.06.003", "10.1080/14697688.2014.968356", "10.1016/j.physa.2011.02.004", "10.1111/cgf.12791", "10.1111/j.1467-8659.2011.01946.x", "10.1007/978-3-642-25591-5_27", "10.1037/h0046049", "10.1073/pnas.1203176109", "10.1111/j.1467-9701.2011.01360.x", "10.1073/pnas.1109521108", "10.1371/journal.pone.0097331", "10.1007/s00191-009-0160-x", "10.1111/j.1467-9531.2007.00179.x", "10.1103/PhysRevLett.93.188701", "10.1016/j.physa.2005.02.075", "10.1140/epjb/e2007-00131-6", "10.2307/270703", "10.1111/j.1467-8659.2009.01450.x", "10.1038/nature10311", "10.1080/00224065.1986.11979014", "10.1142/9789812777638_0001", "10.1098/rsif.2009.0495", "10.1098/rsif.2009.0495", "10.1016/j.gloenvcha.2013.09.008", "10.1017/S1876404511200046", "10.1029/2010WR010307", "10.1007/BF01063907", "10.1371/journal.pone.0088666", "10.1093/biosci/biu225", "10.1007/3-540-44590-0_37", "10.1002/(SICI)1099-131X(199705)16:3&lt;147::AID-FOR652&gt;3.0.CO;2-X", "10.1126/science.1089167", "10.1016/j.compenvurbsys.2009.01.007", "10.1177/0022343310378914", "10.2139/ssrn.922059", "10.1080/13658816.2013.868466", "10.1371/journal.pone.0098247", "10.1371/journal.pone.0039756", "10.1126/science.1216556", "10.1029/2011GL046837", "10.1016/j.socnet.2010.06.001", "10.1559/152304087783875273", "10.1017/CBO9780511815478", "10.1371/journal.pone.0040337", "10.1179/000870410X12658023467367", "10.1016/j.ssresearch.2013.06.003"]}, "10.1109/TVCG.2018.2864812": {"doi": "10.1109/TVCG.2018.2864812", "author": ["Y. Ming", "H. Qu", "E. Bertini"], "title": "RuleMatrix: Visualizing and Understanding Classifiers with Rules", "year": "2019", "abstract": "With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. Then, we design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.", "keywords": ["data visualisation", "interactive systems", "knowledge representation", "learning (artificial intelligence)", "matrix algebra", "pattern classification", "rule matrix", "black-box model", "matrix-based visualization", "standardized rule-based knowledge representation", "predictive models", "interactive visualization technique", "machine learning systems", "Machine learning", "Data visualization", "Visualization", "Neural networks", "Decision trees", "Data models", "Support vector machines", "explainable machine learning", "rule visualization", "visual analytics"], "referenced_by": ["IKEY:8858933", "IKEY:8805420", "IKEY:8805439", "IKEY:8812988", "IKEY:8807299", "IKEY:8820172", "IKEY:8920401", "IKEY:9086289", "IKEY:9086281", "IKEY:9064929", "IKEY:9262659", "IKEY:9308631"], "referencing": ["IKEY:6208380", "IKEY:8017618", "IKEY:8022871", "IKEY:7536654", "IKEY:4564457", "IKEY:8019872", "IKEY:7539329", "IKEY:7539404", "IKEY:6056510", "IKEY:8017583", "IKEY:6102453", "IKEY:8019861", "IKEY:6208380", "IKEY:8017618", "IKEY:8022871", "IKEY:7536654", "IKEY:4564457", "IKEY:8019872", "IKEY:7539329", "IKEY:7539404", "IKEY:6056510", "IKEY:8017583", "IKEY:6102453", "IKEY:8019861", "IKEY:6208380", "IKEY:8017618", "IKEY:8022871", "IKEY:7536654", "IKEY:4564457", "IKEY:8019872", "IKEY:7539329", "IKEY:7539404", "IKEY:6056510", "IKEY:8017583", "IKEY:6102453", "IKEY:8019861", "10.1145/3173574.3174156", "10.1145/2783258.2788613", "10.1145/2594473.2594475", "10.1145/335191.335372", "10.1145/3200489", "10.1145/2939672.2939778", "10.1145/3173574.3174156", "10.1145/2783258.2788613", "10.1145/2594473.2594475", "10.1145/335191.335372", "10.1145/3200489", "10.1145/2939672.2939778", "10.1145/3173574.3174156", "10.1145/2783258.2788613", "10.1145/2594473.2594475", "10.1145/335191.335372", "10.1145/3200489", "10.1145/2939672.2939778", "10.1016/0950-7051(96)81920-4", "10.1016/j.csda.2009.12.013", "10.1007/s10618-008-0089-y", "10.1609/aimag.v38i3.2741", "10.1016/j.dss.2010.12.003", "10.1214/15-AOAS848", "10.1016/j.visinf.2017.01.006", "10.1016/0005-1098(78)90005-5", "10.1007/BF00058680", "10.1016/j.neucom.2017.01.105", "10.1007/978-1-4899-3324-9", "10.1016/0169-023X(94)00020-4", "10.1016/0950-7051(96)81920-4", "10.1016/j.csda.2009.12.013", "10.1007/s10618-008-0089-y", "10.1609/aimag.v38i3.2741", "10.1016/j.dss.2010.12.003", "10.1214/15-AOAS848", "10.1016/j.visinf.2017.01.006", "10.1016/0005-1098(78)90005-5", "10.1007/BF00058680", "10.1016/j.neucom.2017.01.105", "10.1007/978-1-4899-3324-9", "10.1016/0169-023X(94)00020-4", "10.1016/0950-7051(96)81920-4", "10.1016/j.csda.2009.12.013", "10.1007/s10618-008-0089-y", "10.1609/aimag.v38i3.2741", "10.1016/j.dss.2010.12.003", "10.1214/15-AOAS848", "10.1016/j.visinf.2017.01.006", "10.1016/0005-1098(78)90005-5", "10.1007/BF00058680", "10.1016/j.neucom.2017.01.105", "10.1007/978-1-4899-3324-9", "10.1016/0169-023X(94)00020-4"]}, "10.1109/TVCG.2018.2865044": {"doi": "10.1109/TVCG.2018.2865044", "author": ["H. Strobelt", "S. Gehrmann", "M. Behrisch", "A. Perer", "H. Pfister", "A. M. Rush"], "title": "Seq2seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models", "year": "2019", "abstract": "Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and \u201cwhat if\u201d-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.", "keywords": ["data visualisation", "learning (artificial intelligence)", "neural nets", "program debugging", "sequences", "seq2seq-Vis", "source sequence", "target sequence", "visual debugging tool", "neural sequence-to-sequence models", "blackbox pipeline", "vector space", "deep learning methods", "visual analysis tool", "Analytical models", "Visualization", "Tools", "Predictive models", "Machine learning", "Data models", "Atmosphere", "Explainable AI", "Visual Debugging", "Visual Analytics", "Machine Learning", "Deep Learning", "NLP"], "referenced_by": ["IKEY:8440124", "IKEY:8667702", "IKEY:8805421", "IKEY:8827593", "IKEY:8805457", "IKEY:8827944", "IKEY:8805439", "IKEY:8812988", "IKEY:8807299", "IKEY:8933677", "IKEY:8933677", "IKEY:8933744", "IKEY:8970240", "IKEY:8986948", "IKEY:9014377", "IKEY:9086238", "IKEY:9196460", "IKEY:9308631"], "referencing": ["IKEY:8022871", "IKEY:726791", "IKEY:7298640", "IKEY:8023823", "IKEY:8017583", "IKEY:8022871", "IKEY:726791", "IKEY:7298640", "IKEY:8023823", "IKEY:8017583", "IKEY:8022871", "IKEY:726791", "IKEY:7298640", "IKEY:8023823", "IKEY:8017583", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.18653/v1/D17-1042", "10.1371/journal.pone.0130140", "10.18653/v1/P17-1106", "10.5334/jors.178", "10.18653/v1/P17-4012", "10.18653/v1/W17-3204", "10.1007/BF02289694", "10.18653/v1/D17-2021", "10.18653/v1/D16-1011", "10.18653/v1/N16-1082", "10.18653/v1/K16-1028", "10.23915/distill.00001", "10.23915/distill.00010", "10.24963/ijcai.2017/371", "10.18653/v1/P17-4004", "10.18653/v1/D15-1044", "10.18653/v1/P17-1099", "10.18653/v1/D17-1042", "10.1371/journal.pone.0130140", "10.18653/v1/P17-1106", "10.5334/jors.178", "10.18653/v1/P17-4012", "10.18653/v1/W17-3204", "10.1007/BF02289694", "10.18653/v1/D17-2021", "10.18653/v1/D16-1011", "10.18653/v1/N16-1082", "10.18653/v1/K16-1028", "10.23915/distill.00001", "10.23915/distill.00010", "10.24963/ijcai.2017/371", "10.18653/v1/P17-4004", "10.18653/v1/D15-1044", "10.18653/v1/P17-1099", "10.18653/v1/D17-1042", "10.1371/journal.pone.0130140", "10.18653/v1/P17-1106", "10.5334/jors.178", "10.18653/v1/P17-4012", "10.18653/v1/W17-3204", "10.1007/BF02289694", "10.18653/v1/D17-2021", "10.18653/v1/D16-1011", "10.18653/v1/N16-1082", "10.18653/v1/K16-1028", "10.23915/distill.00001", "10.23915/distill.00010", "10.24963/ijcai.2017/371", "10.18653/v1/P17-4004", "10.18653/v1/D15-1044", "10.18653/v1/P17-1099"]}, "10.1109/TVCG.2018.2864499": {"doi": "10.1109/TVCG.2018.2864499", "author": ["J. Zhang", "Y. Wang", "P. Molino", "L. Li", "D. S. Ebert"], "title": "Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models", "year": "2019", "abstract": "Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models' outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classification and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied.", "keywords": ["data analysis", "data visualisation", "iterative methods", "learning (artificial intelligence)", "neural nets", "regression analysis", "model-agnostic framework", "machine learning models", "visual analysis techniques", "internal logic", "specific model type", "model development", "diagnosis process", "potential machine learning", "regression tasks", "classification tasks", "feature discrimination", "customizable tabular view", "models outcome", "scatterplot-based visual summary", "refinement", "explanation", "inspection", "generic framework", "deep neural networks", "debugging", "interpretation", "manifold", "Visualization", "Analytical models", "Task analysis", "Machine learning", "Manifolds", "Data models", "Computational modeling", "Interactive machine learning", "performance analysis", "model comparison", "model debugging"], "referenced_by": ["IKEY:8667661", "IKEY:8735919", "IKEY:8805421", "IKEY:8805420", "IKEY:8805457", "IKEY:8805439", "IKEY:8807255", "IKEY:8812988", "IKEY:8807299", "IKEY:9086289", "IKEY:9086215", "IKEY:9086281", "IKEY:9308631"], "referencing": ["IKEY:6875957", "IKEY:7347637", "IKEY:6875982", "IKEY:6634167", "IKEY:6488679", "IKEY:8022871", "IKEY:5635185", "IKEY:8019879", "IKEY:8017582", "IKEY:6484064", "IKEY:6634169", "IKEY:6875995", "IKEY:5290695", "IKEY:6840370", "IKEY:7539329", "IKEY:7539404", "IKEY:981851", "IKEY:8017583", "IKEY:7539314", "IKEY:8019861", "IKEY:6875957", "IKEY:7347637", "IKEY:6875982", "IKEY:6634167", "IKEY:6488679", "IKEY:8022871", "IKEY:5635185", "IKEY:8019879", "IKEY:8017582", "IKEY:6484064", "IKEY:6634169", "IKEY:6875995", "IKEY:5290695", "IKEY:6840370", "IKEY:7539329", "IKEY:7539404", "IKEY:981851", "IKEY:8017583", "IKEY:7539314", "IKEY:8019861", "IKEY:6875957", "IKEY:7347637", "IKEY:6875982", "IKEY:6634167", "IKEY:6488679", "IKEY:8022871", "IKEY:5635185", "IKEY:8019879", "IKEY:8017582", "IKEY:6484064", "IKEY:6634169", "IKEY:6875995", "IKEY:5290695", "IKEY:6840370", "IKEY:7539329", "IKEY:7539404", "IKEY:981851", "IKEY:8017583", "IKEY:7539314", "IKEY:8019861", "10.1145/2702123.2702509", "10.1145/1753326.1753529", "10.1145/2858036.2858529", "10.1145/2678025.2701399", "10.1145/2939672.2939778", "10.1145/1518701.1518895", "10.1145/2702123.2702509", "10.1145/1753326.1753529", "10.1145/2858036.2858529", "10.1145/2678025.2701399", "10.1145/2939672.2939778", "10.1145/1518701.1518895", "10.1145/2702123.2702509", "10.1145/1753326.1753529", "10.1145/2858036.2858529", "10.1145/2678025.2701399", "10.1145/2939672.2939778", "10.1145/1518701.1518895", "10.1609/aimag.v35i4.2513", "10.1214/aoms/1177729694", "10.1038/nature14539", "10.1016/j.visinf.2017.01.006", "10.3115/v1/D14-1162", "10.1111/cgf.12389", "10.1609/aimag.v35i4.2513", "10.1214/aoms/1177729694", "10.1038/nature14539", "10.1016/j.visinf.2017.01.006", "10.3115/v1/D14-1162", "10.1111/cgf.12389", "10.1609/aimag.v35i4.2513", "10.1214/aoms/1177729694", "10.1038/nature14539", "10.1016/j.visinf.2017.01.006", "10.3115/v1/D14-1162", "10.1111/cgf.12389"]}, "10.1109/TVCG.2018.2864769": {"doi": "10.1109/TVCG.2018.2864769", "author": ["M. El-Assady", "F. Sperrle", "O. Deussen", "D. Keim", "C. Collins"], "title": "Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution", "year": "2019", "abstract": "To effectively assess the potential consequences of human interventions in model-driven analytics systems, we establish the concept of speculative execution as a visual analytics paradigm for creating user-steerable preview mechanisms. This paper presents an explainable, mixed-initiative topic modeling framework that integrates speculative execution into the algorithmic decision-making process. Our approach visualizes the model-space of our novel incremental hierarchical topic modeling algorithm, unveiling its inner-workings. We support the active incorporation of the user's domain knowledge in every step through explicit model manipulation interactions. In addition, users can initialize the model with expected topic seeds, the backbone priors. For a more targeted optimization, the modeling process automatically triggers a speculative execution of various optimization strategies, and requests feedback whenever the measured model quality deteriorates. Users compare the proposed optimizations to the current model state and preview their effect on the next model iterations, before applying one of them. This supervised human-in-the-Ioop process targets maximum improvement for minimum feedback and has proven to be effective in three independent studies that confirm topic model quality improvements.", "keywords": ["data analysis", "data visualisation", "decision making", "optimisation", "topic model optimization", "user-steerable speculative execution", "potential consequences", "human interventions", "model-driven analytics systems", "visual analytics paradigm", "user-steerable preview mechanisms", "mixed-initiative topic modeling framework", "algorithmic decision-making process", "model-space", "explicit model manipulation interactions", "expected topic seeds", "optimization strategies", "current model state", "model iterations", "human-in-the-Ioop process", "topic model quality improvements", "incremental hierarchical topic modeling algorithm", "users domain knowledge", "requests feedback", "minimum feedback", "Analytical models", "Visual analytics", "Optimization", "Clustering algorithms", "Computational modeling", "Task analysis", "User-Steerable Topic Modeling", "Speculative Execution", "Mixed-Initiative Visual Analytics", "Explainable Machine Learning"], "referenced_by": ["IKEY:8534018", "IKEY:8807224", "IKEY:8807299", "IKEY:8933646", "IKEY:8986922", "IKEY:8986917", "IKEY:9161563"], "referencing": ["IKEY:7042493", "IKEY:6102461", "IKEY:8019825", "IKEY:8017615", "IKEY:8017613", "IKEY:6634101", "IKEY:1324634", "IKEY:6634167", "IKEY:7539597", "IKEY:6875995", "IKEY:196114", "IKEY:6634179", "IKEY:7042493", "IKEY:6102461", "IKEY:8019825", "IKEY:8017615", "IKEY:8017613", "IKEY:6634101", "IKEY:1324634", "IKEY:6634167", "IKEY:7539597", "IKEY:6875995", "IKEY:196114", "IKEY:6634179", "IKEY:7042493", "IKEY:6102461", "IKEY:8019825", "IKEY:8017615", "IKEY:8017613", "IKEY:6634101", "IKEY:1324634", "IKEY:6634167", "IKEY:7539597", "IKEY:6875995", "IKEY:196114", "IKEY:6634179", "10.1145/1553374.1553378", "10.1145/775047.775110", "10.1145/2133806.2133826", "10.1145/1667053.1667056", "10.1145/1143844.1143859", "10.1145/1189769.1189779", "10.1145/2207676.2207738", "10.1145/2212776.2223772", "10.1145/2678025.2701370", "10.1145/219717.219748", "10.1145/1273496.1273576", "10.1145/882262.882291", "10.1145/1835804.1835827", "10.1145/860435.860485", "10.1145/1553374.1553378", "10.1145/775047.775110", "10.1145/2133806.2133826", "10.1145/1667053.1667056", "10.1145/1143844.1143859", "10.1145/1189769.1189779", "10.1145/2207676.2207738", "10.1145/2212776.2223772", "10.1145/2678025.2701370", "10.1145/219717.219748", "10.1145/1273496.1273576", "10.1145/882262.882291", "10.1145/1835804.1835827", "10.1145/860435.860485", "10.1145/1553374.1553378", "10.1145/775047.775110", "10.1145/2133806.2133826", "10.1145/1667053.1667056", "10.1145/1143844.1143859", "10.1145/1189769.1189779", "10.1145/2207676.2207738", "10.1145/2212776.2223772", "10.1145/2678025.2701370", "10.1145/219717.219748", "10.1145/1273496.1273576", "10.1145/882262.882291", "10.1145/1835804.1835827", "10.1145/860435.860485", "10.1007/978-1-4614-3223-4_4", "10.1561/1500000030", "10.1016/j.csda.2008.01.011", "10.1007/BF00114265", "10.3115/1075096.1075167", "10.1016/0004-3702(89)90046-5", "10.1007/s10994-013-5413-0", "10.1007/978-3-540-70956-5_7", "10.1007/978-3-319-09259-1_7", "10.1057/palgrave.ivs.9500157", "10.1016/j.ijhcs.2017.03.007", "10.1016/j.visinf.2017.01.006", "10.3115/1690219.1690287", "10.1177/0165551515617393", "10.3115/1220175.1220178", "10.3115/v1/W14-3111", "10.1111/cgf.12924", "10.1198/016214506000000302", "10.1016/j.visinf.2017.01.005", "10.1007/978-1-4614-3223-4_4", "10.1561/1500000030", "10.1016/j.csda.2008.01.011", "10.1007/BF00114265", "10.3115/1075096.1075167", "10.1016/0004-3702(89)90046-5", "10.1007/s10994-013-5413-0", "10.1007/978-3-540-70956-5_7", "10.1007/978-3-319-09259-1_7", "10.1057/palgrave.ivs.9500157", "10.1016/j.ijhcs.2017.03.007", "10.1016/j.visinf.2017.01.006", "10.3115/1690219.1690287", "10.1177/0165551515617393", "10.3115/1220175.1220178", "10.3115/v1/W14-3111", "10.1111/cgf.12924", "10.1198/016214506000000302", "10.1016/j.visinf.2017.01.005", "10.1007/978-1-4614-3223-4_4", "10.1561/1500000030", "10.1016/j.csda.2008.01.011", "10.1007/BF00114265", "10.3115/1075096.1075167", "10.1016/0004-3702(89)90046-5", "10.1007/s10994-013-5413-0", "10.1007/978-3-540-70956-5_7", "10.1007/978-3-319-09259-1_7", "10.1057/palgrave.ivs.9500157", "10.1016/j.ijhcs.2017.03.007", "10.1016/j.visinf.2017.01.006", "10.3115/1690219.1690287", "10.1177/0165551515617393", "10.3115/1220175.1220178", "10.3115/v1/W14-3111", "10.1111/cgf.12924", "10.1198/016214506000000302", "10.1016/j.visinf.2017.01.005"]}, "10.1109/TVCG.2018.2864838": {"doi": "10.1109/TVCG.2018.2864838", "author": ["D. Sacha", "M. Kraus", "D. A. Keim", "M. Chen"], "title": "VIS4ML: An Ontology for Visual Analytics Assisted Machine Learning", "year": "2019", "abstract": "While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely \u201cVA-assisted ML\u201d. The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly.", "keywords": ["data visualisation", "knowledge representation languages", "learning (artificial intelligence)", "ontologies (artificial intelligence)", "semantic Web", "machine learning", "machine-learned models", "established VA concepts", "VIS4ML captures", "model-development workflows", "traditional VA pipeline", "advanced VA techniques", "ML processes", "existing VA workflows", "VA-assisted ML", "Ontologies", "Data visualization", "Analytical models", "Data models", "Task analysis", "OWL", "Machine learning", "Visual Analytics", "Visualization", "Machine Learning", "Human-Computer Interaction", "Ontology", "VIS4ML"], "referenced_by": [], "referencing": ["IKEY:6777435", "IKEY:7368928", "IKEY:8013488", "IKEY:8402187", "IKEY:1372256", "IKEY:1438250", "IKEY:4677361", "IKEY:1250972", "IKEY:8022871", "IKEY:8019883", "IKEY:8019866", "IKEY:8019879", "IKEY:7536654", "IKEY:8017582", "IKEY:8019878", "IKEY:4734003", "IKEY:8019872", "IKEY:7539329", "IKEY:7539404", "IKEY:8019867", "IKEY:6875967", "IKEY:7536217", "IKEY:8494828", "IKEY:8017583", "IKEY:7539314", "IKEY:31462", "IKEY:7539323", "IKEY:8019861", "IKEY:6777435", "IKEY:7368928", "IKEY:8013488", "IKEY:8402187", "IKEY:1372256", "IKEY:1438250", "IKEY:4677361", "IKEY:1250972", "IKEY:8022871", "IKEY:8019883", "IKEY:8019866", "IKEY:8019879", "IKEY:7536654", "IKEY:8017582", "IKEY:8019878", "IKEY:4734003", "IKEY:8019872", "IKEY:7539329", "IKEY:7539404", "IKEY:8019867", "IKEY:6875967", "IKEY:7536217", "IKEY:8494828", "IKEY:8017583", "IKEY:7539314", "IKEY:31462", "IKEY:7539323", "IKEY:8019861", "IKEY:6777435", "IKEY:7368928", "IKEY:8013488", "IKEY:8402187", "IKEY:1372256", "IKEY:1438250", "IKEY:4677361", "IKEY:1250972", "IKEY:8022871", "IKEY:8019883", "IKEY:8019866", "IKEY:8019879", "IKEY:7536654", "IKEY:8017582", "IKEY:8019878", "IKEY:4734003", "IKEY:8019872", "IKEY:7539329", "IKEY:7539404", "IKEY:8019867", "IKEY:6875967", "IKEY:7536217", "IKEY:8494828", "IKEY:8017583", "IKEY:7539314", "IKEY:31462", "IKEY:7539323", "IKEY:8019861", "10.1145/604045.604056", "10.1145/2512208", "10.1145/1978942.1979444", "10.1145/1287620.1287621", "10.1145/2757001.2757003", "10.1145/2468356.2468677", "10.1145/3011141.3011207", "10.1145/604045.604056", "10.1145/2512208", "10.1145/1978942.1979444", "10.1145/1287620.1287621", "10.1145/2757001.2757003", "10.1145/2468356.2468677", "10.1145/3011141.3011207", "10.1145/604045.604056", "10.1145/2512208", "10.1145/1978942.1979444", "10.1145/1287620.1287621", "10.1145/2757001.2757003", "10.1145/2468356.2468677", "10.1145/3011141.3011207", "10.1609/aimag.v35i4.2513", "10.1111/cgf.13324", "10.1007/s10844-014-0304-9", "10.1111/cgf.13092", "10.1111/j.1467-8659.2008.01230.x", "10.1057/ivs.2008.28", "10.1016/j.aei.2016.04.003", "10.1007/978-3-642-04747-3_21", "10.1007/978-3-642-40897-7_9", "10.1016/j.neucom.2017.01.105", "10.1057/ivs.2008.29", "10.2200/S00429ED1V01Y201207AIM018", "10.1609/aimag.v35i4.2513", "10.1111/cgf.13324", "10.1007/s10844-014-0304-9", "10.1111/cgf.13092", "10.1111/j.1467-8659.2008.01230.x", "10.1057/ivs.2008.28", "10.1016/j.aei.2016.04.003", "10.1007/978-3-642-04747-3_21", "10.1007/978-3-642-40897-7_9", "10.1016/j.neucom.2017.01.105", "10.1057/ivs.2008.29", "10.2200/S00429ED1V01Y201207AIM018", "10.1609/aimag.v35i4.2513", "10.1111/cgf.13324", "10.1007/s10844-014-0304-9", "10.1111/cgf.13092", "10.1111/j.1467-8659.2008.01230.x", "10.1057/ivs.2008.28", "10.1016/j.aei.2016.04.003", "10.1007/978-3-642-04747-3_21", "10.1007/978-3-642-40897-7_9", "10.1016/j.neucom.2017.01.105", "10.1057/ivs.2008.29", "10.2200/S00429ED1V01Y201207AIM018"]}, "10.1109/TVCG.2018.2864886": {"doi": "10.1109/TVCG.2018.2864886", "author": ["P. Law", "Z. Liu", "S. Malik", "R. C. Basole"], "title": "MAQUI: Interweaving Queries and Pattern Mining for Recursive Event Sequence Exploration", "year": "2019", "abstract": "Exploring event sequences by defining queries alone or by using mining algorithms alone is often not sufficient to support analysis. Analysts often interweave querying and mining in a recursive manner during event sequence analysis: sequences extracted as query results are used for mining patterns, patterns generated are incorporated into a new query for segmenting the sequences, and the resulting segments are mined or queried again. To support flexible analysis, we propose a framework that describes the process of interwoven querying and mining. Based on this framework, we developed MAQUI, a Mining And Querying User Interface that enables recursive event sequence exploration. To understand the efficacy of MAQUI, we conducted two case studies with domain experts. The findings suggest that the capability of interweaving querying and mining helps the participants articulate their questions and gain novel insights from their data.", "keywords": ["data mining", "query processing", "user interfaces", "query/pattern mining interweaving", "mining and querying user interface", "mining algorithms", "recursive event sequence exploration", "MAQUI", "Data mining", "Task analysis", "Data visualization", "Public transportation", "Companies", "Complexity theory", "Sequential pattern mining", "temporal query", "event sequence exploration"], "referenced_by": ["IKEY:8891842", "IKEY:8805439", "IKEY:8807220"], "referencing": ["IKEY:8019837", "IKEY:8025640", "IKEY:7883512", "IKEY:7429778", "IKEY:4035762", "IKEY:8017615", "IKEY:6875996", "IKEY:5295262", "IKEY:7192665", "IKEY:6876022", "IKEY:7539341", "IKEY:6634100", "IKEY:7347682", "IKEY:6876049", "IKEY:5290698", "IKEY:8147270", "IKEY:5332595", "IKEY:8019837", "IKEY:8025640", "IKEY:7883512", "IKEY:7429778", "IKEY:4035762", "IKEY:8017615", "IKEY:6875996", "IKEY:5295262", "IKEY:7192665", "IKEY:6876022", "IKEY:7539341", "IKEY:6634100", "IKEY:7347682", "IKEY:6876049", "IKEY:5290698", "IKEY:8147270", "IKEY:5332595", "IKEY:8019837", "IKEY:8025640", "IKEY:7883512", "IKEY:7429778", "IKEY:4035762", "IKEY:8017615", "IKEY:6875996", "IKEY:5295262", "IKEY:7192665", "IKEY:6876022", "IKEY:7539341", "IKEY:6634100", "IKEY:7347682", "IKEY:6876049", "IKEY:5290698", "IKEY:8147270", "IKEY:5332595", "10.1145/775047.775109", "10.1145/3025453.3025777", "10.1145/2856767.2856779", "10.1145/2470654.2481325", "10.1145/319950.320010", "10.1145/2557500.2557508", "10.1145/846183.846188", "10.1145/1357054.1357129", "10.1145/1978942.1979196", "10.1145/1150402.1150502", "10.1145/775047.775109", "10.1145/3025453.3025777", "10.1145/2856767.2856779", "10.1145/2470654.2481325", "10.1145/319950.320010", "10.1145/2557500.2557508", "10.1145/846183.846188", "10.1145/1357054.1357129", "10.1145/1978942.1979196", "10.1145/1150402.1150502", "10.1145/775047.775109", "10.1145/3025453.3025777", "10.1145/2856767.2856779", "10.1145/2470654.2481325", "10.1145/319950.320010", "10.1145/2557500.2557508", "10.1145/846183.846188", "10.1145/1357054.1357129", "10.1145/1978942.1979196", "10.1145/1150402.1150502", "10.1007/s40273-015-0333-4", "10.1007/978-3-319-06483-3_8", "10.1177/1473871611416549", "10.1016/j.jbi.2014.01.007", "10.5220/0005716900480059", "10.1111/cgf.13208", "10.1016/j.jbi.2014.09.003", "10.1177/1473871614526077", "10.1007/s40273-015-0333-4", "10.1007/978-3-319-06483-3_8", "10.1177/1473871611416549", "10.1016/j.jbi.2014.01.007", "10.5220/0005716900480059", "10.1111/cgf.13208", "10.1016/j.jbi.2014.09.003", "10.1177/1473871614526077", "10.1007/s40273-015-0333-4", "10.1007/978-3-319-06483-3_8", "10.1177/1473871611416549", "10.1016/j.jbi.2014.01.007", "10.5220/0005716900480059", "10.1111/cgf.13208", "10.1016/j.jbi.2014.09.003", "10.1177/1473871614526077"]}, "10.1109/TVCG.2018.2864475": {"doi": "10.1109/TVCG.2018.2864475", "author": ["X. Zhao", "Y. Wu", "D. L. Lee", "W. Cui"], "title": "iForest: Interpreting Random Forests via Visual Analytics", "year": "2019", "abstract": "As an ensemble model that consists of many independent decision trees, random forests generate predictions by feeding the input to internal trees and summarizing their outputs. The ensemble nature of the model helps random forests outperform any individual decision tree. However, it also leads to a poor model interpretability, which significantly hinders the model from being used in fields that require transparent and explainable predictions, such as medical diagnosis and financial fraud detection. The interpretation challenges stem from the variety and complexity of the contained decision trees. Each decision tree has its unique structure and properties, such as the features used in the tree and the feature threshold in each tree node. Thus, a data input may lead to a variety of decision paths. To understand how a final prediction is achieved, it is desired to understand and compare all decision paths in the context of all tree structures, which is a huge challenge for any users. In this paper, we propose a visual analytic system aiming at interpreting random forest models and predictions. In addition to providing users with all the tree information, we summarize the decision paths in random forests, which eventually reflects the working mechanism of the model and reduces users' mental burden of interpretation. To demonstrate the effectiveness of our system, two usage scenarios and a qualitative user study are conducted.", "keywords": ["data visualisation", "decision trees", "learning (artificial intelligence)", "tree data structures", "random forests", "individual decision tree", "medical diagnosis", "financial fraud detection", "contained decision trees", "tree node", "decision paths", "tree structures", "visual analytic system", "random forest models", "tree information", "visual analytics", "ensemble model", "independent decision trees", "internal trees", "ensemble nature", "Forestry", "Vegetation", "Predictive models", "Decision trees", "Machine learning", "Cognition", "Impurities", "Interpretable Machine Learning", "Random Forests", "Random Forest Visualization", "Visual Analytics"], "referenced_by": ["IKEY:8801827", "IKEY:8812988", "IKEY:8807299", "IKEY:8982409", "IKEY:9002770", "IKEY:9177770"], "referencing": ["IKEY:7014400", "IKEY:8017582", "IKEY:8019878", "IKEY:4167900", "IKEY:6102453", "IKEY:1184032", "IKEY:7014400", "IKEY:8017582", "IKEY:8019878", "IKEY:4167900", "IKEY:6102453", "IKEY:1184032", "IKEY:7014400", "IKEY:8017582", "IKEY:8019878", "IKEY:4167900", "IKEY:6102453", "IKEY:1184032", "10.1145/347090.347124", "10.1145/2783258.2788613", "10.1145/3236009", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.1145/102377.115768", "10.1145/347090.347124", "10.1145/2783258.2788613", "10.1145/3236009", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.1145/102377.115768", "10.1145/347090.347124", "10.1145/2783258.2788613", "10.1145/3236009", "10.1145/2858036.2858529", "10.1145/2939672.2939778", "10.1145/102377.115768", "10.1016/j.artmed.2005.10.008", "10.24963/ijcai.2017/202", "10.1023/A:1010933404324", "10.1214/ss/1009213726", "10.1186/1471-2105-7-3", "10.1016/j.patrec.2005.10.010", "10.1214/aos/1013203451", "10.1016/j.patrec.2010.03.014", "10.1016/0277-9536(86)90041-9", "10.1016/j.knosys.2008.03.047", "10.1016/j.ijhcs.2006.07.005", "10.1201/b17511", "10.1007/3-540-45571-X_40", "10.1007/978-3-642-31537-4_13", "10.1007/978-3-319-04717-1_9", "10.1016/j.actpsy.2012.04.004", "10.1006/ijhc.2001.0499", "10.1017/S0269888900007098", "10.1016/j.cageo.2009.02.006", "10.1016/j.artmed.2005.10.008", "10.24963/ijcai.2017/202", "10.1023/A:1010933404324", "10.1214/ss/1009213726", "10.1186/1471-2105-7-3", "10.1016/j.patrec.2005.10.010", "10.1214/aos/1013203451", "10.1016/j.patrec.2010.03.014", "10.1016/0277-9536(86)90041-9", "10.1016/j.knosys.2008.03.047", "10.1016/j.ijhcs.2006.07.005", "10.1201/b17511", "10.1007/3-540-45571-X_40", "10.1007/978-3-642-31537-4_13", "10.1007/978-3-319-04717-1_9", "10.1016/j.actpsy.2012.04.004", "10.1006/ijhc.2001.0499", "10.1017/S0269888900007098", "10.1016/j.cageo.2009.02.006", "10.1016/j.artmed.2005.10.008", "10.24963/ijcai.2017/202", "10.1023/A:1010933404324", "10.1214/ss/1009213726", "10.1186/1471-2105-7-3", "10.1016/j.patrec.2005.10.010", "10.1214/aos/1013203451", "10.1016/j.patrec.2010.03.014", "10.1016/0277-9536(86)90041-9", "10.1016/j.knosys.2008.03.047", "10.1016/j.ijhcs.2006.07.005", "10.1201/b17511", "10.1007/3-540-45571-X_40", "10.1007/978-3-642-31537-4_13", "10.1007/978-3-319-04717-1_9", "10.1016/j.actpsy.2012.04.004", "10.1006/ijhc.2001.0499", "10.1017/S0269888900007098", "10.1016/j.cageo.2009.02.006"]}, "10.1109/TVCG.2018.2864885": {"doi": "10.1109/TVCG.2018.2864885", "author": ["S. Guo", "Z. Jin", "D. Gotz", "F. Du", "H. Zha", "N. Cao"], "title": "Visual Progression Analysis of Event Sequence Data", "year": "2019", "abstract": "Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identification and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a significant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help define those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET2, which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET2: (1) case studies with two real-world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design.", "keywords": ["data analysis", "data mining", "data visualisation", "health care", "human factors", "medical information systems", "unsupervised stage analysis algorithm", "critical events", "progression analysis algorithm", "visual progression analysis", "event sequence data", "event type", "event sequence warping", "event representation estimation", "data captures", "performance evaluation", "health care", "Visualization", "Diseases", "Aggregates", "Data visualization", "Pattern matching", "Interviews", "Progression Analysis", "Visual Analysis", "Event Sequence Data"], "referenced_by": ["IKEY:8805450", "IKEY:8827944", "IKEY:9005687", "IKEY:8663312", "IKEY:9308628", "10.1007/978-981-15-1377-0_51", "10.1016/j.visinf.2020.04.001", "10.1016/j.visinf.2020.04.005", "10.2196/17687", "10.3390/ijerph17228303", "10.1007/s41095-020-0191-7"], "referencing": ["IKEY:1211378", "IKEY:8019837", "IKEY:8025640", "IKEY:7883512", "IKEY:7429778", "IKEY:6875996", "IKEY:8017612", "IKEY:1399857", "IKEY:6876049", "IKEY:5290711", "IKEY:6876015", "IKEY:7929921", "IKEY:1211378", "IKEY:8019837", "IKEY:8025640", "IKEY:7883512", "IKEY:7429778", "IKEY:6875996", "IKEY:8017612", "IKEY:1399857", "IKEY:6876049", "IKEY:5290711", "IKEY:6876015", "IKEY:7929921", "IKEY:1211378", "IKEY:8019837", "IKEY:8025640", "IKEY:7883512", "IKEY:7429778", "IKEY:6875996", "IKEY:8017612", "IKEY:1399857", "IKEY:6876049", "IKEY:5290711", "IKEY:6876015", "IKEY:7929921", "10.1145/775047.775109", "10.1145/3025453.3025777", "10.1145/2856767.2856779", "10.1145/1631162.1631169", "10.1145/1978942.1978975", "10.1145/2557500.2557508", "10.1145/1645953.1646098", "10.1145/2623330.2623754", "10.1145/1978942.1979196", "10.1145/2566486.2568044", "10.1145/2702123.2702419", "10.1145/775047.775109", "10.1145/3025453.3025777", "10.1145/2856767.2856779", "10.1145/1631162.1631169", "10.1145/1978942.1978975", "10.1145/2557500.2557508", "10.1145/1645953.1646098", "10.1145/2623330.2623754", "10.1145/1978942.1979196", "10.1145/2566486.2568044", "10.1145/2702123.2702419", "10.1145/775047.775109", "10.1145/3025453.3025777", "10.1145/2856767.2856779", "10.1145/1631162.1631169", "10.1145/1978942.1978975", "10.1145/2557500.2557508", "10.1145/1645953.1646098", "10.1145/2623330.2623754", "10.1145/1978942.1979196", "10.1145/2566486.2568044", "10.1145/2702123.2702419", "10.1007/978-3-642-53914-5_15", "10.1016/j.jbi.2014.01.007", "10.1007/978-3-319-63564-4_3", "10.1016/j.jbi.2012.10.001", "10.1016/S1474-4422(09)70299-6", "10.1038/sdata.2016.35", "10.1007/s10115-004-0154-9", "10.1007/3-540-44565-X_3", "10.1101/gr.75202", "10.1016/B978-155860915-0/50038-X", "10.3233/IDA-2007-11508", "10.1073/pnas.052587399", "10.1523/JNEUROSCI.23-03-00994.2003", "10.1093/cercor/11.1.1", "10.1007/978-3-642-53914-5_15", "10.1016/j.jbi.2014.01.007", "10.1007/978-3-319-63564-4_3", "10.1016/j.jbi.2012.10.001", "10.1016/S1474-4422(09)70299-6", "10.1038/sdata.2016.35", "10.1007/s10115-004-0154-9", "10.1007/3-540-44565-X_3", "10.1101/gr.75202", "10.1016/B978-155860915-0/50038-X", "10.3233/IDA-2007-11508", "10.1073/pnas.052587399", "10.1523/JNEUROSCI.23-03-00994.2003", "10.1093/cercor/11.1.1", "10.1007/978-3-642-53914-5_15", "10.1016/j.jbi.2014.01.007", "10.1007/978-3-319-63564-4_3", "10.1016/j.jbi.2012.10.001", "10.1016/S1474-4422(09)70299-6", "10.1038/sdata.2016.35", "10.1007/s10115-004-0154-9", "10.1007/3-540-44565-X_3", "10.1101/gr.75202", "10.1016/B978-155860915-0/50038-X", "10.3233/IDA-2007-11508", "10.1073/pnas.052587399", "10.1523/JNEUROSCI.23-03-00994.2003", "10.1093/cercor/11.1.1"]}, "10.1109/TVCG.2018.2864526": {"doi": "10.1109/TVCG.2018.2864526", "author": ["P. Law", "R. C. Basole", "Y. Wu"], "title": "Duet: Helping Data Analysis Novices Conduct Pairwise Comparisons by Minimal Specification", "year": "2019", "abstract": "Data analysis novices often encounter barriers in executing low-level operations for pairwise comparisons. They may also run into barriers in interpreting the artifacts (e.g., visualizations) created as a result of the operations. We developed Duet, a visual analysis system designed to help data analysis novices conduct pairwise comparisons by addressing execution and interpretation barriers. To reduce the barriers in executing low-level operations during pairwise comparison, Duet employs minimal specification: when one object group (i.e. a group of records in a data table) is specified, Duet recommends object groups that are similar to or different from the specified one; when two object groups are specified, Duet recommends similar and different attributes between them. To lower the barriers in interpreting its recommendations, Duet explains the recommended groups and attributes using both visualizations and textual descriptions. We conducted a qualitative evaluation with eight participants to understand the effectiveness of Duet. The results suggest that minimal specification is easy to use and Duet's explanations are helpful for interpreting the recommendations despite some usability issues.", "keywords": ["data analysis", "data visualisation", "decision making", "recommender systems", "object group", "data table", "minimal specification", "Duet's explanations", "low-level operations", "pairwise comparison", "visual analysis system", "interpretation barriers", "groups recommendation", "data analysis novices", "Duet recommendation", "textual descriptions", "qualitative evaluation", "Data analysis", "Data visualization", "Tools", "Law enforcement", "Visualization", "Systems operation", "Knowledge discovery", "Pairwise comparison", "novices", "data analysis", "automatic insight generation"], "referenced_by": ["IKEY:8891842", "IKEY:8805439", "IKEY:9086215"], "referencing": ["IKEY:7534883", "IKEY:6102435", "IKEY:854761", "IKEY:1195991", "IKEY:8017615", "IKEY:5613431", "IKEY:8019833", "IKEY:4658124", "IKEY:7192668", "IKEY:8019860", "IKEY:7192728", "IKEY:7534883", "IKEY:6102435", "IKEY:854761", "IKEY:1195991", "IKEY:8017615", "IKEY:5613431", "IKEY:8019833", "IKEY:4658124", "IKEY:7192668", "IKEY:8019860", "IKEY:7192728", "IKEY:7534883", "IKEY:6102435", "IKEY:854761", "IKEY:1195991", "IKEY:8017615", "IKEY:5613431", "IKEY:8019833", "IKEY:4658124", "IKEY:7192668", "IKEY:8019860", "IKEY:7192728", "10.1145/2207676.2207738", "10.1145/3025171.3025227", "10.1145/3025453.3025777", "10.1145/1842993.1843029", "10.1145/2807442.2807478", "10.1145/358916.358995", "10.1145/1978942.1979444", "10.1145/2213836.2213931", "10.1145/985692.985712", "10.1145/1518701.1518942", "10.1145/2678025.2701399", "10.1145/2807442.2807459", "10.1145/2984511.2984588", "10.1145/506443.506619", "10.1145/3035918.3035922", "10.1145/3025453.3025768", "10.1145/2501988.2502040", "10.1145/2207676.2207738", "10.1145/3025171.3025227", "10.1145/3025453.3025777", "10.1145/1842993.1843029", "10.1145/2807442.2807478", "10.1145/358916.358995", "10.1145/1978942.1979444", "10.1145/2213836.2213931", "10.1145/985692.985712", "10.1145/1518701.1518942", "10.1145/2678025.2701399", "10.1145/2807442.2807459", "10.1145/2984511.2984588", "10.1145/506443.506619", "10.1145/3035918.3035922", "10.1145/3025453.3025768", "10.1145/2501988.2502040", "10.1145/2207676.2207738", "10.1145/3025171.3025227", "10.1145/3025453.3025777", "10.1145/1842993.1843029", "10.1145/2807442.2807478", "10.1145/358916.358995", "10.1145/1978942.1979444", "10.1145/2213836.2213931", "10.1145/985692.985712", "10.1145/1518701.1518942", "10.1145/2678025.2701399", "10.1145/2807442.2807459", "10.1145/2984511.2984588", "10.1145/506443.506619", "10.1145/3035918.3035922", "10.1145/3025453.3025768", "10.1145/2501988.2502040", "10.1177/1473871618806555", "10.14778/3137765.3137813", "10.1177/0272989X10373805", "10.1007/978-3-540-24670-1_3", "10.2307/3001913", "10.14778/2831360.2831371", "10.1057/ivs.2008.27", "10.1177/1473871618806555", "10.14778/3137765.3137813", "10.1177/0272989X10373805", "10.1007/978-3-540-24670-1_3", "10.2307/3001913", "10.14778/2831360.2831371", "10.1057/ivs.2008.27", "10.1177/1473871618806555", "10.14778/3137765.3137813", "10.1177/0272989X10373805", "10.1007/978-3-540-24670-1_3", "10.2307/3001913", "10.14778/2831360.2831371", "10.1057/ivs.2008.27"]}, "10.1109/TVCG.2018.2865240": {"doi": "10.1109/TVCG.2018.2865240", "author": ["D. Moritz", "C. Wang", "G. L. Nelson", "H. Lin", "A. M. Smith", "B. Howe", "J. Heer"], "title": "Formalizing Visualization Design Knowledge as Constraints: Actionable and Extensible Models in Draco", "year": "2019", "abstract": "There exists a gap between visualization design guidelines and their application in visualization tools. While empirical studies can provide design guidance, we lack a formal framework for representing design knowledge, integrating results across studies, and applying this knowledge in automated design tools that promote effective encodings and facilitate visual exploration. We propose modeling visualization design knowledge as a collection of constraints, in conjunction with a method to learn weights for soft constraints from experimental data. Using constraints, we can take theoretical design knowledge and express it in a concrete, extensible, and testable form: the resulting models can recommend visualization designs and can easily be augmented with additional constraints or updated weights. We implement our approach in Draco, a constraint-based system based on Answer Set Programming (ASP). We demonstrate how to construct increasingly sophisticated automated visualization design systems, including systems based on weights learned directly from the results of graphical perception experiments.", "keywords": ["constraint handling", "data visualisation", "logic programming", "visualization design knowledge", "visualization design guidelines", "automated design tools", "visual exploration", "soft constraints", "constraint-based system", "automated visualization design systems", "Draco", "answer set programming", "ASP", "Data visualization", "Encoding", "Task analysis", "Tools", "Visualization", "Programming", "Computational modeling", "Automated Visualization Design", "Perceptual Effectiveness", "Constraints", "Knowledge Bases", "Answer Set Programming"], "referenced_by": ["IKEY:8813126", "IKEY:8807266", "IKEY:8805429", "IKEY:8933570", "IKEY:8973383", "IKEY:9089446", "IKEY:9307969"], "referencing": ["IKEY:6875906", "IKEY:6634120", "IKEY:6875978", "IKEY:819548", "IKEY:4376133", "IKEY:8017646", "IKEY:8017651", "IKEY:8017651", "IKEY:7539624", "IKEY:4053083", "IKEY:5783900", "IKEY:8017604", "IKEY:7192728", "IKEY:6875906", "IKEY:6634120", "IKEY:6875978", "IKEY:819548", "IKEY:4376133", "IKEY:8017646", "IKEY:8017651", "IKEY:8017651", "IKEY:7539624", "IKEY:4053083", "IKEY:5783900", "IKEY:8017604", "IKEY:7192728", "IKEY:6875906", "IKEY:6634120", "IKEY:6875978", "IKEY:819548", "IKEY:4376133", "IKEY:8017646", "IKEY:8017651", "IKEY:8017651", "IKEY:7539624", "IKEY:4053083", "IKEY:5783900", "IKEY:8017604", "IKEY:7192728", "10.1145/2043174.2043195", "10.1145/108360.108361", "10.1145/2807442.2807478", "10.1145/1142473.1142560", "10.1145/1753326.1753357", "10.1145/2213836.2213931", "10.1145/3025453.3025866", "10.1145/1102351.1102407", "10.1145/22949.22950", "10.1145/2702123.2702608", "10.1145/97243.97273", "10.1145/2984511.2984588", "10.1145/2282338.2282370", "10.1145/2939502.2939506", "10.1145/3025453.3025768", "10.1145/2043174.2043195", "10.1145/108360.108361", "10.1145/2807442.2807478", "10.1145/1142473.1142560", "10.1145/1753326.1753357", "10.1145/2213836.2213931", "10.1145/3025453.3025866", "10.1145/1102351.1102407", "10.1145/22949.22950", "10.1145/2702123.2702608", "10.1145/97243.97273", "10.1145/2984511.2984588", "10.1145/2282338.2282370", "10.1145/2939502.2939506", "10.1145/3025453.3025768", "10.1145/2043174.2043195", "10.1145/108360.108361", "10.1145/2807442.2807478", "10.1145/1142473.1142560", "10.1145/1753326.1753357", "10.1145/2213836.2213931", "10.1145/3025453.3025866", "10.1145/1102351.1102407", "10.1145/22949.22950", "10.1145/2702123.2702608", "10.1145/97243.97273", "10.1145/2984511.2984588", "10.1145/2282338.2282370", "10.1145/2939502.2939506", "10.1145/3025453.3025768", "10.2307/2288400", "10.1023/A:1018924526592", "10.1613/jair.5714", "10.1017/S1471068415000150", "10.2200/S00457ED1V01Y201211AIM019", "10.1016/0743-1066(94)90033-7", "10.1111/cgf.13409", "10.1016/S0004-3702(02)00186-8", "10.1561/1500000016", "10.1201/b17511", "10.1007/3-540-45241-9_12", "10.3115/1699510.1699512", "10.1007/BF00117105", "10.1007/s10994-006-5833-1", "10.1007/3-540-49201-1_21", "10.1167/16.5.11", "10.2307/2288400", "10.1023/A:1018924526592", "10.1613/jair.5714", "10.1017/S1471068415000150", "10.2200/S00457ED1V01Y201211AIM019", "10.1016/0743-1066(94)90033-7", "10.1111/cgf.13409", "10.1016/S0004-3702(02)00186-8", "10.1561/1500000016", "10.1201/b17511", "10.1007/3-540-45241-9_12", "10.3115/1699510.1699512", "10.1007/BF00117105", "10.1007/s10994-006-5833-1", "10.1007/3-540-49201-1_21", "10.1167/16.5.11", "10.2307/2288400", "10.1023/A:1018924526592", "10.1613/jair.5714", "10.1017/S1471068415000150", "10.2200/S00457ED1V01Y201211AIM019", "10.1016/0743-1066(94)90033-7", "10.1111/cgf.13409", "10.1016/S0004-3702(02)00186-8", "10.1561/1500000016", "10.1201/b17511", "10.1007/3-540-45241-9_12", "10.3115/1699510.1699512", "10.1007/BF00117105", "10.1007/s10994-006-5833-1", "10.1007/3-540-49201-1_21", "10.1167/16.5.11"]}, "10.1109/TVCG.2018.2865118": {"doi": "10.1109/TVCG.2018.2865118", "author": ["V. Molchanov", "L. Linsen"], "title": "Shape-preserving Star Coordinates", "year": "2019", "abstract": "Dimensionality reduction is commonly applied to multidimensional data to reduce the complexity of their analysis. In visual analysis systems, projections embed multidimensional data into 2D or 3D spaces for graphical representation. To facilitate a robust and accurate analysis, essential characteristics of the multidimensional data shall be preserved when projecting. Orthographic star coordinates is a state-of-the-art linear projection method that avoids distortion of multidimensional clusters by restricting interactive exploration to orthographic projections. However, existing numerical methods for computing orthographic star coordinates have a number of limitations when putting them into practice. We overcome these limitations by proposing the novel concept of shape-preserving star coordinates where shape preservation is assured using a superset of orthographic projections. Our scheme is explicit, exact, simple, fast, parameter-free, and stable. To maintain a valid shape-preserving star-coordinates configuration during user interaction with one of the star-coordinates axes, we derive an algorithm that only requires us to modify the configuration of one additional compensatory axis. Different design goals can be targeted by using different strategies for selecting the compensatory axis. We propose and discuss four strategies including a strategy that approximates orthographic star coordinates very well and a data-driven strategy. We further present shape-preserving morphing strategies between two shape-preserving configurations, which can be adapted for the generation of data tours. We apply our concept to multiple data analysis scenarios to document its applicability and validate its desired properties.", "keywords": ["data analysis", "data visualisation", "object detection", "pattern clustering", "robust analysis", "multidimensional data", "orthographic star coordinates", "multidimensional clusters", "orthographic projections", "shape preservation", "valid shape-preserving star-coordinates configuration", "star-coordinates axes", "approximates orthographic star", "data-driven strategy", "shape-preserving morphing strategies", "multiple data analysis scenarios", "visual analysis systems", "linear projection method", "Shape", "Two dimensional displays", "Visualization", "Data analysis", "Principal component analysis", "Distortion", "Data visualization", "Star coordinates", "multidimensional data projection", "multivariate data visualization"], "referenced_by": ["IKEY:9086221"], "referencing": ["IKEY:4027077", "IKEY:5613430", "IKEY:1672644", "IKEY:6634131", "IKEY:7192684", "IKEY:7192699", "IKEY:6875998", "IKEY:4027077", "IKEY:5613430", "IKEY:1672644", "IKEY:6634131", "IKEY:7192684", "IKEY:7192699", "IKEY:6875998", "IKEY:4027077", "IKEY:5613430", "IKEY:1672644", "IKEY:6634131", "IKEY:7192684", "IKEY:7192699", "IKEY:6875998", "10.1145/502512.502530", "10.1145/502512.502530", "10.1145/502512.502530", "10.1137/0906011", "10.3390/pr5040075", "10.1177/1473871612439357", "10.1080/01621459.1987.10478427", "10.1093/biomet/58.3.453", "10.1037/h0071325", "10.4135/9781412985130", "10.1111/cgf.12117", "10.1111/cgf.13196", "10.1137/1.9781611972733.16", "10.1007/s00180-011-0271-3", "10.1016/j.cag.2016.08.007", "10.1137/0906011", "10.3390/pr5040075", "10.1177/1473871612439357", "10.1080/01621459.1987.10478427", "10.1093/biomet/58.3.453", "10.1037/h0071325", "10.4135/9781412985130", "10.1111/cgf.12117", "10.1111/cgf.13196", "10.1137/1.9781611972733.16", "10.1007/s00180-011-0271-3", "10.1016/j.cag.2016.08.007", "10.1137/0906011", "10.3390/pr5040075", "10.1177/1473871612439357", "10.1080/01621459.1987.10478427", "10.1093/biomet/58.3.453", "10.1037/h0071325", "10.4135/9781412985130", "10.1111/cgf.12117", "10.1111/cgf.13196", "10.1137/1.9781611972733.16", "10.1007/s00180-011-0271-3", "10.1016/j.cag.2016.08.007"]}, "10.1109/TVCG.2018.2865126": {"doi": "10.1109/TVCG.2018.2865126", "author": ["D. Weng", "R. Chen", "Z. Deng", "F. Wu", "J. Chen", "Y. Wu"], "title": "SRVis: Towards Better Spatial Integration in Ranking Visualization", "year": "2019", "abstract": "Interactive ranking techniques have substantially promoted analysts' ability in making judicious and informed decisions effectively based on multiple criteria. However, the existing techniques cannot satisfactorily support the analysis tasks involved in ranking large-scale spatial alternatives, such as selecting optimal locations for chain stores, where the complex spatial contexts involved are essential to the decision-making process. Limitations observed in the prior attempts of integrating rankings with spatial contexts motivate us to develop a context-integrated visual ranking technique. Based on a set of generic design requirements we summarized by collaborating with domain experts, we propose SRVis, a novel spatial ranking visualization technique that supports efficient spatial multi-criteria decision-making processes by addressing three major challenges in the aforementioned context integration, namely, a) the presentation of spatial rankings and contexts, b) the scalability of rankings' visual representations, and c) the analysis of context-integrated spatial rankings. Specifically, we encode massive rankings and their cause with scalable matrix-based visualizations and stacked bar charts based on a novel two-phase optimization framework that minimizes the information loss, and the flexible spatial filtering and intuitive comparative analysis are adopted to enable the in-depth evaluation of the rankings and assist users in selecting the best spatial alternative. The effectiveness of the proposed technique has been evaluated and demonstrated with an empirical study of optimization methods, two case studies, and expert interviews.", "keywords": ["bar charts", "data visualisation", "decision making", "matrix algebra", "optimisation", "spatial filters", "judicious decisions", "informed decisions", "analysis tasks", "large-scale spatial alternatives", "optimal locations", "complex spatial contexts", "context-integrated visual ranking technique", "SRVis", "spatial ranking visualization technique", "context-integrated spatial rankings", "spatial filtering", "spatial multicriteria decision-making processes", "matrix-based visualizations", "bar charts", "optimization methods", "in-depth evaluation", "Visualization", "Bars", "Decision making", "Data visualization", "Scalability", "Spatial databases", "Reliability", "Spatial ranking", "visualization"], "referenced_by": ["IKEY:8440840", "IKEY:8807264", "IKEY:8807233", "IKEY:8933750"], "referencing": ["IKEY:7534822", "IKEY:929933", "IKEY:6634194", "IKEY:6064996", "IKEY:4658136", "IKEY:6875982", "IKEY:7021853", "IKEY:6634146", "IKEY:4658150", "IKEY:5190852", "IKEY:5949270", "IKEY:7534856", "IKEY:6102455", "IKEY:7536654", "IKEY:6522454", "IKEY:7156392", "IKEY:7539380", "IKEY:7792176", "IKEY:7579406", "IKEY:7192695", "IKEY:7879127", "IKEY:6876015", "IKEY:7506246", "IKEY:7534822", "IKEY:929933", "IKEY:6634194", "IKEY:6064996", "IKEY:4658136", "IKEY:6875982", "IKEY:7021853", "IKEY:6634146", "IKEY:4658150", "IKEY:5190852", "IKEY:5949270", "IKEY:7534856", "IKEY:6102455", "IKEY:7536654", "IKEY:6522454", "IKEY:7156392", "IKEY:7539380", "IKEY:7792176", "IKEY:7579406", "IKEY:7192695", "IKEY:7879127", "IKEY:6876015", "IKEY:7506246", "IKEY:7534822", "IKEY:929933", "IKEY:6634194", "IKEY:6064996", "IKEY:4658136", "IKEY:6875982", "IKEY:7021853", "IKEY:6634146", "IKEY:4658150", "IKEY:5190852", "IKEY:5949270", "IKEY:7534856", "IKEY:6102455", "IKEY:7536654", "IKEY:6522454", "IKEY:7156392", "IKEY:7539380", "IKEY:7792176", "IKEY:7579406", "IKEY:7192695", "IKEY:7879127", "IKEY:6876015", "IKEY:7506246", "10.1145/1133265.1133308", "10.1145/1385569.1385603", "10.1145/989863.989885", "10.1145/3020165.3020174", "10.1145/2702123.2702237", "10.1145/3173574.3173821", "10.1145/1133265.1133308", "10.1145/1385569.1385603", "10.1145/989863.989885", "10.1145/3020165.3020174", "10.1145/2702123.2702237", "10.1145/3173574.3173821", "10.1145/1133265.1133308", "10.1145/1385569.1385603", "10.1145/989863.989885", "10.1145/3020165.3020174", "10.1145/2702123.2702237", "10.1145/3173574.3173821", "10.1080/136588199241247", "10.3166/jds.12.193-208", "10.1038/nature05302", "10.1016/j.disopt.2005.08.005", "10.1111/cgf.12910", "10.1111/j.0033-0124.1985.00075.x", "10.1287/moor.1.2.117", "10.1007/978-3-642-48318-9", "10.1080/13658810010005525", "10.1111/cgf.12132", "10.1007/BF02289694", "10.1561/1500000016", "10.1098/rspl.1895.0041", "10.1016/j.jcss.2013.01.017", "10.1007/978-1-4757-3157-6", "10.1080/136588199241247", "10.3166/jds.12.193-208", "10.1038/nature05302", "10.1016/j.disopt.2005.08.005", "10.1111/cgf.12910", "10.1111/j.0033-0124.1985.00075.x", "10.1287/moor.1.2.117", "10.1007/978-3-642-48318-9", "10.1080/13658810010005525", "10.1111/cgf.12132", "10.1007/BF02289694", "10.1561/1500000016", "10.1098/rspl.1895.0041", "10.1016/j.jcss.2013.01.017", "10.1007/978-1-4757-3157-6", "10.1080/136588199241247", "10.3166/jds.12.193-208", "10.1038/nature05302", "10.1016/j.disopt.2005.08.005", "10.1111/cgf.12910", "10.1111/j.0033-0124.1985.00075.x", "10.1287/moor.1.2.117", "10.1007/978-3-642-48318-9", "10.1080/13658810010005525", "10.1111/cgf.12132", "10.1007/BF02289694", "10.1561/1500000016", "10.1098/rspl.1895.0041", "10.1016/j.jcss.2013.01.017", "10.1007/978-1-4757-3157-6"]}, "10.1109/TVCG.2018.2865141": {"doi": "10.1109/TVCG.2018.2865141", "author": ["J. Jo", "F. Vernier", "P. Dragicevic", "J. Fekete"], "title": "A Declarative Rendering Model for Multiclass Density Maps", "year": "2019", "abstract": "Multiclass maps are scatterplots, multidimensional projections, or thematic geographic maps where data points have a categorical attribute in addition to two quantitative attributes. This categorical attribute is often rendered using shape or color, which does not scale when overplotting occurs. When the number of data points increases, multiclass maps must resort to data aggregation to remain readable. We present multiclass density maps: multiple 2D histograms computed for each of the category values. Multiclass density maps are meant as a building block to improve the expressiveness and scalability of multiclass map visualization. In this article, we first present a short survey of aggregated multiclass maps, mainly from cartography. We then introduce a declarative model-a simple yet expressive JSON grammar associated with visual semantics-that specifies a wide design space of visualizations for multiclass density maps. Our declarative model is expressive and can be efficiently implemented in visualization front-ends such as modern web browsers. Furthermore, it can be reconfigured dynamically to support data exploration tasks without recomputing the raw data. Finally, we demonstrate how our model can be used to reproduce examples from the past and support exploring data at scale.", "keywords": ["cartography", "data aggregation", "data analysis", "data visualisation", "grammars", "online front-ends", "rendering (computer graphics)", "multiclass density maps", "categorical attribute", "multiclass map visualization", "aggregated multiclass maps", "expressive JSON grammar", "declarative rendering model", "scatterplots", "multidimensional projections", "thematic geographic maps", "data aggregation", "multiple 2D histograms", "visualization front-ends", "modern Web browsers", "Data visualization", "Image color analysis", "Task analysis", "Scalability", "Visualization", "Computational modeling", "Rendering (computer graphics)", "Scalability", "multiclass scatterplots", "density maps", "aggregation", "declarative specification", "visualization grammar"], "referenced_by": ["IKEY:8811948", "IKEY:8848845", "IKEY:8809223", "IKEY:9308625", "10.1016/j.visinf.2019.03.004", "10.3390/info10100302", "10.1080/15230406.2020.1733438", "10.1016/j.visinf.2020.10.002"], "referencing": ["IKEY:7465244", "IKEY:6064996", "IKEY:6691712", "IKEY:1173156", "IKEY:8017615", "IKEY:4376150", "IKEY:6634137", "IKEY:6484064", "IKEY:7864468", "IKEY:4178161", "IKEY:7348077", "IKEY:6634181", "IKEY:8017602", "IKEY:7539624", "IKEY:6065022", "IKEY:5290769", "IKEY:7465244", "IKEY:6064996", "IKEY:6691712", "IKEY:1173156", "IKEY:8017615", "IKEY:4376150", "IKEY:6634137", "IKEY:6484064", "IKEY:7864468", "IKEY:4178161", "IKEY:7348077", "IKEY:6634181", "IKEY:8017602", "IKEY:7539624", "IKEY:6065022", "IKEY:5290769", "IKEY:7465244", "IKEY:6064996", "IKEY:6691712", "IKEY:1173156", "IKEY:8017615", "IKEY:4376150", "IKEY:6634137", "IKEY:6484064", "IKEY:7864468", "IKEY:4178161", "IKEY:7348077", "IKEY:6634181", "IKEY:8017602", "IKEY:7539624", "IKEY:6065022", "IKEY:5290769", "10.1145/2669557.2669578", "10.1145/2669557.2669559", "10.1145/3173574.3173991", "10.1145/2702123.2702585", "10.1145/1476589.1476628", "10.1145/2514.2517", "10.1145/170088.170095", "10.1145/2872427.2883041", "10.1145/2669557.2669578", "10.1145/2669557.2669559", "10.1145/3173574.3173991", "10.1145/2702123.2702585", "10.1145/1476589.1476628", "10.1145/2514.2517", "10.1145/170088.170095", "10.1145/2872427.2883041", "10.1145/2669557.2669578", "10.1145/2669557.2669559", "10.1145/3173574.3173991", "10.1145/2702123.2702585", "10.1145/1476589.1476628", "10.1145/2514.2517", "10.1145/170088.170095", "10.1145/2872427.2883041", "10.1037/xhp0000255", "10.1057/palgrave.ivs.9500122", "10.14714/CP29.672", "10.1179/000870403235002042", "10.1057/ivs.2009.34", "10.3138/cart.52.4.2016-0007", "10.1111/cgf.12129", "10.2200/S00357ED1V01Y201105VIS002", "10.1201/b17511", "10.1559/152304000783547786", "10.1111/cgf.12878", "10.2307/2683294", "10.2307/1390904", "10.1037/xhp0000255", "10.1057/palgrave.ivs.9500122", "10.14714/CP29.672", "10.1179/000870403235002042", "10.1057/ivs.2009.34", "10.3138/cart.52.4.2016-0007", "10.1111/cgf.12129", "10.2200/S00357ED1V01Y201105VIS002", "10.1201/b17511", "10.1559/152304000783547786", "10.1111/cgf.12878", "10.2307/2683294", "10.2307/1390904", "10.1037/xhp0000255", "10.1057/palgrave.ivs.9500122", "10.14714/CP29.672", "10.1179/000870403235002042", "10.1057/ivs.2009.34", "10.3138/cart.52.4.2016-0007", "10.1111/cgf.12129", "10.2200/S00357ED1V01Y201105VIS002", "10.1201/b17511", "10.1559/152304000783547786", "10.1111/cgf.12878", "10.2307/2683294", "10.2307/1390904"]}, "10.1109/TVCG.2018.2865194": {"doi": "10.1109/TVCG.2018.2865194", "author": ["R. Faust", "D. Glickenstein", "C. Scheidegger"], "title": "DimReader: Axis lines that explain non-linear projections", "year": "2019", "abstract": "Non-linear dimensionality reduction (NDR) methods such as LLE and t-SNE are popular with visualization researchers and experienced data analysts, but present serious problems of interpretation. In this paper, we present DimReader, a technique that recovers readable axes from such techniques. DimReader is based on analyzing infinitesimal perturbations of the dataset with respect to variables of interest. The perturbations define exactly how we want to change each point in the original dataset and we measure the effect that these changes have on the projection. The recovered axes are in direct analogy with the axis lines (grid lines) of traditional scatterplots. We also present methods for discovering perturbations on the input data that change the projection the most. The calculation of the perturbations is efficient and easily integrated into programs written in modern programming languages. We present results of DimReader on a variety of NDR methods and datasets both synthetic and real-life, and show how it can be used to compare different NDR methods. Finally, we discuss limitations of our proposal and situations where further research is needed.", "keywords": ["data analysis", "data mining", "data visualisation", "programming languages", "DimReader", "axis lines", "nonlinear projections", "nonlinear dimensionality reduction methods", "visualization researchers", "data analysts", "grid lines", "input data", "NDR methods", "infinitesimal perturbations analysis", "axes recover", "programming languages", "scatter plots", "Perturbation methods", "Dimensionality reduction", "Data visualization", "Visualization", "Encoding", "Sensitivity analysis", "Tools", "Non-linear dimensionality reduction", "auto-differentiation"], "referenced_by": ["IKEY:8863966", "IKEY:9064929"], "referencing": ["IKEY:6472235", "IKEY:6875906", "IKEY:6875900", "IKEY:6634168", "IKEY:567787", "IKEY:5652460", "IKEY:6464263", "IKEY:7194836", "IKEY:6102449", "IKEY:6634124", "IKEY:4553710", "IKEY:6065024", "IKEY:6875930", "IKEY:4607318", "IKEY:1173161", "IKEY:4378370", "IKEY:7536217", "IKEY:6634128", "IKEY:7192695", "IKEY:5725236", "IKEY:6472235", "IKEY:6875906", "IKEY:6875900", "IKEY:6634168", "IKEY:567787", "IKEY:5652460", "IKEY:6464263", "IKEY:7194836", "IKEY:6102449", "IKEY:6634124", "IKEY:4553710", "IKEY:6065024", "IKEY:6875930", "IKEY:4607318", "IKEY:1173161", "IKEY:4378370", "IKEY:7536217", "IKEY:6634128", "IKEY:7192695", "IKEY:5725236", "IKEY:6472235", "IKEY:6875906", "IKEY:6875900", "IKEY:6634168", "IKEY:567787", "IKEY:5652460", "IKEY:6464263", "IKEY:7194836", "IKEY:6102449", "IKEY:6634124", "IKEY:4553710", "IKEY:6065024", "IKEY:6875930", "IKEY:4607318", "IKEY:1173161", "IKEY:4378370", "IKEY:7536217", "IKEY:6634128", "IKEY:7192695", "IKEY:5725236", "10.1016/j.neucom.2006.11.018", "10.1007/s00357-001-0031-0", "10.1007/978-3-642-57951-6_5", "10.1177/1473871615600010", "10.2307/1268249", "10.1073/pnas.1031596100", "10.1111/cgf.12107", "10.2172/15002155", "10.1137/1.9780898717761", "10.1111/j.1467-8659.2009.01475.x", "10.1111/j.1467-8659.2010.01835.x", "10.1126/science.290.5500.2319", "10.1007/BF02289530", "10.1016/j.neucom.2006.11.018", "10.1007/s00357-001-0031-0", "10.1007/978-3-642-57951-6_5", "10.1177/1473871615600010", "10.2307/1268249", "10.1073/pnas.1031596100", "10.1111/cgf.12107", "10.2172/15002155", "10.1137/1.9780898717761", "10.1111/j.1467-8659.2009.01475.x", "10.1111/j.1467-8659.2010.01835.x", "10.1126/science.290.5500.2319", "10.1007/BF02289530", "10.1016/j.neucom.2006.11.018", "10.1007/s00357-001-0031-0", "10.1007/978-3-642-57951-6_5", "10.1177/1473871615600010", "10.2307/1268249", "10.1073/pnas.1031596100", "10.1111/cgf.12107", "10.2172/15002155", "10.1137/1.9780898717761", "10.1111/j.1467-8659.2009.01475.x", "10.1111/j.1467-8659.2010.01835.x", "10.1126/science.290.5500.2319", "10.1007/BF02289530"]}, "10.1109/TVCG.2018.2865146": {"doi": "10.1109/TVCG.2018.2865146", "author": ["E. Wall", "M. Agnihotri", "L. Matzen", "K. Divis", "M. Haass", "A. Endert", "J. Stasko"], "title": "A Heuristic Approach to Value-Driven Evaluation of Visualizations", "year": "2019", "abstract": "Recently, an approach for determining the value of a visualization was proposed, one moving beyond simple measurements of task accuracy and speed. The value equation contains components for the time savings a visualization provides, the insights and insightful questions it spurs, the overall essence of the data it conveys, and the confidence about the data and its domain it inspires. This articulation of value is purely descriptive, however, providing no actionable method of assessing a visualization's value. In this work, we create a heuristic-based evaluation methodology to accompany the value equation for assessing interactive visualizations. We refer to the methodology colloquially as ICE-T, based on an anagram of the four value components. Our approach breaks the four components down into guidelines, each of which is made up of a small set of low-level heuristics. Evaluators who have knowledge of visualization design principles then assess the visualization with respect to the heuristics. We conducted an initial trial of the methodology on three interactive visualizations of the same data set, each evaluated by 15 visualization experts. We found that the methodology showed promise, obtaining consistent ratings across the three visualizations and mirroring judgments of the utility of the visualizations by instructors of the course in which they were developed.", "keywords": ["data visualisation", "heuristic-based evaluation methodology", "interactive visualizations", "value components", "low-level heuristics", "visualization design principles", "mirroring judgments", "heuristic approach", "value-driven evaluation", "simple measurements", "task accuracy", "visualization experts", "Data visualization", "Task analysis", "Usability", "Visualization", "Benchmark testing", "Tools", "Guidelines", "Visualization evaluation", "heuristics", "value of visualization"], "referenced_by": ["IKEY:8809393", "IKEY:8933570", "IKEY:9086245", "IKEY:9064929"], "referencing": ["IKEY:1432689", "IKEY:4797511", "IKEY:1509067", "IKEY:6295805", "IKEY:963289", "IKEY:6095544", "IKEY:1626178", "IKEY:4359491", "IKEY:1432690", "IKEY:1510530", "IKEY:1634309", "IKEY:1432689", "IKEY:4797511", "IKEY:1509067", "IKEY:6295805", "IKEY:963289", "IKEY:6095544", "IKEY:1626178", "IKEY:4359491", "IKEY:1432690", "IKEY:1510530", "IKEY:1634309", "IKEY:1432689", "IKEY:4797511", "IKEY:1509067", "IKEY:6295805", "IKEY:963289", "IKEY:6095544", "IKEY:1626178", "IKEY:4359491", "IKEY:1432690", "IKEY:1510530", "IKEY:1634309", "10.1145/1168149.1168163", "10.1145/1842993.1843029", "10.1145/2858036.2858280", "10.1145/142750.142834", "10.1145/97243.97281", "10.1145/1357054.1357101", "10.1145/989863.989880", "10.1145/2993901.2993903", "10.1145/1168149.1168158", "10.1145/2669557.2669579", "10.1145/2669557.2669580", "10.1145/1168149.1168162", "10.1145/1168149.1168163", "10.1145/1842993.1843029", "10.1145/2858036.2858280", "10.1145/142750.142834", "10.1145/97243.97281", "10.1145/1357054.1357101", "10.1145/989863.989880", "10.1145/2993901.2993903", "10.1145/1168149.1168158", "10.1145/2669557.2669579", "10.1145/2669557.2669580", "10.1145/1168149.1168162", "10.1145/1168149.1168163", "10.1145/1842993.1843029", "10.1145/2858036.2858280", "10.1145/142750.142834", "10.1145/97243.97281", "10.1145/1357054.1357101", "10.1145/989863.989880", "10.1145/2993901.2993903", "10.1145/1168149.1168158", "10.1145/2669557.2669579", "10.1145/2669557.2669580", "10.1145/1168149.1168162", "10.1007/978-3-540-70956-5_2", "10.1006/ijhc.2000.0422", "10.1177/1473871613490678", "10.1057/ivs.2009.16", "10.1007/978-1-4614-7485-2_12", "10.1016/j.apergo.2015.11.016", "10.5220/0006133202250232", "10.1177/1473871611407399", "10.1177/1473871613490290", "10.1007/978-3-319-58071-5_28", "10.1006/ijhc.2000.0420", "10.1007/978-3-540-70956-5_2", "10.1006/ijhc.2000.0422", "10.1177/1473871613490678", "10.1057/ivs.2009.16", "10.1007/978-1-4614-7485-2_12", "10.1016/j.apergo.2015.11.016", "10.5220/0006133202250232", "10.1177/1473871611407399", "10.1177/1473871613490290", "10.1007/978-3-319-58071-5_28", "10.1006/ijhc.2000.0420", "10.1007/978-3-540-70956-5_2", "10.1006/ijhc.2000.0422", "10.1177/1473871613490678", "10.1057/ivs.2009.16", "10.1007/978-1-4614-7485-2_12", "10.1016/j.apergo.2015.11.016", "10.5220/0006133202250232", "10.1177/1473871611407399", "10.1177/1473871613490290", "10.1007/978-3-319-58071-5_28", "10.1006/ijhc.2000.0420"]}, "10.1109/TVCG.2018.2865117": {"doi": "10.1109/TVCG.2018.2865117", "author": ["M. Feng", "E. Peck", "L. Harrison"], "title": "Patterns and Pace: Quantifying Diverse Exploration Behavior with Visualizations on the Web", "year": "2019", "abstract": "The diverse and vibrant ecosystem of interactive visualizations on the web presents an opportunity for researchers and practitioners to observe and analyze how everyday people interact with data visualizations. However, existing metrics of visualization interaction behavior used in research do not fully reveal the breadth of peoples' open-ended explorations with visualizations. One possible way to address this challenge is to determine high-level goals for visualization interaction metrics, and infer corresponding features from user interaction data that characterize different aspects of peoples' explorations of visualizations. In this paper, we identify needs for visualization behavior measurement, and develop corresponding candidate features that can be inferred from users' interaction data. We then propose metrics that capture novel aspects of peoples' open-ended explorations, including exploration uniqueness and exploration pacing. We evaluate these metrics along with four other metrics recently proposed in visualization literature by applying them to interaction data from prior visualization studies. The results of these evaluations suggest that these new metrics 1) reveal new characteristics of peoples' use of visualizations, 2) can be used to evaluate statistical differences between visualization designs, and 3) are statistically independent of prior metrics used in visualization research. We discuss implications of these results for future studies, including the potential for applying these metrics in visualization interaction analysis, as well as emerging challenges in developing and selecting metrics depicting visualization explorations.", "keywords": ["data visualisation", "human computer interaction", "interactive systems", "Internet", "data visualizations", "visualization interaction behavior", "visualization interaction metrics", "user interaction data", "visualization behavior measurement", "visualization designs", "visualization interaction analysis", "visualization explorations", "Data visualization", "Extraterrestrial measurements", "Companies", "Visual analytics", "Feature extraction", "Interaction", "Visualization", "Quantitative Evaluation"], "referenced_by": ["IKEY:8933611", "IKEY:8933779"], "referencing": ["IKEY:6064985", "IKEY:7192649", "IKEY:7192637", "IKEY:6875913", "IKEY:4389009", "IKEY:4909118", "IKEY:7539616", "IKEY:7192662", "IKEY:4658129", "IKEY:4389008", "IKEY:6876022", "IKEY:7539341", "IKEY:6634100", "IKEY:6751253", "IKEY:1432690", "IKEY:7534787", "IKEY:6378977", "IKEY:8017606", "IKEY:4376144", "IKEY:6064985", "IKEY:7192649", "IKEY:7192637", "IKEY:6875913", "IKEY:4389009", "IKEY:4909118", "IKEY:7539616", "IKEY:7192662", "IKEY:4658129", "IKEY:4389008", "IKEY:6876022", "IKEY:7539341", "IKEY:6634100", "IKEY:6751253", "IKEY:1432690", "IKEY:7534787", "IKEY:6378977", "IKEY:8017606", "IKEY:4376144", "IKEY:6064985", "IKEY:7192649", "IKEY:7192637", "IKEY:6875913", "IKEY:4389009", "IKEY:4909118", "IKEY:7539616", "IKEY:7192662", "IKEY:4658129", "IKEY:4389008", "IKEY:6876022", "IKEY:7539341", "IKEY:6634100", "IKEY:6751253", "IKEY:1432690", "IKEY:7534787", "IKEY:6378977", "IKEY:8017606", "IKEY:4376144", "10.1145/2702123.2702452", "10.1145/365024.365325", "10.1145/3173574.3173711", "10.1145/2702123.2702275", "10.1145/503376.503420", "10.1145/2678025.2701407", "10.1145/1357054.1357287", "10.1145/2702123.2702590", "10.1145/989863.989880", "10.1145/2110192.2110195", "10.1145/1753326.1753687", "10.1145/2020408.2020581", "10.1145/1978942.1979196", "10.1145/2702123.2702419", "10.1145/2702123.2702452", "10.1145/365024.365325", "10.1145/3173574.3173711", "10.1145/2702123.2702275", "10.1145/503376.503420", "10.1145/2678025.2701407", "10.1145/1357054.1357287", "10.1145/2702123.2702590", "10.1145/989863.989880", "10.1145/2110192.2110195", "10.1145/1753326.1753687", "10.1145/2020408.2020581", "10.1145/1978942.1979196", "10.1145/2702123.2702419", "10.1145/2702123.2702452", "10.1145/365024.365325", "10.1145/3173574.3173711", "10.1145/2702123.2702275", "10.1145/503376.503420", "10.1145/2678025.2701407", "10.1145/1357054.1357287", "10.1145/2702123.2702590", "10.1145/989863.989880", "10.1145/2110192.2110195", "10.1145/1753326.1753687", "10.1145/2020408.2020581", "10.1145/1978942.1979196", "10.1145/2702123.2702419", "10.1007/978-1-4419-0492-8_2", "10.1111/cgf.13208", "10.1016/0306-4573(88)90021-0", "10.1007/978-1-4419-0492-8_2", "10.1111/cgf.13208", "10.1016/0306-4573(88)90021-0", "10.1007/978-1-4419-0492-8_2", "10.1111/cgf.13208", "10.1016/0306-4573(88)90021-0"]}, "10.1109/TVCG.2018.2865076": {"doi": "10.1109/TVCG.2018.2865076", "author": ["Y. Zhang", "K. Chanana", "C. Dunne"], "title": "IDMVis: Temporal Event Sequence Visualization for Type 1 Diabetes Treatment Decision Support", "year": "2019", "abstract": "Type 1 diabetes is a chronic, incurable autoimmune disease affecting millions of Americans in which the body stops producing insulin and blood glucose levels rise. The goal of intensive diabetes management is to lower average blood glucose through frequent adjustments to insulin protocol, diet, and behavior. Manual logs and medical device data are collected by patients, but these multiple sources are presented in disparate visualization designs to the clinician-making temporal inference difficult. We conducted a design study over 18 months with clinicians performing intensive diabetes management. We present a data abstraction and novel hierarchical task abstraction for this domain. We also contribute IDMVis: a visualization tool for temporal event sequences with multidimensional, interrelated data. IDMVis includes a novel technique for folding and aligning records by dual sentinel events and scaling the intermediate timeline. We validate our design decisions based on our domain abstractions, best practices, and through a qualitative evaluation with six clinicians. The results of this study indicate that IDMVis accurately reflects the workflow of clinicians. Using IDMVis, clinicians are able to identify issues of data quality such as missing or conflicting data, reconstruct patient records when data is missing, differentiate between days with different patterns, and promote educational interventions after identifying discrepancies.", "keywords": ["blood", "data visualisation", "decision support systems", "diseases", "medical diagnostic computing", "patient diagnosis", "patient treatment", "sugar", "dual sentinel events", "design decisions", "domain abstractions", "clinicians", "IDMVis", "patient records", "temporal event sequence visualization", "type 1 diabetes treatment decision support", "blood glucose levels", "intensive diabetes management", "insulin protocol", "manual logs", "medical device data", "disparate visualization designs", "data abstraction", "novel hierarchical task abstraction", "visualization tool", "multidimensional data", "interrelated data", "folding records", "aligning records", "chronic", "incurable autoimmune disease", "Americans", "diet", "behavior", "Data visualization", "Diabetes", "Blood", "Sugar", "Insulin", "Task analysis", "Tools", "Design study", "task analysis", "event sequence visualization", "time series data", "qualitative evaluation", "health applications"], "referenced_by": ["IKEY:8805466", "IKEY:8805434", "IKEY:8809711", "IKEY:8809920", "IKEY:8933584", "IKEY:8945034"], "referencing": ["IKEY:6634168", "IKEY:7429778", "IKEY:6183556", "IKEY:8023762", "IKEY:5290695", "IKEY:6327248", "IKEY:545307", "IKEY:235203", "IKEY:7879100", "IKEY:6634168", "IKEY:7429778", "IKEY:6183556", "IKEY:8023762", "IKEY:5290695", "IKEY:6327248", "IKEY:545307", "IKEY:235203", "IKEY:7879100", "IKEY:6634168", "IKEY:7429778", "IKEY:6183556", "IKEY:8023762", "IKEY:5290695", "IKEY:6327248", "IKEY:545307", "IKEY:235203", "IKEY:7879100", "10.1145/203356.203365", "10.1145/3173574.3174077", "10.1145/1357054.1357129", "10.1145/203356.203365", "10.1145/3173574.3174077", "10.1145/1357054.1357129", "10.1145/203356.203365", "10.1145/3173574.3174077", "10.1145/1357054.1357129", "10.1111/j.1467-8659.2012.03092.x", "10.1201/9781410607775.ch2", "10.1111/cgf.12900", "10.1016/0933-3657(91)90005-V", "10.1177/1932296815576956", "10.2307/2685478", "10.1201/b17511", "10.1136/bmjdrc-2017-000437", "10.1016/j.pec.2013.09.002", "10.1177/1473871615621602", "10.1007/978-3-319-28661-7_5", "10.1561/1100000039", "10.1080/14639220903165169", "10.2337/dc14-2919", "10.1111/0824-7935.00114", "10.1016/j.artmed.2005.03.001", "10.1007/s00779-006-0087-2", "10.1016/j.cmpb.2010.10.007", "10.1177/1098214005283748", "10.1177/1932296814568806", "10.1177/1932296817691305", "10.2337/diaspect.18.3.181", "10.1111/j.1467-8659.2012.03092.x", "10.1201/9781410607775.ch2", "10.1111/cgf.12900", "10.1016/0933-3657(91)90005-V", "10.1177/1932296815576956", "10.2307/2685478", "10.1201/b17511", "10.1136/bmjdrc-2017-000437", "10.1016/j.pec.2013.09.002", "10.1177/1473871615621602", "10.1007/978-3-319-28661-7_5", "10.1561/1100000039", "10.1080/14639220903165169", "10.2337/dc14-2919", "10.1111/0824-7935.00114", "10.1016/j.artmed.2005.03.001", "10.1007/s00779-006-0087-2", "10.1016/j.cmpb.2010.10.007", "10.1177/1098214005283748", "10.1177/1932296814568806", "10.1177/1932296817691305", "10.2337/diaspect.18.3.181", "10.1111/j.1467-8659.2012.03092.x", "10.1201/9781410607775.ch2", "10.1111/cgf.12900", "10.1016/0933-3657(91)90005-V", "10.1177/1932296815576956", "10.2307/2685478", "10.1201/b17511", "10.1136/bmjdrc-2017-000437", "10.1016/j.pec.2013.09.002", "10.1177/1473871615621602", "10.1007/978-3-319-28661-7_5", "10.1561/1100000039", "10.1080/14639220903165169", "10.2337/dc14-2919", "10.1111/0824-7935.00114", "10.1016/j.artmed.2005.03.001", "10.1007/s00779-006-0087-2", "10.1016/j.cmpb.2010.10.007", "10.1177/1098214005283748", "10.1177/1932296814568806", "10.1177/1932296817691305", "10.2337/diaspect.18.3.181"]}, "10.1109/TVCG.2018.2865077": {"doi": "10.1109/TVCG.2018.2865077", "author": ["A. Gogolou", "T. Tsandilas", "T. Palpanas", "A. Bezerianos"], "title": "Comparing Similarity Perception in Time Series Visualizations", "year": "2019", "abstract": "A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.", "keywords": ["data visualisation", "electroencephalography", "time series", "similarity perception", "time series visualizations", "time series data", "similar patterns", "recurring phenomena", "similar temporal sequences", "time series similarity", "automatically generated results", "automatic similarity measures", "line charts", "horizon graphs", "time series results", "similarity constraints", "visual representations", "dynamic time warping", "EEG signals", "colorfields", "Time series analysis", "Task analysis", "Visualization", "Data visualization", "Time measurement", "Electroencephalography", "Encoding", "Time series", "similarity perception", "automatic similarity search", "line charts", "horizon graphs", "colorfields", "evaluation"], "referenced_by": ["IKEY:8807238", "IKEY:8807351", "IKEY:9089446", "10.1145/3377391.3377400", "10.1007/s00371-019-01673-y", "10.3390/data4020074", "10.1111/cgf.13698", "10.1016/j.cmpb.2019.105224", "10.1007/978-3-030-53021-1_8", "10.1016/j.bspc.2020.102135"], "referencing": ["IKEY:6065006", "IKEY:4389007", "IKEY:4658136", "IKEY:4221727", "IKEY:7883519", "IKEY:8365983", "IKEY:5613429", "IKEY:135886", "IKEY:7883518", "IKEY:6155162", "IKEY:6327267", "IKEY:963273", "IKEY:6065009", "IKEY:6065006", "IKEY:4389007", "IKEY:4658136", "IKEY:4221727", "IKEY:7883519", "IKEY:8365983", "IKEY:5613429", "IKEY:135886", "IKEY:7883518", "IKEY:6155162", "IKEY:6327267", "IKEY:963273", "IKEY:6065009", "IKEY:6065006", "IKEY:4389007", "IKEY:4658136", "IKEY:4221727", "IKEY:7883519", "IKEY:8365983", "IKEY:5613429", "IKEY:135886", "IKEY:7883518", "IKEY:6155162", "IKEY:6327267", "IKEY:963273", "IKEY:6065009", "10.1145/2556288.2557200", "10.1145/1385569.1385666", "10.1145/2207676.2208556", "10.1145/2678025.2701379", "10.1145/191839.191925", "10.1145/2470654.2466443", "10.1145/1518701.1518897", "10.1145/1622176.1622217", "10.1145/1133265.1133348", "10.1145/3173574.3173962", "10.1145/1357054.1357286", "10.1145/2814710.2814719", "10.1145/2470654.2466441", "10.1145/2339530.2339576", "10.1145/1056808.1057017", "10.1145/634067.634292", "10.1145/1978942.1979195", "10.1145/2556288.2557200", "10.1145/1385569.1385666", "10.1145/2207676.2208556", "10.1145/2678025.2701379", "10.1145/191839.191925", "10.1145/2470654.2466443", "10.1145/1518701.1518897", "10.1145/1622176.1622217", "10.1145/1133265.1133348", "10.1145/3173574.3173962", "10.1145/1357054.1357286", "10.1145/2814710.2814719", "10.1145/2470654.2466441", "10.1145/2339530.2339576", "10.1145/1056808.1057017", "10.1145/634067.634292", "10.1145/1978942.1979195", "10.1145/2556288.2557200", "10.1145/1385569.1385666", "10.1145/2207676.2208556", "10.1145/2678025.2701379", "10.1145/191839.191925", "10.1145/2470654.2466443", "10.1145/1518701.1518897", "10.1145/1622176.1622217", "10.1145/1133265.1133348", "10.1145/3173574.3173962", "10.1145/1357054.1357286", "10.1145/2814710.2814719", "10.1145/2470654.2466441", "10.1145/2339530.2339576", "10.1145/1056808.1057017", "10.1145/634067.634292", "10.1145/1978942.1979195", "10.1007/978-0-85729-079-3", "10.1007/s10618-013-0312-3", "10.1177/001316448104100307", "10.14778/1454159.1454226", "10.1007/978-3-319-26633-6_13", "10.1080/01621459.1987.10478410", "10.1016/j.engappai.2010.09.007", "10.1007/3-540-60299-2_9", "10.1057/palgrave.ivs.9500061", "10.1016/j.compbiomed.2008.04.010", "10.1016/j.jneumeth.2016.02.025", "10.5698/978-0-9979756-0-4", "10.1016/j.cag.2007.01.032", "10.1016/j.brainresbull.2015.04.007", "10.1111/j.1535-7511.2006.00145.x", "10.1016/j.neulet.2011.03.070", "10.1097/EDE.0b013e3181e5b06a", "10.14778/2824032.2824099", "10.1007/s00778-016-0442-5", "10.1007/978-0-85729-079-3", "10.1007/s10618-013-0312-3", "10.1177/001316448104100307", "10.14778/1454159.1454226", "10.1007/978-3-319-26633-6_13", "10.1080/01621459.1987.10478410", "10.1016/j.engappai.2010.09.007", "10.1007/3-540-60299-2_9", "10.1057/palgrave.ivs.9500061", "10.1016/j.compbiomed.2008.04.010", "10.1016/j.jneumeth.2016.02.025", "10.5698/978-0-9979756-0-4", "10.1016/j.cag.2007.01.032", "10.1016/j.brainresbull.2015.04.007", "10.1111/j.1535-7511.2006.00145.x", "10.1016/j.neulet.2011.03.070", "10.1097/EDE.0b013e3181e5b06a", "10.14778/2824032.2824099", "10.1007/s00778-016-0442-5", "10.1007/978-0-85729-079-3", "10.1007/s10618-013-0312-3", "10.1177/001316448104100307", "10.14778/1454159.1454226", "10.1007/978-3-319-26633-6_13", "10.1080/01621459.1987.10478410", "10.1016/j.engappai.2010.09.007", "10.1007/3-540-60299-2_9", "10.1057/palgrave.ivs.9500061", "10.1016/j.compbiomed.2008.04.010", "10.1016/j.jneumeth.2016.02.025", "10.5698/978-0-9979756-0-4", "10.1016/j.cag.2007.01.032", "10.1016/j.brainresbull.2015.04.007", "10.1111/j.1535-7511.2006.00145.x", "10.1016/j.neulet.2011.03.070", "10.1097/EDE.0b013e3181e5b06a", "10.14778/2824032.2824099", "10.1007/s00778-016-0442-5"]}, "10.1109/TVCG.2018.2865265": {"doi": "10.1109/TVCG.2018.2865265", "author": ["W. K\u00f6pp", "T. Weinkauf"], "title": "Temporal Treemaps: Static Visualization of Evolving Trees", "year": "2019", "abstract": "We consider temporally evolving trees with changing topology and data: tree nodes may persist for a time range, merge or split, and the associated data may change. Essentially, one can think of this as a time series of trees with a node correspondence per hierarchy level between consecutive time steps. Existing visualization approaches for such data include animated 2D treemaps, where the dynamically changing layout makes it difficult to observe the data in its entirety. We present a method to visualize this dynamic data in a static, nested, and space-filling visualization. This is based on two major contributions: First, the layout constitutes a graph drawing problem. We approach it for the entire time span at once using a combination of a heuristic and simulated annealing. Second, we propose a rendering that emphasizes the hierarchy through an adaption of the classic cushion treemaps. We showcase the wide range of applicability using data from feature tracking in time-dependent scalar fields, evolution of file system hierarchies, and world population.", "keywords": ["computer animation", "data visualisation", "tree data structures", "trees (mathematics)", "file system hierarchies", "temporal treemaps", "changing topology", "tree nodes", "associated data", "time series", "node correspondence", "hierarchy level", "consecutive time steps", "visualization approaches", "dynamic data", "static space-filling visualization", "graph drawing problem", "classic cushion treemaps", "time-dependent scalar fields", "nested space-filling visualization", "feature tracking", "Layout", "Data visualization", "Rendering (computer graphics)", "Time series analysis", "Topology", "Regression tree analysis", "Two dimensional displays", "Treemaps", "Temporal trees"], "referenced_by": ["IKEY:8854335", "IKEY:8845772", "IKEY:8807213", "IKEY:8730513"], "referencing": ["IKEY:6065001", "IKEY:4658136", "IKEY:8267086", "IKEY:6875938", "IKEY:8017613", "IKEY:981848", "IKEY:175815", "IKEY:963283", "IKEY:8019841", "IKEY:5521413", "IKEY:6185545", "IKEY:4376152", "IKEY:801860", "IKEY:4658155", "IKEY:1634320", "IKEY:6065001", "IKEY:4658136", "IKEY:8267086", "IKEY:6875938", "IKEY:8017613", "IKEY:981848", "IKEY:175815", "IKEY:963283", "IKEY:8019841", "IKEY:5521413", "IKEY:6185545", "IKEY:4376152", "IKEY:801860", "IKEY:4658155", "IKEY:1634320", "IKEY:6065001", "IKEY:4658136", "IKEY:8267086", "IKEY:6875938", "IKEY:8017613", "IKEY:981848", "IKEY:175815", "IKEY:963283", "IKEY:8019841", "IKEY:5521413", "IKEY:6185545", "IKEY:4376152", "IKEY:801860", "IKEY:4658155", "IKEY:1634320", "10.1145/102377.115768", "10.1145/102377.115768", "10.1145/102377.115768", "10.1111/cgf.12910", "10.1111/cgf.12791", "10.1007/978-1-349-03521-2", "10.1016/S0022-0000(76)80045-1", "10.7155/jgaa.00237", "10.1002/1097-024X(200009)30:11&lt;1203::AID-SPE338&gt;3.3.CO;2-E", "10.1016/S0020-0190(01)00325-8", "10.1007/3-540-56279-6_98", "10.1126/science.220.4598.671", "10.1111/cgf.13164", "10.1007/978-3-319-50106-2_30", "10.1016/j.infsof.2016.10.003", "10.1111/cgf.12910", "10.1111/cgf.12791", "10.1007/978-1-349-03521-2", "10.1016/S0022-0000(76)80045-1", "10.7155/jgaa.00237", "10.1002/1097-024X(200009)30:11&lt;1203::AID-SPE338&gt;3.3.CO;2-E", "10.1016/S0020-0190(01)00325-8", "10.1007/3-540-56279-6_98", "10.1126/science.220.4598.671", "10.1111/cgf.13164", "10.1007/978-3-319-50106-2_30", "10.1016/j.infsof.2016.10.003", "10.1111/cgf.12910", "10.1111/cgf.12791", "10.1007/978-1-349-03521-2", "10.1016/S0022-0000(76)80045-1", "10.7155/jgaa.00237", "10.1002/1097-024X(200009)30:11&lt;1203::AID-SPE338&gt;3.3.CO;2-E", "10.1016/S0020-0190(01)00325-8", "10.1007/3-540-56279-6_98", "10.1126/science.220.4598.671", "10.1111/cgf.13164", "10.1007/978-3-319-50106-2_30", "10.1016/j.infsof.2016.10.003"]}, "10.1109/TVCG.2018.2865149": {"doi": "10.1109/TVCG.2018.2865149", "author": ["C. Nobre", "M. Streit", "A. Lex"], "title": "Juniper: A Tree+Table Approach to Multivariate Graph Visualization", "year": "2019", "abstract": "Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree-table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.", "keywords": ["data visualisation", "matrix algebra", "trees (mathematics)", "Juniper", "tree-table multivariate graph visualization technique", "spanning tree", "interaction techniques", "multivariate networks", "subgraphs", "bipartite network", "multitype network", "hybrid node-link matrix technique", "citation metrics", "adjacency matrix technique", "Task analysis", "Data visualization", "Layout", "Topology", "Visualization", "Network topology", "Encoding", "Multivariate graphs", "networks", "tree-based graph visualization", "adjacency matrix", "spanning trees", "visualization"], "referenced_by": ["IKEY:8812063", "IKEY:8805434", "IKEY:8807233", "IKEY:8933537", "IKEY:8986909"], "referencing": ["IKEY:4658137", "IKEY:1180907", "IKEY:4475479", "IKEY:1532126", "IKEY:4376154", "IKEY:4015425", "IKEY:7583708", "IKEY:1249009", "IKEY:175815", "IKEY:6876017", "IKEY:5429609", "IKEY:8019832", "IKEY:885091", "IKEY:7192717", "IKEY:6875972", "IKEY:5290699", "IKEY:7539669", "IKEY:4658137", "IKEY:1180907", "IKEY:4475479", "IKEY:1532126", "IKEY:4376154", "IKEY:4015425", "IKEY:7583708", "IKEY:1249009", "IKEY:175815", "IKEY:6876017", "IKEY:5429609", "IKEY:8019832", "IKEY:885091", "IKEY:7192717", "IKEY:6875972", "IKEY:5290699", "IKEY:7539669", "IKEY:4658137", "IKEY:1180907", "IKEY:4475479", "IKEY:1532126", "IKEY:4376154", "IKEY:4015425", "IKEY:7583708", "IKEY:1249009", "IKEY:175815", "IKEY:6876017", "IKEY:5429609", "IKEY:8019832", "IKEY:885091", "IKEY:7192717", "IKEY:6875972", "IKEY:5290699", "IKEY:7539669", "10.1145/1385569.1385584", "10.1145/2207676.2208293", "10.1145/1357054.1357074", "10.1145/1168149.1168168", "10.1145/1385569.1385584", "10.1145/2207676.2208293", "10.1145/1357054.1357074", "10.1145/1168149.1168168", "10.1145/1385569.1385584", "10.1145/2207676.2208293", "10.1145/1357054.1357074", "10.1145/1168149.1168168", "10.1111/j.1467-8659.2009.01687.x", "10.1056/NEJMsa066082", "10.1073/pnas.95.25.14863", "10.1038/nmeth.1436", "10.1057/palgrave.ivs.9500092", "10.1007/978-0-387-35504-7_6", "10.1007/978-3-540-74800-7_24", "10.1111/cgf.12642", "10.1007/978-3-319-06793-3", "10.1111/cgf.13184", "10.1093/bioinformatics/btx324", "10.2307/2685881", "10.1093/bioinformatics/btn068", "10.1093/bioinformatics/btp454", "10.1111/j.1467-8659.2012.03110.x", "10.1111/j.1467-8659.2009.01710.x", "10.1007/3-540-37623-2_30", "10.1111/cgf.12883", "10.1093/bioinformatics/btq675", "10.1111/j.1467-8659.2009.01687.x", "10.1056/NEJMsa066082", "10.1073/pnas.95.25.14863", "10.1038/nmeth.1436", "10.1057/palgrave.ivs.9500092", "10.1007/978-0-387-35504-7_6", "10.1007/978-3-540-74800-7_24", "10.1111/cgf.12642", "10.1007/978-3-319-06793-3", "10.1111/cgf.13184", "10.1093/bioinformatics/btx324", "10.2307/2685881", "10.1093/bioinformatics/btn068", "10.1093/bioinformatics/btp454", "10.1111/j.1467-8659.2012.03110.x", "10.1111/j.1467-8659.2009.01710.x", "10.1007/3-540-37623-2_30", "10.1111/cgf.12883", "10.1093/bioinformatics/btq675", "10.1111/j.1467-8659.2009.01687.x", "10.1056/NEJMsa066082", "10.1073/pnas.95.25.14863", "10.1038/nmeth.1436", "10.1057/palgrave.ivs.9500092", "10.1007/978-0-387-35504-7_6", "10.1007/978-3-540-74800-7_24", "10.1111/cgf.12642", "10.1007/978-3-319-06793-3", "10.1111/cgf.13184", "10.1093/bioinformatics/btx324", "10.2307/2685881", "10.1093/bioinformatics/btn068", "10.1093/bioinformatics/btp454", "10.1111/j.1467-8659.2012.03110.x", "10.1111/j.1467-8659.2009.01710.x", "10.1007/3-540-37623-2_30", "10.1111/cgf.12883", "10.1093/bioinformatics/btq675"]}, "10.1109/TVCG.2018.2865139": {"doi": "10.1109/TVCG.2018.2865139", "author": ["W. Chen", "F. Guo", "D. Han", "J. Pan", "X. Nie", "J. Xia", "X. Zhang"], "title": "Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks", "year": "2019", "abstract": "When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.", "keywords": ["data visualisation", "interactive systems", "Internet", "visualized network", "network nodes", "structure-based suggestive exploration approach", "user request", "user interaction", "multiple similar structures", "unexplored structures", "Web-based visual exploration system", "global features", "local features", "vectorized representation", "Visualization", "Navigation", "Engines", "History", "Tools", "Systems support", "Layout", "Large Network Exploration", "Structure-Based Exploration", "Suggestive Exploration"], "referenced_by": ["IKEY:8781856", "IKEY:8805452"], "referencing": ["10.1145/2702123.2702446", "10.1145/1556262.1556300", "10.1145/2339530.2339769", "10.1145/1978942.1978967", "10.1145/2470654.2466444", "10.1145/2016656.2016671", "10.1145/2939672.2939754", "10.1145/1376616.1376660", "10.1145/1150402.1150479", "10.1145/1518701.1519056", "10.1145/2623330.2623732", "10.1145/2909132.2909246", "10.1145/3097983.3098061", "10.1145/1376616.1376675", "10.1145/2702123.2702446", "10.1145/1556262.1556300", "10.1145/2339530.2339769", "10.1145/1978942.1978967", "10.1145/2470654.2466444", "10.1145/2016656.2016671", "10.1145/2939672.2939754", "10.1145/1376616.1376660", "10.1145/1150402.1150479", "10.1145/1518701.1519056", "10.1145/2623330.2623732", "10.1145/2909132.2909246", "10.1145/3097983.3098061", "10.1145/1376616.1376675", "10.1145/2702123.2702446", "10.1145/1556262.1556300", "10.1145/2339530.2339769", "10.1145/1978942.1978967", "10.1145/2470654.2466444", "10.1145/2016656.2016671", "10.1145/2939672.2939754", "10.1145/1376616.1376660", "10.1145/1150402.1150479", "10.1145/1518701.1519056", "10.1145/2623330.2623732", "10.1145/2909132.2909246", "10.1145/3097983.3098061", "10.1145/1376616.1376675", "10.1111/cgf.12397", "10.1002/aris.1440370106", "10.1007/978-1-4613-0303-9_28", "10.1111/j.1467-8659.2011.01957.x", "10.1007/978-3-319-05813-9_11", "10.1111/j.1467-8659.2011.01935.x", "10.1177/1473871612455749", "10.1007/978-3-642-41939-3_4", "10.1007/978-3-540-71681-5_7", "10.7155/jgaa.00150", "10.1371/journal.pone.0098679", "10.1111/cgf.12642", "10.1111/cgf.13184", "10.1007/s00371-013-0892-3", "10.1016/j.comnet.2011.08.019", "10.1111/cgf.12883", "10.1093/bioinformatics/bth436", "10.1111/j.1467-8659.2011.01898.x", "10.14778/1920841.1920887", "10.1111/cgf.12397", "10.1002/aris.1440370106", "10.1007/978-1-4613-0303-9_28", "10.1111/j.1467-8659.2011.01957.x", "10.1007/978-3-319-05813-9_11", "10.1111/j.1467-8659.2011.01935.x", "10.1177/1473871612455749", "10.1007/978-3-642-41939-3_4", "10.1007/978-3-540-71681-5_7", "10.7155/jgaa.00150", "10.1371/journal.pone.0098679", "10.1111/cgf.12642", "10.1111/cgf.13184", "10.1007/s00371-013-0892-3", "10.1016/j.comnet.2011.08.019", "10.1111/cgf.12883", "10.1093/bioinformatics/bth436", "10.1111/j.1467-8659.2011.01898.x", "10.14778/1920841.1920887", "10.1111/cgf.12397", "10.1002/aris.1440370106", "10.1007/978-1-4613-0303-9_28", "10.1111/j.1467-8659.2011.01957.x", "10.1007/978-3-319-05813-9_11", "10.1111/j.1467-8659.2011.01935.x", "10.1177/1473871612455749", "10.1007/978-3-642-41939-3_4", "10.1007/978-3-540-71681-5_7", "10.7155/jgaa.00150", "10.1371/journal.pone.0098679", "10.1111/cgf.12642", "10.1111/cgf.13184", "10.1007/s00371-013-0892-3", "10.1016/j.comnet.2011.08.019", "10.1111/cgf.12883", "10.1093/bioinformatics/bth436", "10.1111/j.1467-8659.2011.01898.x", "10.14778/1920841.1920887"]}, "10.1109/TVCG.2018.2864911": {"doi": "10.1109/TVCG.2018.2864911", "author": ["Y. Wang", "Y. Wang", "H. Zhang", "Y. Sun", "C. Fu", "M. Sedlmair", "B. Chen", "O. Deussen"], "title": "Structure-aware Fisheye Views for Efficient Large Graph Exploration", "year": "2019", "abstract": "Traditional fisheye views for exploring large graphs introduce substantial distortions that often lead to a decreased readability of paths and other interesting structures. To overcome these problems, we propose a framework for structure-aware fisheye views. Using edge orientations as constraints for graph layout optimization allows us not only to reduce spatial and temporal distortions during fisheye zooms, but also to improve the readability of the graph structure. Furthermore, the framework enables us to optimize fisheye lenses towards specific tasks and design a family of new lenses: polyfocal, cluster, and path lenses. A GPU implementation lets us process large graphs with up to 15,000 nodes at interactive rates. A comprehensive evaluation, a user study, and two case studies demonstrate that our structure-aware fisheye views improve layout readability and user performance.", "keywords": ["data visualisation", "graph theory", "lenses", "optimisation", "graph exploration", "edge orientations", "spatial temporal distortions", "GPU implementation", "path lenses", "cluster lenses", "polyfocal lenses", "fisheye lenses", "graph structure", "fisheye zooms", "graph layout optimization", "structure-aware fisheye views", "Layout", "Lenses", "Optimization", "Task analysis", "Distortion", "Visualization", "Sun", "Graph Visualization", "Focus-Context Technique", "Structure-aware Zoom", "Graph Layout Technique"], "referenced_by": ["IKEY:8807379", "IKEY:8807234"], "referencing": ["IKEY:7192681", "IKEY:4015435", "IKEY:4658142", "IKEY:1432691", "IKEY:221135", "IKEY:841119", "IKEY:4475457", "IKEY:6065028", "IKEY:689657", "IKEY:4308636", "IKEY:1648236", "IKEY:5290699", "IKEY:1298802", "IKEY:4376131", "IKEY:8017634", "IKEY:1249008", "IKEY:6327250", "IKEY:7192681", "IKEY:4015435", "IKEY:4658142", "IKEY:1432691", "IKEY:221135", "IKEY:841119", "IKEY:4475457", "IKEY:6065028", "IKEY:689657", "IKEY:4308636", "IKEY:1648236", "IKEY:5290699", "IKEY:1298802", "IKEY:4376131", "IKEY:8017634", "IKEY:1249008", "IKEY:6327250", "IKEY:7192681", "IKEY:4015435", "IKEY:4658142", "IKEY:1432691", "IKEY:221135", "IKEY:841119", "IKEY:4475457", "IKEY:6065028", "IKEY:689657", "IKEY:4308636", "IKEY:1648236", "IKEY:5290699", "IKEY:1298802", "IKEY:4376131", "IKEY:8017634", "IKEY:1249008", "IKEY:6327250", "10.1145/97243.97250", "10.1145/3025453.3025628", "10.1145/22339.22342", "10.1145/223904.223934", "10.1145/586081.586086", "10.1145/223904.223956", "10.1145/1168149.1168168", "10.1145/2898361", "10.1145/1518701.1519056", "10.1145/166117.166125", "10.1145/142750.142763", "10.1145/97243.97250", "10.1145/3025453.3025628", "10.1145/22339.22342", "10.1145/223904.223934", "10.1145/586081.586086", "10.1145/223904.223956", "10.1145/1168149.1168168", "10.1145/2898361", "10.1145/1518701.1519056", "10.1145/166117.166125", "10.1145/142750.142763", "10.1145/97243.97250", "10.1145/3025453.3025628", "10.1145/22339.22342", "10.1145/223904.223934", "10.1145/586081.586086", "10.1145/223904.223956", "10.1145/1168149.1168168", "10.1145/2898361", "10.1145/1518701.1519056", "10.1145/166117.166125", "10.1145/142750.142763", "10.1112/jlms/s2-18.3.475", "10.1111/j.1467-8659.2009.01687.x", "10.1016/S1389-1286(00)00083-9", "10.1111/j.1467-8659.2009.01449.x", "10.1007/3-540-63938-1_77", "10.1007/978-3-319-27261-0_41", "10.1177/1473871612455749", "10.1179/caj.1978.15.1.36", "10.1016/0020-0190(89)90102-6", "10.1073/pnas.0601602103", "10.1007/978-3-319-06793-3_5", "10.1007/3-540-63938-1_67", "10.1093/bioinformatics/btq675", "10.1016/j.isprsjprs.2016.03.013", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01898.x", "10.1112/jlms/s2-18.3.475", "10.1111/j.1467-8659.2009.01687.x", "10.1016/S1389-1286(00)00083-9", "10.1111/j.1467-8659.2009.01449.x", "10.1007/3-540-63938-1_77", "10.1007/978-3-319-27261-0_41", "10.1177/1473871612455749", "10.1179/caj.1978.15.1.36", "10.1016/0020-0190(89)90102-6", "10.1073/pnas.0601602103", "10.1007/978-3-319-06793-3_5", "10.1007/3-540-63938-1_67", "10.1093/bioinformatics/btq675", "10.1016/j.isprsjprs.2016.03.013", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01898.x", "10.1112/jlms/s2-18.3.475", "10.1111/j.1467-8659.2009.01687.x", "10.1016/S1389-1286(00)00083-9", "10.1111/j.1467-8659.2009.01449.x", "10.1007/3-540-63938-1_77", "10.1007/978-3-319-27261-0_41", "10.1177/1473871612455749", "10.1179/caj.1978.15.1.36", "10.1016/0020-0190(89)90102-6", "10.1073/pnas.0601602103", "10.1007/978-3-319-06793-3_5", "10.1007/3-540-63938-1_67", "10.1093/bioinformatics/btq675", "10.1016/j.isprsjprs.2016.03.013", "10.1016/j.cag.2009.06.002", "10.1111/j.1467-8659.2011.01898.x"]}, "10.1109/TVCG.2018.2865151": {"doi": "10.1109/TVCG.2018.2865151", "author": ["T. Major", "R. C. Basole"], "title": "Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach", "year": "2019", "abstract": "Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach.", "keywords": ["data visualisation", "network structure", "visualization systems", "blended visualization approach", "unit visualization techniques", "Graphicle", "relational data", "multivariate data", "visual exploration", "network visualizations", "Data visualization", "Layout", "Visualization", "Medical services", "Aggregates", "Bars", "Organizations", "Unit visualization", "network visualization", "context"], "referenced_by": ["IKEY:8812063", "IKEY:8967136", "IKEY:9104977"], "referencing": ["IKEY:4447668", "IKEY:6327277", "IKEY:5184827", "IKEY:4376146", "IKEY:4376154", "IKEY:841119", "IKEY:6875946", "IKEY:6634152", "IKEY:1648235", "IKEY:6113135", "IKEY:545307", "IKEY:4015424", "IKEY:6875972", "IKEY:5290699", "IKEY:1249004", "IKEY:5613448", "IKEY:4376132", "IKEY:5333880", "IKEY:6634163", "IKEY:4447668", "IKEY:6327277", "IKEY:5184827", "IKEY:4376146", "IKEY:4376154", "IKEY:841119", "IKEY:6875946", "IKEY:6634152", "IKEY:1648235", "IKEY:6113135", "IKEY:545307", "IKEY:4015424", "IKEY:6875972", "IKEY:5290699", "IKEY:1249004", "IKEY:5613448", "IKEY:4376132", "IKEY:5333880", "IKEY:6634163", "IKEY:4447668", "IKEY:6327277", "IKEY:5184827", "IKEY:4376146", "IKEY:4376154", "IKEY:841119", "IKEY:6875946", "IKEY:6634152", "IKEY:1648235", "IKEY:6113135", "IKEY:545307", "IKEY:4015424", "IKEY:6875972", "IKEY:5290699", "IKEY:1249004", "IKEY:5613448", "IKEY:4376132", "IKEY:5333880", "IKEY:6634163", "10.1145/2702123.2702446", "10.1145/2470654.2466444", "10.1145/22627.22342", "10.1145/336597.336637", "10.1145/1124772.1124851", "10.1145/1124772.1124891", "10.1145/2702123.2702446", "10.1145/2470654.2466444", "10.1145/22627.22342", "10.1145/336597.336637", "10.1145/1124772.1124851", "10.1145/1124772.1124891", "10.1145/2702123.2702446", "10.1145/2470654.2466444", "10.1145/22627.22342", "10.1145/336597.336637", "10.1145/1124772.1124851", "10.1145/1124772.1124891", "10.1111/j.1467-8659.2009.01687.x", "10.1057/palgrave.ivs.9500003", "10.1111/j.1467-8659.2008.01231.x", "10.1006/ijhc.2002.1017", "10.1111/j.1467-8659.2011.01898.x", "10.2307/2686111", "10.30770/2572-1852-103.2.7", "10.1111/j.1467-8659.2009.01687.x", "10.1057/palgrave.ivs.9500003", "10.1111/j.1467-8659.2008.01231.x", "10.1006/ijhc.2002.1017", "10.1111/j.1467-8659.2011.01898.x", "10.2307/2686111", "10.30770/2572-1852-103.2.7", "10.1111/j.1467-8659.2009.01687.x", "10.1057/palgrave.ivs.9500003", "10.1111/j.1467-8659.2008.01231.x", "10.1006/ijhc.2002.1017", "10.1111/j.1467-8659.2011.01898.x", "10.2307/2686111", "10.30770/2572-1852-103.2.7"]}, "10.1109/TVCG.2018.2865144": {"doi": "10.1109/TVCG.2018.2865144", "author": ["S. K. Badam", "A. Mathisen", "R. R\u00e4dle", "C. N. Klokmose", "N. Elmqvist"], "title": "Vistrates: A Component Model for Ubiquitous Analytics", "year": "2019", "abstract": "Visualization tools are often specialized for specific tasks, which turns the user's analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where components-the building blocks of this model-can be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce Vistrates, a literate computing platform for developing, assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective, Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic \u201canytime\u201d and \u201canywhere\u201d motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices..", "keywords": ["data analysis", "data visualisation", "object-oriented programming", "software reusability", "ubiquitous computing", "ubiquitous analytics", "visualization tools", "component model design", "data visualization", "modular designs", "visualization perspective", "Vistrates features", "visual representations", "component repository", "component pipelines", "visualization components", "JavaScript", "Python source code", "Data visualization", "Tools", "Collaboration", "Media", "Substrates", "Task analysis", "Data analysis", "Components", "literate computing", "development", "exploration", "dissemination", "collaboration", "heterogeneous devices"], "referenced_by": ["IKEY:8914209", "IKEY:8945039", "IKEY:9034060", "IKEY:9127201"], "referencing": ["10.1145/245882.245893", "10.1145/1753326.1753336", "10.1145/2858036.2858387", "10.1145/2669485.2669518", "10.1145/332040.332473", "10.1145/989863.989865", "10.1145/3125571.3125602", "10.1145/3170427.3188563", "10.1145/289444.289495", "10.1145/1240624.1240781", "10.1145/3173574.3173593", "10.1145/2807442.2807446", "10.1145/3173574.3173697", "10.1145/2396636.2396673", "10.1145/2858036.2858435", "10.1145/3173574.3173973", "10.1145/3126594.3126642", "10.1145/2642918.2647360", "10.1145/27636.28056", "10.1145/1118178.1118215", "10.1145/245882.245893", "10.1145/1753326.1753336", "10.1145/2858036.2858387", "10.1145/2669485.2669518", "10.1145/332040.332473", "10.1145/989863.989865", "10.1145/3125571.3125602", "10.1145/3170427.3188563", "10.1145/289444.289495", "10.1145/1240624.1240781", "10.1145/3173574.3173593", "10.1145/2807442.2807446", "10.1145/3173574.3173697", "10.1145/2396636.2396673", "10.1145/2858036.2858435", "10.1145/3173574.3173973", "10.1145/3126594.3126642", "10.1145/2642918.2647360", "10.1145/27636.28056", "10.1145/1118178.1118215", "10.1145/245882.245893", "10.1145/1753326.1753336", "10.1145/2858036.2858387", "10.1145/2669485.2669518", "10.1145/332040.332473", "10.1145/989863.989865", "10.1145/3125571.3125602", "10.1145/3170427.3188563", "10.1145/289444.289495", "10.1145/1240624.1240781", "10.1145/3173574.3173593", "10.1145/2807442.2807446", "10.1145/3173574.3173697", "10.1145/2396636.2396673", "10.1145/2858036.2858435", "10.1145/3173574.3173973", "10.1145/3126594.3126642", "10.1145/2642918.2647360", "10.1145/27636.28056", "10.1145/1118178.1118215", "10.1177/1473871617725907", "10.1007/s00779-013-0727-2", "10.1177/1473871617752910", "10.1057/palgrave.ivs.9500167", "10.1177/1473871611412817", "10.1111/j.1467-8659.2009.01444.x", "10.1177/1473871612441874", "10.1111/cgf.13206", "10.1111/cgf.12129", "10.1111/cgf.12392", "10.1038/515151a", "10.1108/eb026526", "10.1016/0020-7373(91)90039-A", "10.1038/scientificamerican0991-94", "10.1177/1473871617725907", "10.1007/s00779-013-0727-2", "10.1177/1473871617752910", "10.1057/palgrave.ivs.9500167", "10.1177/1473871611412817", "10.1111/j.1467-8659.2009.01444.x", "10.1177/1473871612441874", "10.1111/cgf.13206", "10.1111/cgf.12129", "10.1111/cgf.12392", "10.1038/515151a", "10.1108/eb026526", "10.1016/0020-7373(91)90039-A", "10.1038/scientificamerican0991-94", "10.1177/1473871617725907", "10.1007/s00779-013-0727-2", "10.1177/1473871617752910", "10.1057/palgrave.ivs.9500167", "10.1177/1473871611412817", "10.1111/j.1467-8659.2009.01444.x", "10.1177/1473871612441874", "10.1111/cgf.13206", "10.1111/cgf.12129", "10.1111/cgf.12392", "10.1038/515151a", "10.1108/eb026526", "10.1016/0020-7373(91)90039-A", "10.1038/scientificamerican0991-94"]}, "10.1109/TVCG.2018.2865231": {"doi": "10.1109/TVCG.2018.2865231", "author": ["H. Subramonyam", "E. Adar"], "title": "SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays", "year": "2019", "abstract": "Details-on-demand is a crucial feature in the visual information-seeking process but is often only implemented in highly constrained settings. The most common solution, hover queries (i.e., tooltips), are fast and expressive but are usually limited to single mark (e.g., a bar in a bar chart). `Queries' to retrieve details for more complex sets of objects (e.g., comparisons between pairs of elements, averages across multiple items, trend lines, etc.) are difficult for end-users to invoke explicitly. Further, the output of these queries require complex annotations and overlays which need to be displayed and dismissed on demand to avoid clutter. In this work we introduce SmartCues, a library to support details-on-demand through dynamically computed overlays. For end-users, SmartCues provides multitouch interactions to construct complex queries for a variety of details. For designers, SmartCues offers an interaction library that can be used out-of-the-box, and can be extended for new charts and detail types. We demonstrate how SmartCues can be implemented across a wide array of visualization types and, through a lab study, show that end users can effectively use SmartCues.", "keywords": ["data visualisation", "interactive systems", "query processing", "multitouch query approach", "details-on-demand", "dynamically computed overlays", "visual information-seeking process", "highly constrained settings", "complex annotations", "multitouch interactions", "complex queries", "end users", "smartcues", "Bars", "US Department of Defense", "Task analysis", "Visualization", "Data visualization", "Libraries", "Color", "Graphical overlays", "details-on-demand", "graph comprehension"], "referenced_by": [], "referencing": ["IKEY:528688", "IKEY:1532136", "IKEY:6064996", "IKEY:6634168", "IKEY:1215008", "IKEY:4015436", "IKEY:5652885", "IKEY:6634182", "IKEY:6400487", "IKEY:1648235", "IKEY:6875985", "IKEY:6327269", "IKEY:4658124", "IKEY:6327275", "IKEY:8031599", "IKEY:5613452", "IKEY:545307", "IKEY:8017606", "IKEY:4376144", "IKEY:528688", "IKEY:1532136", "IKEY:6064996", "IKEY:6634168", "IKEY:1215008", "IKEY:4015436", "IKEY:5652885", "IKEY:6634182", "IKEY:6400487", "IKEY:1648235", "IKEY:6875985", "IKEY:6327269", "IKEY:4658124", "IKEY:6327275", "IKEY:8031599", "IKEY:5613452", "IKEY:545307", "IKEY:8017606", "IKEY:4376144", "IKEY:528688", "IKEY:1532136", "IKEY:6064996", "IKEY:6634168", "IKEY:1215008", "IKEY:4015436", "IKEY:5652885", "IKEY:6634182", "IKEY:6400487", "IKEY:1648235", "IKEY:6875985", "IKEY:6327269", "IKEY:4658124", "IKEY:6327275", "IKEY:8031599", "IKEY:5613452", "IKEY:545307", "IKEY:8017606", "IKEY:4376144", "10.1145/245882.245893", "10.1145/2470654.2466143", "10.1145/2396636.2396675", "10.1145/212332.212334", "10.1145/175276.175283", "10.1145/2470654.2481318", "10.1145/2807442.2807478", "10.1145/1357054.1357203", "10.1145/2133806.2133821", "10.1145/1240624.1240781", "10.1145/302979.303030", "10.1145/2470654.2481374", "10.1145/1753326.1753654", "10.1145/2556288.2557231", "10.1145/2598153.2598163", "10.1145/2992154.2992157", "10.1145/2047196.2047227", "10.1145/238218.238281", "10.1145/2449396.2449439", "10.1145/345513.345271", "10.1145/245882.245893", "10.1145/2470654.2466143", "10.1145/2396636.2396675", "10.1145/212332.212334", "10.1145/175276.175283", "10.1145/2470654.2481318", "10.1145/2807442.2807478", "10.1145/1357054.1357203", "10.1145/2133806.2133821", "10.1145/1240624.1240781", "10.1145/302979.303030", "10.1145/2470654.2481374", "10.1145/1753326.1753654", "10.1145/2556288.2557231", "10.1145/2598153.2598163", "10.1145/2992154.2992157", "10.1145/2047196.2047227", "10.1145/238218.238281", "10.1145/2449396.2449439", "10.1145/345513.345271", "10.1145/245882.245893", "10.1145/2470654.2466143", "10.1145/2396636.2396675", "10.1145/212332.212334", "10.1145/175276.175283", "10.1145/2470654.2481318", "10.1145/2807442.2807478", "10.1145/1357054.1357203", "10.1145/2133806.2133821", "10.1145/1240624.1240781", "10.1145/302979.303030", "10.1145/2470654.2481374", "10.1145/1753326.1753654", "10.1145/2556288.2557231", "10.1145/2598153.2598163", "10.1145/2992154.2992157", "10.1145/2047196.2047227", "10.1145/238218.238281", "10.1145/2449396.2449439", "10.1145/345513.345271", "10.1007/978-3-642-31223-6_13", "10.1007/978-3-540-87730-1_30", "10.1037/1076-898X.4.2.75", "10.2307/2288400", "10.1007/11783183_5", "10.2307/749671", "10.1007/978-3-642-19917-2_11", "10.1177/1473871611406623", "10.1006/jvlc.1996.0009", "10.1002/acp.2350030302", "10.1207/s15327051hci0804_3", "10.1016/j.learninstruc.2011.02.002", "10.14778/2732240.2732247", "10.1080/01621459.1987.10478448", "10.1007/978-3-540-76856-2_64", "10.1007/978-3-642-31223-6_13", "10.1007/978-3-540-87730-1_30", "10.1037/1076-898X.4.2.75", "10.2307/2288400", "10.1007/11783183_5", "10.2307/749671", "10.1007/978-3-642-19917-2_11", "10.1177/1473871611406623", "10.1006/jvlc.1996.0009", "10.1002/acp.2350030302", "10.1207/s15327051hci0804_3", "10.1016/j.learninstruc.2011.02.002", "10.14778/2732240.2732247", "10.1080/01621459.1987.10478448", "10.1007/978-3-540-76856-2_64", "10.1007/978-3-642-31223-6_13", "10.1007/978-3-540-87730-1_30", "10.1037/1076-898X.4.2.75", "10.2307/2288400", "10.1007/11783183_5", "10.2307/749671", "10.1007/978-3-642-19917-2_11", "10.1177/1473871611406623", "10.1006/jvlc.1996.0009", "10.1002/acp.2350030302", "10.1207/s15327051hci0804_3", "10.1016/j.learninstruc.2011.02.002", "10.14778/2732240.2732247", "10.1080/01621459.1987.10478448", "10.1007/978-3-540-76856-2_64"]}, "10.1109/TVCG.2018.2865235": {"doi": "10.1109/TVCG.2018.2865235", "author": ["R. Langner", "U. Kister", "R. Dachselt"], "title": "Multiple Coordinated Views at Large Displays for Multiple Users: Empirical Findings on User Behavior, Movements, and Distances", "year": "2019", "abstract": "Interactive wall-sized displays benefit data visualization. Due to their sheer display size, they make it possible to show large amounts of data in multiple coordinated views (MCV) and facilitate collaborative data analysis. In this work, we propose a set of important design considerations and contribute a fundamental input vocabulary and interaction mapping for MCV functionality. We also developed a fully functional application with more than 45 coordinated views visualizing a real-world, multivariate data set of crime activities, which we used in a comprehensive qualitative user study investigating how pairs of users behave. Most importantly, we found that flexible movement is essential and-depending on user goals-is connected to collaboration, perception, and interaction. Therefore, we argue that for future systems interaction from the distance is required and needs good support. We show that our consistent design for both direct touch at the large display and distant interaction using mobile phones enables the seamless exploration of large-scale MCV at wall-sized displays. Our MCV application builds on design aspects such as simplicity, flexibility, and visual consistency and, therefore, supports realistic workflows. We believe that in the future, many visual data analysis scenarios will benefit from wall-sized displays presenting numerous coordinated visualizations, for which our findings provide a valuable foundation.", "keywords": ["data analysis", "data visualisation", "groupware", "interactive systems", "smart phones", "touch sensitive screens", "distant interaction", "large-scale MCV", "user behavior", "interactive wall-sized displays", "data visualization", "multiple coordinated views", "collaborative data analysis", "fully functional application", "multivariate data set", "visual data analysis", "systems interaction", "input vocabulary", "interaction mapping", "direct touch", "mobile phones", "coordinated visualizations", "Data visualization", "Collaboration", "Visualization", "Mobile handsets", "Data analysis", "Tools", "Task analysis", "Multiple coordinated views", "wall-sized displays", "mobile devices", "distant interaction", "physical navigation", "user behavior", "user movements", "multi-user", "collaborative data analysis"], "referenced_by": ["IKEY:8919878", "IKEY:8933655", "IKEY:9307756"], "referencing": ["10.1145/1753326.1753336", "10.1145/2317956.2318025", "10.1145/1240624.1240656", "10.1145/2207676.2208297", "10.1145/2396636.2396675", "10.1145/2207676.2208639", "10.1145/2556288.2556956", "10.1145/2254556.2254708", "10.1145/1518701.1518704", "10.1145/2557500.2557541", "10.1145/2470654.2481318", "10.1145/1897239.1897250", "10.1145/2556288.2557170", "10.1145/1099203.1099209", "10.1145/3173574.3173593", "10.1145/2576099", "10.1145/2702123.2702312", "10.1145/2207676.2208691", "10.1145/2817721.2817726", "10.1145/2785830.2785849", "10.1145/2858036.2858039", "10.1145/3025453.3025594", "10.1145/2556288.2557020", "10.1145/2380116.2380121", "10.1145/3206505.3206506", "10.1145/2817721.2817735", "10.1145/2702123.2702406", "10.1145/2254556.2254652", "10.1145/2556288.2557231", "10.1145/2992154.2992157", "10.1145/1031607.1031655", "10.1145/2207676.2208690", "10.1145/3173574.3173747", "10.1145/2470654.2470695", "10.1145/1124772.1124950", "10.1145/1936652.1936693", "10.1145/1731903.1731926", "10.1145/2669485.2669507", "10.1145/3025453.3026006", "10.1145/2858036.2858118", "10.1145/1753326.1753336", "10.1145/2317956.2318025", "10.1145/1240624.1240656", "10.1145/2207676.2208297", "10.1145/2396636.2396675", "10.1145/2207676.2208639", "10.1145/2556288.2556956", "10.1145/2254556.2254708", "10.1145/1518701.1518704", "10.1145/2557500.2557541", "10.1145/2470654.2481318", "10.1145/1897239.1897250", "10.1145/2556288.2557170", "10.1145/1099203.1099209", "10.1145/3173574.3173593", "10.1145/2576099", "10.1145/2702123.2702312", "10.1145/2207676.2208691", "10.1145/2817721.2817726", "10.1145/2785830.2785849", "10.1145/2858036.2858039", "10.1145/3025453.3025594", "10.1145/2556288.2557020", "10.1145/2380116.2380121", "10.1145/3206505.3206506", "10.1145/2817721.2817735", "10.1145/2702123.2702406", "10.1145/2254556.2254652", "10.1145/2556288.2557231", "10.1145/2992154.2992157", "10.1145/1031607.1031655", "10.1145/2207676.2208690", "10.1145/3173574.3173747", "10.1145/2470654.2470695", "10.1145/1124772.1124950", "10.1145/1936652.1936693", "10.1145/1731903.1731926", "10.1145/2669485.2669507", "10.1145/3025453.3026006", "10.1145/2858036.2858118", "10.1145/1753326.1753336", "10.1145/2317956.2318025", "10.1145/1240624.1240656", "10.1145/2207676.2208297", "10.1145/2396636.2396675", "10.1145/2207676.2208639", "10.1145/2556288.2556956", "10.1145/2254556.2254708", "10.1145/1518701.1518704", "10.1145/2557500.2557541", "10.1145/2470654.2481318", "10.1145/1897239.1897250", "10.1145/2556288.2557170", "10.1145/1099203.1099209", "10.1145/3173574.3173593", "10.1145/2576099", "10.1145/2702123.2702312", "10.1145/2207676.2208691", "10.1145/2817721.2817726", "10.1145/2785830.2785849", "10.1145/2858036.2858039", "10.1145/3025453.3025594", "10.1145/2556288.2557020", "10.1145/2380116.2380121", "10.1145/3206505.3206506", "10.1145/2817721.2817735", "10.1145/2702123.2702406", "10.1145/2254556.2254652", "10.1145/2556288.2557231", "10.1145/2992154.2992157", "10.1145/1031607.1031655", "10.1145/2207676.2208690", "10.1145/3173574.3173747", "10.1145/2470654.2470695", "10.1145/1124772.1124950", "10.1145/1936652.1936693", "10.1145/1731903.1731926", "10.1145/2669485.2669507", "10.1145/3025453.3026006", "10.1145/2858036.2858118", "10.1177/1473871611415997", "10.1177/1473871617725907", "10.1016/j.cag.2007.01.029", "10.1007/s00779-013-0727-2", "10.1111/j.1467-8659.2009.01444.x", "10.1007/978-3-319-22698-9_31", "10.1111/cgf.13206", "10.1111/cgf.12871", "10.1177/1473871611415997", "10.1177/1473871617725907", "10.1016/j.cag.2007.01.029", "10.1007/s00779-013-0727-2", "10.1111/j.1467-8659.2009.01444.x", "10.1007/978-3-319-22698-9_31", "10.1111/cgf.13206", "10.1111/cgf.12871", "10.1177/1473871611415997", "10.1177/1473871617725907", "10.1016/j.cag.2007.01.029", "10.1007/s00779-013-0727-2", "10.1111/j.1467-8659.2009.01444.x", "10.1007/978-3-319-22698-9_31", "10.1111/cgf.13206", "10.1111/cgf.12871"]}, "10.1109/TVCG.2018.2865234": {"doi": "10.1109/TVCG.2018.2865234", "author": ["M. Brehmer", "B. Lee", "P. Isenberg", "E. K. Choe"], "title": "Visualizing Ranges over Time on Mobile Phones: A Task-Based Crowdsourced Evaluation", "year": "2019", "abstract": "In the first crowdsourced visualization experiment conducted exclusively on mobile phones, we compare approaches to visualizing ranges over time on small displays. People routinely consume such data via a mobile phone, from temperatures in weather forecasting apps to sleep and blood pressure readings in personal health apps. However, we lack guidance on how to effectively visualize ranges on small displays in the context of different value retrieval and comparison tasks, or with respect to different data characteristics such as periodicity, seasonality, or the cardinality of ranges. Central to our experiment is a comparison between two ways to lay out ranges: a more conventional linear layout strikes a balance between quantitative and chronological scale resolution, while a less conventional radial layout emphasizes the cyclicality of time and may prioritize discrimination between values at its periphery. With results from 87 crowd workers, we found that while participants completed tasks more quickly with linear layouts than with radial ones, there were few differences in terms of error rate between layout conditions. We also found that participants performed similarly with both layouts in tasks that involved comparing superimposed observed and average ranges.", "keywords": ["crowdsourcing", "data visualisation", "Internet", "mobile computing", "smart phones", "data characteristics", "personal health apps", "blood pressure readings", "weather forecasting apps", "crowdsourced visualization experiment", "task-based crowdsourced evaluation", "mobile phone", "visualizing ranges", "linear layouts", "Data visualization", "Mobile handsets", "Temperature distribution", "Layout", "Task analysis", "Encoding", "Meteorology", "Evaluation", "graphical perception", "mobile phones", "range visualization", "crowdsourcing"], "referenced_by": ["IKEY:8805467", "IKEY:8807238", "IKEY:8805428"], "referencing": ["IKEY:6064996", "IKEY:6634168", "IKEY:5613430", "IKEY:4770098", "IKEY:7445239", "IKEY:5613429", "IKEY:7274257", "IKEY:4388994", "IKEY:6064996", "IKEY:6634168", "IKEY:5613430", "IKEY:4770098", "IKEY:7445239", "IKEY:5613429", "IKEY:7274257", "IKEY:4388994", "IKEY:6064996", "IKEY:6634168", "IKEY:5613430", "IKEY:4770098", "IKEY:7445239", "IKEY:5613429", "IKEY:7274257", "IKEY:4388994", "10.1145/2632048.2632100", "10.1145/2858036.2858300", "10.1145/2556288.2557200", "10.1145/2396636.2396675", "10.1145/2993901.2993906", "10.1145/1133265.1133364", "10.1145/2750858.2804266", "10.1145/2470654.2481318", "10.1145/2470654.2466443", "10.1145/1753326.1753357", "10.1145/2858036.2858558", "10.1145/3170427.3170631", "10.1145/1753326.1753679", "10.1145/2786567.2786571", "10.1145/2632048.2632100", "10.1145/2858036.2858300", "10.1145/2556288.2557200", "10.1145/2396636.2396675", "10.1145/2993901.2993906", "10.1145/1133265.1133364", "10.1145/2750858.2804266", "10.1145/2470654.2481318", "10.1145/2470654.2466443", "10.1145/1753326.1753357", "10.1145/2858036.2858558", "10.1145/3170427.3170631", "10.1145/1753326.1753679", "10.1145/2786567.2786571", "10.1145/2632048.2632100", "10.1145/2858036.2858300", "10.1145/2556288.2557200", "10.1145/2396636.2396675", "10.1145/2993901.2993906", "10.1145/1133265.1133364", "10.1145/2750858.2804266", "10.1145/2470654.2481318", "10.1145/2470654.2466443", "10.1145/1753326.1753357", "10.1145/2858036.2858558", "10.1145/3170427.3170631", "10.1145/1753326.1753679", "10.1145/2786567.2786571", "10.1002/smi.1292", "10.1007/978-3-319-66435-4_5", "http://", "10.2307/2288400", "https://", "10.1007/978-3-319-26633-6_13", "10.1038/nmeth.2659", "10.1201/9781315281575-6", "10.1201/b17511", "10.1002/smi.1292", "10.1007/978-3-319-66435-4_5", "http://", "10.2307/2288400", "https://", "10.1007/978-3-319-26633-6_13", "10.1038/nmeth.2659", "10.1201/9781315281575-6", "10.1201/b17511", "10.1002/smi.1292", "10.1007/978-3-319-66435-4_5", "http://", "10.2307/2288400", "https://", "10.1007/978-3-319-26633-6_13", "10.1038/nmeth.2659", "10.1201/9781315281575-6", "10.1201/b17511"]}, "10.1109/TVCG.2018.2865142": {"doi": "10.1109/TVCG.2018.2865142", "author": ["T. Blascheck", "L. Besan\u00e7on", "A. Bezerianos", "B. Lee", "P. Isenberg"], "title": "Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches", "year": "2019", "abstract": "We present the results of two perception studies to assess how quickly people can perform a simple data comparison task for small-scale visualizations on a smartwatch. The main goal of these studies is to extend our understanding of design constraints for smartwatch visualizations. Previous work has shown that a vast majority of smartwatch interactions last under 5 s. It is still unknown what people can actually perceive from visualizations during such short glances, in particular with such a limited display space of smartwatches. To shed light on this question, we conducted two perception studies that assessed the lower bounds of task time for a simple data comparison task. We tested three chart types common on smartwatches: bar charts, donut charts, and radial bar charts with three different data sizes: 7, 12, and 24 data values. In our first study, we controlled the differences of the two target bars to be compared, while the second study varied the difference randomly. For both studies, we found that participants performed the task on average in <;300 ms for the bar chart, <;220 ms for the donut chart, and in <; 1780 ms for the radial bar chart. Thresholds in the second study per chart type were on average 1.14-1.35\u00d7 higher than in the first study. Our results show that bar and donut charts should be preferred on smartwatch displays when quick data comparisons are necessary.", "keywords": ["computer displays", "data visualisation", "human computer interaction", "mobile computing", "user interfaces", "visual perception", "donut chart", "radial bar chart", "chart type", "smartwatch displays", "glanceable visualization", "data comparison performance", "perception studies", "small-scale visualizations", "smartwatch interactions", "data sizes", "smartwatch visualization design constraints", "time 5.0 s", "Data visualization", "Bars", "Task analysis", "Visualization", "Human computer interaction", "Indexes", "Glanceable visualization", "smartwatch", "perception", "quantitative evaluation", "data comparison"], "referenced_by": ["IKEY:8794768", "IKEY:8807238", "IKEY:8805428"], "referencing": ["IKEY:7864462", "IKEY:6787200", "IKEY:7445239", "IKEY:7593375", "IKEY:6875917", "IKEY:6327245", "IKEY:5613429", "IKEY:6634087", "IKEY:6155162", "IKEY:6327267", "IKEY:6876021", "IKEY:4376132", "IKEY:7864462", "IKEY:6787200", "IKEY:7445239", "IKEY:7593375", "IKEY:6875917", "IKEY:6327245", "IKEY:5613429", "IKEY:6634087", "IKEY:6155162", "IKEY:6327267", "IKEY:6876021", "IKEY:4376132", "IKEY:7864462", "IKEY:6787200", "IKEY:7445239", "IKEY:7593375", "IKEY:6875917", "IKEY:6327245", "IKEY:5613429", "IKEY:6634087", "IKEY:6155162", "IKEY:6327267", "IKEY:6876021", "IKEY:4376132", "10.1145/2807442.2807499", "10.1145/2971648.2971754", "10.1145/1518701.1518897", "10.1145/3173574.3173593", "10.1145/2802083.2802085", "10.1145/2702123.2702226", "10.1145/3025453.3025817", "10.1145/2807442.2807499", "10.1145/2971648.2971754", "10.1145/1518701.1518897", "10.1145/3173574.3173593", "10.1145/2802083.2802085", "10.1145/2702123.2702226", "10.1145/3025453.3025817", "10.1145/2807442.2807499", "10.1145/2971648.2971754", "10.1145/1518701.1518897", "10.1145/3173574.3173593", "10.1145/2802083.2802085", "10.1145/2702123.2702226", "10.1145/3025453.3025817", "10.1111/cgf.12104", "10.2307/2288400", "10.1007/978-3-319-26633-6_13", "10.1016/S0042-6989(97)00340-4", "10.1016/j.socec.2004.09.033", "10.7326/0003-4819-130-12-199906150-00008", "10.1111/j.1467-9280.2009.02316.x", "10.1111/j.1540-5907.2011.00525.x", "10.1038/nmeth.2659", "10.1080/00335558008248231", "10.1111/cgf.12888", "10.1016/0010-0277(84)90023-4", "10.1057/palgrave.ivs.9500025", "10.1007/978-3-540-33037-0_8", "10.1038/nature06860", "10.1111/cgf.12104", "10.2307/2288400", "10.1007/978-3-319-26633-6_13", "10.1016/S0042-6989(97)00340-4", "10.1016/j.socec.2004.09.033", "10.7326/0003-4819-130-12-199906150-00008", "10.1111/j.1467-9280.2009.02316.x", "10.1111/j.1540-5907.2011.00525.x", "10.1038/nmeth.2659", "10.1080/00335558008248231", "10.1111/cgf.12888", "10.1016/0010-0277(84)90023-4", "10.1057/palgrave.ivs.9500025", "10.1007/978-3-540-33037-0_8", "10.1038/nature06860", "10.1111/cgf.12104", "10.2307/2288400", "10.1007/978-3-319-26633-6_13", "10.1016/S0042-6989(97)00340-4", "10.1016/j.socec.2004.09.033", "10.7326/0003-4819-130-12-199906150-00008", "10.1111/j.1467-9280.2009.02316.x", "10.1111/j.1540-5907.2011.00525.x", "10.1038/nmeth.2659", "10.1080/00335558008248231", "10.1111/cgf.12888", "10.1016/0010-0277(84)90023-4", "10.1057/palgrave.ivs.9500025", "10.1007/978-3-540-33037-0_8", "10.1038/nature06860"]}, "10.1109/TVCG.2018.2865138": {"doi": "10.1109/TVCG.2018.2865138", "author": ["D. Haehn", "J. Tompkin", "H. Pfister"], "title": "Evaluating \u2018Graphical Perception\u2019 with CNNs", "year": "2019", "abstract": "Convolutional neural networks can successfully perform many computer vision tasks on images. For visualization, how do CNNs perform when applied to graphical perception tasks? We investigate this question by reproducing Cleveland and McGill's seminal 1984 experiments, which measured human perception efficiency of different visual encodings and defined elementary perceptual tasks for visualization. We measure the graphical perceptual capabilities of four network architectures on five different visualization tasks and compare to existing and new human performance baselines. While under limited circumstances CNNs are able to meet or outperform human task performance, we find that CNNs are not currently a good model for human graphical perception. We present the results of these experiments to foster the understanding of how CNNs succeed and fail when applied to data visualizations.", "keywords": ["computer vision", "convolution", "data visualisation", "feedforward neural nets", "human factors", "visual perception", "human graphical perception", "data visualizations", "convolutional neural networks", "computer vision tasks", "elementary perceptual tasks", "network architectures", "human task performance", "CNNs", "visual encodings", "Visualization", "Task analysis", "Bars", "Data visualization", "Convolutional neural networks", "Multilayer perceptrons", "Computational modeling", "Machine Perception", "Graphical Perception", "Deep Learning", "Convolutional Neural Networks"], "referenced_by": ["IKEY:8805456"], "referencing": ["IKEY:8099678", "IKEY:6875978", "IKEY:726791", "IKEY:8265530", "IKEY:5728805", "IKEY:6876021", "IKEY:8100241", "IKEY:8099678", "IKEY:6875978", "IKEY:726791", "IKEY:8265530", "IKEY:5728805", "IKEY:6876021", "IKEY:8100241", "IKEY:8099678", "IKEY:6875978", "IKEY:726791", "IKEY:8265530", "IKEY:5728805", "IKEY:6876021", "IKEY:8100241", "10.1145/3126594.3126653", "10.1145/2642918.2647411", "10.1145/2470654.2481410", "10.1145/1753326.1753357", "10.1145/62402.62431", "10.1145/2047196.2047247", "10.1145/1240624.1240701", "10.1145/3126594.3126653", "10.1145/2642918.2647411", "10.1145/2470654.2481410", "10.1145/1753326.1753357", "10.1145/62402.62431", "10.1145/2047196.2047247", "10.1145/1240624.1240701", "10.1145/3126594.3126653", "10.1145/2642918.2647411", "10.1145/2470654.2481410", "10.1145/1753326.1753357", "10.1145/62402.62431", "10.1145/2047196.2047247", "10.1145/1240624.1240701", "10.1007/978-3-319-46454-1_49", "10.2307/2288400", "10.1126/science.229.4716.828", "10.1007/978-3-642-46466-9_18", "10.1016/j.neuron.2017.06.011", "10.1007/BF02288564", "10.1007/978-3-319-46493-0_15", "10.1126/science.aab3050", "10.1038/nature14539", "10.1111/cgf.13193", "10.1037/0033-295X.95.1.15", "10.1016/S0169-7439(00)00122-2", "10.1038/nn.4244", "10.1007/978-3-319-46454-1_49", "10.2307/2288400", "10.1126/science.229.4716.828", "10.1007/978-3-642-46466-9_18", "10.1016/j.neuron.2017.06.011", "10.1007/BF02288564", "10.1007/978-3-319-46493-0_15", "10.1126/science.aab3050", "10.1038/nature14539", "10.1111/cgf.13193", "10.1037/0033-295X.95.1.15", "10.1016/S0169-7439(00)00122-2", "10.1038/nn.4244", "10.1007/978-3-319-46454-1_49", "10.2307/2288400", "10.1126/science.229.4716.828", "10.1007/978-3-642-46466-9_18", "10.1016/j.neuron.2017.06.011", "10.1007/BF02288564", "10.1007/978-3-319-46493-0_15", "10.1126/science.aab3050", "10.1038/nature14539", "10.1111/cgf.13193", "10.1037/0033-295X.95.1.15", "10.1016/S0169-7439(00)00122-2", "10.1038/nn.4244"]}, "10.1109/TVCG.2018.2865230": {"doi": "10.1109/TVCG.2018.2865230", "author": ["S. Liu", "Z. Li", "T. Li", "V. Srikumar", "V. Pascucci", "P. Bremer"], "title": "NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models", "year": "2019", "abstract": "With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.", "keywords": ["data visualisation", "inference mechanisms", "learning (artificial intelligence)", "natural language processing", "neural nets", "natural language inference problem", "perturbation-driven visual interrogation tool", "deep learning", "neural network model", "linguistic tasks", "natural language processing", "hard-to-debug-systems", "visualization system", "Natural languages", "Task analysis", "Neural networks", "Visualization", "Computational modeling", "Analytical models", "Predictive models", "Natural Language Processing", "Interpretable Machine Learning", "Natural Language Inference", "Attention Visualization"], "referenced_by": ["IKEY:8844254", "IKEY:8883193", "IKEY:8805457", "IKEY:8827944", "IKEY:8820172", "IKEY:9251980"], "referencing": ["IKEY:8017618", "IKEY:8022871", "IKEY:8019879", "IKEY:7536654", "IKEY:8019864", "IKEY:8019872", "IKEY:8017583", "IKEY:1532820", "IKEY:8019861", "IKEY:8017618", "IKEY:8022871", "IKEY:8019879", "IKEY:7536654", "IKEY:8019864", "IKEY:8019872", "IKEY:8017583", "IKEY:1532820", "IKEY:8019861", "IKEY:8017618", "IKEY:8022871", "IKEY:8019879", "IKEY:7536654", "IKEY:8019864", "IKEY:8019872", "IKEY:8017583", "IKEY:1532820", "IKEY:8019861", "10.1145/2858036.2858529", "10.1145/219717.219748", "10.1145/2939672.2939778", "10.1145/2858036.2858529", "10.1145/219717.219748", "10.1145/2939672.2939778", "10.1145/2858036.2858529", "10.1145/219717.219748", "10.1145/2939672.2939778", "10.18653/v1/D15-1075", "10.2200/S00509ED1V01Y201305HLT023", "10.23915/distill.00007", "10.18653/v1/D16-1244", "10.18653/v1/D16-1244", "10.3115/v1/D14-1162", "10.18653/v1/D15-1044", "10.18653/v1/N16-1174", "10.18653/v1/D15-1075", "10.2200/S00509ED1V01Y201305HLT023", "10.23915/distill.00007", "10.18653/v1/D16-1244", "10.18653/v1/D16-1244", "10.3115/v1/D14-1162", "10.18653/v1/D15-1044", "10.18653/v1/N16-1174", "10.18653/v1/D15-1075", "10.2200/S00509ED1V01Y201305HLT023", "10.23915/distill.00007", "10.18653/v1/D16-1244", "10.18653/v1/D16-1244", "10.3115/v1/D14-1162", "10.18653/v1/D15-1044", "10.18653/v1/N16-1174"]}, "10.1109/TVCG.2018.2865119": {"doi": "10.1109/TVCG.2018.2865119", "author": ["S. K. Badam", "Z. Liu", "N. Elmqvist"], "title": "Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading", "year": "2019", "abstract": "Today's data-rich documents are often complex datasets in themselves, consisting of information in different formats such as text, figures, and data tables. These additional media augment the textual narrative in the document. However, the static layout of a traditional for-print document often impedes deep understanding of its content because of the need to navigate to access content scattered throughout the text. In this paper, we seek to facilitate enhanced comprehension of such documents through a contextual visualization technique that couples text content with data tables contained in the document. We parse the text content and data tables, cross-link the components using a keyword-based matching algorithm, and generate on-demand visualizations based on the reader's current focus within a document. We evaluate this technique in a user study comparing our approach to a traditional reading experience. Results from our study show that (1) participants comprehend the content better with tighter coupling of text and data, (2) the contextual visualizations enable participants to develop better summaries that capture the main data-rich insights within the document, and (3) overall, our method enables participants to develop a more detailed understanding of the document content.", "keywords": ["collections of physical data", "data visualisation", "information retrieval", "text analysis", "elastic documents", "coupling text", "enhanced document reading", "data tables", "access content", "contextual visualization technique", "print document", "keyword-based matching algorithm", "Data visualization", "Visualization", "Layout", "Portable document format", "Media", "Hurricanes", "Couplings", "Document reading", "contextual visualizations", "visual aids", "comprehension", "summarization"], "referenced_by": [], "referencing": ["IKEY:1231178", "IKEY:6064996", "IKEY:7539348", "IKEY:7593375", "IKEY:6875917", "IKEY:6064988", "IKEY:4376133", "IKEY:5277546", "IKEY:6875988", "IKEY:7860200", "IKEY:885091", "IKEY:5290723", "IKEY:5290726", "IKEY:5290722", "IKEY:1231178", "IKEY:6064996", "IKEY:7539348", "IKEY:7593375", "IKEY:6875917", "IKEY:6064988", "IKEY:4376133", "IKEY:5277546", "IKEY:6875988", "IKEY:7860200", "IKEY:885091", "IKEY:5290723", "IKEY:5290726", "IKEY:5290722", "IKEY:1231178", "IKEY:6064996", "IKEY:7539348", "IKEY:7593375", "IKEY:6875917", "IKEY:6064988", "IKEY:4376133", "IKEY:5277546", "IKEY:6875988", "IKEY:7860200", "IKEY:885091", "IKEY:5290723", "IKEY:5290726", "IKEY:5290722", "10.1145/3025453.3025631", "10.1145/288392.288585", "10.1145/2858036.2858430", "10.1145/2509908.2509909", "10.1145/2623330.2623617", "10.1145/2559206.2578881", "10.1145/2556288.2557228", "10.1145/2702613.2732778", "10.1145/2702613.2732501", "10.1145/1993316.1993536", "10.1145/1012037.1012063", "10.1145/1978942.1979444", "10.1145/2556288.2557241", "10.1145/102377.115768", "10.1145/1978942.1979430", "10.1145/2501988.2502036", "10.1145/332040.332440", "10.1145/3025453.3025631", "10.1145/288392.288585", "10.1145/2858036.2858430", "10.1145/2509908.2509909", "10.1145/2623330.2623617", "10.1145/2559206.2578881", "10.1145/2556288.2557228", "10.1145/2702613.2732778", "10.1145/2702613.2732501", "10.1145/1993316.1993536", "10.1145/1012037.1012063", "10.1145/1978942.1979444", "10.1145/2556288.2557241", "10.1145/102377.115768", "10.1145/1978942.1979430", "10.1145/2501988.2502036", "10.1145/332040.332440", "10.1145/3025453.3025631", "10.1145/288392.288585", "10.1145/2858036.2858430", "10.1145/2509908.2509909", "10.1145/2623330.2623617", "10.1145/2559206.2578881", "10.1145/2556288.2557228", "10.1145/2702613.2732778", "10.1145/2702613.2732501", "10.1145/1993316.1993536", "10.1145/1012037.1012063", "10.1145/1978942.1979444", "10.1145/2556288.2557241", "10.1145/102377.115768", "10.1145/1978942.1979430", "10.1145/2501988.2502036", "10.1145/332040.332440", "10.1111/cgf.12104", "10.1111/cgf.13180", "10.14778/2536274.2536276", "10.1177/0956797613504966", "10.1016/0749-596X(92)90008-L", "10.1111/j.1551-6708.1987.tb00863.x", "10.1061/(ASCE)1527-6988(2008)9:1(29)", "10.3322/caac.21254", "10.3322/caac.21332", "10.4300/JGME-D-12-00156.1", "10.1111/cgf.12104", "10.1111/cgf.13180", "10.14778/2536274.2536276", "10.1177/0956797613504966", "10.1016/0749-596X(92)90008-L", "10.1111/j.1551-6708.1987.tb00863.x", "10.1061/(ASCE)1527-6988(2008)9:1(29)", "10.3322/caac.21254", "10.3322/caac.21332", "10.4300/JGME-D-12-00156.1", "10.1111/cgf.12104", "10.1111/cgf.13180", "10.14778/2536274.2536276", "10.1177/0956797613504966", "10.1016/0749-596X(92)90008-L", "10.1111/j.1551-6708.1987.tb00863.x", "10.1061/(ASCE)1527-6988(2008)9:1(29)", "10.3322/caac.21254", "10.3322/caac.21332", "10.4300/JGME-D-12-00156.1"]}, "10.1109/TVCG.2018.2865145": {"doi": "10.1109/TVCG.2018.2865145", "author": ["A. Srinivasan", "S. M. Drucker", "A. Endert", "J. Stasko"], "title": "Augmenting Visualizations with Interactive Data Facts to Facilitate Interpretation and Communication", "year": "2019", "abstract": "Recently, an increasing number of visualization systems have begun to incorporate natural language generation (NLG) capabilities into their interfaces. NLG-based visualization systems typically leverage a suite of statistical functions to automatically extract key facts about the underlying data and surface them as natural language sentences alongside visualizations. With current systems, users are typically required to read the system-generated sentences and mentally map them back to the accompanying visualization. However, depending on the features of the visualization (e.g., visualization type, data density) and the complexity of the data fact, mentally mapping facts to visualizations can be a challenging task. Furthermore, more than one visualization could be used to illustrate a single data fact. Unfortunately, current tools provide little or no support for users to explore such alternatives. In this paper, we explore how system-generated data facts can be treated as interactive widgets to help users interpret visualizations and communicate their findings. We present Voder, a system that lets users interact with automatically-generated data facts to explore both alternative visualizations to convey a data fact as well as a set of embellishments to highlight a fact within a visualization. Leveraging data facts as interactive widgets, Voder also facilitates data fact-based visualization search. To assess Voder's design and features, we conducted a preliminary user study with 12 participants having varying levels of experience with visualization tools. Participant feedback suggested that interactive data facts aided them in interpreting visualizations. Participants also stated that the suggestions surfaced through the facts helped them explore alternative visualizations and embellishments to communicate individual data facts.", "keywords": ["data visualisation", "natural language processing", "natural language generation", "statistical functions", "data fact-based visualization search", "Voder design", "visualization tools", "automatically-generated data facts", "interactive widgets", "system-generated data facts", "data density", "system-generated sentences", "natural language sentences", "NLG-based visualization systems", "interactive data facts", "augmenting visualizations", "Data visualization", "Tools", "Visualization", "Natural languages", "Data mining", "Histograms", "Complexity theory", "Natural Language Generation", "Mixed-initiative Interaction", "Visualization Recommendation", "Data-driven Communication"], "referenced_by": ["IKEY:8813126", "IKEY:8807349", "IKEY:8805442", "IKEY:8933766", "IKEY:8933695", "IKEY:9086209", "IKEY:9268315"], "referencing": ["IKEY:6634168", "IKEY:4797511", "IKEY:5613431", "IKEY:6634182", "IKEY:6327269", "IKEY:6412677", "IKEY:4376133", "IKEY:1626178", "IKEY:8031599", "IKEY:235203", "IKEY:8019835", "IKEY:8019860", "IKEY:146375", "IKEY:7192728", "IKEY:6634168", "IKEY:4797511", "IKEY:5613431", "IKEY:6634182", "IKEY:6327269", "IKEY:6412677", "IKEY:4376133", "IKEY:1626178", "IKEY:8031599", "IKEY:235203", "IKEY:8019835", "IKEY:8019860", "IKEY:146375", "IKEY:7192728", "IKEY:6634168", "IKEY:4797511", "IKEY:5613431", "IKEY:6634182", "IKEY:6327269", "IKEY:6412677", "IKEY:4376133", "IKEY:1626178", "IKEY:8031599", "IKEY:235203", "IKEY:8019835", "IKEY:8019860", "IKEY:146375", "IKEY:7192728", "10.1145/108360.108361", "10.1145/2807442.2807478", "10.1145/302979.303030", "10.1145/1978942.1979444", "10.1145/3025453.3025866", "10.1145/2556288.2557241", "10.1145/3172944.3173007", "10.1145/2702123.2702608", "10.1145/2984511.2984588", "10.1145/3035918.3035922", "10.1145/3025453.3025768", "10.1145/108360.108361", "10.1145/2807442.2807478", "10.1145/302979.303030", "10.1145/1978942.1979444", "10.1145/3025453.3025866", "10.1145/2556288.2557241", "10.1145/3172944.3173007", "10.1145/2702123.2702608", "10.1145/2984511.2984588", "10.1145/3035918.3035922", "10.1145/3025453.3025768", "10.1145/108360.108361", "10.1145/2807442.2807478", "10.1145/302979.303030", "10.1145/1978942.1979444", "10.1145/3025453.3025866", "10.1145/2556288.2557241", "10.1145/3172944.3173007", "10.1145/2702123.2702608", "10.1145/2984511.2984588", "10.1145/3035918.3035922", "10.1145/3025453.3025768", "10.1080/00401706.1987.10488204", "10.1007/s00371-015-1132-9", "10.1177/1473871618806555", "10.14778/3137765.3137813", "10.1111/cgf.13207", "10.1017/S1351324997001502", "10.14778/2733004.2733035", "10.3115/981732.981751", "10.1080/00401706.1987.10488204", "10.1007/s00371-015-1132-9", "10.1177/1473871618806555", "10.14778/3137765.3137813", "10.1111/cgf.13207", "10.1017/S1351324997001502", "10.14778/2733004.2733035", "10.3115/981732.981751", "10.1080/00401706.1987.10488204", "10.1007/s00371-015-1132-9", "10.1177/1473871618806555", "10.14778/3137765.3137813", "10.1111/cgf.13207", "10.1017/S1351324997001502", "10.14778/2733004.2733035", "10.3115/981732.981751"]}, "10.1109/TVCG.2018.2864903": {"doi": "10.1109/TVCG.2018.2864903", "author": ["A. Sarikaya", "M. Correll", "L. Bartram", "M. Tory", "D. Fisher"], "title": "What Do We Talk About When We Talk About Dashboards?", "year": "2019", "abstract": "Dashboards are one of the most common use cases for data visualization, and their design and contexts of use are considerably different from exploratory visualization tools. In this paper, we look at the broad scope of how dashboards are used in practice through an analysis of dashboard examples and documentation about their use. We systematically review the literature surrounding dashboard use, construct a design space for dashboards, and identify major dashboard types. We characterize dashboards by their design goals, levels of interaction, and the practices around them. Our framework and literature review suggest a number of fruitful research directions to better support dashboard design, implementation and use.", "keywords": ["data visualisation", "data visualization", "exploratory visualization tools", "dashboard examples", "dashboard use", "dashboard types", "dashboard design", "Visualization", "Data visualization", "Encoding", "Measurement", "Decision making", "Monitoring", "Tools", "Dashboards", "literature review", "survey", "design space", "open coding"], "referenced_by": [], "referencing": ["10.1145/2207676.2208288", "10.1145/2070710.2070717", "10.1145/2717318", "10.1145/2207676.2208288", "10.1145/2070710.2070717", "10.1145/2717318", "10.1145/2207676.2208288", "10.1145/2070710.2070717", "10.1145/2717318", "10.17705/1jais.00423", "10.1111/1748-8583.12090", "10.9707/1944-5660.1155", "10.1080/13658816.2014.977905", "10.1080/09523987.2017.1408267", "10.1007/978-3-642-40477-1_18", "10.1007/978-3-642-37157-8_8", "10.1177/0272989X10373805", "10.1007/978-1-4302-4945-0", "10.1007/978-3-319-40700-5_12", "10.2148/benv.42.3.498", "10.1080/1369118X.2016.1153126", "10.1002/9781119427599", "10.3390/info8020047", "10.1093/cjres/rsu027", "10.1016/j.geoforum.2016.10.006", "10.1016/j.landusepol.2017.10.019", "10.1007/978-3-642-39215-3_14", "10.1007/978-3-642-32270-9_7", "10.22269/150309", "10.5194/isprs-annals-IV-4-W1-19-2016", "10.1177/1098611117709785", "10.1093/jhuman/huw011", "10.1136/amiajnl-2014-002963", "10.1007/s10758-017-9316-1", "10.1177/0956797615623770", "10.1177/0002764213479363", "10.1097/00115514-201509000-00005", "10.1002/9781119283089", "10.1097/CIN.0000000000000106", "10.1080/02680939.2015.1035758", "10.1016/j.accinf.2011.08.002", "10.17705/1jais.00423", "10.1111/1748-8583.12090", "10.9707/1944-5660.1155", "10.1080/13658816.2014.977905", "10.1080/09523987.2017.1408267", "10.1007/978-3-642-40477-1_18", "10.1007/978-3-642-37157-8_8", "10.1177/0272989X10373805", "10.1007/978-1-4302-4945-0", "10.1007/978-3-319-40700-5_12", "10.2148/benv.42.3.498", "10.1080/1369118X.2016.1153126", "10.1002/9781119427599", "10.3390/info8020047", "10.1093/cjres/rsu027", "10.1016/j.geoforum.2016.10.006", "10.1016/j.landusepol.2017.10.019", "10.1007/978-3-642-39215-3_14", "10.1007/978-3-642-32270-9_7", "10.22269/150309", "10.5194/isprs-annals-IV-4-W1-19-2016", "10.1177/1098611117709785", "10.1093/jhuman/huw011", "10.1136/amiajnl-2014-002963", "10.1007/s10758-017-9316-1", "10.1177/0956797615623770", "10.1177/0002764213479363", "10.1097/00115514-201509000-00005", "10.1002/9781119283089", "10.1097/CIN.0000000000000106", "10.1080/02680939.2015.1035758", "10.1016/j.accinf.2011.08.002", "10.17705/1jais.00423", "10.1111/1748-8583.12090", "10.9707/1944-5660.1155", "10.1080/13658816.2014.977905", "10.1080/09523987.2017.1408267", "10.1007/978-3-642-40477-1_18", "10.1007/978-3-642-37157-8_8", "10.1177/0272989X10373805", "10.1007/978-1-4302-4945-0", "10.1007/978-3-319-40700-5_12", "10.2148/benv.42.3.498", "10.1080/1369118X.2016.1153126", "10.1002/9781119427599", "10.3390/info8020047", "10.1093/cjres/rsu027", "10.1016/j.geoforum.2016.10.006", "10.1016/j.landusepol.2017.10.019", "10.1007/978-3-642-39215-3_14", "10.1007/978-3-642-32270-9_7", "10.22269/150309", "10.5194/isprs-annals-IV-4-W1-19-2016", "10.1177/1098611117709785", "10.1093/jhuman/huw011", "10.1136/amiajnl-2014-002963", "10.1007/s10758-017-9316-1", "10.1177/0956797615623770", "10.1177/0002764213479363", "10.1097/00115514-201509000-00005", "10.1002/9781119283089", "10.1097/CIN.0000000000000106", "10.1080/02680939.2015.1035758", "10.1016/j.accinf.2011.08.002"]}, "10.1109/TVCG.2018.2865192": {"doi": "10.1109/TVCG.2018.2865192", "author": ["Y. Yang", "T. Dwyer", "B. Jenny", "K. Marriott", "M. Cordeil", "H. Chen"], "title": "Origin-Destination Flow Maps in Immersive Environments", "year": "2019", "abstract": "Immersive virtual- and augmented-reality headsets can overlay a flat image against any surface or hang virtual objects in the space around the user. The technology is rapidly improving and may, in the long term, replace traditional flat panel displays in many situations. When displays are no longer intrinsically flat, how should we use the space around the user for abstract data visualisation? In this paper, we ask this question with respect to origin-destination flow data in a global geographic context. We report on the findings of three studies exploring different spatial encodings for flow maps. The first experiment focuses on different 2D and 3D encodings for flows on flat maps. We find that participants are significantly more accurate with raised flow paths whose height is proportional to flow distance but fastest with traditional straight line 2D flows. In our second and third experiment we compared flat maps, 3D globes and a novel interactive design we call MapsLink, involving a pair of linked flat maps. We find that participants took significantly more time with MapsLink than other flow maps while the 3D globe with raised flows was the fastest, most accurate, and most preferred method. Our work suggests that careful use of the third spatial dimension can resolve visual clutter in complex flow maps.", "keywords": ["augmented reality", "data visualisation", "encoding", "flat panel displays", "geographic information systems", "image processing", "origin-destination flow maps", "immersive environments", "augmented-reality headsets", "flat image", "abstract data visualisation", "global geographic context", "linked flat maps", "flat panel displays", "spatial encodings", "flow paths", "straight line 2D flows", "MapsLink", "3D globe", "interactive design", "visual clutter", "virtual-reality headsets", "Three-dimensional displays", "Data visualization", "Two dimensional displays", "Encoding", "Clutter", "Virtual reality", "Aerospace electronics", "Origin-destination", "Flow Map", "Virtual Reality", "Cartographic Information Visualisation", "Immersive Analytics"], "referenced_by": ["IKEY:8781587", "IKEY:8797978"], "referencing": ["IKEY:7539373", "IKEY:6065021", "IKEY:7314296", "IKEY:4376140", "IKEY:7539620", "IKEY:528697", "IKEY:7160094", "IKEY:486685", "IKEY:5742390", "IKEY:4126225", "IKEY:8031577", "IKEY:7390081", "IKEY:559226", "IKEY:1532150", "IKEY:6065019", "IKEY:6875972", "IKEY:1249008", "IKEY:7539669", "IKEY:7539373", "IKEY:6065021", "IKEY:7314296", "IKEY:4376140", "IKEY:7539620", "IKEY:528697", "IKEY:7160094", "IKEY:486685", "IKEY:5742390", "IKEY:4126225", "IKEY:8031577", "IKEY:7390081", "IKEY:559226", "IKEY:1532150", "IKEY:6065019", "IKEY:6875972", "IKEY:1249008", "IKEY:7539669", "IKEY:7539373", "IKEY:6065021", "IKEY:7314296", "IKEY:4376140", "IKEY:7539620", "IKEY:528697", "IKEY:7160094", "IKEY:486685", "IKEY:5742390", "IKEY:4126225", "IKEY:8031577", "IKEY:7390081", "IKEY:559226", "IKEY:1532150", "IKEY:6065019", "IKEY:6875972", "IKEY:1249008", "IKEY:7539669", "10.1145/3173574.3173664", "10.1145/3126594.3126613", "10.1145/245882.245901", "10.1145/159544.159587", "10.1145/1518701.1519054", "10.1145/2254556.2254652", "10.1145/1080402.1080411", "10.1145/2702123.2702172", "10.1145/3013971.3013983", "10.1145/3173574.3173664", "10.1145/3126594.3126613", "10.1145/245882.245901", "10.1145/159544.159587", "10.1145/1518701.1519054", "10.1145/2254556.2254652", "10.1145/1080402.1080411", "10.1145/2702123.2702172", "10.1145/3013971.3013983", "10.1145/3173574.3173664", "10.1145/3126594.3126613", "10.1145/245882.245901", "10.1145/159544.159587", "10.1145/1518701.1519054", "10.1145/2254556.2254652", "10.1145/1080402.1080411", "10.1145/2702123.2702172", "10.1145/3013971.3013983", "10.1126/science.1248676", "10.1111/j.1467-8659.2011.01946.x", "10.1016/j.jvlc.2016.07.006", "10.1038/nature03548", "10.1080/13658810701349037", "10.1016/j.jvlc.2014.03.001", "10.1080/13658816.2017.1307378", "10.1080/15230406.2016.1262280", "10.1179/caj.1971.8.2.139", "10.1179/caj.1969.6.2.131", "10.1177/1473871616681375", "10.1201/b17511", "10.1007/978-3-319-03841-4_34", "10.1007/s00168-008-0256-5", "10.1016/j.compenvurbsys.2009.01.007", "10.2307/1791753", "10.1080/03085696708592302", "10.1080/17445647.2017.1313788", "10.1080/15230406.2018.1437359", "10.1111/j.0033-0124.1981.00419.x", "10.1559/152304087783875273", "10.1007/s41651-017-0001-7", "10.1353/sgo.1976.0003", "10.1179/000870410X12658023467367", "10.1111/cgf.13431", "10.1093/comjnl/bxx117", "10.1126/science.1248676", "10.1111/j.1467-8659.2011.01946.x", "10.1016/j.jvlc.2016.07.006", "10.1038/nature03548", "10.1080/13658810701349037", "10.1016/j.jvlc.2014.03.001", "10.1080/13658816.2017.1307378", "10.1080/15230406.2016.1262280", "10.1179/caj.1971.8.2.139", "10.1179/caj.1969.6.2.131", "10.1177/1473871616681375", "10.1201/b17511", "10.1007/978-3-319-03841-4_34", "10.1007/s00168-008-0256-5", "10.1016/j.compenvurbsys.2009.01.007", "10.2307/1791753", "10.1080/03085696708592302", "10.1080/17445647.2017.1313788", "10.1080/15230406.2018.1437359", "10.1111/j.0033-0124.1981.00419.x", "10.1559/152304087783875273", "10.1007/s41651-017-0001-7", "10.1353/sgo.1976.0003", "10.1179/000870410X12658023467367", "10.1111/cgf.13431", "10.1093/comjnl/bxx117", "10.1126/science.1248676", "10.1111/j.1467-8659.2011.01946.x", "10.1016/j.jvlc.2016.07.006", "10.1038/nature03548", "10.1080/13658810701349037", "10.1016/j.jvlc.2014.03.001", "10.1080/13658816.2017.1307378", "10.1080/15230406.2016.1262280", "10.1179/caj.1971.8.2.139", "10.1179/caj.1969.6.2.131", "10.1177/1473871616681375", "10.1201/b17511", "10.1007/978-3-319-03841-4_34", "10.1007/s00168-008-0256-5", "10.1016/j.compenvurbsys.2009.01.007", "10.2307/1791753", "10.1080/03085696708592302", "10.1080/17445647.2017.1313788", "10.1080/15230406.2018.1437359", "10.1111/j.0033-0124.1981.00419.x", "10.1559/152304087783875273", "10.1007/s41651-017-0001-7", "10.1353/sgo.1976.0003", "10.1179/000870410X12658023467367", "10.1111/cgf.13431", "10.1093/comjnl/bxx117"]}, "10.1109/TVCG.2018.2865191": {"doi": "10.1109/TVCG.2018.2865191", "author": ["C. Hurter", "N. H. Riche", "S. M. Drucker", "M. Cordeil", "R. Alligier", "R. Vuillemot"], "title": "FiberClay: Sculpting Three Dimensional Trajectories to Reveal Structural Insights", "year": "2019", "abstract": "Visualizing 3D trajectories to extract insights about their similarities and spatial configuration is a critical task in several domains. Air traffic controllers for example deal with large quantities of aircrafts routes to optimize safety in airspace and neuroscientists attempt to understand neuronal pathways in the human brain by visualizing bundles of fibers from DTI images. Extracting insights from masses of 3D trajectories is challenging as the multiple three dimensional lines have complex geometries, may overlap, cross or even merge with each other, making it impossible to follow individual ones in dense areas. As trajectories are inherently spatial and three dimensional, we propose FiberClay: a system to display and interact with 3D trajectories in immersive environments. FiberClay renders a large quantity of trajectories in real time using GP-GPU techniques. FiberClay also introduces a new set of interactive techniques for composing complex queries in 3D space leveraging immersive environment controllers and user position. These techniques enable an analyst to select and compare sets of trajectories with specific geometries and data properties. We conclude by discussing insights found using FiberClay with domain experts in air traffic control and neurology.", "keywords": ["brain", "data visualisation", "graphics processing units", "interactive systems", "neurophysiology", "rendering (computer graphics)", "structural insights", "spatial configuration", "critical task", "air traffic controllers", "aircrafts routes", "airspace", "neuroscientists", "neuronal pathways", "human brain", "DTI images", "multiple three dimensional lines", "complex geometries", "FiberClay renders", "GP-GPU techniques", "interactive techniques", "3D space leveraging immersive environment controllers", "air traffic control", "neurology", "3D dimensional trajectories", "Data visualization", "Three-dimensional displays", "Trajectory", "Two dimensional displays", "Optical fiber devices", "Aircraft navigation", "Immersive Analytics", "3D Visualization", "Dynamic Queries", "Bimanual Interaction", "Multidimensional Data"], "referenced_by": ["IKEY:8797978", "IKEY:8820171", "IKEY:8805456", "IKEY:8854316", "IKEY:9089492", "IKEY:9089546", "IKEY:9190298", "IKEY:9169859"], "referencing": ["IKEY:7539617", "IKEY:6065015", "IKEY:7160096", "IKEY:175794", "IKEY:7314296", "IKEY:4658123", "IKEY:6065003", "IKEY:7042344", "IKEY:6634127", "IKEY:5742390", "IKEY:8031577", "IKEY:8017623", "IKEY:6787171", "IKEY:5290707", "IKEY:7390081", "IKEY:6064940", "IKEY:7160093", "IKEY:6846743", "IKEY:7192701", "IKEY:6634128", "IKEY:1432687", "IKEY:946631", "IKEY:6327262", "IKEY:8017617", "IKEY:7539617", "IKEY:6065015", "IKEY:7160096", "IKEY:175794", "IKEY:7314296", "IKEY:4658123", "IKEY:6065003", "IKEY:7042344", "IKEY:6634127", "IKEY:5742390", "IKEY:8031577", "IKEY:8017623", "IKEY:6787171", "IKEY:5290707", "IKEY:7390081", "IKEY:6064940", "IKEY:7160093", "IKEY:6846743", "IKEY:7192701", "IKEY:6634128", "IKEY:1432687", "IKEY:946631", "IKEY:6327262", "IKEY:8017617", "IKEY:7539617", "IKEY:6065015", "IKEY:7160096", "IKEY:175794", "IKEY:7314296", "IKEY:4658123", "IKEY:6065003", "IKEY:7042344", "IKEY:6634127", "IKEY:5742390", "IKEY:8031577", "IKEY:8017623", "IKEY:6787171", "IKEY:5290707", "IKEY:7390081", "IKEY:6064940", "IKEY:7160093", "IKEY:6846743", "IKEY:7192701", "IKEY:6634128", "IKEY:1432687", "IKEY:946631", "IKEY:6327262", "IKEY:8017617", "10.1145/2992154.2996365", "10.1145/3126594.3126613", "10.1145/3013971.3014006", "10.1145/1357054.1357203", "10.1145/108844.108883", "10.1145/800186.810616", "10.1145/3025453.3025566", "10.1145/234972.234975", "10.1145/1279640.1279642", "10.1145/2992154.2996365", "10.1145/3126594.3126613", "10.1145/3013971.3014006", "10.1145/1357054.1357203", "10.1145/108844.108883", "10.1145/800186.810616", "10.1145/3025453.3025566", "10.1145/234972.234975", "10.1145/1279640.1279642", "10.1145/2992154.2996365", "10.1145/3126594.3126613", "10.1145/3013971.3014006", "10.1145/1357054.1357203", "10.1145/108844.108883", "10.1145/800186.810616", "10.1145/3025453.3025566", "10.1145/234972.234975", "10.1145/1279640.1279642", "10.1016/B978-155860915-0/50004-4", "10.1007/s12031-007-0029-0", "10.1111/cgf.12804", "10.1016/j.ijhcs.2013.03.003", "10.1080/00401706.1987.10488204", "10.1111/j.1467-8659.2009.01687.x", "10.1057/palgrave.ivs.9500061", "10.1016/j.trc.2014.03.005", "10.1111/j.1467-8659.2012.03079.x", "10.1057/palgrave.ivs.9500097", "10.3390/informatics4030026", "10.1201/b17511", "10.1177/001872089303500306", "10.1016/S1088-467X(99)00013-X", "10.1016/j.ijhcs.2005.02.001", "10.1016/B978-155860915-0/50004-4", "10.1007/s12031-007-0029-0", "10.1111/cgf.12804", "10.1016/j.ijhcs.2013.03.003", "10.1080/00401706.1987.10488204", "10.1111/j.1467-8659.2009.01687.x", "10.1057/palgrave.ivs.9500061", "10.1016/j.trc.2014.03.005", "10.1111/j.1467-8659.2012.03079.x", "10.1057/palgrave.ivs.9500097", "10.3390/informatics4030026", "10.1201/b17511", "10.1177/001872089303500306", "10.1016/S1088-467X(99)00013-X", "10.1016/j.ijhcs.2005.02.001", "10.1016/B978-155860915-0/50004-4", "10.1007/s12031-007-0029-0", "10.1111/cgf.12804", "10.1016/j.ijhcs.2013.03.003", "10.1080/00401706.1987.10488204", "10.1111/j.1467-8659.2009.01687.x", "10.1057/palgrave.ivs.9500061", "10.1016/j.trc.2014.03.005", "10.1111/j.1467-8659.2012.03079.x", "10.1057/palgrave.ivs.9500097", "10.3390/informatics4030026", "10.1201/b17511", "10.1177/001872089303500306", "10.1016/S1088-467X(99)00013-X", "10.1016/j.ijhcs.2005.02.001"]}, "10.1109/TVCG.2018.2865152": {"doi": "10.1109/TVCG.2018.2865152", "author": ["R. Sicat", "J. Li", "J. Choi", "M. Cordeil", "W. -K. Jeong", "B. Bach", "H. Pfister"], "title": "DXR: A Toolkit for Building Immersive Data Visualizations", "year": "2019", "abstract": "This paper presents DXR, a toolkit for building immersive data visualizations based on the Unity development platform. Over the past years, immersive data visualizations in augmented and virtual reality (AR, VR) have been emerging as a promising medium for data sense-making beyond the desktop. However, creating immersive visualizations remains challenging, and often require complex low-level programming and tedious manual encoding of data attributes to geometric and visual properties. These can hinder the iterative idea-to-prototype process, especially for developers without experience in 3D graphics, AR, and VR programming. With DXR, developers can efficiently specify visualization designs using a concise declarative visualization grammar inspired by Vega-Lite. DXR further provides a GUI for easy and quick edits and previews of visualization designs in-situ, i.e., while immersed in the virtual world. DXR also provides reusable templates and customizable graphical marks, enabling unique and engaging visualizations. We demonstrate the flexibility of DXR through several examples spanning a wide range of applications.", "keywords": ["augmented reality", "data visualisation", "grammars", "graphical user interfaces", "unity development platform", "engaging visualizations", "unique visualizations", "concise declarative visualization grammar", "visualization designs", "visual properties", "geometric properties", "immersive visualizations", "data sense-making", "building immersive data visualizations", "DXR", "Data visualization", "Visualization", "Tools", "Three-dimensional displays", "Programming", "Libraries", "Graphical user interfaces", "Augmented Reality", "Virtual Reality", "Immersive Visualization", "Immersive Analytics", "Visualization Toolkit", "Augmented Reality", "Computer Graphics", "Data Visualization", "Humans", "Imaging, Three-Dimensional", "Software", "User-Computer Interface", "Virtual Reality"], "referenced_by": ["IKEY:8811981", "IKEY:8942356", "IKEY:9067881", "IKEY:9089446", "IKEY:9105984", "IKEY:8611113", "IKEY:9127197", "IKEY:8674573", "IKEY:8730513"], "referencing": ["IKEY:8019876", "IKEY:7539580", "IKEY:5290720", "IKEY:6064996", "IKEY:7314296", "IKEY:6875916", "IKEY:7539620", "IKEY:7004282", "IKEY:1382905", "IKEY:5613453", "IKEY:7536218", "IKEY:7192663", "IKEY:6876040", "IKEY:7539624", "IKEY:7192704", "IKEY:8017617", "IKEY:7539328", "IKEY:8019876", "IKEY:7539580", "IKEY:5290720", "IKEY:6064996", "IKEY:7314296", "IKEY:6875916", "IKEY:7539620", "IKEY:7004282", "IKEY:1382905", "IKEY:5613453", "IKEY:7536218", "IKEY:7192663", "IKEY:6876040", "IKEY:7539624", "IKEY:7192704", "IKEY:8017617", "IKEY:7539328", "IKEY:8019876", "IKEY:7539580", "IKEY:5290720", "IKEY:6064996", "IKEY:7314296", "IKEY:6875916", "IKEY:7539620", "IKEY:7004282", "IKEY:1382905", "IKEY:5613453", "IKEY:7536218", "IKEY:7192663", "IKEY:6876040", "IKEY:7539624", "IKEY:7192704", "IKEY:8017617", "IKEY:7539328", "10.1145/2556288.2557010", "10.1145/2598153.2598175", "10.1145/3173574.3173664", "10.1145/3126594.3126613", "10.1145/3013971.3014006", "10.1145/2642918.2647369", "10.1145/1980462.1980470", "10.1145/3009939.3009947", "10.1145/1518701.1518871", "10.1145/2556288.2557010", "10.1145/2598153.2598175", "10.1145/3173574.3173664", "10.1145/3126594.3126613", "10.1145/3013971.3014006", "10.1145/2642918.2647369", "10.1145/1980462.1980470", "10.1145/3009939.3009947", "10.1145/1518701.1518871", "10.1145/2556288.2557010", "10.1145/2598153.2598175", "10.1145/3173574.3173664", "10.1145/3126594.3126613", "10.1145/3013971.3014006", "10.1145/2642918.2647369", "10.1145/1980462.1980470", "10.1145/3009939.3009947", "10.1145/1518701.1518871", "10.1111/cgf.12804", "10.1016/j.visinf.2017.11.002", "10.1111/cgf.12391", "10.1111/cgf.12804", "10.1016/j.visinf.2017.11.002", "10.1111/cgf.12391", "10.1111/cgf.12804", "10.1016/j.visinf.2017.11.002", "10.1111/cgf.12391"]}, "10.1109/TVCG.2018.2865237": {"doi": "10.1109/TVCG.2018.2865237", "author": ["B. Patnaik", "A. Batch", "N. Elmqvist"], "title": "Information Olfactation: Harnessing Scent to Convey Data", "year": "2019", "abstract": "Olfactory feedback for analytical tasks is a virtually unexplored area in spite of the advantages it offers for information recall, feature identification, and location detection. Here we introduce the concept of information olfactation as the fragrant sibling of information visualization, and discuss how scent can be used to convey data. Building on a review of the human olfactory system and mirroring common visualization practice, we propose olfactory marks, the substrate in which they exist, and their olfactory channels that are available to designers. To exemplify this idea, we present viScent: A six-scent stereo olfactory display capable of conveying olfactory glyphs of varying temperature and direction, as well as a corresponding software system that integrates the display with a traditional visualization display. Finally, we present three applications that make use of the viScent system: A 2D graph visualization, a 2D line and point chart, and an immersive analytics graph visualization in 3D virtual reality. We close the paper with a review of possible extensions of viScent and applications of information olfactation for general visualization beyond the examples in this paper.", "keywords": ["chemioception", "data visualisation", "virtual reality", "information olfactation", "olfactory feedback", "information recall", "feature identification", "location detection", "information visualization", "human olfactory system", "olfactory marks", "olfactory channels", "six-scent stereo olfactory display", "olfactory glyphs", "viScent system", "2D graph visualization", "immersive analytics graph visualization", "software system", "visualization display", "3D virtual reality", "Olfactory", "Data visualization", "Visualization", "Task analysis", "Two dimensional displays", "Neurons", "Virtual reality", "Olfaction", "smell", "scent", "olfactory display", "immersive analytics", "immersion"], "referenced_by": ["IKEY:8805424"], "referencing": ["10.1145/2487268.2487270", "10.1145/3025453.3026004", "10.1145/1027933.1027965", "10.1145/1124772.1124869", "10.1145/3126594.3126613", "10.1145/3132272.3134121", "10.1145/3122986.3122998", "10.1145/3123021.3123035", "10.1145/3001959.3001964", "10.1145/3132818.3132833", "10.1145/2660579.2660584", "10.1145/286498.286652", "10.1145/2851581.2892471", "10.1145/3174910.3174922", "10.1145/2775441.2775483", "10.1145/3131785.3131817", "10.1145/2556288.2557008", "10.1145/1734605.1734634", "10.1145/2851581.2892570", "10.1145/2487268.2487270", "10.1145/3025453.3026004", "10.1145/1027933.1027965", "10.1145/1124772.1124869", "10.1145/3126594.3126613", "10.1145/3132272.3134121", "10.1145/3122986.3122998", "10.1145/3123021.3123035", "10.1145/3001959.3001964", "10.1145/3132818.3132833", "10.1145/2660579.2660584", "10.1145/286498.286652", "10.1145/2851581.2892471", "10.1145/3174910.3174922", "10.1145/2775441.2775483", "10.1145/3131785.3131817", "10.1145/2556288.2557008", "10.1145/1734605.1734634", "10.1145/2851581.2892570", "10.1145/2487268.2487270", "10.1145/3025453.3026004", "10.1145/1027933.1027965", "10.1145/1124772.1124869", "10.1145/3126594.3126613", "10.1145/3132272.3134121", "10.1145/3122986.3122998", "10.1145/3123021.3123035", "10.1145/3001959.3001964", "10.1145/3132818.3132833", "10.1145/2660579.2660584", "10.1145/286498.286652", "10.1145/2851581.2892471", "10.1145/3174910.3174922", "10.1145/2775441.2775483", "10.1145/3131785.3131817", "10.1145/2556288.2557008", "10.1145/1734605.1734634", "10.1145/2851581.2892570", "10.1097/01.mlg.0000191549.17796.13", "10.1016/j.neuropsychologia.2012.10.023", "10.1016/j.neubiorev.2013.06.009", "10.1126/science.1249168", "10.2307/1423118", "10.1371/journal.pone.0073289", "10.1038/ncomms2444", "10.1002/lary.24340", "10.1002/ffj.3249", "10.3758/s13423-013-0397-0", "10.3758/BF03198586", "10.1093/chemse/24.2.191", "10.1111/j.1467-8659.2009.01449.x", "10.1002/ffj.3331", "10.1177/1473871611413180", "10.1037/h0040080", "10.1162/pres.1992.1.4.482", "10.1093/chemse/bjn068", "10.7554/eLife.08127", "10.2307/1423010", "10.1016/j.neuron.2013.04.033", "10.17077/drivingassessment.1010", "10.1093/chemse/bjs087", "10.3758/BF03211293", "10.2307/1423407", "10.3758/BF03210754", "10.1101/cshperspect.a001776", "10.3758/s13421-011-0080-5", "10.1038/ncomms7083", "10.1093/chemse/bjs141", "10.1038/s41598-017-07285-7", "10.1093/chemse/bjj016", "10.1115/1.2794204", "10.1038/srep05796", "10.1007/s00405-007-0446-2", "10.1371/journal.pone.0101651", "10.1016/j.buildenv.2017.12.038", "10.1093/chemse/bjj012", "10.1093/chemse/16.6.631", "10.1085/jgp.83.2.233", "10.1201/b17511", "10.1523/JNEUROSCI.1282-11.2011", "10.1006/nimg.2000.0713", "10.1038/nn1819", "10.1016/0092-8674(94)90015-9", "10.1016/j.jinsphys.2009.06.009", "10.1371/journal.pbio.0020146", "10.1016/j.neuroimage.2007.05.021", "10.1162/pres.1994.3.2.130", "10.1038/32654", "10.1152/jn.2000.83.1.537", "10.1016/j.ijhcs.2017.06.003", "10.1085/jgp.46.3.453", "10.1016/j.enbuild.2015.12.002", "10.1007/s00415-008-0807-9", "10.1038/nn1892", "10.1093/cercor/bhw222", "10.3758/BF03193837", "10.1111/j.1749-6632.2009.04017.x", "10.1111/cgf.13431", "10.1097/01.mlg.0000191549.17796.13", "10.1016/j.neuropsychologia.2012.10.023", "10.1016/j.neubiorev.2013.06.009", "10.1126/science.1249168", "10.2307/1423118", "10.1371/journal.pone.0073289", "10.1038/ncomms2444", "10.1002/lary.24340", "10.1002/ffj.3249", "10.3758/s13423-013-0397-0", "10.3758/BF03198586", "10.1093/chemse/24.2.191", "10.1111/j.1467-8659.2009.01449.x", "10.1002/ffj.3331", "10.1177/1473871611413180", "10.1037/h0040080", "10.1162/pres.1992.1.4.482", "10.1093/chemse/bjn068", "10.7554/eLife.08127", "10.2307/1423010", "10.1016/j.neuron.2013.04.033", "10.17077/drivingassessment.1010", "10.1093/chemse/bjs087", "10.3758/BF03211293", "10.2307/1423407", "10.3758/BF03210754", "10.1101/cshperspect.a001776", "10.3758/s13421-011-0080-5", "10.1038/ncomms7083", "10.1093/chemse/bjs141", "10.1038/s41598-017-07285-7", "10.1093/chemse/bjj016", "10.1115/1.2794204", "10.1038/srep05796", "10.1007/s00405-007-0446-2", "10.1371/journal.pone.0101651", "10.1016/j.buildenv.2017.12.038", "10.1093/chemse/bjj012", "10.1093/chemse/16.6.631", "10.1085/jgp.83.2.233", "10.1201/b17511", "10.1523/JNEUROSCI.1282-11.2011", "10.1006/nimg.2000.0713", "10.1038/nn1819", "10.1016/0092-8674(94)90015-9", "10.1016/j.jinsphys.2009.06.009", "10.1371/journal.pbio.0020146", "10.1016/j.neuroimage.2007.05.021", "10.1162/pres.1994.3.2.130", "10.1038/32654", "10.1152/jn.2000.83.1.537", "10.1016/j.ijhcs.2017.06.003", "10.1085/jgp.46.3.453", "10.1016/j.enbuild.2015.12.002", "10.1007/s00415-008-0807-9", "10.1038/nn1892", "10.1093/cercor/bhw222", "10.3758/BF03193837", "10.1111/j.1749-6632.2009.04017.x", "10.1111/cgf.13431", "10.1097/01.mlg.0000191549.17796.13", "10.1016/j.neuropsychologia.2012.10.023", "10.1016/j.neubiorev.2013.06.009", "10.1126/science.1249168", "10.2307/1423118", "10.1371/journal.pone.0073289", "10.1038/ncomms2444", "10.1002/lary.24340", "10.1002/ffj.3249", "10.3758/s13423-013-0397-0", "10.3758/BF03198586", "10.1093/chemse/24.2.191", "10.1111/j.1467-8659.2009.01449.x", "10.1002/ffj.3331", "10.1177/1473871611413180", "10.1037/h0040080", "10.1162/pres.1992.1.4.482", "10.1093/chemse/bjn068", "10.7554/eLife.08127", "10.2307/1423010", "10.1016/j.neuron.2013.04.033", "10.17077/drivingassessment.1010", "10.1093/chemse/bjs087", "10.3758/BF03211293", "10.2307/1423407", "10.3758/BF03210754", "10.1101/cshperspect.a001776", "10.3758/s13421-011-0080-5", "10.1038/ncomms7083", "10.1093/chemse/bjs141", "10.1038/s41598-017-07285-7", "10.1093/chemse/bjj016", "10.1115/1.2794204", "10.1038/srep05796", "10.1007/s00405-007-0446-2", "10.1371/journal.pone.0101651", "10.1016/j.buildenv.2017.12.038", "10.1093/chemse/bjj012", "10.1093/chemse/16.6.631", "10.1085/jgp.83.2.233", "10.1201/b17511", "10.1523/JNEUROSCI.1282-11.2011", "10.1006/nimg.2000.0713", "10.1038/nn1819", "10.1016/0092-8674(94)90015-9", "10.1016/j.jinsphys.2009.06.009", "10.1371/journal.pbio.0020146", "10.1016/j.neuroimage.2007.05.021", "10.1162/pres.1994.3.2.130", "10.1038/32654", "10.1152/jn.2000.83.1.537", "10.1016/j.ijhcs.2017.06.003", "10.1085/jgp.46.3.453", "10.1016/j.enbuild.2015.12.002", "10.1007/s00415-008-0807-9", "10.1038/nn1892", "10.1093/cercor/bhw222", "10.3758/BF03193837", "10.1111/j.1749-6632.2009.04017.x", "10.1111/cgf.13431"]}, "10.1109/TVCG.2018.2865159": {"doi": "10.1109/TVCG.2018.2865159", "author": ["M. Le Goc", "C. Perin", "S. Follmer", "J. Fekete", "P. Dragicevic"], "title": "Dynamic Composite Data Physicalization Using Wheeled Micro-Robots", "year": "2019", "abstract": "This paper introduces dynamic composite physicalizations, a new class of physical visualizations that use collections of self-propelled objects to represent data. Dynamic composite physicalizations can be used both to give physical form to well-known interactive visualization techniques, and to explore new visualizations and interaction paradigms. We first propose a design space characterizing composite physicalizations based on previous work in the fields of Information Visualization and Human Computer Interaction. We illustrate dynamic composite physicalizations in two scenarios demonstrating potential benefits for collaboration and decision making, as well as new opportunities for physical interaction. We then describe our implementation using wheeled micro-robots capable of locating themselves and sensing user input, before discussing limitations and opportunities for future work.", "keywords": ["data visualisation", "human computer interaction", "microrobots", "mobile robots", "dynamic composite data physicalization", "wheeled microrobots", "physical visualizations", "interactive visualization techniques", "physical interaction", "information visualization", "human computer interaction", "decision making", "Data visualization", "Visualization", "Two dimensional displays", "Collaboration", "Animation", "Shape", "Human computer interaction", "information visualization", "data physicalization", "tangible user interfaces"], "referenced_by": ["IKEY:8805424", "IKEY:9238588"], "referencing": ["10.1145/3025453.3025877", "10.1145/2396636.2396675", "10.1145/3025453.3025512", "10.1145/289444.289491", "10.1145/1978942.1979233", "10.1145/2858036.2858058", "10.1145/2501988.2502032", "10.1145/1518701.1518851", "10.1145/2207676.2208691", "10.1145/2470654.2481359", "10.1145/2702123.2702180", "10.1145/502512.502530", "10.1145/3130931", "10.1145/1142405.1142429", "10.1145/1978942.1979033", "10.1145/2807442.2807488", "10.1145/2909132.2909247", "10.1145/2984511.2984547", "10.1145/2642918.2647377", "10.1145/2207676.2208370", "10.1145/1226969.1226984", "10.1145/2076354.2076368", "10.1145/571985.572011", "10.1145/2556288.2557379", "10.1145/255950.153577", "10.1145/2556288.2557231", "10.1145/2702123.2702604", "10.1145/3173574.3173728", "10.1145/258549.258803", "10.1145/1057237.1057242", "10.1145/2702123.2702237", "10.1145/1866029.1866075", "10.1145/1413634.1413696", "10.1145/3025453.3025877", "10.1145/2396636.2396675", "10.1145/3025453.3025512", "10.1145/289444.289491", "10.1145/1978942.1979233", "10.1145/2858036.2858058", "10.1145/2501988.2502032", "10.1145/1518701.1518851", "10.1145/2207676.2208691", "10.1145/2470654.2481359", "10.1145/2702123.2702180", "10.1145/502512.502530", "10.1145/3130931", "10.1145/1142405.1142429", "10.1145/1978942.1979033", "10.1145/2807442.2807488", "10.1145/2909132.2909247", "10.1145/2984511.2984547", "10.1145/2642918.2647377", "10.1145/2207676.2208370", "10.1145/1226969.1226984", "10.1145/2076354.2076368", "10.1145/571985.572011", "10.1145/2556288.2557379", "10.1145/255950.153577", "10.1145/2556288.2557231", "10.1145/2702123.2702604", "10.1145/3173574.3173728", "10.1145/258549.258803", "10.1145/1057237.1057242", "10.1145/2702123.2702237", "10.1145/1866029.1866075", "10.1145/1413634.1413696", "10.1145/3025453.3025877", "10.1145/2396636.2396675", "10.1145/3025453.3025512", "10.1145/289444.289491", "10.1145/1978942.1979233", "10.1145/2858036.2858058", "10.1145/2501988.2502032", "10.1145/1518701.1518851", "10.1145/2207676.2208691", "10.1145/2470654.2481359", "10.1145/2702123.2702180", "10.1145/502512.502530", "10.1145/3130931", "10.1145/1142405.1142429", "10.1145/1978942.1979033", "10.1145/2807442.2807488", "10.1145/2909132.2909247", "10.1145/2984511.2984547", "10.1145/2642918.2647377", "10.1145/2207676.2208370", "10.1145/1226969.1226984", "10.1145/2076354.2076368", "10.1145/571985.572011", "10.1145/2556288.2557379", "10.1145/255950.153577", "10.1145/2556288.2557231", "10.1145/2702123.2702604", "10.1145/3173574.3173728", "10.1145/258549.258803", "10.1145/1057237.1057242", "10.1145/2702123.2702237", "10.1145/1866029.1866075", "10.1145/1413634.1413696", "10.1111/cgf.12935", "10.1515/9783110854688", "10.2307/2288400", "10.4324/9781315658520", "10.1016/0004-3702(94)00017-U", "10.4135/9781412985130", "10.1007/s10551-008-9665-8", "10.1559/152304086783900068", "10.1177/001872088202400109", "10.1007/s00779-009-0279-7", "10.1007/978-3-319-67687-6_25", "10.1080/01449298208914450", "10.1177/014662168000400305", "10.1111/cgf.12935", "10.1515/9783110854688", "10.2307/2288400", "10.4324/9781315658520", "10.1016/0004-3702(94)00017-U", "10.4135/9781412985130", "10.1007/s10551-008-9665-8", "10.1559/152304086783900068", "10.1177/001872088202400109", "10.1007/s00779-009-0279-7", "10.1007/978-3-319-67687-6_25", "10.1080/01449298208914450", "10.1177/014662168000400305", "10.1111/cgf.12935", "10.1515/9783110854688", "10.2307/2288400", "10.4324/9781315658520", "10.1016/0004-3702(94)00017-U", "10.4135/9781412985130", "10.1007/s10551-008-9665-8", "10.1559/152304086783900068", "10.1177/001872088202400109", "10.1007/s00779-009-0279-7", "10.1007/978-3-319-67687-6_25", "10.1080/01449298208914450", "10.1177/014662168000400305"]}, "10.1109/TVCG.2018.2865241": {"doi": "10.1109/TVCG.2018.2865241", "author": ["E. Kerzner", "S. Goodwin", "J. Dykes", "S. Jones", "M. Meyer"], "title": "A Framework for Creative Visualization-Opportunities Workshops", "year": "2019", "abstract": "Applied visualization researchers often work closely with domain collaborators to explore new and useful applications of visualization. The early stages of collaborations are typically time consuming for all stakeholders as researchers piece together an understanding of domain challenges from disparate discussions and meetings. A number of recent projects, however, report on the use of creative visualization-opportunities (CVO) workshops to accelerate the early stages of applied work, eliciting a wealth of requirements in a few days of focused work. Yet, there is no established guidance for how to use such workshops effectively. In this paper, we present the results of a 2-year collaboration in which we analyzed the use of 17 workshops in 10 visualization contexts. Its primary contribution is a framework for CVO workshops that: 1) identifies a process model for using workshops; 2) describes a structure of what happens within effective workshops; 3) recommends 25 actionable guidelines for future workshops; and 4) presents an example workshop and workshop methods. The creation of this framework exemplifies the use of critical reflection to learn about visualization in practice from diverse studies and experience.", "keywords": ["data analysis", "data visualisation", "workshop methods", "creative visualization-opportunities workshops", "applied visualization researchers", "domain collaborators", "domain challenges", "CVO workshops", "critical reflection", "Conferences", "Data visualization", "Visualization", "Collaboration", "Stakeholders", "Creativity", "User-centered visualization design", "design studies", "creativity workshops", "critically reflective practice"], "referenced_by": [], "referencing": ["10.1145/3064663.3064692", "10.1145/2598510.2598564", "10.1145/2757226.2764544", "10.1145/2598510.2598566", "10.1145/1013115.1013132", "10.1145/2993901.2993916", "10.1145/153571.255960", "10.1145/1900441.1900476", "10.1145/2110192.2110204", "10.1145/1168149.1168158", "10.1145/2470654.2470716", "10.1145/3064663.3064692", "10.1145/2598510.2598564", "10.1145/2757226.2764544", "10.1145/2598510.2598566", "10.1145/1013115.1013132", "10.1145/2993901.2993916", "10.1145/153571.255960", "10.1145/1900441.1900476", "10.1145/2110192.2110204", "10.1145/1168149.1168158", "10.1145/2470654.2470716", "10.1145/3064663.3064692", "10.1145/2598510.2598564", "10.1145/2757226.2764544", "10.1145/2598510.2598566", "10.1145/1013115.1013132", "10.1145/2993901.2993916", "10.1145/153571.255960", "10.1145/1900441.1900476", "10.1145/2110192.2110204", "10.1145/1168149.1168158", "10.1145/2470654.2470716", "10.1037/h0026747", "10.1191/1478088706qp063oa", "10.1002/chp.1340180402", "10.1007/BF00988593", "10.1177/160940690900800406", "10.4018/978-1-59140-506-1.ch015", "10.1111/cgf.13184", "10.1016/0147-1767(85)90062-8", "10.1111/1467-8691.00101", "10.1207/s15324834basp1201_1", "10.1201/b15703", "10.1080/15710880701875068", "10.1007/978-0-230-36655-8", "10.1002/ace.36719915005", "10.1111/cgf.12635", "10.1037/h0026747", "10.1191/1478088706qp063oa", "10.1002/chp.1340180402", "10.1007/BF00988593", "10.1177/160940690900800406", "10.4018/978-1-59140-506-1.ch015", "10.1111/cgf.13184", "10.1016/0147-1767(85)90062-8", "10.1111/1467-8691.00101", "10.1207/s15324834basp1201_1", "10.1201/b15703", "10.1080/15710880701875068", "10.1007/978-0-230-36655-8", "10.1002/ace.36719915005", "10.1111/cgf.12635", "10.1037/h0026747", "10.1191/1478088706qp063oa", "10.1002/chp.1340180402", "10.1007/BF00988593", "10.1177/160940690900800406", "10.4018/978-1-59140-506-1.ch015", "10.1111/cgf.13184", "10.1016/0147-1767(85)90062-8", "10.1111/1467-8691.00101", "10.1207/s15324834basp1201_1", "10.1201/b15703", "10.1080/15710880701875068", "10.1007/978-0-230-36655-8", "10.1002/ace.36719915005", "10.1111/cgf.12635"]}, "10.1109/TVCG.2018.2864836": {"doi": "10.1109/TVCG.2018.2864836", "author": ["J. Wood", "A. Kachkaev", "J. Dykes"], "title": "Design Exposition with Literate Visualization", "year": "2019", "abstract": "We propose a new approach to the visualization design and communication process, literate visualization, based upon and extending, Donald Knuth's idea of literate programming. It integrates the process of writing data visualization code with description of the design choices that led to the implementation (design exposition). We develop a model of design exposition characterised by four visualization designer architypes: the evaluator, the autonomist, the didacticist and the rationalist. The model is used to justify the key characteristics of literate visualization: `notebook' documents that integrate live coding input, rendered output and textual narrative; low cost of authoring textual narrative; guidelines to encourage structured visualization design and its documentation. We propose narrative schemas for structuring and validating a wide range of visualization design approaches and models, and branching narratives for capturing alternative designs and design views. We describe a new open source literate visualization environment, litvis, based on a declarative interface to Vega and Vega-Lite through the functional programming language Elm combined with markdown for formatted narrative. We informally assess the approach, its implementation and potential by considering three examples spanning a range of design abstractions: new visualization idioms; validation though visualization algebra; and feminist data visualization. We argue that the rich documentation of the design process provided by literate visualization offers the potential to improve the validity of visualization design and so benefit both academic visualization and visualization practice.", "keywords": ["data visualisation", "functional programming", "interactive systems", "linear algebra", "text analysis", "design exposition", "literate programming", "data visualization code", "visualization designer architypes", "textual narrative", "structured visualization design", "visualization design approaches", "design views", "open source literate visualization environment", "design abstractions", "visualization idioms", "visualization algebra", "feminist data visualization", "design process", "academic visualization", "visualization practice", "design models", "communication process", "alternative designs capture", "functional programming language Elm", "Data visualization", "Visualization", "Programming", "Encoding", "Documentation", "Couplings", "storytelling", "design", "literate programming", "theory"], "referenced_by": ["IKEY:8617760", "IKEY:8805460", "IKEY:8816695", "IKEY:8809711"], "referencing": ["IKEY:6634166", "IKEY:6875930", "IKEY:8023762", "IKEY:6065017", "IKEY:6876000", "IKEY:7536128", "IKEY:5290695", "IKEY:7192707", "IKEY:7539624", "IKEY:6327248", "IKEY:5484109", "IKEY:6875966", "IKEY:6634166", "IKEY:6875930", "IKEY:8023762", "IKEY:6065017", "IKEY:6876000", "IKEY:7536128", "IKEY:5290695", "IKEY:7192707", "IKEY:7539624", "IKEY:6327248", "IKEY:5484109", "IKEY:6875966", "IKEY:6634166", "IKEY:6875930", "IKEY:8023762", "IKEY:6065017", "IKEY:6876000", "IKEY:7536128", "IKEY:5290695", "IKEY:7192707", "IKEY:7539624", "IKEY:6327248", "IKEY:5484109", "IKEY:6875966", "10.1145/3173574.3173748", "10.1145/2993901.2993916", "10.1145/3173574.3173606", "10.1145/1168149.1168158", "10.1145/1168149.1168162", "10.1145/3173574.3173748", "10.1145/2993901.2993916", "10.1145/3173574.3173606", "10.1145/1168149.1168158", "10.1145/1168149.1168162", "10.1145/3173574.3173748", "10.1145/2993901.2993916", "10.1145/3173574.3173606", "10.1145/1168149.1168158", "10.1145/1168149.1168162", "10.2307/1390686", "10.1177/1745691612462588", "10.1080/00098659809602729", "10.1093/comjnl/27.2.97", "10.1177/1473871613510429", "10.1007/PL00013715", "10.1111/j.1469-7610.1976.tb00381.x", "10.2307/1390686", "10.1177/1745691612462588", "10.1080/00098659809602729", "10.1093/comjnl/27.2.97", "10.1177/1473871613510429", "10.1007/PL00013715", "10.1111/j.1469-7610.1976.tb00381.x", "10.2307/1390686", "10.1177/1745691612462588", "10.1080/00098659809602729", "10.1093/comjnl/27.2.97", "10.1177/1473871613510429", "10.1007/PL00013715", "10.1111/j.1469-7610.1976.tb00381.x"]}, "10.1109/TVCG.2018.2864899": {"doi": "10.1109/TVCG.2018.2864899", "author": ["T. Tang", "S. Rubab", "J. Lai", "W. Cui", "L. Yu", "Y. Wu"], "title": "iStoryline: Effective Convergence to Hand-drawn Storylines", "year": "2019", "abstract": "Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes (1) how artists utilize narrative elements and (2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations.", "keywords": ["data visualisation", "interactive systems", "optimisation", "hand-drawn storyline", "storyline visualization techniques", "optimization goals", "narrative contexts", "iStoryline", "user interactions", "authoring tool", "high-level user interactions", "optimization algorithms", "Visualization", "Layout", "Tools", "Motion pictures", "Optimization methods", "Guidelines", "Hand-drawn illustrations", "automatic layout", "design space", "interactions", "optimization"], "referenced_by": [], "referencing": ["IKEY:7539370", "IKEY:8017577", "IKEY:7581076", "IKEY:7577822", "IKEY:5290700", "IKEY:7192669", "IKEY:7192690", "IKEY:7536218", "IKEY:6227086", "IKEY:7536654", "IKEY:7360233", "IKEY:6846815", "IKEY:6876042", "IKEY:8017594", "IKEY:7383181", "IKEY:7015617", "IKEY:6327274", "IKEY:6876015", "IKEY:7539370", "IKEY:8017577", "IKEY:7581076", "IKEY:7577822", "IKEY:5290700", "IKEY:7192669", "IKEY:7192690", "IKEY:7536218", "IKEY:6227086", "IKEY:7536654", "IKEY:7360233", "IKEY:6846815", "IKEY:6876042", "IKEY:8017594", "IKEY:7383181", "IKEY:7015617", "IKEY:6327274", "IKEY:6876015", "IKEY:7539370", "IKEY:8017577", "IKEY:7581076", "IKEY:7577822", "IKEY:5290700", "IKEY:7192669", "IKEY:7192690", "IKEY:7536218", "IKEY:6227086", "IKEY:7536654", "IKEY:7360233", "IKEY:6846815", "IKEY:6876042", "IKEY:8017594", "IKEY:7383181", "IKEY:7015617", "IKEY:6327274", "IKEY:6876015", "10.1145/568522.568523", "10.1145/2598510.2598566", "10.1145/1842993.1843035", "10.1145/3173574.3173697", "10.1145/3132272.3132299", "10.1145/1879211.1879219", "10.1145/2851581.2890236", "10.1145/3173574.3173909", "10.1145/568522.568523", "10.1145/2598510.2598566", "10.1145/1842993.1843035", "10.1145/3173574.3173697", "10.1145/3132272.3132299", "10.1145/1879211.1879219", "10.1145/2851581.2890236", "10.1145/3173574.3173909", "10.1145/568522.568523", "10.1145/2598510.2598566", "10.1145/1842993.1843035", "10.1145/3173574.3173697", "10.1145/3132272.3132299", "10.1145/1879211.1879219", "10.1145/2851581.2890236", "10.1145/3173574.3173909", "10.3102/0013189X09353787", "10.1007/978-3-540-31843-9_22", "10.1177/1529100614525555", "10.1111/j.1467-8659.2011.01955.x", "10.3102/0013189X09353787", "10.1007/978-3-540-31843-9_22", "10.1177/1529100614525555", "10.1111/j.1467-8659.2011.01955.x", "10.3102/0013189X09353787", "10.1007/978-3-540-31843-9_22", "10.1177/1529100614525555", "10.1111/j.1467-8659.2011.01955.x"]}, "10.1109/TVCG.2018.2865232": {"doi": "10.1109/TVCG.2018.2865232", "author": ["Q. Wang", "Z. Li", "S. Fu", "W. Cui", "H. Qu"], "title": "Narvis: Authoring Narrative Slideshows for Introducing Data Visualization Designs", "year": "2019", "abstract": "Visual designs can be complex in modern data visualization systems, which poses special challenges for explaining them to the non-experts. However, few if any presentation tools are tailored for this purpose. In this study, we present Narvis, a slideshow authoring tool designed for introducing data visualizations to non-experts. Narvis targets two types of end users: teachers, experts in data visualization who produce tutorials for explaining a data visualization, and students, non-experts who try to understand visualization designs through tutorials. We present an analysis of requirements through close discussions with the two types of end users. The resulting considerations guide the design and implementation of Narvis. Additionally, to help teachers better organize their introduction slideshows, we specify a data visualization as a hierarchical combination of components, which are automatically detected and extracted by Narvis. The teachers craft an introduction slideshow through first organizing these components, and then explaining them sequentially. A series of templates are provided for adding annotations and animations to improve efficiency during the authoring process. We evaluate Narvis through a qualitative analysis of the authoring experience, and a preliminary evaluation of the generated slideshows.", "keywords": ["authoring systems", "data visualisation", "authoring narrative slideshows", "visual designs", "modern data visualization systems", "Narvis", "slideshow authoring tool", "end users", "introduction slideshow", "data visualization designs", "animations", "authoring process", "authoring experience", "Data visualization", "Tools", "Visualization", "Tutorials", "Encoding", "Videos", "Interviews", "Education", "Narrative Visualization", "Authoring Tools"], "referenced_by": [], "referencing": ["IKEY:7539370", "IKEY:5290720", "IKEY:7539294", "IKEY:7185421", "IKEY:6065008", "IKEY:4388992", "IKEY:7192669", "IKEY:4376146", "IKEY:6634182", "IKEY:6183556", "IKEY:7274435", "IKEY:7061477", "IKEY:7912255", "IKEY:5613449", "IKEY:7539370", "IKEY:5290720", "IKEY:7539294", "IKEY:7185421", "IKEY:6065008", "IKEY:4388992", "IKEY:7192669", "IKEY:4376146", "IKEY:6634182", "IKEY:6183556", "IKEY:7274435", "IKEY:7061477", "IKEY:7912255", "IKEY:5613449", "IKEY:7539370", "IKEY:5290720", "IKEY:7539294", "IKEY:7185421", "IKEY:6065008", "IKEY:4388992", "IKEY:7192669", "IKEY:4376146", "IKEY:6634182", "IKEY:6183556", "IKEY:7274435", "IKEY:7061477", "IKEY:7912255", "IKEY:5613449", "10.1145/2702123.2702431", "10.1145/2702123.2702452", "10.1145/1996461.1996501", "10.1145/2642918.2647411", "10.1145/1284420.1284427", "10.1145/2598510.2598566", "10.1145/2858036.2858435", "10.1145/2047196.2047247", "10.1145/3002151.3002155", "10.1145/2702123.2702431", "10.1145/2702123.2702452", "10.1145/1996461.1996501", "10.1145/2642918.2647411", "10.1145/1284420.1284427", "10.1145/2598510.2598566", "10.1145/2858036.2858435", "10.1145/2047196.2047247", "10.1145/3002151.3002155", "10.1145/2702123.2702431", "10.1145/2702123.2702452", "10.1145/1996461.1996501", "10.1145/2642918.2647411", "10.1145/1284420.1284427", "10.1145/2598510.2598566", "10.1145/2858036.2858435", "10.1145/2047196.2047247", "10.1145/3002151.3002155", "10.2307/2288400", "10.1111/cogs.12016", "10.1038/35058500", "10.1111/cgf.13195", "10.1016/S0042-6989(00)00168-1", "10.1201/9781315281575", "10.1111/cgf.12391", "10.1111/cgf.12392", "10.1016/j.ipm.2015.02.003", "10.1007/s12528-011-9042-y", "10.2307/2288400", "10.1111/cogs.12016", "10.1038/35058500", "10.1111/cgf.13195", "10.1016/S0042-6989(00)00168-1", "10.1201/9781315281575", "10.1111/cgf.12391", "10.1111/cgf.12392", "10.1016/j.ipm.2015.02.003", "10.1007/s12528-011-9042-y", "10.2307/2288400", "10.1111/cogs.12016", "10.1038/35058500", "10.1111/cgf.13195", "10.1016/S0042-6989(00)00168-1", "10.1201/9781315281575", "10.1111/cgf.12391", "10.1111/cgf.12392", "10.1016/j.ipm.2015.02.003", "10.1007/s12528-011-9042-y"]}, "10.1109/TVCG.2018.2865158": {"doi": "10.1109/TVCG.2018.2865158", "author": ["D. Ren", "B. Lee", "M. Brehmer"], "title": "Charticulator: Interactive Construction of Bespoke Chart Layouts", "year": "2019", "abstract": "We present Charticulator, an interactive authoring tool that enables the creation of bespoke and reusable chart layouts. Charticulator is our response to most existing chart construction interfaces that require authors to choose from predefined chart layouts, thereby precluding the construction of novel charts. In contrast, Charticulator transforms a chart specification into mathematical layout constraints and automatically computes a set of layout attributes using a constraint-solving algorithm to realize the chart. It allows for the articulation of compound marks or glyphs as well as links between these glyphs, all without requiring any coding or knowledge of constraint satisfaction. Furthermore, thanks to the constraint-based layout approach, Charticulator can export chart designs into reusable templates that can be imported into other visualization tools. In addition to describing Charticulator's conceptual framework and design, we present three forms of evaluation: a gallery to illustrate its expressiveness, a user study to verify its usability, and a click-count comparison between Charticulator and three existing tools. Finally, we discuss the limitations and potentials of Charticulator as well as directions for future research. Charticulator is available with its source code at https://charticulator.com.", "keywords": ["authoring systems", "constraint satisfaction problems", "data visualisation", "graph theory", "interactive systems", "user interfaces", "bespoke chart layouts", "interactive authoring tool", "mathematical layout constraints", "constraint-based layout approach", "charticulator", "chart construction interfaces", "constraint-solving algorithm", "glyphs", "constraint satisfaction", "visualization tool", "Layout", "Tools", "Visualization", "Programming", "Data visualization", "Transforms", "Interactive visualization authoring", "Chart layout design", "Glyph design", "Constraint-based design", "Reusable chart layout"], "referenced_by": [], "referencing": ["IKEY:7539580", "IKEY:7192646", "IKEY:5290720", "IKEY:6064996", "IKEY:874345", "IKEY:4015425", "IKEY:7536218", "IKEY:8031599", "IKEY:6876042", "IKEY:7539624", "IKEY:7192704", "IKEY:981851", "IKEY:7192728", "IKEY:7539580", "IKEY:7192646", "IKEY:5290720", "IKEY:6064996", "IKEY:874345", "IKEY:4015425", "IKEY:7536218", "IKEY:8031599", "IKEY:6876042", "IKEY:7539624", "IKEY:7192704", "IKEY:981851", "IKEY:7192728", "IKEY:7539580", "IKEY:7192646", "IKEY:5290720", "IKEY:6064996", "IKEY:874345", "IKEY:4015425", "IKEY:7536218", "IKEY:8031599", "IKEY:6876042", "IKEY:7539624", "IKEY:7192704", "IKEY:981851", "IKEY:7192728", "10.1145/504704.504705", "10.1145/2501988.2502046", "10.1145/358886.358895", "10.1145/964696.964710", "10.1145/3173574.3173697", "10.1145/3125571.3125585", "10.1145/2858036.2858435", "10.1145/2207676.2208292", "10.1145/74877.74917", "10.1145/263407.263521", "10.1145/3173574.3173909", "10.1145/3025453.3025768", "10.1145/2858036.2858075", "10.1145/504704.504705", "10.1145/2501988.2502046", "10.1145/358886.358895", "10.1145/964696.964710", "10.1145/3173574.3173697", "10.1145/3125571.3125585", "10.1145/2858036.2858435", "10.1145/2207676.2208292", "10.1145/74877.74917", "10.1145/263407.263521", "10.1145/3173574.3173909", "10.1145/3025453.3025768", "10.1145/2858036.2858075", "10.1145/504704.504705", "10.1145/2501988.2502046", "10.1145/358886.358895", "10.1145/964696.964710", "10.1145/3173574.3173697", "10.1145/3125571.3125585", "10.1145/2858036.2858435", "10.1145/2207676.2208292", "10.1145/74877.74917", "10.1145/263407.263521", "10.1145/3173574.3173909", "10.1145/3025453.3025768", "10.1145/2858036.2858075", "10.1016/j.visinf.2018.04.008", "10.1007/s00146-006-0050-9", "10.1111/cgf.12391", "10.1023/A:1009708715411", "10.1016/j.visinf.2018.04.008", "10.1007/s00146-006-0050-9", "10.1111/cgf.12391", "10.1023/A:1009708715411", "10.1016/j.visinf.2018.04.008", "10.1007/s00146-006-0050-9", "10.1111/cgf.12391", "10.1023/A:1009708715411"]}, "10.1109/TVCG.2018.2865075": {"doi": "10.1109/TVCG.2018.2865075", "author": ["A. Sarvghad", "B. Saket", "A. Endert", "N. Weibel"], "title": "Embedded Merge Split: Visual Adjustment of Data Grouping", "year": "2019", "abstract": "Data grouping is among the most frequently used operations in data visualization. It is the process through which relevant information is gathered, simplified, and expressed in summary form. Many popular visualization tools support automatic grouping of data (e.g., dividing up a numerical variable into bins). Although grouping plays a pivotal role in supporting data exploration, further adjustment and customization of auto-generated grouping criteria is non-trivial. Such adjustments are currently performed either programmatically or through menus and dialogues which require specific parameter adjustments over several steps. In response, we introduce Embedded Merge & Split (EMS), a new interaction technique for direct adjustment of data grouping criteria. We demonstrate how the EMS technique can be designed to directly manipulate width and position in bar charts and histograms, as a means for adjustment of data grouping criteria. We also offer a set of design guidelines for supporting EMS. Finally, we present the results of two user studies, providing initial evidence that EMS can significantly reduce interaction time compared to WIMP-based technique and was subjectively preferred by participants.", "keywords": ["data visualisation", "merging", "user interfaces", "EMS", "visual adjustment", "data visualization", "data exploration", "auto-generated grouping criteria", "direct adjustment", "data grouping criteria", "automatic grouping", "parameter adjustments", "embedded merge and split", "visualization tools", "Data visualization", "Tools", "Visualization", "Bars", "Histograms", "Data analysis", "Synthetic aperture sonar", "Data Visualization", "Direct Manipulation", "Embedded Merge & Split", "Data Grouping", "Embedded Interaction"], "referenced_by": ["IKEY:8807303", "IKEY:8809678"], "referencing": ["IKEY:5432167", "IKEY:6400486", "IKEY:7192671", "IKEY:6875985", "IKEY:1634321", "IKEY:4658124", "IKEY:6327275", "IKEY:7539327", "IKEY:7875127", "IKEY:5432167", "IKEY:6400486", "IKEY:7192671", "IKEY:6875985", "IKEY:1634321", "IKEY:4658124", "IKEY:6327275", "IKEY:7539327", "IKEY:7875127", "IKEY:5432167", "IKEY:6400486", "IKEY:7192671", "IKEY:6875985", "IKEY:1634321", "IKEY:4658124", "IKEY:6327275", "IKEY:7539327", "IKEY:7875127", "10.1145/2396636.2396675", "10.1145/332040.332473", "10.1145/108844.108874", "10.1145/2380116.2380152", "10.1145/2207676.2207741", "10.1145/1978942.1979444", "10.1145/1978942.1979033", "10.1145/2556288.2557379", "10.1145/2556288.2557231", "10.1145/1377966.1377971", "10.1145/2396636.2396675", "10.1145/332040.332473", "10.1145/108844.108874", "10.1145/2380116.2380152", "10.1145/2207676.2207741", "10.1145/1978942.1979444", "10.1145/1978942.1979033", "10.1145/2556288.2557379", "10.1145/2556288.2557231", "10.1145/1377966.1377971", "10.1145/2396636.2396675", "10.1145/332040.332473", "10.1145/108844.108874", "10.1145/2380116.2380152", "10.1145/2207676.2207741", "10.1145/1978942.1979444", "10.1145/1978942.1979033", "10.1145/2556288.2557379", "10.1145/2556288.2557231", "10.1145/1377966.1377971", "10.1177/1473871611413180", "10.2307/2283767", "10.1207/s15327051hci0104_2", "10.1007/s10928-011-9223-3", "10.1201/b17511", "10.1111/j.1467-8659.2009.01678.x", "10.1111/cgf.12391", "10.1007/11555261_24", "10.1186/2049-2618-2-26", "10.1177/1473871611413180", "10.2307/2283767", "10.1207/s15327051hci0104_2", "10.1007/s10928-011-9223-3", "10.1201/b17511", "10.1111/j.1467-8659.2009.01678.x", "10.1111/cgf.12391", "10.1007/11555261_24", "10.1186/2049-2618-2-26", "10.1177/1473871611413180", "10.2307/2283767", "10.1207/s15327051hci0104_2", "10.1007/s10928-011-9223-3", "10.1201/b17511", "10.1111/j.1467-8659.2009.01678.x", "10.1111/cgf.12391", "10.1007/11555261_24", "10.1186/2049-2618-2-26"]}, "10.1109/TVCG.2018.2865147": {"doi": "10.1109/TVCG.2018.2865147", "author": ["K. B. Schloss", "C. C. Gramazio", "A. T. Silverman", "M. L. Parker", "A. S. Wang"], "title": "Mapping Color to Meaning in Colormap Data Visualizations", "year": "2019", "abstract": "To interpret data visualizations, people must determine how visual features map onto concepts. For example, to interpret colormaps, people must determine how dimensions of color (e.g., lightness, hue) map onto quantities of a given measure (e.g., brain activity, correlation magnitude). This process is easier when the encoded mappings in the visualization match people's predictions of how visual features will map onto concepts, their inferred mappings. To harness this principle in visualization design, it is necessary to understand what factors determine people's inferred mappings. In this study, we investigated how inferred color-quantity mappings for colormap data visualizations were influenced by the background color. Prior literature presents seemingly conflicting accounts of how the background color affects inferred color-quantity mappings. The present results help resolve those conflicts, demonstrating that sometimes the background has an effect and sometimes it does not, depending on whether the colormap appears to vary in opacity. When there is no apparent variation in opacity, participants infer that darker colors map to larger quantities (dark-is-more bias). As apparent variation in opacity increases, participants become biased toward inferring that more opaque colors map to larger quantities (opaque-is-more bias). These biases work together on light backgrounds and conflict on dark backgrounds. Under such conflicts, the opaque-is-more bias can negate, or even supersede the dark-is-more bias. The results suggest that if a design goal is to produce colormaps that match people's inferred mappings and are robust to changes in background color, it is beneficial to use colormaps that will not appear to vary in opacity on any background color, and to encode larger quantities in darker colors.", "keywords": ["data visualisation", "image colour analysis", "opaque-is-more bias", "opaque colors map", "dark-is-more bias", "darker colors map", "conflict", "background color", "inferred color-quantity mappings", "visualization design", "inferred mappings", "visual features", "visualization match people", "encoded mappings", "features map", "colormap data visualizations", "mapping color", "Image color analysis", "Data visualization", "Visualization", "Visual Reasoning", "Visual Communication", "Colormaps", "Color Perception", "Visual Encoding", "Visual Design"], "referenced_by": ["IKEY:8805429", "IKEY:8809846", "IKEY:9089446"], "referencing": ["IKEY:4118486", "IKEY:8017653", "IKEY:7539386", "IKEY:5613429", "IKEY:4376151", "IKEY:736450", "IKEY:8017604", "IKEY:7760", "IKEY:7305807", "IKEY:4118486", "IKEY:8017653", "IKEY:7539386", "IKEY:5613429", "IKEY:4376151", "IKEY:736450", "IKEY:8017604", "IKEY:7760", "IKEY:7305807", "IKEY:4118486", "IKEY:8017653", "IKEY:7539386", "IKEY:5613429", "IKEY:4376151", "IKEY:736450", "IKEY:8017604", "IKEY:7760", "IKEY:7305807", "10.1145/1518701.1518897", "10.1145/3173574.3174172", "10.1145/800031.808606", "10.1145/3173574.3173846", "10.1145/1518701.1518897", "10.1145/3173574.3174172", "10.1145/800031.808606", "10.1145/3173574.3173846", "10.1145/1518701.1518897", "10.1145/3173574.3174172", "10.1145/800031.808606", "10.1145/3173574.3173846", "10.1559/152304090783805663", "10.1126/scitranslmed.aah6904", "10.3758/BF03203917", "10.1016/B978-0-08-042415-6.50014-4", "10.1559/152304097782439231", "10.1016/j.neuroimage.2013.01.068", "10.1179/000870473787339347", "10.3138/4Q4P-5402-9032-7171", "10.1016/j.visres.2004.02.009", "10.1179/000870403235002042", "10.1016/j.neuroimage.2015.04.026", "10.1063/1.881857", "10.1111/cgf.12127", "10.1559/152304089783813918", "10.1038/scientificamerican0474-90", "10.1007/978-3-642-10520-3_9", "10.1117/12.384882", "10.1063/1.4822401", "10.1179/000870409X12488753453372", "10.1186/s41235-018-0090-y", "10.1177/1073858409355817", "10.1016/j.cag.2010.11.015", "10.1037/0033-295X.109.3.492", "10.1016/0010-0285(92)90004-L", "10.1037/1076-898X.5.4.393", "10.1111/j.1756-8765.2010.01113.x", "10.1006/ijhc.2002.1017", "10.3758/BF03201236", "10.1559/152304090783805663", "10.1126/scitranslmed.aah6904", "10.3758/BF03203917", "10.1016/B978-0-08-042415-6.50014-4", "10.1559/152304097782439231", "10.1016/j.neuroimage.2013.01.068", "10.1179/000870473787339347", "10.3138/4Q4P-5402-9032-7171", "10.1016/j.visres.2004.02.009", "10.1179/000870403235002042", "10.1016/j.neuroimage.2015.04.026", "10.1063/1.881857", "10.1111/cgf.12127", "10.1559/152304089783813918", "10.1038/scientificamerican0474-90", "10.1007/978-3-642-10520-3_9", "10.1117/12.384882", "10.1063/1.4822401", "10.1179/000870409X12488753453372", "10.1186/s41235-018-0090-y", "10.1177/1073858409355817", "10.1016/j.cag.2010.11.015", "10.1037/0033-295X.109.3.492", "10.1016/0010-0285(92)90004-L", "10.1037/1076-898X.5.4.393", "10.1111/j.1756-8765.2010.01113.x", "10.1006/ijhc.2002.1017", "10.3758/BF03201236", "10.1559/152304090783805663", "10.1126/scitranslmed.aah6904", "10.3758/BF03203917", "10.1016/B978-0-08-042415-6.50014-4", "10.1559/152304097782439231", "10.1016/j.neuroimage.2013.01.068", "10.1179/000870473787339347", "10.3138/4Q4P-5402-9032-7171", "10.1016/j.visres.2004.02.009", "10.1179/000870403235002042", "10.1016/j.neuroimage.2015.04.026", "10.1063/1.881857", "10.1111/cgf.12127", "10.1559/152304089783813918", "10.1038/scientificamerican0474-90", "10.1007/978-3-642-10520-3_9", "10.1117/12.384882", "10.1063/1.4822401", "10.1179/000870409X12488753453372", "10.1186/s41235-018-0090-y", "10.1177/1073858409355817", "10.1016/j.cag.2010.11.015", "10.1037/0033-295X.109.3.492", "10.1016/0010-0285(92)90004-L", "10.1037/1076-898X.5.4.393", "10.1111/j.1756-8765.2010.01113.x", "10.1006/ijhc.2002.1017", "10.3758/BF03201236"]}, "10.1109/TVCG.2018.2864912": {"doi": "10.1109/TVCG.2018.2864912", "author": ["Y. Wang", "X. Chen", "T. Ge", "C. Bao", "M. Sedlmair", "C. Fu", "O. Deussen", "B. Chen"], "title": "Optimizing Color Assignment for Perception of Class Separability in Multiclass Scatterplots", "year": "2019", "abstract": "Appropriate choice of colors significantly aids viewers in understanding the structures in multiclass scatterplots and becomes more important with a growing number of data points and groups. An appropriate color mapping is also an important parameter for the creation of an aesthetically pleasing scatterplot. Currently, users of visualization software routinely rely on color mappings that have been pre-defined by the software. A default color mapping, however, cannot ensure an optimal perceptual separability between groups, and sometimes may even lead to a misinterpretation of the data. In this paper, we present an effective approach for color assignment based on a set of given colors that is designed to optimize the perception of scatterplots. Our approach takes into account the spatial relationships, density, degree of overlap between point clusters, and also the background color. For this purpose, we use a genetic algorithm that is able to efficiently find good color assignments. We implemented an interactive color assignment system with three extensions of the basic method that incorporates top K suggestions, user-defined color subsets, and classes of interest for the optimization. To demonstrate the effectiveness of our assignment technique, we conducted a numerical study and a controlled user study to compare our approach with default color assignments; our findings were verified by two expert studies. The results show that our approach is able to support users in distinguishing cluster numbers faster and more precisely than default assignment methods.", "keywords": ["data visualisation", "genetic algorithms", "image colour analysis", "pattern clustering", "background color", "good color assignments", "interactive color assignment system", "user-defined color subsets", "assignment technique", "default color assignments", "default assignment methods", "class separability", "multiclass scatterplots", "data points", "aesthetically pleasing scatterplot", "visualization software", "color mappings", "default color mapping", "optimal perceptual separability", "color mapping", "genetic algorithm", "top K suggestions", "cluster numbers", "Image color analysis", "Visualization", "Data visualization", "Task analysis", "Genetic algorithms", "Optimization", "Tools", "Color perception", "visual design", "scatterplots"], "referenced_by": ["IKEY:8794768", "IKEY:8807243", "IKEY:8807244", "IKEY:8809844", "IKEY:8848845"], "referencing": ["IKEY:7465244", "IKEY:480803", "IKEY:7539556", "IKEY:6634120", "IKEY:7539386", "IKEY:568118", "IKEY:6365630", "IKEY:6618995", "IKEY:6247743", "IKEY:8017602", "IKEY:6634128", "IKEY:7192709", "IKEY:8017604", "IKEY:5332628", "IKEY:4577975", "IKEY:4658198", "IKEY:7920403", "IKEY:7305807", "IKEY:7465244", "IKEY:480803", "IKEY:7539556", "IKEY:6634120", "IKEY:7539386", "IKEY:568118", "IKEY:6365630", "IKEY:6618995", "IKEY:6247743", "IKEY:8017602", "IKEY:6634128", "IKEY:7192709", "IKEY:8017604", "IKEY:5332628", "IKEY:4577975", "IKEY:4658198", "IKEY:7920403", "IKEY:7305807", "IKEY:7465244", "IKEY:480803", "IKEY:7539556", "IKEY:6634120", "IKEY:7539386", "IKEY:568118", "IKEY:6365630", "IKEY:6618995", "IKEY:6247743", "IKEY:8017602", "IKEY:6634128", "IKEY:7192709", "IKEY:8017604", "IKEY:5332628", "IKEY:4577975", "IKEY:4658198", "IKEY:7920403", "IKEY:7305807", "10.1145/2669557.2669559", "10.1145/1842993.1843034", "10.1145/2669557.2669559", "10.1145/1842993.1843034", "10.1145/2669557.2669559", "10.1145/1842993.1843034", "10.1111/j.1467-8659.2009.01359.x", "10.4324/9780203807002", "10.1080/01969727408546059", "10.1179/000870403235002042", "10.1016/0042-6989(64)90037-9", "10.1111/cgf.12499", "10.1007/978-0-387-39351-3", "10.1111/cgf.12127", "10.1179/caj.2000.37.2.93", "10.1201/b17511", "10.1016/0377-0427(87)90125-7", "10.1111/cgf.12632", "10.1111/j.1467-8659.2012.03125.x", "10.1002/col.20070", "10.1016/j.cag.2010.11.015", "10.1111/j.1467-8659.2009.01467.x", "10.1016/j.csda.2008.11.033", "10.1111/j.1467-8659.2009.01359.x", "10.4324/9780203807002", "10.1080/01969727408546059", "10.1179/000870403235002042", "10.1016/0042-6989(64)90037-9", "10.1111/cgf.12499", "10.1007/978-0-387-39351-3", "10.1111/cgf.12127", "10.1179/caj.2000.37.2.93", "10.1201/b17511", "10.1016/0377-0427(87)90125-7", "10.1111/cgf.12632", "10.1111/j.1467-8659.2012.03125.x", "10.1002/col.20070", "10.1016/j.cag.2010.11.015", "10.1111/j.1467-8659.2009.01467.x", "10.1016/j.csda.2008.11.033", "10.1111/j.1467-8659.2009.01359.x", "10.4324/9780203807002", "10.1080/01969727408546059", "10.1179/000870403235002042", "10.1016/0042-6989(64)90037-9", "10.1111/cgf.12499", "10.1007/978-0-387-39351-3", "10.1111/cgf.12127", "10.1179/caj.2000.37.2.93", "10.1201/b17511", "10.1016/0377-0427(87)90125-7", "10.1111/cgf.12632", "10.1111/j.1467-8659.2012.03125.x", "10.1002/col.20070", "10.1016/j.cag.2010.11.015", "10.1111/j.1467-8659.2009.01467.x", "10.1016/j.csda.2008.11.033"]}, "10.1109/TVCG.2018.2864907": {"doi": "10.1109/TVCG.2018.2864907", "author": ["M. Correll", "M. Li", "G. Kindlmann", "C. Scheidegger"], "title": "Looks Good To Me: Visualizations As Sanity Checks", "year": "2019", "abstract": "Famous examples such as Anscombe's Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks.", "keywords": ["crowdsourcing", "data visualisation", "statistical analysis", "visual patterns", "visual inspection", "final visual appearance", "visual features", "visual signatures", "algebraic visualization design", "Data visualization", "Visualization", "Histograms", "Bandwidth", "Data integrity", "Kernel", "Data analysis", "Graphical perception", "data quality", "univariate visualizations"], "referenced_by": ["IKEY:8807247", "IKEY:8919687", "IKEY:8983015"], "referencing": ["IKEY:7539286", "IKEY:6064996", "IKEY:6875915", "IKEY:7883519", "IKEY:7536212", "IKEY:6875950", "IKEY:6875978", "IKEY:6327249", "IKEY:6875930", "IKEY:7864468", "IKEY:7539624", "IKEY:8017604", "IKEY:7217849", "IKEY:5613434", "IKEY:7192728", "IKEY:7539286", "IKEY:6064996", "IKEY:6875915", "IKEY:7883519", "IKEY:7536212", "IKEY:6875950", "IKEY:6875978", "IKEY:6327249", "IKEY:6875930", "IKEY:7864468", "IKEY:7539624", "IKEY:8017604", "IKEY:7217849", "IKEY:5613434", "IKEY:7192728", "IKEY:7539286", "IKEY:6064996", "IKEY:6875915", "IKEY:7883519", "IKEY:7536212", "IKEY:6875950", "IKEY:6875978", "IKEY:6327249", "IKEY:6875930", "IKEY:7864468", "IKEY:7539624", "IKEY:8017604", "IKEY:7217849", "IKEY:5613434", "IKEY:7192728", "10.1145/3025453.3025870", "10.1145/2470654.2466443", "10.1145/1753326.1753357", "10.1145/2254556.2254659", "10.1145/2702123.2702585", "10.1145/3025453.3025912", "10.1145/2858036.2858155", "10.1145/3025453.3025870", "10.1145/2470654.2466443", "10.1145/1753326.1753357", "10.1145/2254556.2254659", "10.1145/2702123.2702585", "10.1145/3025453.3025912", "10.1145/2858036.2858155", "10.1145/3025453.3025870", "10.1145/2470654.2466443", "10.1145/1753326.1753357", "10.1145/2254556.2254659", "10.1145/2702123.2702585", "10.1145/3025453.3025912", "10.1145/2858036.2858155", "10.1037/1082-989X.10.4.389", "10.2307/2288400", "10.1007/BF01025868", "10.2307/2685478", "10.1111/j.1539-6924.1987.tb00488.x", "10.1080/01621459.1996.10476701", "10.1023/A:1021564703268", "10.1080/00045608.2011.577364", "10.2307/2289526", "10.1016/j.jesp.2017.01.006", "10.1111/j.1467-8659.2009.01677.x", "10.1002/wics.35", "10.1214/088342304000000297", "10.1111/j.2517-6161.1991.tb01857.x", "10.2307/2686111", "10.1037/1082-989X.10.4.389", "10.2307/2288400", "10.1007/BF01025868", "10.2307/2685478", "10.1111/j.1539-6924.1987.tb00488.x", "10.1080/01621459.1996.10476701", "10.1023/A:1021564703268", "10.1080/00045608.2011.577364", "10.2307/2289526", "10.1016/j.jesp.2017.01.006", "10.1111/j.1467-8659.2009.01677.x", "10.1002/wics.35", "10.1214/088342304000000297", "10.1111/j.2517-6161.1991.tb01857.x", "10.2307/2686111", "10.1037/1082-989X.10.4.389", "10.2307/2288400", "10.1007/BF01025868", "10.2307/2685478", "10.1111/j.1539-6924.1987.tb00488.x", "10.1080/01621459.1996.10476701", "10.1023/A:1021564703268", "10.1080/00045608.2011.577364", "10.2307/2289526", "10.1016/j.jesp.2017.01.006", "10.1111/j.1467-8659.2009.01677.x", "10.1002/wics.35", "10.1214/088342304000000297", "10.1111/j.2517-6161.1991.tb01857.x", "10.2307/2686111"]}, "10.1109/TVCG.2018.2865266": {"doi": "10.1109/TVCG.2018.2865266", "author": ["Y. Wang", "Z. Wang", "C. Fu", "H. Schmauder", "O. Deussen", "D. Weiskopf"], "title": "Image-Based Aspect Ratio Selection", "year": "2019", "abstract": "Selecting a good aspect ratio is crucial for effective 2D diagrams. There are several aspect ratio selection methods for function plots and line charts, but only few can handle general, discrete diagrams such as 2D scatter plots. However, these methods either lack a perceptual foundation or heavily rely on intermediate isoline representations, which depend on choosing the right isovalues and are time-consuming to compute. This paper introduces a general image-based approach for selecting aspect ratios for a wide variety of 2D diagrams, ranging from scatter plots and density function plots to line charts. Our approach is derived from Federer's co-area formula and a line integral representation that enable us to directly construct image-based versions of existing selection methods using density fields. In contrast to previous methods, our approach bypasses isoline computation, so it is faster to compute, while following the perceptual foundation to select aspect ratios. Furthermore, this approach is complemented by an anisotropic kernel density estimation to construct density fields, allowing us to more faithfully characterize data patterns, such as the subgroups in scatterplots or dense regions in time series. We demonstrate the effectiveness of our approach by quantitatively comparing to previous methods and revisiting a prior user study. Finally, we present extensions for ROI banking, multi-scale banking, and the application to image data.", "keywords": ["data visualisation", "Federer co-area formula", "image data", "anisotropic kernel density estimation", "isoline computation", "density fields", "image-based versions", "line integral representation", "density function plots", "aspect ratios", "general image-based approach", "intermediate isoline representations", "perceptual foundation", "scatter plots", "discrete diagrams", "general diagrams", "line charts", "aspect ratio selection methods", "effective 2D diagrams", "good aspect ratio", "Two dimensional displays", "Banking", "Data visualization", "Kernel", "Market research", "Estimation", "Visualization", "Aspect ratio", "image-based method", "Federer's co-area formula", "density field", "anisotropic kernel density estimation"], "referenced_by": ["IKEY:8794768"], "referencing": ["IKEY:4658159", "IKEY:4015490", "IKEY:6197188", "IKEY:6634178", "IKEY:4015420", "IKEY:5290770", "IKEY:5613469", "IKEY:8017602", "IKEY:4658188", "IKEY:6064993", "IKEY:6327267", "IKEY:5332628", "IKEY:7817898", "IKEY:8239850", "IKEY:1532142", "IKEY:4658159", "IKEY:4015490", "IKEY:6197188", "IKEY:6634178", "IKEY:4015420", "IKEY:5290770", "IKEY:5613469", "IKEY:8017602", "IKEY:4658188", "IKEY:6064993", "IKEY:6327267", "IKEY:5332628", "IKEY:7817898", "IKEY:8239850", "IKEY:1532142", "IKEY:4658159", "IKEY:4015490", "IKEY:6197188", "IKEY:6634178", "IKEY:4015420", "IKEY:5290770", "IKEY:5613469", "IKEY:8017602", "IKEY:4658188", "IKEY:6064993", "IKEY:6327267", "IKEY:5332628", "IKEY:7817898", "IKEY:8239850", "IKEY:1532142", "10.1145/2094114.2094126", "10.1145/1073204.1073241", "10.1145/22949.22950", "10.1145/2094114.2094126", "10.1145/1073204.1073241", "10.1145/22949.22950", "10.1145/2094114.2094126", "10.1145/1073204.1073241", "10.1145/22949.22950", "10.2307/1390686", "10.1080/01621459.1988.10478598", "10.1167/3.9.11", "10.1090/S0002-9947-1959-0110078-1", "10.1007/978-3-642-62010-2", "10.1137/0802003", "10.1111/j.1467-8659.2011.01912.x", "10.1016/j.visres.2008.03.006", "10.1111/cgf.12117", "10.1007/978-1-4899-3324-9", "10.1038/358600a0", "10.1163/156856895X00098", "10.1111/j.1467-8659.2012.03122.x", "10.2307/1390686", "10.1080/01621459.1988.10478598", "10.1167/3.9.11", "10.1090/S0002-9947-1959-0110078-1", "10.1007/978-3-642-62010-2", "10.1137/0802003", "10.1111/j.1467-8659.2011.01912.x", "10.1016/j.visres.2008.03.006", "10.1111/cgf.12117", "10.1007/978-1-4899-3324-9", "10.1038/358600a0", "10.1163/156856895X00098", "10.1111/j.1467-8659.2012.03122.x", "10.2307/1390686", "10.1080/01621459.1988.10478598", "10.1167/3.9.11", "10.1090/S0002-9947-1959-0110078-1", "10.1007/978-3-642-62010-2", "10.1137/0802003", "10.1111/j.1467-8659.2011.01912.x", "10.1016/j.visres.2008.03.006", "10.1111/cgf.12117", "10.1007/978-1-4899-3324-9", "10.1038/358600a0", "10.1163/156856895X00098", "10.1111/j.1467-8659.2012.03122.x"]}, "10.1109/TVCG.2018.2865233": {"doi": "10.1109/TVCG.2018.2865233", "author": ["E. Dimara", "G. Bailly", "A. Bezerianos", "S. Franconeri"], "title": "Mitigating the Attraction Effect with Visualizations", "year": "2019", "abstract": "Human decisions are prone to biases, and this is no less true for decisions made within data visualizations. Bias mitigation strategies often focus on the person, by educating people about their biases, typically with little success. We focus instead on the system, presenting the first evidence that altering the design of an interactive visualization tool can mitigate a strong bias - the attraction effect. Participants viewed 2D scatterplots where choices between superior alternatives were affected by the placement of other suboptimal points. We found that highlighting the superior alternatives weakened the bias, but did not eliminate it. We then tested an interactive approach where participants completely removed locally dominated points from the view, inspired by the elimination by aspects strategy in the decision-making literature. This approach strongly decreased the bias, leading to a counterintuitive suggestion: tools that allow removing inappropriately salient or distracting data from a view may help lead users to make more rational decisions.", "keywords": ["data visualisation", "decision making", "attraction effect", "superior alternatives", "suboptimal points", "interactive approach", "decision-making literature", "rational decisions", "human decisions", "data visualizations", "bias mitigation strategies", "interactive visualization tool", "Data visualization", "Training", "Decision making", "Cognition", "Visualization", "Task analysis", "Decision making", "cognitive bias", "bias alleviation", "bias mitigation", "debiasing", "information visualization", "attraction effect"], "referenced_by": [], "referencing": ["10.1145/1385569.1385603", "10.1145/3025453.3025512", "10.1145/989863.989885", "10.1145/2702123.2702608", "10.1145/97243.97273", "10.1145/2675133.2685033", "10.1145/1385569.1385603", "10.1145/3025453.3025512", "10.1145/989863.989885", "10.1145/2702123.2702608", "10.1145/97243.97273", "10.1145/2675133.2685033", "10.1145/1385569.1385603", "10.1145/3025453.3025512", "10.1145/989863.989885", "10.1145/2702123.2702608", "10.1145/97243.97273", "10.1145/2675133.2685033", "10.1016/j.obhdp.2011.07.002", "10.1037/0033-2909.110.3.486", "10.1017/S0140525X07001653", "10.1006/anbe.2001.1925", "10.1086/209535", "10.1287/mksc.18.3.230", "10.1037/0022-3514.70.4.661", "10.1007/978-94-017-1406-8_2", "10.1016/0010-0285(86)90002-2", "10.1136/bmjqs-2012-001712", "10.2514/6.2004-6313", "10.1126/science.2648573", "10.1007/978-3-319-26633-6_13", "10.1007/978-3-319-07127-5_9", "10.1037/0096-1523.3.4.552", "10.1086/209351", "10.1016/0010-0285(86)90001-0", "10.1037/0096-3445.120.1.34", "10.1007/s10648-014-9249-3", "10.1111/j.1756-8765.2008.01006.x", "10.1136/bmjqs-2011-000149", "10.1002/int.4550070706", "10.1017/S1068280500004238", "10.1509/jmkr.46.1.1", "10.1509/jmkr.46.3.330", "10.1016/j.jesp.2012.08.010", "10.1006/obhd.1996.0006", "10.1016/0030-5073(78)90037-5", "10.1086/208899", "10.1509/jmr.14.0208", "10.1371/journal.pone.0142444", "10.1023/A:1007740225484", "10.1016/S0167-9236(02)00137-9", "10.1037/0003-066X.58.9.697", "10.1016/0010-0285(72)90016-3", "10.1016/0010-0277(93)90037-V", "10.1111/j.1467-9280.1990.tb00243.x", "10.1098/rspb.2010.1045", "10.1037/0012-1649.26.6.952", "10.1207/s15327051hci0701_3", "10.1177/2372732215600886", "10.1016/j.jsha.2013.04.003", "10.1037/h0027568", "10.1201/b17511", "10.1177/01461672002611010", "10.1037/1089-2680.2.2.175", "10.1080/02841860802251559", "10.1017/CBO9781139173933", "10.1006/obhd.1999.2880", "10.4324/9781315696935", "10.1038/nature21054", "10.1177/0956797613497022", "10.1037/0278-7393.28.3.497", "10.1037/h0042769", "10.1086/209205", "10.2307/3172740", "10.1037/a0015145", "10.1016/j.ijforecast.2012.02.002", "10.1037/h0032955", "10.1093/cercor/bhr315", "10.1037/0278-7393.17.4.767", "10.1037/a0028857", "10.2307/3150659", "10.2196/jmir.8889", "10.1007/978-3-540-73214-3_15", "10.1016/j.obhdp.2011.07.002", "10.1037/0033-2909.110.3.486", "10.1017/S0140525X07001653", "10.1006/anbe.2001.1925", "10.1086/209535", "10.1287/mksc.18.3.230", "10.1037/0022-3514.70.4.661", "10.1007/978-94-017-1406-8_2", "10.1016/0010-0285(86)90002-2", "10.1136/bmjqs-2012-001712", "10.2514/6.2004-6313", "10.1126/science.2648573", "10.1007/978-3-319-26633-6_13", "10.1007/978-3-319-07127-5_9", "10.1037/0096-1523.3.4.552", "10.1086/209351", "10.1016/0010-0285(86)90001-0", "10.1037/0096-3445.120.1.34", "10.1007/s10648-014-9249-3", "10.1111/j.1756-8765.2008.01006.x", "10.1136/bmjqs-2011-000149", "10.1002/int.4550070706", "10.1017/S1068280500004238", "10.1509/jmkr.46.1.1", "10.1509/jmkr.46.3.330", "10.1016/j.jesp.2012.08.010", "10.1006/obhd.1996.0006", "10.1016/0030-5073(78)90037-5", "10.1086/208899", "10.1509/jmr.14.0208", "10.1371/journal.pone.0142444", "10.1023/A:1007740225484", "10.1016/S0167-9236(02)00137-9", "10.1037/0003-066X.58.9.697", "10.1016/0010-0285(72)90016-3", "10.1016/0010-0277(93)90037-V", "10.1111/j.1467-9280.1990.tb00243.x", "10.1098/rspb.2010.1045", "10.1037/0012-1649.26.6.952", "10.1207/s15327051hci0701_3", "10.1177/2372732215600886", "10.1016/j.jsha.2013.04.003", "10.1037/h0027568", "10.1201/b17511", "10.1177/01461672002611010", "10.1037/1089-2680.2.2.175", "10.1080/02841860802251559", "10.1017/CBO9781139173933", "10.1006/obhd.1999.2880", "10.4324/9781315696935", "10.1038/nature21054", "10.1177/0956797613497022", "10.1037/0278-7393.28.3.497", "10.1037/h0042769", "10.1086/209205", "10.2307/3172740", "10.1037/a0015145", "10.1016/j.ijforecast.2012.02.002", "10.1037/h0032955", "10.1093/cercor/bhr315", "10.1037/0278-7393.17.4.767", "10.1037/a0028857", "10.2307/3150659", "10.2196/jmir.8889", "10.1007/978-3-540-73214-3_15", "10.1016/j.obhdp.2011.07.002", "10.1037/0033-2909.110.3.486", "10.1017/S0140525X07001653", "10.1006/anbe.2001.1925", "10.1086/209535", "10.1287/mksc.18.3.230", "10.1037/0022-3514.70.4.661", "10.1007/978-94-017-1406-8_2", "10.1016/0010-0285(86)90002-2", "10.1136/bmjqs-2012-001712", "10.2514/6.2004-6313", "10.1126/science.2648573", "10.1007/978-3-319-26633-6_13", "10.1007/978-3-319-07127-5_9", "10.1037/0096-1523.3.4.552", "10.1086/209351", "10.1016/0010-0285(86)90001-0", "10.1037/0096-3445.120.1.34", "10.1007/s10648-014-9249-3", "10.1111/j.1756-8765.2008.01006.x", "10.1136/bmjqs-2011-000149", "10.1002/int.4550070706", "10.1017/S1068280500004238", "10.1509/jmkr.46.1.1", "10.1509/jmkr.46.3.330", "10.1016/j.jesp.2012.08.010", "10.1006/obhd.1996.0006", "10.1016/0030-5073(78)90037-5", "10.1086/208899", "10.1509/jmr.14.0208", "10.1371/journal.pone.0142444", "10.1023/A:1007740225484", "10.1016/S0167-9236(02)00137-9", "10.1037/0003-066X.58.9.697", "10.1016/0010-0285(72)90016-3", "10.1016/0010-0277(93)90037-V", "10.1111/j.1467-9280.1990.tb00243.x", "10.1098/rspb.2010.1045", "10.1037/0012-1649.26.6.952", "10.1207/s15327051hci0701_3", "10.1177/2372732215600886", "10.1016/j.jsha.2013.04.003", "10.1037/h0027568", "10.1201/b17511", "10.1177/01461672002611010", "10.1037/1089-2680.2.2.175", "10.1080/02841860802251559", "10.1017/CBO9781139173933", "10.1006/obhd.1999.2880", "10.4324/9781315696935", "10.1038/nature21054", "10.1177/0956797613497022", "10.1037/0278-7393.28.3.497", "10.1037/h0042769", "10.1086/209205", "10.2307/3172740", "10.1037/a0015145", "10.1016/j.ijforecast.2012.02.002", "10.1037/h0032955", "10.1093/cercor/bhr315", "10.1037/0278-7393.17.4.767", "10.1037/a0028857", "10.2307/3150659", "10.2196/jmir.8889", "10.1007/978-3-540-73214-3_15"]}, "10.1109/TVCG.2018.2864884": {"doi": "10.1109/TVCG.2018.2864884", "author": ["B. Ondov", "N. Jardine", "N. Elmqvist", "S. Franconeri"], "title": "Face to Face: Evaluating Visual Comparison", "year": "2019", "abstract": "Data are often viewed as a single set of values, but those values frequently must be compared with another set. The existing evaluations of designs that facilitate these comparisons tend to be based on intuitive reasoning, rather than quantifiable measures. We build on this work with a series of crowdsourced experiments that use low-level perceptual comparison tasks that arise frequently in comparisons within data visualizations (e.g., which value changes the most between the two sets of data?). Participants completed these tasks across a variety of layouts: overlaid, two arrangements of juxtaposed small multiples, mirror-symmetric small multiples, and animated transitions. A staircase procedure sought the difficulty level (e.g., value change delta) that led to equivalent accuracy for each layout. Confirming prior intuition, we observe high levels of performance for overlaid versus standard small multiples. However, we also find performance improvements for both mirror symmetric small multiples and animated transitions. While some results are incongruent with common wisdom in data visualization, they align with previous work in perceptual psychology, and thus have potentially strong implications for visual comparison designs.", "keywords": ["computer animation", "crowdsourcing", "data visualisation", "psychology", "visual perception", "data visualization", "visual comparison designs", "intuitive reasoning", "crowdsourced experiments", "juxtaposed small multiples", "animated transitions", "staircase procedure", "perceptual psychology", "low-level perceptual comparison tasks", "mirror-symmetric small multiples", "overlaid layout", "Task analysis", "Visualization", "Data visualization", "Correlation", "Bars", "Layout", "Mirrors", "Graphical perception", "visual perception", "visual comparison", "crowdsourced evaluation"], "referenced_by": ["IKEY:8807320", "IKEY:8845772", "IKEY:8794768", "IKEY:8919687", "IKEY:9086215"], "referencing": ["IKEY:8017604", "IKEY:1432689", "IKEY:5473226", "IKEY:4118486", "IKEY:6064996", "IKEY:7225156", "IKEY:6876010", "IKEY:8017615", "IKEY:6875978", "IKEY:4376146", "IKEY:6183556", "IKEY:5613429", "IKEY:8017651", "IKEY:4658146", "IKEY:8019841", "IKEY:885091", "IKEY:7305807", "IKEY:8017604", "IKEY:1432689", "IKEY:5473226", "IKEY:4118486", "IKEY:6064996", "IKEY:7225156", "IKEY:6876010", "IKEY:8017615", "IKEY:6875978", "IKEY:4376146", "IKEY:6183556", "IKEY:5613429", "IKEY:8017651", "IKEY:4658146", "IKEY:8019841", "IKEY:885091", "IKEY:7305807", "IKEY:8017604", "IKEY:1432689", "IKEY:5473226", "IKEY:4118486", "IKEY:6064996", "IKEY:7225156", "IKEY:6876010", "IKEY:8017615", "IKEY:6875978", "IKEY:4376146", "IKEY:6183556", "IKEY:5613429", "IKEY:8017651", "IKEY:4658146", "IKEY:8019841", "IKEY:885091", "IKEY:7305807", "10.1145/2909132.2909255", "10.1145/1978942.1979233", "10.1145/2702123.2702476", "10.1145/1753326.1753357", "10.1145/1518701.1518897", "10.1145/3025453.3025912", "10.1145/2993901.2993910", "10.1145/102377.115768", "10.1145/2909132.2909255", "10.1145/1978942.1979233", "10.1145/2702123.2702476", "10.1145/1753326.1753357", "10.1145/1518701.1518897", "10.1145/3025453.3025912", "10.1145/2993901.2993910", "10.1145/102377.115768", "10.1145/2909132.2909255", "10.1145/1978942.1979233", "10.1145/2702123.2702476", "10.1145/1753326.1753357", "10.1145/1518701.1518897", "10.1145/3025453.3025912", "10.1145/2993901.2993910", "10.1145/102377.115768", "10.1016/0042-6989(79)90154-8", "10.3758/s13414-016-1116-5", "10.1515/9783110854688", "10.1167/11.5.4", "10.1186/gb-2011-12-5-r50", "10.2307/2288400", "10.3758/BF03203266", "10.1037/0033-295X.96.3.433", "10.1177/1473871613513228", "10.1177/1473871611416549", "10.1111/j.1467-8306.2006.00514.x", "10.1093/acprof:osobl/9780199734337.003.0030", "10.1371/journal.pone.0158261", "10.1016/S0042-6989(99)00163-7", "10.1177/0956797611418346", "10.1111/j.1467-8659.2009.01710.x", "10.1016/0042-6989(85)90171-3", "10.1186/1471-2105-12-385", "10.1002/wcs.1328", "10.1016/j.cag.2010.11.015", "10.1080/135062800394658", "10.1167/16.5.11", "10.3390/sym2031510", "10.1016/0010-0285(80)90005-5", "10.1006/ijhc.2002.1017", "10.1016/S1364-6613(97)01105-4", "10.1177/0956797615585002", "10.1016/0042-6989(79)90154-8", "10.3758/s13414-016-1116-5", "10.1515/9783110854688", "10.1167/11.5.4", "10.1186/gb-2011-12-5-r50", "10.2307/2288400", "10.3758/BF03203266", "10.1037/0033-295X.96.3.433", "10.1177/1473871613513228", "10.1177/1473871611416549", "10.1111/j.1467-8306.2006.00514.x", "10.1093/acprof:osobl/9780199734337.003.0030", "10.1371/journal.pone.0158261", "10.1016/S0042-6989(99)00163-7", "10.1177/0956797611418346", "10.1111/j.1467-8659.2009.01710.x", "10.1016/0042-6989(85)90171-3", "10.1186/1471-2105-12-385", "10.1002/wcs.1328", "10.1016/j.cag.2010.11.015", "10.1080/135062800394658", "10.1167/16.5.11", "10.3390/sym2031510", "10.1016/0010-0285(80)90005-5", "10.1006/ijhc.2002.1017", "10.1016/S1364-6613(97)01105-4", "10.1177/0956797615585002", "10.1016/0042-6989(79)90154-8", "10.3758/s13414-016-1116-5", "10.1515/9783110854688", "10.1167/11.5.4", "10.1186/gb-2011-12-5-r50", "10.2307/2288400", "10.3758/BF03203266", "10.1037/0033-295X.96.3.433", "10.1177/1473871613513228", "10.1177/1473871611416549", "10.1111/j.1467-8306.2006.00514.x", "10.1093/acprof:osobl/9780199734337.003.0030", "10.1371/journal.pone.0158261", "10.1016/S0042-6989(99)00163-7", "10.1177/0956797611418346", "10.1111/j.1467-8659.2009.01710.x", "10.1016/0042-6989(85)90171-3", "10.1186/1471-2105-12-385", "10.1002/wcs.1328", "10.1016/j.cag.2010.11.015", "10.1080/135062800394658", "10.1167/16.5.11", "10.3390/sym2031510", "10.1016/0010-0285(80)90005-5", "10.1006/ijhc.2002.1017", "10.1016/S1364-6613(97)01105-4", "10.1177/0956797615585002"]}, "10.1109/TVCG.2018.2865264": {"doi": "10.1109/TVCG.2018.2865264", "author": ["G. Ryan", "A. Mosca", "R. Chang", "E. Wu"], "title": "At a Glance: Pixel Approximate Entropy as a Measure of Line Chart Complexity", "year": "2019", "abstract": "When inspecting information visualizations under time critical settings, such as emergency response or monitoring the heart rate in a surgery room, the user only has a small amount of time to view the visualization \u201cat a glance\u201d. In these settings, it is important to provide a quantitative measure of the visualization to understand whether or not the visualization is too \u201ccomplex\u201d to accurately judge at a glance. This paper proposes Pixel Approximate Entropy (PAE), which adapts the approximate entropy statistical measure commonly used to quantify regularity and unpredictability in time-series data, as a measure of visual complexity for line charts. We show that PAE is correlated with user-perceived chart complexity, and that increased chart PAE correlates with reduced judgement accuracy. `We also find that the correlation between PAE values and participants' judgment increases when the user has less time to examine the line charts.", "keywords": ["data visualisation", "entropy", "statistical analysis", "time series", "line chart complexity", "heart rate", "surgery room", "time-series data", "visual complexity", "user-perceived chart complexity", "PAE values", "entropy statistical measure", "pixel approximate entropy", "information visualizations", "Data visualization", "Entropy", "Complexity theory", "Visualization", "Task analysis", "Noise measurement", "Shape", "Visualization", "Graphical Perception", "Entropy", "At-a-glance"], "referenced_by": ["IKEY:8809850", "IKEY:9223207", "IKEY:9259753"], "referencing": ["IKEY:6793099", "IKEY:6064985", "IKEY:6634187", "IKEY:6634103", "IKEY:5613460", "IKEY:5613439", "IKEY:6875978", "IKEY:773807", "IKEY:5653598", "IKEY:4376133", "IKEY:1382895", "IKEY:4035766", "IKEY:4658174", "IKEY:5613434", "IKEY:6793099", "IKEY:6064985", "IKEY:6634187", "IKEY:6634103", "IKEY:5613460", "IKEY:5613439", "IKEY:6875978", "IKEY:773807", "IKEY:5653598", "IKEY:4376133", "IKEY:1382895", "IKEY:4035766", "IKEY:4658174", "IKEY:5613434", "IKEY:6793099", "IKEY:6064985", "IKEY:6634187", "IKEY:6634103", "IKEY:5613460", "IKEY:5613439", "IKEY:6875978", "IKEY:773807", "IKEY:5653598", "IKEY:4376133", "IKEY:1382895", "IKEY:4035766", "IKEY:4658174", "IKEY:5613434", "10.1145/2939502.2939512", "10.1145/2882903.2915249", "10.1145/2702123.2702443", "10.1145/1518701.1518897", "10.1145/253260.253291", "10.1145/2858036.2858155", "10.1145/2939502.2939512", "10.1145/2882903.2915249", "10.1145/2702123.2702443", "10.1145/1518701.1518897", "10.1145/253260.253291", "10.1145/2858036.2858155", "10.1145/2939502.2939512", "10.1145/2882903.2915249", "10.1145/2702123.2702443", "10.1145/1518701.1518897", "10.1145/253260.253291", "10.1145/2858036.2858155", "10.1103/PhysRevE.86.046206", "10.3390/e17063595", "10.1137/1.9781611972818.60", "10.1016/0010-0285(82)90007-X", "10.1111/j.1540-6261.1976.tb01889.x", "10.3758/s13423-017-1295-7", "10.1080/17470215808416249", "10.1201/9781315369228", "10.1016/j.medengphy.2008.04.005", "10.1016/S0042-6989(02)00596-5", "10.1103/PhysRevLett.89.068102", "10.1177/0963721409359277", "10.1111/cgf.12142", "10.1016/j.jml.2007.11.004", "10.1161/01.CIR.101.23.e215", "10.1016/j.cogpsych.2008.06.001", "10.1161/01.CIR.96.3.842", "10.1111/cgf.12094", "10.1037/0033-2909.112.1.24", "10.1002/acp.2350030302", "10.1063/1.166092", "10.1073/pnas.88.6.2297", "10.1126/science.1145183", "10.1037/0278-7393.2.5.509", "10.1111/j.1467-9280.2008.02243.x", "10.1016/j.visres.2004.04.006", "10.1167/11.11.1085", "10.1167/16.12.811", "10.3758/s13423-016-1174-7", "10.1111/j.1467-8659.2009.01694.x", "10.1152/ajpheart.2000.278.6.H2039", "10.14778/3137628.3137645", "10.1167/7.2.17", "10.1111/j.1467-9280.1994.tb00500.x", "10.1167/16.5.11", "10.1006/jvci.1993.1025", "10.3390/e13010254", "10.1007/s10439-012-0668-3", "10.1103/PhysRevE.86.046206", "10.3390/e17063595", "10.1137/1.9781611972818.60", "10.1016/0010-0285(82)90007-X", "10.1111/j.1540-6261.1976.tb01889.x", "10.3758/s13423-017-1295-7", "10.1080/17470215808416249", "10.1201/9781315369228", "10.1016/j.medengphy.2008.04.005", "10.1016/S0042-6989(02)00596-5", "10.1103/PhysRevLett.89.068102", "10.1177/0963721409359277", "10.1111/cgf.12142", "10.1016/j.jml.2007.11.004", "10.1161/01.CIR.101.23.e215", "10.1016/j.cogpsych.2008.06.001", "10.1161/01.CIR.96.3.842", "10.1111/cgf.12094", "10.1037/0033-2909.112.1.24", "10.1002/acp.2350030302", "10.1063/1.166092", "10.1073/pnas.88.6.2297", "10.1126/science.1145183", "10.1037/0278-7393.2.5.509", "10.1111/j.1467-9280.2008.02243.x", "10.1016/j.visres.2004.04.006", "10.1167/11.11.1085", "10.1167/16.12.811", "10.3758/s13423-016-1174-7", "10.1111/j.1467-8659.2009.01694.x", "10.1152/ajpheart.2000.278.6.H2039", "10.14778/3137628.3137645", "10.1167/7.2.17", "10.1111/j.1467-9280.1994.tb00500.x", "10.1167/16.5.11", "10.1006/jvci.1993.1025", "10.3390/e13010254", "10.1007/s10439-012-0668-3", "10.1103/PhysRevE.86.046206", "10.3390/e17063595", "10.1137/1.9781611972818.60", "10.1016/0010-0285(82)90007-X", "10.1111/j.1540-6261.1976.tb01889.x", "10.3758/s13423-017-1295-7", "10.1080/17470215808416249", "10.1201/9781315369228", "10.1016/j.medengphy.2008.04.005", "10.1016/S0042-6989(02)00596-5", "10.1103/PhysRevLett.89.068102", "10.1177/0963721409359277", "10.1111/cgf.12142", "10.1016/j.jml.2007.11.004", "10.1161/01.CIR.101.23.e215", "10.1016/j.cogpsych.2008.06.001", "10.1161/01.CIR.96.3.842", "10.1111/cgf.12094", "10.1037/0033-2909.112.1.24", "10.1002/acp.2350030302", "10.1063/1.166092", "10.1073/pnas.88.6.2297", "10.1126/science.1145183", "10.1037/0278-7393.2.5.509", "10.1111/j.1467-9280.2008.02243.x", "10.1016/j.visres.2004.04.006", "10.1167/11.11.1085", "10.1167/16.12.811", "10.3758/s13423-016-1174-7", "10.1111/j.1467-8659.2009.01694.x", "10.1152/ajpheart.2000.278.6.H2039", "10.14778/3137628.3137645", "10.1167/7.2.17", "10.1111/j.1467-9280.1994.tb00500.x", "10.1167/16.5.11", "10.1006/jvci.1993.1025", "10.3390/e13010254", "10.1007/s10439-012-0668-3"]}, "10.1109/TVCG.2018.2865193": {"doi": "10.1109/TVCG.2018.2865193", "author": ["L. Liu", "L. Padilla", "S. H. Creem-Regehr", "D. H. House"], "title": "Visualizing Uncertain Tropical Cyclone Predictions using Representative Samples from Ensembles of Forecast Tracks", "year": "2019", "abstract": "A common approach to sampling the space of a prediction is the generation of an ensemble of potential outcomes, where the ensemble's distribution reveals the statistical structure of the prediction space. For example, the US National Hurricane Center generates multiple day predictions for a storm's path, size, and wind speed, and then uses a Monte Carlo approach to sample this prediction into a large ensemble of potential storm outcomes. Various forms of summary visualizations are generated from such an ensemble, often using spatial spread to indicate its statistical characteristics. However, studies have shown that changes in the size of such summary glyphs, representing changes in the uncertainty of the prediction, are frequently confounded with other attributes of the phenomenon, such as its size or strength. In addition, simulation ensembles typically encode multivariate information, which can be difficult or confusing to include in a summary display. This problem can be overcome by directly displaying the ensemble as a set of annotated trajectories, however this solution will not be effective if ensembles are densely overdrawn or structurally disorganized. We propose to overcome these difficulties by selectively sampling the original ensemble, constructing a smaller representative and spatially well organized ensemble. This can be drawn directly as a set of paths that implicitly reveals the underlying spatial uncertainty distribution of the prediction. Since this approach does not use a visual channel to encode uncertainty, additional information can more easily be encoded in the display without leading to visual confusion. To demonstrate our argument, we describe the development of a visualization for ensembles of tropical cyclone forecast tracks, explaining how their spatial and temporal predictions, as well as other crucial storm characteristics such as size and intensity, can be clearly revealed. We verify the effectiveness of this visualization approach through a cognitive study exploring how storm damage estimates are affected by the density of tracks drawn, and by the presence or absence of annotating information on storm size and intensity.", "keywords": ["data visualisation", "Monte Carlo methods", "storms", "weather forecasting", "wind", "multiple day predictions", "tropical cyclone predictions", "forecast tracks", "US National Hurricane Center", "storm", "wind speed", "Monte Carlo approach", "statistical characteristics", "spatial uncertainty distribution", "Storms", "Uncertainty", "Visualization", "Hurricanes", "Tropical cyclones", "Prediction algorithms", "Predictive models", "uncertainty visualization", "hurricane forecasts", "ensemble visualization", "ensemble sampling", "implicit uncertainty"], "referenced_by": ["IKEY:8807296", "IKEY:8918276"], "referencing": ["IKEY:80341", "IKEY:8017624", "IKEY:7563342", "IKEY:6875964", "IKEY:5613483", "IKEY:80341", "IKEY:8017624", "IKEY:7563342", "IKEY:6875964", "IKEY:5613483", "IKEY:80341", "IKEY:8017624", "IKEY:7563342", "IKEY:6875964", "IKEY:5613483", "10.1145/3173574.3173718", "10.1145/2858036.2858558", "10.1145/3173574.3173718", "10.1145/2858036.2858558", "10.1145/3173574.3173718", "10.1145/2858036.2858558", "10.18637/jss.v067.i01", "10.1080/00207179608921659", "10.1615/Int.J.UncertaintyQuantification.2012003966", "10.1175/WAF-D-12-00116.1", "10.1175/2009WAF2222286.1", "10.3138/FM57-6770-U75U-7727", "10.1111/cgf.12649", "10.1214/aos/1176347507", "10.20982/tqmp.04.2.p061", "10.1186/s41235-017-0076-1", "10.1007/978-3-540-71158-2_12", "10.1080/13875868.2015.1137577", "10.1090/qam/15914", "10.1179/000870406X93490", "10.18637/jss.v067.i01", "10.1080/00207179608921659", "10.1615/Int.J.UncertaintyQuantification.2012003966", "10.1175/WAF-D-12-00116.1", "10.1175/2009WAF2222286.1", "10.3138/FM57-6770-U75U-7727", "10.1111/cgf.12649", "10.1214/aos/1176347507", "10.20982/tqmp.04.2.p061", "10.1186/s41235-017-0076-1", "10.1007/978-3-540-71158-2_12", "10.1080/13875868.2015.1137577", "10.1090/qam/15914", "10.1179/000870406X93490", "10.18637/jss.v067.i01", "10.1080/00207179608921659", "10.1615/Int.J.UncertaintyQuantification.2012003966", "10.1175/WAF-D-12-00116.1", "10.1175/2009WAF2222286.1", "10.3138/FM57-6770-U75U-7727", "10.1111/cgf.12649", "10.1214/aos/1176347507", "10.20982/tqmp.04.2.p061", "10.1186/s41235-017-0076-1", "10.1007/978-3-540-71158-2_12", "10.1080/13875868.2015.1137577", "10.1090/qam/15914", "10.1179/000870406X93490"]}, "10.1109/TVCG.2018.2864909": {"doi": "10.1109/TVCG.2018.2864909", "author": ["A. Kale", "F. Nguyen", "M. Kay", "J. Hullman"], "title": "Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data", "year": "2019", "abstract": "Animated representations of outcomes drawn from distributions (hypothetical outcome plots, or HOPs) are used in the media and other public venues to communicate uncertainty. HOPs greatly improve multivariate probability estimation over conventional static uncertainty visualizations and leverage the ability of the visual system to quickly, accurately, and automatically process the summary statistical properties of ensembles. However, it is unclear how well HOPs support applied tasks resembling real world judgments posed in uncertainty communication. We identify and motivate an appropriate task to investigate realistic judgments of uncertainty in the public domain through a qualitative analysis of uncertainty visualizations in the news. We contribute two crowdsourced experiments comparing the effectiveness of HOPs, error bars, and line ensembles for supporting perceptual decision-making from visualized uncertainty. Participants infer which of two possible underlying trends is more likely to have produced a sample of time series data by referencing uncertainty visualizations which depict the two trends with variability due to sampling error. By modeling each participant's accuracy as a function of the level of evidence presented over many repeated judgments, we find that observers are able to correctly infer the underlying trend in samples conveying a lower level of evidence when using HOPs rather than static aggregate uncertainty visualizations as a decision aid. Modeling approaches like ours contribute theoretically grounded and richly descriptive accounts of user perceptions to visualization evaluation.", "keywords": ["data analysis", "data visualisation", "probability", "time series", "hypothetical outcome plots", "multivariate probability estimation", "time series data", "static aggregate uncertainty visualizations", "ambiguous data trends", "HOPs", "qualitative analysis", "Uncertainty", "Data visualization", "Visualization", "Bars", "Task analysis", "Observers", "Encoding", "uncertainty visualization", "hypothetical outcome plots", "psychometric functions"], "referenced_by": [], "referencing": ["IKEY:6875915", "IKEY:6064986", "IKEY:8017624", "IKEY:4376198", "IKEY:6875915", "IKEY:6064986", "IKEY:8017624", "IKEY:4376198", "IKEY:6875915", "IKEY:6064986", "IKEY:8017624", "IKEY:4376198", "10.1145/3173574.3173718", "10.1145/3173574.3173718", "10.1145/3173574.3173718", "10.1177/0956797610363543", "10.1111/j.1467-9280.2008.02098.x", "10.1016/j.tics.2011.01.003", "10.1016/j.obhdp.2011.07.002", "10.1037/1082-989X.10.4.389", "10.1111/risa.12462", "10.3138/3645-4V22-0M23-3T52", "10.21236/ADA218976", "10.1126/science.216.4550.1138", "10.2307/1419876", "10.1016/S0959-4752(98)00051-6", "10.1016/S0098-3004(97)00005-8", "10.1016/S0098-3004(97)00011-3", "10.1111/j.1751-5823.2002.tb00336.x", "10.1016/S0042-6989(97)00340-4", "10.1037/0033-295X.102.4.684", "10.1016/j.proeps.2009.09.160", "10.1037/a0013899", "10.1037/0003-066X.39.12.1372", "10.1111/j.0956-7976.2004.00715.x", "10.3758/s13423-013-0572-3", "10.1097/00001888-199805000-00024", "10.1167/15.4.5", "10.1371/journal.pone.0142444", "10.1371/journal.pmed.0020124", "10.1037/a0025185", "10.1111/j.1551-6708.1987.tb00863.x", "10.1038/ncomms13186", "10.1111/cgf.12127", "10.1006/obhd.1997.2679", "10.3758/s13423-012-0247-5", "10.1002/0470033312", "10.1037/xap0000037", "10.1186/s41235-017-0076-1", "10.1007/978-3-642-32677-6_15", "10.1016/j.neuron.2016.03.025", "10.1121/1.4733540", "10.1016/j.ijforecast.2012.02.002", "10.6028/NIST.TN.1297", "10.1037/h0031322", "10.1007/978-94-010-1834-0_8", "10.1006/ijhc.2002.1017", "10.1207/s15516709cog1801_3", "10.1177/0956797610363543", "10.1111/j.1467-9280.2008.02098.x", "10.1016/j.tics.2011.01.003", "10.1016/j.obhdp.2011.07.002", "10.1037/1082-989X.10.4.389", "10.1111/risa.12462", "10.3138/3645-4V22-0M23-3T52", "10.21236/ADA218976", "10.1126/science.216.4550.1138", "10.2307/1419876", "10.1016/S0959-4752(98)00051-6", "10.1016/S0098-3004(97)00005-8", "10.1016/S0098-3004(97)00011-3", "10.1111/j.1751-5823.2002.tb00336.x", "10.1016/S0042-6989(97)00340-4", "10.1037/0033-295X.102.4.684", "10.1016/j.proeps.2009.09.160", "10.1037/a0013899", "10.1037/0003-066X.39.12.1372", "10.1111/j.0956-7976.2004.00715.x", "10.3758/s13423-013-0572-3", "10.1097/00001888-199805000-00024", "10.1167/15.4.5", "10.1371/journal.pone.0142444", "10.1371/journal.pmed.0020124", "10.1037/a0025185", "10.1111/j.1551-6708.1987.tb00863.x", "10.1038/ncomms13186", "10.1111/cgf.12127", "10.1006/obhd.1997.2679", "10.3758/s13423-012-0247-5", "10.1002/0470033312", "10.1037/xap0000037", "10.1186/s41235-017-0076-1", "10.1007/978-3-642-32677-6_15", "10.1016/j.neuron.2016.03.025", "10.1121/1.4733540", "10.1016/j.ijforecast.2012.02.002", "10.6028/NIST.TN.1297", "10.1037/h0031322", "10.1007/978-94-010-1834-0_8", "10.1006/ijhc.2002.1017", "10.1207/s15516709cog1801_3", "10.1177/0956797610363543", "10.1111/j.1467-9280.2008.02098.x", "10.1016/j.tics.2011.01.003", "10.1016/j.obhdp.2011.07.002", "10.1037/1082-989X.10.4.389", "10.1111/risa.12462", "10.3138/3645-4V22-0M23-3T52", "10.21236/ADA218976", "10.1126/science.216.4550.1138", "10.2307/1419876", "10.1016/S0959-4752(98)00051-6", "10.1016/S0098-3004(97)00005-8", "10.1016/S0098-3004(97)00011-3", "10.1111/j.1751-5823.2002.tb00336.x", "10.1016/S0042-6989(97)00340-4", "10.1037/0033-295X.102.4.684", "10.1016/j.proeps.2009.09.160", "10.1037/a0013899", "10.1037/0003-066X.39.12.1372", "10.1111/j.0956-7976.2004.00715.x", "10.3758/s13423-013-0572-3", "10.1097/00001888-199805000-00024", "10.1167/15.4.5", "10.1371/journal.pone.0142444", "10.1371/journal.pmed.0020124", "10.1037/a0025185", "10.1111/j.1551-6708.1987.tb00863.x", "10.1038/ncomms13186", "10.1111/cgf.12127", "10.1006/obhd.1997.2679", "10.3758/s13423-012-0247-5", "10.1002/0470033312", "10.1037/xap0000037", "10.1186/s41235-017-0076-1", "10.1007/978-3-642-32677-6_15", "10.1016/j.neuron.2016.03.025", "10.1121/1.4733540", "10.1016/j.ijforecast.2012.02.002", "10.6028/NIST.TN.1297", "10.1037/h0031322", "10.1007/978-94-010-1834-0_8", "10.1006/ijhc.2002.1017", "10.1207/s15516709cog1801_3"]}, "10.1109/TVCG.2018.2864889": {"doi": "10.1109/TVCG.2018.2864889", "author": ["J. Hullman", "X. Qiao", "M. Correll", "A. Kale", "M. Kay"], "title": "In Pursuit of Error: A Survey of Uncertainty Visualization Evaluation", "year": "2019", "abstract": "Understanding and accounting for uncertainty is critical to effectively reasoning about visualized data. However, evaluating the impact of an uncertainty visualization is complex due to the difficulties that people have interpreting uncertainty and the challenge of defining correct behavior with uncertainty information. Currently, evaluators of uncertainty visualization must rely on general purpose visualization evaluation frameworks which can be ill-equipped to provide guidance with the unique difficulties of assessing judgments under uncertainty. To help evaluators navigate these complexities, we present a taxonomy for characterizing decisions made in designing an evaluation of an uncertainty visualization. Our taxonomy differentiates six levels of decisions that comprise an uncertainty visualization evaluation: the behavioral targets of the study, expected effects from an uncertainty visualization, evaluation goals, measures, elicitation techniques, and analysis approaches. Applying our taxonomy to 86 user studies of uncertainty visualizations, we find that existing evaluation practice, particularly in visualization research, focuses on Performance and Satisfaction-based measures that assume more predictable and statistically-driven judgment behavior than is suggested by research on human judgment and decision making. We reflect on common themes in evaluation practice concerning the interpretation and semantics of uncertainty, the use of confidence reporting, and a bias toward evaluating performance as accuracy rather than decision quality. We conclude with a concrete set of recommendations for evaluators designed to reduce the mismatch between the conceptualization of uncertainty in visualization versus other fields.", "keywords": ["data visualisation", "decision making", "probability", "statistical analysis", "uncertainty visualization evaluation", "visualized data", "uncertainty information", "visualization evaluation frameworks", "taxonomy", "statistically-driven judgment behavior", "human judgment", "decision making", "probability distribution", "Uncertainty", "Visualization", "Taxonomy", "Data visualization", "Task analysis", "Measurement uncertainty", "Decision making", "Uncertainty visualization", "user study", "subjective confidence", "probability distribution"], "referenced_by": [], "referencing": ["10.1145/1520340.1520616", "10.1145/3173574.3174216", "10.1145/2832987.2833050", "10.1145/3025453.3025998", "10.1145/1394281.1394312", "10.1145/2993901.2993919", "10.1145/1377966.1377974", "10.1145/2858036.2858558", "10.1145/1168149.1168158", "10.1145/1520340.1520616", "10.1145/3173574.3174216", "10.1145/2832987.2833050", "10.1145/3025453.3025998", "10.1145/1394281.1394312", "10.1145/2993901.2993919", "10.1145/1377966.1377974", "10.1145/2858036.2858558", "10.1145/1168149.1168158", "10.1145/1520340.1520616", "10.1145/3173574.3174216", "10.1145/2832987.2833050", "10.1145/3025453.3025998", "10.1145/1394281.1394312", "10.1145/2993901.2993919", "10.1145/1377966.1377974", "10.1145/2858036.2858558", "10.1145/1168149.1168158", "10.1559/152304003100011180", "10.2307/1907921", "10.1037/1082-989X.10.4.389", "10.1518/001872005775570916", "10.3138/3645-4V22-0M23-3T52", "10.1080/13658816.2015.1131829", "10.1111/1467-629X.00040", "10.1177/1555343411432338", "10.1371/journal.pone.0096511", "10.14714/CP38.793", "10.2307/1884324", "10.1016/S0098-3004(97)00011-3", "10.1037/0033-295X.102.4.684", "10.1007/s11548-012-0790-6", "10.1080/17524032.2016.1176946", "10.1007/BF01211526", "10.1371/journal.pone.0142444", "10.1111/j.1539-6924.1987.tb00488.x", "10.1371/journal.pmed.0020124", "10.1177/0963721413481473", "10.1175/WAF1020.1", "10.1037/a0025185", "10.2307/1914185", "10.1017/CBO9780511809477", "10.1080/15230406.2015.1089792", "10.1179/1743277414Y.0000000099", "10.1111/risa.12531", "10.1559/152304000783548037", "10.1006/obhd.1997.2679", "10.14714/CP13.1000", "10.1559/1523040054738936", "10.3758/PBR.16.1.204", "10.1518/155534309X474460", "10.3758/s13423-012-0247-5", "10.3758/s13423-012-0247-5", "10.1002/0470033312", "10.1037/xap0000037", "10.1080/00223980.1993.9915580", "10.1016/0749-5978(91)90008-H", "10.1007/978-3-642-32677-6_15", "10.1016/j.neuron.2016.03.025", "10.1002/rcs.1541", "10.1057/ivs.2009.1", "10.6028/NIST.TN.1297", "10.1037/h0031322", "10.1016/0010-0285(73)90033-9", "10.1007/978-94-010-1834-0_8", "10.1559/152304003100011180", "10.2307/1907921", "10.1037/1082-989X.10.4.389", "10.1518/001872005775570916", "10.3138/3645-4V22-0M23-3T52", "10.1080/13658816.2015.1131829", "10.1111/1467-629X.00040", "10.1177/1555343411432338", "10.1371/journal.pone.0096511", "10.14714/CP38.793", "10.2307/1884324", "10.1016/S0098-3004(97)00011-3", "10.1037/0033-295X.102.4.684", "10.1007/s11548-012-0790-6", "10.1080/17524032.2016.1176946", "10.1007/BF01211526", "10.1371/journal.pone.0142444", "10.1111/j.1539-6924.1987.tb00488.x", "10.1371/journal.pmed.0020124", "10.1177/0963721413481473", "10.1175/WAF1020.1", "10.1037/a0025185", "10.2307/1914185", "10.1017/CBO9780511809477", "10.1080/15230406.2015.1089792", "10.1179/1743277414Y.0000000099", "10.1111/risa.12531", "10.1559/152304000783548037", "10.1006/obhd.1997.2679", "10.14714/CP13.1000", "10.1559/1523040054738936", "10.3758/PBR.16.1.204", "10.1518/155534309X474460", "10.3758/s13423-012-0247-5", "10.3758/s13423-012-0247-5", "10.1002/0470033312", "10.1037/xap0000037", "10.1080/00223980.1993.9915580", "10.1016/0749-5978(91)90008-H", "10.1007/978-3-642-32677-6_15", "10.1016/j.neuron.2016.03.025", "10.1002/rcs.1541", "10.1057/ivs.2009.1", "10.6028/NIST.TN.1297", "10.1037/h0031322", "10.1016/0010-0285(73)90033-9", "10.1007/978-94-010-1834-0_8", "10.1559/152304003100011180", "10.2307/1907921", "10.1037/1082-989X.10.4.389", "10.1518/001872005775570916", "10.3138/3645-4V22-0M23-3T52", "10.1080/13658816.2015.1131829", "10.1111/1467-629X.00040", "10.1177/1555343411432338", "10.1371/journal.pone.0096511", "10.14714/CP38.793", "10.2307/1884324", "10.1016/S0098-3004(97)00011-3", "10.1037/0033-295X.102.4.684", "10.1007/s11548-012-0790-6", "10.1080/17524032.2016.1176946", "10.1007/BF01211526", "10.1371/journal.pone.0142444", "10.1111/j.1539-6924.1987.tb00488.x", "10.1371/journal.pmed.0020124", "10.1177/0963721413481473", "10.1175/WAF1020.1", "10.1037/a0025185", "10.2307/1914185", "10.1017/CBO9780511809477", "10.1080/15230406.2015.1089792", "10.1179/1743277414Y.0000000099", "10.1111/risa.12531", "10.1559/152304000783548037", "10.1006/obhd.1997.2679", "10.14714/CP13.1000", "10.1559/1523040054738936", "10.3758/PBR.16.1.204", "10.1518/155534309X474460", "10.3758/s13423-012-0247-5", "10.3758/s13423-012-0247-5", "10.1002/0470033312", "10.1037/xap0000037", "10.1080/00223980.1993.9915580", "10.1016/0749-5978(91)90008-H", "10.1007/978-3-642-32677-6_15", "10.1016/j.neuron.2016.03.025", "10.1002/rcs.1541", "10.1057/ivs.2009.1", "10.6028/NIST.TN.1297", "10.1037/h0031322", "10.1016/0010-0285(73)90033-9", "10.1007/978-94-010-1834-0_8"]}, "10.1109/TVCG.2018.2864914": {"doi": "10.1109/TVCG.2018.2864914", "author": ["H. Song", "D. A. Szafir"], "title": "Where's My Data? Evaluating Visualizations with Missing Data", "year": "2019", "abstract": "Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts' perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios.", "keywords": ["bar charts", "data analysis", "data visualisation", "graph theory", "time series", "data quality", "visualization designers", "evaluating visualizations", "data collection failures", "time series datasets", "data analysts perception", "line graphs", "bar charts", "Data visualization", "Data integrity", "Interpolation", "Visualization", "Bars", "Encoding", "Time series analysis", "Information Visualization", "Graphical Perception", "Time Series Data", "Data Wrangling", "Imputation"], "referenced_by": ["IKEY:8805467"], "referencing": ["IKEY:7836686", "IKEY:6902893", "IKEY:7536111", "IKEY:7347672", "IKEY:6064996", "IKEY:6327283", "IKEY:6875915", "IKEY:7042514", "IKEY:6634120", "IKEY:7192667", "IKEY:7194845", "IKEY:6327255", "IKEY:7192716", "IKEY:6327268", "IKEY:346317", "IKEY:6327281", "IKEY:4035764", "IKEY:7836686", "IKEY:6902893", "IKEY:7536111", "IKEY:7347672", "IKEY:6064996", "IKEY:6327283", "IKEY:6875915", "IKEY:7042514", "IKEY:6634120", "IKEY:7192667", "IKEY:7194845", "IKEY:6327255", "IKEY:7192716", "IKEY:6327268", "IKEY:346317", "IKEY:6327281", "IKEY:4035764", "IKEY:7836686", "IKEY:6902893", "IKEY:7536111", "IKEY:7347672", "IKEY:6064996", "IKEY:6327283", "IKEY:6875915", "IKEY:7042514", "IKEY:6634120", "IKEY:7192667", "IKEY:7194845", "IKEY:6327255", "IKEY:7192716", "IKEY:6327268", "IKEY:346317", "IKEY:6327281", "IKEY:4035764", "10.1145/2858036.2858300", "10.1145/2556288.2557200", "10.1145/358198.358204", "10.1145/3105971.3105984", "10.1145/2207676.2208556", "10.1145/3025453.3025922", "10.1145/2470654.2466443", "10.1145/2637748.2638432", "10.1145/1518701.1518897", "10.1145/1978942.1979444", "10.1145/2858036.2858558", "10.1145/566654.566636", "10.1145/505248.506010", "10.1145/2858036.2858300", "10.1145/2556288.2557200", "10.1145/358198.358204", "10.1145/3105971.3105984", "10.1145/2207676.2208556", "10.1145/3025453.3025922", "10.1145/2470654.2466443", "10.1145/2637748.2638432", "10.1145/1518701.1518897", "10.1145/1978942.1979444", "10.1145/2858036.2858558", "10.1145/566654.566636", "10.1145/505248.506010", "10.1145/2858036.2858300", "10.1145/2556288.2557200", "10.1145/358198.358204", "10.1145/3105971.3105984", "10.1145/2207676.2208556", "10.1145/3025453.3025922", "10.1145/2470654.2466443", "10.1145/2637748.2638432", "10.1145/1518701.1518897", "10.1145/1978942.1979444", "10.1145/2858036.2858558", "10.1145/566654.566636", "10.1145/505248.506010", "10.1007/11555261_66", "10.1037/0022-0167.34.4.481", "10.1016/S1071-5819(03)00038-7", "10.1007/11555261_68", "10.3390/hydrology3040040", "10.1007/978-3-642-32498-7_5", "10.1177/1473871611415994", "10.1023/A:1021564703268", "10.1515/9781400846184-015", "10.2218/ijdc.v10i2.342", "10.4135/9781412986038", "10.1007/s11634-011-0102-y", "10.2307/1390776", "10.1177/1071181312561067", "10.3758/BF03201236", "10.1007/11555261_66", "10.1037/0022-0167.34.4.481", "10.1016/S1071-5819(03)00038-7", "10.1007/11555261_68", "10.3390/hydrology3040040", "10.1007/978-3-642-32498-7_5", "10.1177/1473871611415994", "10.1023/A:1021564703268", "10.1515/9781400846184-015", "10.2218/ijdc.v10i2.342", "10.4135/9781412986038", "10.1007/s11634-011-0102-y", "10.2307/1390776", "10.1177/1071181312561067", "10.3758/BF03201236", "10.1007/11555261_66", "10.1037/0022-0167.34.4.481", "10.1016/S1071-5819(03)00038-7", "10.1007/11555261_68", "10.3390/hydrology3040040", "10.1007/978-3-642-32498-7_5", "10.1177/1473871611415994", "10.1023/A:1021564703268", "10.1515/9781400846184-015", "10.2218/ijdc.v10i2.342", "10.4135/9781412986038", "10.1007/s11634-011-0102-y", "10.2307/1390776", "10.1177/1071181312561067", "10.3758/BF03201236"]}, "10.1109/TVCG.2018.2864913": {"doi": "10.1109/TVCG.2018.2864913", "author": ["N. Mccurdy", "J. Gerdes", "M. Meyer"], "title": "A Framework for Externalizing Implicit Error Using Visualization", "year": "2019", "abstract": "This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn't explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research.", "keywords": ["data analysis", "data visualisation", "error analysis", "medical expert systems", "medical information systems", "data discrepancies", "global health data", "measurement error", "error analysis", "implicit error components", "expert knowledge", "health experts", "visualization", "Tools", "Data visualization", "Public healthcare", "Surveillance", "Diseases", "Visualization", "implicit error", "knowledge externalization", "design study"], "referenced_by": [], "referencing": ["10.1145/3025453.3025738", "10.1145/1518701.1518976", "10.1145/1385569.1385582", "10.1145/1978942.1979157", "10.1145/642611.642616", "10.1145/3025453.3025592", "10.1145/2993901.2993916", "10.1145/3025453.3025738", "10.1145/1518701.1518976", "10.1145/1385569.1385582", "10.1145/1978942.1979157", "10.1145/642611.642616", "10.1145/3025453.3025592", "10.1145/2993901.2993916", "10.1145/3025453.3025738", "10.1145/1518701.1518976", "10.1145/1385569.1385582", "10.1145/1978942.1979157", "10.1145/642611.642616", "10.1145/3025453.3025592", "10.1145/2993901.2993916", "10.1111/j.1467-9604.2007.00468.x", "10.1002/chp.1340180402", "10.1007/BF02416901", "10.1016/j.jbi.2014.04.006", "10.6064/2012/875253", "10.14714/CP38.793", "10.1518/001872095779049543", "10.1371/journal.pmed.1000376", "10.1197/jamia.M2544", "10.1136/amiajnl-2011-000486", "10.1016/j.cie.2014.11.025", "10.1111/cgf.13169", "10.1179/1743277414Y.0000000099", "10.1016/j.jvlc.2011.04.002", "10.1080/15323269.2011.587100", "10.1111/j.0361-3666.2003.00237.x", "10.1007/978-3-642-32677-6_15", "10.1016/S0925-7535(97)00052-0", "10.1197/jamia.M2342", "10.1111/j.1467-8659.2009.01678.x", "10.1177/0165551506070706", "10.9745/GHSP-D-15-00207", "10.1111/cgf.12392", "10.1117/12.587254", "10.1186/1471-2334-11-37", "10.1201/9781315210025", "10.1016/j.cag.2009.06.004", "10.1111/j.1467-9604.2007.00468.x", "10.1002/chp.1340180402", "10.1007/BF02416901", "10.1016/j.jbi.2014.04.006", "10.6064/2012/875253", "10.14714/CP38.793", "10.1518/001872095779049543", "10.1371/journal.pmed.1000376", "10.1197/jamia.M2544", "10.1136/amiajnl-2011-000486", "10.1016/j.cie.2014.11.025", "10.1111/cgf.13169", "10.1179/1743277414Y.0000000099", "10.1016/j.jvlc.2011.04.002", "10.1080/15323269.2011.587100", "10.1111/j.0361-3666.2003.00237.x", "10.1007/978-3-642-32677-6_15", "10.1016/S0925-7535(97)00052-0", "10.1197/jamia.M2342", "10.1111/j.1467-8659.2009.01678.x", "10.1177/0165551506070706", "10.9745/GHSP-D-15-00207", "10.1111/cgf.12392", "10.1117/12.587254", "10.1186/1471-2334-11-37", "10.1201/9781315210025", "10.1016/j.cag.2009.06.004", "10.1111/j.1467-9604.2007.00468.x", "10.1002/chp.1340180402", "10.1007/BF02416901", "10.1016/j.jbi.2014.04.006", "10.6064/2012/875253", "10.14714/CP38.793", "10.1518/001872095779049543", "10.1371/journal.pmed.1000376", "10.1197/jamia.M2544", "10.1136/amiajnl-2011-000486", "10.1016/j.cie.2014.11.025", "10.1111/cgf.13169", "10.1179/1743277414Y.0000000099", "10.1016/j.jvlc.2011.04.002", "10.1080/15323269.2011.587100", "10.1111/j.0361-3666.2003.00237.x", "10.1007/978-3-642-32677-6_15", "10.1016/S0925-7535(97)00052-0", "10.1197/jamia.M2342", "10.1111/j.1467-8659.2009.01678.x", "10.1177/0165551506070706", "10.9745/GHSP-D-15-00207", "10.1111/cgf.12392", "10.1117/12.587254", "10.1186/1471-2334-11-37", "10.1201/9781315210025", "10.1016/j.cag.2009.06.004"]}, "10.1109/TVCG.2018.2864498": {"doi": "10.1109/TVCG.2018.2864498", "author": ["A. Krekhov", "J. Kr\u00fcger"], "title": "Deadeye: A Novel Preattentive Visualization Technique Based on Dichoptic Presentation", "year": "2019", "abstract": "Preattentive visual features such as hue or flickering can effectively draw attention to an object of interest - for instance, an important feature in a scientific visualization. These features appear to pop out and can be recognized by our visual system, independently from the number of distractors. Most cues do not take advantage of the fact that most humans have two eyes. In cases where binocular vision is applied, it is almost exclusively used to convey depth by exposing stereo pairs. We present Deadeye, a novel preattentive visualization technique based on presenting different stimuli to each eye. The target object is rendered for one eye only and is instantly detected by our visual system. In contrast to existing cues, Deadeye does not modify any visual properties of the target and, thus, is particularly suited for visualization applications. Our evaluation confirms that Deadeye is indeed perceived preattentively. We also explore a conjunction search based on our technique and show that, in contrast to 3D depth, the task cannot be processed in parallel.", "keywords": ["data visualisation", "eye", "image colour analysis", "rendering (computer graphics)", "stereo image processing", "visual perception", "scientific visualization", "visual system", "Deadeye", "target object", "visual properties", "visualization applications", "dichoptic presentation", "preattentive visual features", "preattentive visualization technique", "Visualization", "Visual systems", "Image color analysis", "Three-dimensional displays", "Feature extraction", "Shape", "Color", "Popout", "preattentive vision", "comparative visualization", "dichoptic presentation"], "referenced_by": ["IKEY:8805418", "IKEY:9035636"], "referencing": ["IKEY:6064999", "IKEY:6180177", "IKEY:5963660", "IKEY:1532838", "IKEY:6768429", "IKEY:6876019", "IKEY:6064999", "IKEY:6180177", "IKEY:5963660", "IKEY:1532838", "IKEY:6768429", "IKEY:6876019", "IKEY:6064999", "IKEY:6180177", "IKEY:5963660", "IKEY:1532838", "IKEY:6768429", "IKEY:6876019", "10.1145/3025453.3025984", "10.1145/1357054.1357199", "10.1145/503376.503422", "10.1145/2207676.2208638", "10.1145/3025453.3025984", "10.1145/1357054.1357199", "10.1145/503376.503422", "10.1145/2207676.2208638", "10.1145/3025453.3025984", "10.1145/1357054.1357199", "10.1145/503376.503422", "10.1145/2207676.2208638", "10.1016/S0042-6989(97)00167-3", "10.1016/j.neuroimage.2016.12.008", "10.1037/0033-295X.96.1.145", "10.1371/journal.pone.0129101", "10.1167/iovs.03-0878", "10.3758/BF03199301", "10.1126/science.2300824", "10.1111/j.1467-9280.1990.tb00227.x", "10.1016/j.visres.2009.05.001", "10.4324/9780203073858", "10.1111/cgf.12936", "10.1016/j.visres.2009.06.021", "10.1016/S0166-4115(08)62386-9", "10.1037/0033-295X.114.3.599", "10.1038/35058500", "10.1038/290091a0", "10.1038/380621a0", "10.1098/rspb.1979.0029", "10.1007/978-1-4684-6775-8_9", "10.1038/332154a0", "10.1080/135062899395037", "10.1364/JOSAA.7.001209", "10.1016/0042-6989(90)90161-D", "10.1038/320264a0", "10.1016/0042-6989(71)90213-6", "10.3758/s13414-011-0256-x", "10.3758/s13414-011-0100-3", "10.1037/0033-2909.83.5.880", "10.3758/BF03211045", "10.1111/j.1467-9280.1990.tb00067.x", "10.1037/0033-295X.95.1.15", "10.1037/0096-1523.12.1.3", "10.1016/0010-0285(80)90005-5", "10.1167/12.12.2", "10.1037/0096-1523.15.3.419", "10.3758/BF03207480", "10.1038/s41562-017-0058", "10.1007/978-1-4899-5379-7", "10.1007/978-1-4899-5379-7_8", "10.1167/8.5.1", "10.3758/s13414-016-1247-8", "10.1016/S0042-6989(97)00167-3", "10.1016/j.neuroimage.2016.12.008", "10.1037/0033-295X.96.1.145", "10.1371/journal.pone.0129101", "10.1167/iovs.03-0878", "10.3758/BF03199301", "10.1126/science.2300824", "10.1111/j.1467-9280.1990.tb00227.x", "10.1016/j.visres.2009.05.001", "10.4324/9780203073858", "10.1111/cgf.12936", "10.1016/j.visres.2009.06.021", "10.1016/S0166-4115(08)62386-9", "10.1037/0033-295X.114.3.599", "10.1038/35058500", "10.1038/290091a0", "10.1038/380621a0", "10.1098/rspb.1979.0029", "10.1007/978-1-4684-6775-8_9", "10.1038/332154a0", "10.1080/135062899395037", "10.1364/JOSAA.7.001209", "10.1016/0042-6989(90)90161-D", "10.1038/320264a0", "10.1016/0042-6989(71)90213-6", "10.3758/s13414-011-0256-x", "10.3758/s13414-011-0100-3", "10.1037/0033-2909.83.5.880", "10.3758/BF03211045", "10.1111/j.1467-9280.1990.tb00067.x", "10.1037/0033-295X.95.1.15", "10.1037/0096-1523.12.1.3", "10.1016/0010-0285(80)90005-5", "10.1167/12.12.2", "10.1037/0096-1523.15.3.419", "10.3758/BF03207480", "10.1038/s41562-017-0058", "10.1007/978-1-4899-5379-7", "10.1007/978-1-4899-5379-7_8", "10.1167/8.5.1", "10.3758/s13414-016-1247-8", "10.1016/S0042-6989(97)00167-3", "10.1016/j.neuroimage.2016.12.008", "10.1037/0033-295X.96.1.145", "10.1371/journal.pone.0129101", "10.1167/iovs.03-0878", "10.3758/BF03199301", "10.1126/science.2300824", "10.1111/j.1467-9280.1990.tb00227.x", "10.1016/j.visres.2009.05.001", "10.4324/9780203073858", "10.1111/cgf.12936", "10.1016/j.visres.2009.06.021", "10.1016/S0166-4115(08)62386-9", "10.1037/0033-295X.114.3.599", "10.1038/35058500", "10.1038/290091a0", "10.1038/380621a0", "10.1098/rspb.1979.0029", "10.1007/978-1-4684-6775-8_9", "10.1038/332154a0", "10.1080/135062899395037", "10.1364/JOSAA.7.001209", "10.1016/0042-6989(90)90161-D", "10.1038/320264a0", "10.1016/0042-6989(71)90213-6", "10.3758/s13414-011-0256-x", "10.3758/s13414-011-0100-3", "10.1037/0033-2909.83.5.880", "10.3758/BF03211045", "10.1111/j.1467-9280.1990.tb00067.x", "10.1037/0033-295X.95.1.15", "10.1037/0096-1523.12.1.3", "10.1016/0010-0285(80)90005-5", "10.1167/12.12.2", "10.1037/0096-1523.15.3.419", "10.3758/BF03207480", "10.1038/s41562-017-0058", "10.1007/978-1-4899-5379-7", "10.1007/978-1-4899-5379-7_8", "10.1167/8.5.1", "10.3758/s13414-016-1247-8"]}, "10.1109/TVCG.2018.2864813": {"doi": "10.1109/TVCG.2018.2864813", "author": ["T. Wilde", "C. R\u00f6ssi", "H. Theisel"], "title": "Recirculation Surfaces for Flow Visualization", "year": "2019", "abstract": "We present a formal approach to the visual analysis of recirculation in flows by introducing recirculation surfaces for 3D unsteady flow fields. Recirculation surfaces are the loci where massless particle integration returns to its starting point after some variable, finite integration. We give a rigorous definition of recirculation surfaces as 2-manifolds embedded in 5D space and study their properties. Based on this we construct an algorithm for their extraction, which searches for intersections of a recirculation surface with lines defined in 3D. This reduces the problem to a repeated search for critical points in 3D vector fields. We provide a uniform sampling of the search space paired with a surface reconstruction and visualize results. This way, we present the first algorithm for a comprehensive feature extraction in the 5D flow map of a 3D flow. The problem of finding isolated closed orbits in steady vector fields occurs as a special case of recirculation surfaces. This includes isolated closed orbits with saddle behavior. We show recirculation surfaces for a number of artificial and real flow data sets.", "keywords": ["computational fluid dynamics", "computational geometry", "feature extraction", "flow instability", "flow simulation", "flow visualisation", "vectors", "flow visualization", "3D vector fields", "uniform sampling", "feature extraction", "5D flow map", "3D flow", "saddle behavior", "3D unsteady flow fields", "recirculation surface", "time 5.0 d", "Three-dimensional displays", "Orbits", "Visualization", "Surface treatment", "Two dimensional displays", "Null space", "Data visualization", "Flow visualization", "recirculation", "unsteady flow"], "referenced_by": ["IKEY:8805446"], "referencing": ["IKEY:817351", "IKEY:4293020", "IKEY:4447667", "IKEY:1372214", "IKEY:5290756", "IKEY:6183582", "IKEY:1372179", "IKEY:1183786", "IKEY:1028130", "IKEY:4658155", "IKEY:5487517", "IKEY:928168", "IKEY:817351", "IKEY:4293020", "IKEY:4447667", "IKEY:1372214", "IKEY:5290756", "IKEY:6183582", "IKEY:1372179", "IKEY:1183786", "IKEY:1028130", "IKEY:4658155", "IKEY:5487517", "IKEY:928168", "IKEY:817351", "IKEY:4293020", "IKEY:4447667", "IKEY:1372214", "IKEY:5290756", "IKEY:6183582", "IKEY:1372179", "IKEY:1183786", "IKEY:1028130", "IKEY:4658155", "IKEY:5487517", "IKEY:928168", "10.1145/3072959.3073591", "10.1145/3072959.3073591", "10.1145/3072959.3073591", "10.1115/1.4031175", "10.2514/6.2003-59", "10.1007/s00348-016-2126-8", "10.1017/jfm.2015.95", "10.1016/S0167-2789(00)00199-8", "10.1007/978-3-319-04099-8_4", "10.1007/978-3-540-70823-0_3", "10.1007/978-3-540-88606-8_8", "10.1038/s41556-017-0032-9", "10.1063/1.1645276", "10.1007/978-3-540-70823-0_2", "10.1007/978-3-540-88606-8_11", "10.1007/978-3-642-23175-9_4", "10.1007/978-3-642-23175-9_9", "10.1111/cgf.12356", "10.1063/1.3272780", "10.1143/JPSJ.62.3441", "10.1016/S0097-8493(02)00056-0", "10.1007/978-3-540-70823-0_4", "10.3174/ajnr.A3710", "10.1115/1.4031175", "10.2514/6.2003-59", "10.1007/s00348-016-2126-8", "10.1017/jfm.2015.95", "10.1016/S0167-2789(00)00199-8", "10.1007/978-3-319-04099-8_4", "10.1007/978-3-540-70823-0_3", "10.1007/978-3-540-88606-8_8", "10.1038/s41556-017-0032-9", "10.1063/1.1645276", "10.1007/978-3-540-70823-0_2", "10.1007/978-3-540-88606-8_11", "10.1007/978-3-642-23175-9_4", "10.1007/978-3-642-23175-9_9", "10.1111/cgf.12356", "10.1063/1.3272780", "10.1143/JPSJ.62.3441", "10.1016/S0097-8493(02)00056-0", "10.1007/978-3-540-70823-0_4", "10.3174/ajnr.A3710", "10.1115/1.4031175", "10.2514/6.2003-59", "10.1007/s00348-016-2126-8", "10.1017/jfm.2015.95", "10.1016/S0167-2789(00)00199-8", "10.1007/978-3-319-04099-8_4", "10.1007/978-3-540-70823-0_3", "10.1007/978-3-540-88606-8_8", "10.1038/s41556-017-0032-9", "10.1063/1.1645276", "10.1007/978-3-540-70823-0_2", "10.1007/978-3-540-88606-8_11", "10.1007/978-3-642-23175-9_4", "10.1007/978-3-642-23175-9_9", "10.1111/cgf.12356", "10.1063/1.3272780", "10.1143/JPSJ.62.3441", "10.1016/S0097-8493(02)00056-0", "10.1007/978-3-540-70823-0_4", "10.3174/ajnr.A3710"]}, "10.1109/TVCG.2018.2864828": {"doi": "10.1109/TVCG.2018.2864828", "author": ["T. G\u00fcnther", "H. Theisel"], "title": "Objective Vortex Corelines of Finite-sized Objects in Fluid Flows", "year": "2019", "abstract": "Vortices are one of the most-frequently studied phenomena in fluid flows. The center of the rotating motion is called the vortex coreline and its successful detection strongly depends on the choice of the reference frame. The optimal frame moves with the center of the vortex, which incidentally makes the observed fluid flow steady and thus standard vortex coreline extractors such as Sujudi-Haimes become applicable. Recently, an objective optimization framework was proposed that determines a near-steady reference frame for tracer particles. In this paper, we extend this technique to the detection of vortex corelines of inertial particles. An inertial particle is a finite-sized object that is carried by a fluid flow. In contrast to the usual tracer particles, they do not move tangentially with the flow, since they are subject to gravity and exhibit mass-dependent inertia. Their particle state is determined by their position and own velocity, which makes the search for the optimal frame a high-dimensional problem. We demonstrate in this paper that the objective detection of an inertial vortex coreline can be reduced in 2D to a critical point search in 2D. For 3D flows, however, the vortex coreline criterion remains a parallel vectors condition in 6D. To detect the vortex corelines we propose a recursive subdivision approach that is tailored to the underlying structure of the 6D vectors. The resulting algorithm is objective, and we demonstrate the vortex coreline extraction in a number of 2D and 3D vector fields.", "keywords": ["computational fluid dynamics", "flow instability", "vortices", "objective vortex corelines", "optimal frame moves", "observed fluid flow", "inertial particle", "particle state", "objective detection", "inertial vortex coreline", "vortex coreline criterion", "vortex coreline extraction", "vortex coreline extractors", "Three-dimensional displays", "Visualization", "Two dimensional displays", "Atmospheric measurements", "Particle measurements", "Tensile stress", "Feature extraction", "Vortex extraction", "inertial particles", "objectivity", "vortex coreline"], "referenced_by": ["IKEY:9020213"], "referencing": ["IKEY:4459320", "IKEY:175773", "IKEY:7192689", "IKEY:6875993", "IKEY:7539598", "IKEY:35197", "IKEY:663910", "IKEY:809896", "IKEY:745296", "IKEY:7539608", "IKEY:4276078", "IKEY:4745635", "IKEY:4376212", "IKEY:4459320", "IKEY:175773", "IKEY:7192689", "IKEY:6875993", "IKEY:7539598", "IKEY:35197", "IKEY:663910", "IKEY:809896", "IKEY:745296", "IKEY:7539608", "IKEY:4276078", "IKEY:4745635", "IKEY:4376212", "IKEY:4459320", "IKEY:175773", "IKEY:7192689", "IKEY:6875993", "IKEY:7539598", "IKEY:35197", "IKEY:663910", "IKEY:809896", "IKEY:745296", "IKEY:7539608", "IKEY:4276078", "IKEY:4745635", "IKEY:4376212", "10.1145/2897824.2925919", "10.1145/74333.74344", "10.1145/1057432.1057452", "10.1145/2897824.2925919", "10.1145/74333.74344", "10.1145/1057432.1057452", "10.1145/2897824.2925919", "10.1145/74333.74344", "10.1145/1057432.1057452", "10.1016/0377-0257(79)87004-4", "10.1111/cgf.13420", "10.1088/1742-6596/333/1/012003", "10.1111/cgf.12358", "10.1016/0010-4655(88)90020-3", "10.1088/0031-8949/2010/T142/014001", "10.1063/1.857730", "10.1017/S0022112092001460", "10.1016/j.nonrwa.2014.08.002", "10.5194/npg-22-571-2015", "10.1007/978-3-540-70823-0_9", "10.1111/cgf.13114", "10.1111/cgf.12108", "10.1111/cgf.12659", "10.1111/cgf.12846", "10.1111/cgf.12913", "10.1111/cgf.13319", "10.1017/S0022112004002526", "10.1017/jfm.2016.151", "10.1016/j.physd.2007.09.027", "10.1139/tcsme-1987-0004", "10.1017/S0022112095000462", "10.1007/s100219900068", "10.1111/cgf.13439", "10.1007/978-3-642-67220-0_32", "10.1016/j.crme.2015.08.002", "10.1063/1.864230", "10.1143/JPSJ.66.1331", "10.1016/0011-7471(70)90059-8", "10.1111/cgf.13423", "10.1017/S0022112008005089", "10.1007/978-94-007-2482-2_30", "10.1146/annurev.fl.23.010191.003125", "10.1007/978-3-7091-6215-6_33", "10.1007/s11538-010-9594-4", "10.1175/2009JAS2865.1", "10.1111/j.1467-8659.2008.01238.x", "10.1023/A:1001816013475", "10.1007/s10569-015-9617-4", "10.1016/B978-012387582-2/50040-X", "10.2514/2.744", "10.1016/0960-0779(94)90137-6", "10.1016/j.ijengsci.2007.10.005", "10.1016/S0097-8493(02)00056-0", "10.1016/0167-2789(91)90088-Q", "10.1017/S002211209900467X", "10.1016/0377-0257(79)87004-4", "10.1111/cgf.13420", "10.1088/1742-6596/333/1/012003", "10.1111/cgf.12358", "10.1016/0010-4655(88)90020-3", "10.1088/0031-8949/2010/T142/014001", "10.1063/1.857730", "10.1017/S0022112092001460", "10.1016/j.nonrwa.2014.08.002", "10.5194/npg-22-571-2015", "10.1007/978-3-540-70823-0_9", "10.1111/cgf.13114", "10.1111/cgf.12108", "10.1111/cgf.12659", "10.1111/cgf.12846", "10.1111/cgf.12913", "10.1111/cgf.13319", "10.1017/S0022112004002526", "10.1017/jfm.2016.151", "10.1016/j.physd.2007.09.027", "10.1139/tcsme-1987-0004", "10.1017/S0022112095000462", "10.1007/s100219900068", "10.1111/cgf.13439", "10.1007/978-3-642-67220-0_32", "10.1016/j.crme.2015.08.002", "10.1063/1.864230", "10.1143/JPSJ.66.1331", "10.1016/0011-7471(70)90059-8", "10.1111/cgf.13423", "10.1017/S0022112008005089", "10.1007/978-94-007-2482-2_30", "10.1146/annurev.fl.23.010191.003125", "10.1007/978-3-7091-6215-6_33", "10.1007/s11538-010-9594-4", "10.1175/2009JAS2865.1", "10.1111/j.1467-8659.2008.01238.x", "10.1023/A:1001816013475", "10.1007/s10569-015-9617-4", "10.1016/B978-012387582-2/50040-X", "10.2514/2.744", "10.1016/0960-0779(94)90137-6", "10.1016/j.ijengsci.2007.10.005", "10.1016/S0097-8493(02)00056-0", "10.1016/0167-2789(91)90088-Q", "10.1017/S002211209900467X", "10.1016/0377-0257(79)87004-4", "10.1111/cgf.13420", "10.1088/1742-6596/333/1/012003", "10.1111/cgf.12358", "10.1016/0010-4655(88)90020-3", "10.1088/0031-8949/2010/T142/014001", "10.1063/1.857730", "10.1017/S0022112092001460", "10.1016/j.nonrwa.2014.08.002", "10.5194/npg-22-571-2015", "10.1007/978-3-540-70823-0_9", "10.1111/cgf.13114", "10.1111/cgf.12108", "10.1111/cgf.12659", "10.1111/cgf.12846", "10.1111/cgf.12913", "10.1111/cgf.13319", "10.1017/S0022112004002526", "10.1017/jfm.2016.151", "10.1016/j.physd.2007.09.027", "10.1139/tcsme-1987-0004", "10.1017/S0022112095000462", "10.1007/s100219900068", "10.1111/cgf.13439", "10.1007/978-3-642-67220-0_32", "10.1016/j.crme.2015.08.002", "10.1063/1.864230", "10.1143/JPSJ.66.1331", "10.1016/0011-7471(70)90059-8", "10.1111/cgf.13423", "10.1017/S0022112008005089", "10.1007/978-94-007-2482-2_30", "10.1146/annurev.fl.23.010191.003125", "10.1007/978-3-7091-6215-6_33", "10.1007/s11538-010-9594-4", "10.1175/2009JAS2865.1", "10.1111/j.1467-8659.2008.01238.x", "10.1023/A:1001816013475", "10.1007/s10569-015-9617-4", "10.1016/B978-012387582-2/50040-X", "10.2514/2.744", "10.1016/0960-0779(94)90137-6", "10.1016/j.ijengsci.2007.10.005", "10.1016/S0097-8493(02)00056-0", "10.1016/0167-2789(91)90088-Q", "10.1017/S002211209900467X"]}, "10.1109/TVCG.2018.2864507": {"doi": "10.1109/TVCG.2018.2864507", "author": ["N. Lindow", "D. Baum", "M. Leborgne", "H. Hege"], "title": "Interactive Visualization of RNA and DNA Structures", "year": "2019", "abstract": "The analysis and visualization of nucleic acids (RNA and DNA) is playing an increasingly important role due to their fundamental importance for all forms of life and the growing number of known 3D structures of such molecules. The great complexity of these structures, in particular, those of RNA, demands interactive visualization to get deeper insights into the relationship between the 2D secondary structure motifs and their 3D tertiary structures. Over the last decades, a lot of research in molecular visualization has focused on the visual exploration of protein structures while nucleic acids have only been marginally addressed. In contrast to proteins, which are composed of amino acids, the ingredients of nucleic acids are nucleotides. They form structuring patterns that differ from those of proteins and, hence, also require different visualization and exploration techniques. In order to support interactive exploration of nucleic acids, the computation of secondary structure motifs as well as their visualization in 2D and 3D must be fast. Therefore, in this paper, we focus on the performance of both the computation and visualization of nucleic acid structure. We present a ray casting-based visualization of RNA and DNA secondary and tertiary structures, which enables for the first time real-time visualization of even large molecular dynamics trajectories. Furthermore, we provide a detailed description of all important aspects to visualize nucleic acid secondary and tertiary structures. With this, we close an important gap in molecular visualization.", "keywords": ["DNA", "molecular biophysics", "molecular configurations", "proteins", "RNA", "proteins", "amino acids", "ray casting-based visualization", "molecular visualization", "interactive visualization", "DNA structures", "3D tertiary structures", "protein structures", "nucleic acid secondary structure", "RNA structures", "2D secondary structure motifs", "nucleotides", "nucleic acid tertary structure", "Visualization", "RNA", "DNA", "Hydrogen", "Two dimensional displays", "Three-dimensional displays", "Junctions", "Ribonucleic acids", "DNA", "RNA", "secondary & tertiary structures", "interactive rendering", "ray casting", "brushing & linking"], "referenced_by": ["IKEY:8805465", "IKEY:9201509"], "referencing": ["IKEY:7151721", "IKEY:7151721", "IKEY:7151721", "10.1107/S0567740879009249", "10.1093/nar/28.1.235", "10.1093/bioinformatics/4.1.167", "10.1073/pnas.84.23.8385", "10.1021/ja00124a002", "10.1093/nar/gnj031", "10.1093/bioinformatics/btp250", "10.1093/nar/25.22.4679", "10.1093/bioinformatics/19.2.299", "10.1093/nar/gkx365", "10.1007/s003710050084", "10.1093/bioinformatics/btt496", "10.1093/nar/gkg599", "10.1002/0471250953.bi1202s26", "10.1093/bioinformatics/btq321", "10.1002/9783527647064.ch31", "10.1146/annurev.biophys.30.1.1", "10.1111/cgf.13072", "10.1093/nar/gkf540", "10.1017/S1355838201002515", "10.1093/nar/gku973", "10.1111/j.1467-8659.2009.01693.x", "10.1186/1748-7188-6-26", "10.1093/nar/gkv716", "10.1038/nprot.2008.104", "10.1146/annurev.biochem.68.1.287", "10.1126/science.1111771", "10.1038/srep20802", "10.1006/jmbi.2001.4987", "10.1002/jcc.20084", "10.1093/nar/10.21.7041", "10.1093/nar/12.1Part1.75", "10.1261/rna.881308", "10.1006/jmbi.1999.3001", "10.1117/12.872458", "10.1038/nrg3049", "10.1038/171737a0", "10.1006/jmbi.1998.2400", "10.1023/A:1011250219293", "10.1093/nar/gkj454", "10.1093/nar/gkg529", "10.1093/nar/9.1.133", "10.1107/S0567740879009249", "10.1093/nar/28.1.235", "10.1093/bioinformatics/4.1.167", "10.1073/pnas.84.23.8385", "10.1021/ja00124a002", "10.1093/nar/gnj031", "10.1093/bioinformatics/btp250", "10.1093/nar/25.22.4679", "10.1093/bioinformatics/19.2.299", "10.1093/nar/gkx365", "10.1007/s003710050084", "10.1093/bioinformatics/btt496", "10.1093/nar/gkg599", "10.1002/0471250953.bi1202s26", "10.1093/bioinformatics/btq321", "10.1002/9783527647064.ch31", "10.1146/annurev.biophys.30.1.1", "10.1111/cgf.13072", "10.1093/nar/gkf540", "10.1017/S1355838201002515", "10.1093/nar/gku973", "10.1111/j.1467-8659.2009.01693.x", "10.1186/1748-7188-6-26", "10.1093/nar/gkv716", "10.1038/nprot.2008.104", "10.1146/annurev.biochem.68.1.287", "10.1126/science.1111771", "10.1038/srep20802", "10.1006/jmbi.2001.4987", "10.1002/jcc.20084", "10.1093/nar/10.21.7041", "10.1093/nar/12.1Part1.75", "10.1261/rna.881308", "10.1006/jmbi.1999.3001", "10.1117/12.872458", "10.1038/nrg3049", "10.1038/171737a0", "10.1006/jmbi.1998.2400", "10.1023/A:1011250219293", "10.1093/nar/gkj454", "10.1093/nar/gkg529", "10.1093/nar/9.1.133", "10.1107/S0567740879009249", "10.1093/nar/28.1.235", "10.1093/bioinformatics/4.1.167", "10.1073/pnas.84.23.8385", "10.1021/ja00124a002", "10.1093/nar/gnj031", "10.1093/bioinformatics/btp250", "10.1093/nar/25.22.4679", "10.1093/bioinformatics/19.2.299", "10.1093/nar/gkx365", "10.1007/s003710050084", "10.1093/bioinformatics/btt496", "10.1093/nar/gkg599", "10.1002/0471250953.bi1202s26", "10.1093/bioinformatics/btq321", "10.1002/9783527647064.ch31", "10.1146/annurev.biophys.30.1.1", "10.1111/cgf.13072", "10.1093/nar/gkf540", "10.1017/S1355838201002515", "10.1093/nar/gku973", "10.1111/j.1467-8659.2009.01693.x", "10.1186/1748-7188-6-26", "10.1093/nar/gkv716", "10.1038/nprot.2008.104", "10.1146/annurev.biochem.68.1.287", "10.1126/science.1111771", "10.1038/srep20802", "10.1006/jmbi.2001.4987", "10.1002/jcc.20084", "10.1093/nar/10.21.7041", "10.1093/nar/12.1Part1.75", "10.1261/rna.881308", "10.1006/jmbi.1999.3001", "10.1117/12.872458", "10.1038/nrg3049", "10.1038/171737a0", "10.1006/jmbi.1998.2400", "10.1023/A:1011250219293", "10.1093/nar/gkj454", "10.1093/nar/gkg529", "10.1093/nar/9.1.133"]}, "10.1109/TVCG.2018.2864491": {"doi": "10.1109/TVCG.2018.2864491", "author": ["D. Kou\u0159il", "L. \u010cmol\u00edk", "B. Kozl\u00edkov\u00e1", "H. -Y. Wu", "G. Johnson", "D. S. Goodsell", "A. Olson", "M. E. Gr\u00f6ller", "I. Viola"], "title": "Labels on Levels: Labeling of Multi-Scale Multi-Instance and Crowded 3D Biological Environments", "year": "2019", "abstract": "Labeling is intrinsically important for exploring and understanding complex environments and models in a variety of domains. We present a method for interactive labeling of crowded 3D scenes containing very many instances of objects spanning multiple scales in size. In contrast to previous labeling methods, we target cases where many instances of dozens of types are present and where the hierarchical structure of the objects in the scene presents an opportunity to choose the most suitable level for each placed label. Our solution builds on and goes beyond labeling techniques in medical 3D visualization, cartography, and biological illustrations from books and prints. In contrast to these techniques, the main characteristics of our new technique are: 1) a novel way of labeling objects as part of a bigger structure when appropriate, 2) visual clutter reduction by labeling only representative instances for each type of an object, and a strategy of selecting those. The appropriate level of label is chosen by analyzing the scene's depth buffer and the scene objects' hierarchy tree. We address the topic of communicating the parent-children relationship between labels by employing visual hierarchy concepts adapted from graphic design. Selecting representative instances considers several criteria tailored to the character of the data and is combined with a greedy optimization approach. We demonstrate the usage of our method with models from mesoscale biology where these two characteristics-multi-scale and multi-instance-are abundant, along with the fact that these scenes are extraordinarily dense.", "keywords": ["biology computing", "data visualisation", "greedy algorithms", "interactive systems", "optimisation", "3D biological environments", "interactive labeling", "placed label", "labeling techniques", "medical 3D visualization", "representative instances", "object labeling", "multiscale multiinstance labeling", "crowded 3D biological environments", "greedy optimization approach", "mesoscale biology", "scene object hierarchy tree", "scene depth buffer", "visual clutter reduction", "crowded 3D scenes", "Three-dimensional displays", "Labeling", "Proteins", "Visualization", "Blood", "Biological system modeling", "labeling", "multi-scale data", "multi-instance data"], "referenced_by": [], "referencing": ["IKEY:4015429", "IKEY:4658190", "IKEY:5429592", "IKEY:8017635", "IKEY:6815014", "IKEY:6802046", "IKEY:4015429", "IKEY:4658190", "IKEY:5429592", "IKEY:8017635", "IKEY:6815014", "IKEY:6802046", "IKEY:4015429", "IKEY:4658190", "IKEY:5429592", "IKEY:8017635", "IKEY:6815014", "IKEY:6802046", "10.1145/502360.502363", "10.1145/2557423", "10.1145/2070781.2024165", "10.1145/1111411.1111431", "10.1145/97880.97901", "10.1145/1230100.1230105", "10.1145/1377980.1377986", "10.1145/502360.502363", "10.1145/2557423", "10.1145/2070781.2024165", "10.1145/1111411.1111431", "10.1145/97880.97901", "10.1145/1230100.1230105", "10.1145/1377980.1377986", "10.1145/502360.502363", "10.1145/2557423", "10.1145/2070781.2024165", "10.1145/1111411.1111431", "10.1145/97880.97901", "10.1145/1230100.1230105", "10.1145/1377980.1377986", "10.1016/j.comgeo.2009.03.006", "10.7155/jgaa.00379", "10.1287/mnsc.17.4.B141", "10.1016/B978-155860915-0/50040-8", "10.1007/11795018_3", "10.1007/978-3-540-24678-7_10", "10.1111/j.1467-8659.2005.00880.x", "10.1002/bmb.2006.494034042644", "10.1007/978-3-319-04657-0_7", "10.1559/152304075784313304", "10.1038/nmeth.3204", "10.1039/C4FD00017J", "10.7155/jgaa.00169", "10.1057/palgrave.ivs.9500163", "10.1002/jcc.20084", "10.1007/11537311_21", "10.1007/978-3-319-03611-3_17", "10.1007/978-3-319-57336-6_9", "10.1016/j.comgeo.2009.03.006", "10.7155/jgaa.00379", "10.1287/mnsc.17.4.B141", "10.1016/B978-155860915-0/50040-8", "10.1007/11795018_3", "10.1007/978-3-540-24678-7_10", "10.1111/j.1467-8659.2005.00880.x", "10.1002/bmb.2006.494034042644", "10.1007/978-3-319-04657-0_7", "10.1559/152304075784313304", "10.1038/nmeth.3204", "10.1039/C4FD00017J", "10.7155/jgaa.00169", "10.1057/palgrave.ivs.9500163", "10.1002/jcc.20084", "10.1007/11537311_21", "10.1007/978-3-319-03611-3_17", "10.1007/978-3-319-57336-6_9", "10.1016/j.comgeo.2009.03.006", "10.7155/jgaa.00379", "10.1287/mnsc.17.4.B141", "10.1016/B978-155860915-0/50040-8", "10.1007/11795018_3", "10.1007/978-3-540-24678-7_10", "10.1111/j.1467-8659.2005.00880.x", "10.1002/bmb.2006.494034042644", "10.1007/978-3-319-04657-0_7", "10.1559/152304075784313304", "10.1038/nmeth.3204", "10.1039/C4FD00017J", "10.7155/jgaa.00169", "10.1057/palgrave.ivs.9500163", "10.1002/jcc.20084", "10.1007/11537311_21", "10.1007/978-3-319-03611-3_17", "10.1007/978-3-319-57336-6_9"]}, "10.1109/TVCG.2018.2864851": {"doi": "10.1109/TVCG.2018.2864851", "author": ["D. Duran", "P. Hermosilla", "T. Ropinski", "B. Kozl\u00edkov\u00e1", "\u00c1. Vinacua", "P. V\u00e1zquez"], "title": "Visualization of Large Molecular Trajectories", "year": "2019", "abstract": "The analysis of protein-ligand interactions is a time-intensive task. Researchers have to analyze multiple physico-chemical properties of the protein at once and combine them to derive conclusions about the protein-ligand interplay. Typically, several charts are inspected, and 3D animations can be played side-by-side to obtain a deeper understanding of the data. With the advances in simulation techniques, larger and larger datasets are available, with up to hundreds of thousands of steps. Unfortunately, such large trajectories are very difficult to investigate with traditional approaches. Therefore, the need for special tools that facilitate inspection of these large trajectories becomes substantial. In this paper, we present a novel system for visual exploration of very large trajectories in an interactive and user-friendly way. Several visualization motifs are automatically derived from the data to give the user the information about interactions between protein and ligand. Our system offers specialized widgets to ease and accelerate data inspection and navigation to interesting parts of the simulation. The system is suitable also for simulations where multiple ligands are involved. We have tested the usefulness of our tool on a set of datasets obtained from protein engineers, and we describe the expert feedback.", "keywords": ["biology computing", "computer animation", "data mining", "data visualisation", "environmental science computing", "learning (artificial intelligence)", "molecular biophysics", "proteins", "visual exploration", "interactive user-friendly way", "visualization motifs", "data inspection", "protein engineers", "molecular trajectories", "protein-ligand interactions", "time-intensive task", "multiple physico-chemical properties", "protein-ligand interplay", "Trajectory", "Proteins", "Three-dimensional displays", "Computational modeling", "Visualization", "Data models", "Inspection", "Molecular visualization", "simulation inspection", "long trajectories"], "referenced_by": ["IKEY:8794520"], "referencing": ["IKEY:7194835", "IKEY:7006387", "IKEY:7120975", "IKEY:8267086", "IKEY:7429778", "IKEY:7457691", "IKEY:6881728", "IKEY:7539331", "IKEY:6378599", "IKEY:7539341", "IKEY:6876049", "IKEY:7363824", "IKEY:6327272", "IKEY:7194835", "IKEY:7006387", "IKEY:7120975", "IKEY:8267086", "IKEY:7429778", "IKEY:7457691", "IKEY:6881728", "IKEY:7539331", "IKEY:6378599", "IKEY:7539341", "IKEY:6876049", "IKEY:7363824", "IKEY:6327272", "IKEY:7194835", "IKEY:7006387", "IKEY:7120975", "IKEY:8267086", "IKEY:7429778", "IKEY:7457691", "IKEY:6881728", "IKEY:7539331", "IKEY:6378599", "IKEY:7539341", "IKEY:6876049", "IKEY:7363824", "IKEY:6327272", "10.1145/2890478", "10.1145/1364782.1364802", "10.1145/1978942.1979196", "10.1145/2702123.2702419", "10.1145/2890478", "10.1145/1364782.1364802", "10.1145/1978942.1979196", "10.1145/2702123.2702419", "10.1145/2890478", "10.1145/1364782.1364802", "10.1145/1978942.1979196", "10.1145/2702123.2702419", "10.1007/s10822-010-9352-6", "10.1111/cgf.12612", "10.1093/bib/bbq089", "10.1016/j.sbi.2014.04.002", "10.3390/e16010233", "10.1093/comjnl/20.4.364", "10.1186/s12859-016-1448-0", "10.1214/ss/1076102418", "10.1016/0263-7855(96)00018-5", "10.1111/cgf.12928", "10.1016/j.sbi.2012.11.002", "10.1021/ci200227u", "10.2174/1874091X01610010001", "10.1111/cgf.13208", "10.1186/1753-6561-8-S2-S3", "10.1186/1753-6561-8-S2-S5", "10.1038/nmeth.3258", "10.1016/0010-4655(95)00041-D", "10.1021/ct400341p", "10.1093/nar/gkv315", "10.1002/anie.199009921", "10.1007/s10822-010-9352-6", "10.1111/cgf.12612", "10.1093/bib/bbq089", "10.1016/j.sbi.2014.04.002", "10.3390/e16010233", "10.1093/comjnl/20.4.364", "10.1186/s12859-016-1448-0", "10.1214/ss/1076102418", "10.1016/0263-7855(96)00018-5", "10.1111/cgf.12928", "10.1016/j.sbi.2012.11.002", "10.1021/ci200227u", "10.2174/1874091X01610010001", "10.1111/cgf.13208", "10.1186/1753-6561-8-S2-S3", "10.1186/1753-6561-8-S2-S5", "10.1038/nmeth.3258", "10.1016/0010-4655(95)00041-D", "10.1021/ct400341p", "10.1093/nar/gkv315", "10.1002/anie.199009921", "10.1007/s10822-010-9352-6", "10.1111/cgf.12612", "10.1093/bib/bbq089", "10.1016/j.sbi.2014.04.002", "10.3390/e16010233", "10.1093/comjnl/20.4.364", "10.1186/s12859-016-1448-0", "10.1214/ss/1076102418", "10.1016/0263-7855(96)00018-5", "10.1111/cgf.12928", "10.1016/j.sbi.2012.11.002", "10.1021/ci200227u", "10.2174/1874091X01610010001", "10.1111/cgf.13208", "10.1186/1753-6561-8-S2-S3", "10.1186/1753-6561-8-S2-S5", "10.1038/nmeth.3258", "10.1016/0010-4655(95)00041-D", "10.1021/ct400341p", "10.1093/nar/gkv315", "10.1002/anie.199009921"]}, "10.1109/TVCG.2018.2864509": {"doi": "10.1109/TVCG.2018.2864509", "author": ["M. Meuschke", "T. G\u00fcnther", "P. Berg", "R. Wickenh\u00f6fer", "B. Preim", "K. Lawonn"], "title": "Visual Analysis of Aneurysm Data using Statistical Graphics", "year": "2019", "abstract": "This paper presents a framework to explore multi-field data of aneurysms occurring at intracranial and cardiac arteries by using statistical graphics. The rupture of an aneurysm is often a fatal scenario, whereas during treatment serious complications for the patient can occur. Whether an aneurysm ruptures or whether a treatment is successful depends on the interaction of different morphological such as wall deformation and thickness, and hemodynamic attributes like wall shear stress and pressure. Therefore, medical researchers are very interested in better understanding these relationships. However, the required analysis is a time-consuming process, where suspicious wall regions are difficult to detect due to the time-dependent behavior of the data. Our proposed visualization framework enables medical researchers to efficiently assess aneurysm risk and treatment options. This comprises a powerful set of views including 2D and 3D depictions of the aneurysm morphology as well as statistical plots of different scalar fields. Brushing and linking aids the user to identify interesting wall regions and to understand the influence of different attributes on the aneurysm's state. Moreover, a visual comparison of pre- and post-treatment as well as different treatment options is provided. Our analysis techniques are designed in collaboration with domain experts, e.g., physicians, and we provide details about the evaluation.", "keywords": ["biomedical MRI", "blood vessels", "data visualisation", "diseases", "haemodynamics", "medical image processing", "statistical analysis", "aneurysm ruptures", "hemodynamic attributes", "suspicious wall regions", "aneurysm risk", "aneurysm morphology", "visual analysis", "aneurysm data", "statistical graphics", "intracranial arteries", "cardiac arteries", "wall deformation", "Aneurysm", "Data visualization", "Two dimensional displays", "Three-dimensional displays", "Visualization", "Surface morphology", "Shape", "Medical visualizations", "aneurysms", "blood flow", "parametrization"], "referenced_by": ["IKEY:8805441"], "referencing": ["IKEY:6064970", "IKEY:885739", "IKEY:6634145", "IKEY:875181", "IKEY:5557870", "IKEY:8370191", "IKEY:7539321", "IKEY:7539320", "IKEY:868688", "IKEY:1509075", "IKEY:5613474", "IKEY:1563233", "IKEY:6064970", "IKEY:885739", "IKEY:6634145", "IKEY:875181", "IKEY:5557870", "IKEY:8370191", "IKEY:7539321", "IKEY:7539320", "IKEY:868688", "IKEY:1509075", "IKEY:5613474", "IKEY:1563233", "IKEY:6064970", "IKEY:885739", "IKEY:6634145", "IKEY:875181", "IKEY:5557870", "IKEY:8370191", "IKEY:7539321", "IKEY:7539320", "IKEY:868688", "IKEY:1509075", "IKEY:5613474", "IKEY:1563233", "10.1145/1360612.1360643", "10.1145/2516971.2516977", "10.1145/566570.566590", "10.1145/1360612.1360643", "10.1145/2516971.2516977", "10.1145/566570.566590", "10.1145/1360612.1360643", "10.1145/2516971.2516977", "10.1145/566570.566590", "10.1016/B978-0-12-811018-8.00014-X", "10.1115/1.4031794", "10.1115/1.4026108", "10.3174/ajnr.A4734", "10.3174/ajnr.A2274", "10.1136/neurintsurg-2014-011247", "10.1067/mje.2002.123374", "10.1007/978-3-540-30463-0_14", "10.1186/s12968-015-0174-5", "10.1080/03610910903168603", "10.1098/rsif.2011.0490", "10.1016/j.jbiomech.2015.09.039", "10.2307/2032161", "10.1111/cgf.13445", "10.3171/2009.2.FOCUS0921", "10.1002/jmri.20361", "10.1111/cgf.12355", "10.1016/S2214-1235(15)30032-6", "10.1111/cgf.12911", "10.1111/cgf.13171", "10.3171/2013.12.JNS13945", "10.1111/j.1467-8659.2008.01289.x", "10.1111/j.1467-8659.2009.01459.x", "10.1115/1.4033082", "10.1016/j.cag.2011.01.011", "10.1007/s00115-011-3372-x", "10.1016/j.cag.2016.05.024", "10.1002/fld.1786", "10.1111/cgf.12369", "10.1161/01.STR.0000260955.51401.cd", "10.1016/B978-0-12-811018-8.00014-X", "10.1115/1.4031794", "10.1115/1.4026108", "10.3174/ajnr.A4734", "10.3174/ajnr.A2274", "10.1136/neurintsurg-2014-011247", "10.1067/mje.2002.123374", "10.1007/978-3-540-30463-0_14", "10.1186/s12968-015-0174-5", "10.1080/03610910903168603", "10.1098/rsif.2011.0490", "10.1016/j.jbiomech.2015.09.039", "10.2307/2032161", "10.1111/cgf.13445", "10.3171/2009.2.FOCUS0921", "10.1002/jmri.20361", "10.1111/cgf.12355", "10.1016/S2214-1235(15)30032-6", "10.1111/cgf.12911", "10.1111/cgf.13171", "10.3171/2013.12.JNS13945", "10.1111/j.1467-8659.2008.01289.x", "10.1111/j.1467-8659.2009.01459.x", "10.1115/1.4033082", "10.1016/j.cag.2011.01.011", "10.1007/s00115-011-3372-x", "10.1016/j.cag.2016.05.024", "10.1002/fld.1786", "10.1111/cgf.12369", "10.1161/01.STR.0000260955.51401.cd", "10.1016/B978-0-12-811018-8.00014-X", "10.1115/1.4031794", "10.1115/1.4026108", "10.3174/ajnr.A4734", "10.3174/ajnr.A2274", "10.1136/neurintsurg-2014-011247", "10.1067/mje.2002.123374", "10.1007/978-3-540-30463-0_14", "10.1186/s12968-015-0174-5", "10.1080/03610910903168603", "10.1098/rsif.2011.0490", "10.1016/j.jbiomech.2015.09.039", "10.2307/2032161", "10.1111/cgf.13445", "10.3171/2009.2.FOCUS0921", "10.1002/jmri.20361", "10.1111/cgf.12355", "10.1016/S2214-1235(15)30032-6", "10.1111/cgf.12911", "10.1111/cgf.13171", "10.3171/2013.12.JNS13945", "10.1111/j.1467-8659.2008.01289.x", "10.1111/j.1467-8659.2009.01459.x", "10.1115/1.4033082", "10.1016/j.cag.2011.01.011", "10.1007/s00115-011-3372-x", "10.1016/j.cag.2016.05.024", "10.1002/fld.1786", "10.1111/cgf.12369", "10.1161/01.STR.0000260955.51401.cd"]}, "10.1109/TVCG.2018.2864816": {"doi": "10.1109/TVCG.2018.2864816", "author": ["M. Falk", "A. Ynnerman", "D. Treanor", "C. Lundstr\u00f6m"], "title": "Interactive Visualization of 3D Histopathology in Native Resolution", "year": "2019", "abstract": "We present a visualization application that enables effective interactive visual analysis of large-scale 3D histopathology, that is, high-resolution 3D microscopy data of human tissue. Clinical work flows and research based on pathology have, until now, largely been dominated by 2D imaging. As we will show in the paper, studying volumetric histology data will open up novel and useful opportunities for both research and clinical practice. Our starting point is the current lack of appropriate visualization tools in histopathology, which has been a limiting factor in the uptake of digital pathology. Visualization of 3D histology data does pose difficult challenges in several aspects. The full-color datasets are dense and large in scale, on the order of 100,000 \u00d7 100,000 \u00d7 100 voxels. This entails serious demands on both rendering performance and user experience design. Despite this, our developed application supports interactive study of 3D histology datasets at native resolution. Our application is based on tailoring and tuning of existing methods, system integration work, as well as a careful study of domain specific demands emanating from a close participatory design process with domain experts as team members. Results from a user evaluation employing the tool demonstrate a strong agreement among the 14 participating pathologists that 3D histopathology will be a valuable and enabling tool for their work.", "keywords": ["biological tissues", "data visualisation", "image registration", "image resolution", "image segmentation", "interactive systems", "medical image processing", "microscopy", "rendering (computer graphics)", "interactive visualization", "human tissue", "volumetric histology data", "digital pathology", "full-color datasets", "rendering performance", "visualization tools", "high-resolution 3d microscopy data", "3d histopathology", "3d histology datasets", "Three-dimensional displays", "Data visualization", "Pathology", "Rendering (computer graphics)", "Image color analysis", "Microscopy", "Two dimensional displays", "Histology", "Pathology", "Volume Rendering", "Expert Evaluation"], "referenced_by": ["IKEY:8730513"], "referencing": ["IKEY:6562713", "IKEY:5290739", "IKEY:8031591", "IKEY:1183757", "IKEY:6327233", "IKEY:5416665", "IKEY:6727397", "IKEY:1021579", "IKEY:6562713", "IKEY:5290739", "IKEY:8031591", "IKEY:1183757", "IKEY:6327233", "IKEY:5416665", "IKEY:6727397", "IKEY:1021579", "IKEY:6562713", "IKEY:5290739", "IKEY:8031591", "IKEY:1183757", "IKEY:6327233", "IKEY:5416665", "IKEY:6727397", "IKEY:1021579", "10.1145/378456.378484", "10.1145/2834117", "10.1145/378456.378484", "10.1145/2834117", "10.1145/378456.378484", "10.1145/2834117", "10.1001/jama.2017.14585", "10.1117/12.529137", "10.1007/978-3-7091-6783-0_14", "10.1016/j.mri.2012.05.001", "10.1117/12.813756", "10.1111/cgf.12934", "10.4103/2153-3539.151890", "10.1111/his.12629", "10.4103/2153-3539.151894", "10.1073/pnas.1710742114", "10.1093/ajcp/138.suppl1.288", "10.1016/j.ajpath.2012.01.033", "10.1186/s12859-017-1934-z", "10.1111/his.13452", "10.4103/2153-3539.114206", "10.1371/journal.pone.0126817", "10.1001/jama.2017.14585", "10.1117/12.529137", "10.1007/978-3-7091-6783-0_14", "10.1016/j.mri.2012.05.001", "10.1117/12.813756", "10.1111/cgf.12934", "10.4103/2153-3539.151890", "10.1111/his.12629", "10.4103/2153-3539.151894", "10.1073/pnas.1710742114", "10.1093/ajcp/138.suppl1.288", "10.1016/j.ajpath.2012.01.033", "10.1186/s12859-017-1934-z", "10.1111/his.13452", "10.4103/2153-3539.114206", "10.1371/journal.pone.0126817", "10.1001/jama.2017.14585", "10.1117/12.529137", "10.1007/978-3-7091-6783-0_14", "10.1016/j.mri.2012.05.001", "10.1117/12.813756", "10.1111/cgf.12934", "10.4103/2153-3539.151890", "10.1111/his.12629", "10.4103/2153-3539.151894", "10.1073/pnas.1710742114", "10.1093/ajcp/138.suppl1.288", "10.1016/j.ajpath.2012.01.033", "10.1186/s12859-017-1934-z", "10.1111/his.13452", "10.4103/2153-3539.114206", "10.1371/journal.pone.0126817"]}, "10.1109/TVCG.2018.2864852": {"doi": "10.1109/TVCG.2018.2864852", "author": ["S. Boorboor", "S. Jadhav", "M. Ananth", "D. Talmage", "L. Role", "A. Kaufman"], "title": "Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images", "year": "2019", "abstract": "Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.", "keywords": ["biomedical optical imaging", "brain", "cellular biophysics", "data visualisation", "deconvolution", "image classification", "image enhancement", "image filtering", "medical image processing", "neurophysiology", "rendering (computer graphics)", "Hessian-based enhancement filter", "cell-bodies", "intensity-based classification", "confocal microscopy image", "wide-field microscopy brain datasets", "wide-field microscopy images", "multiscale curvilinear filter", "volume rendering techniques", "neuronal structures visualization", "image processing deconvolution technique", "gradient-based distance transform", "out-of-focus blur", "3D structure extraction", "neurites", "opacity map", "Data visualization", "Optical microscopy", "Neurons", "Electron microscopy", "Three-dimensional displays", "Deconvolution", "Wide-field microscopy", "volume visualization", "neuron visualization", "neuroscience"], "referenced_by": [], "referencing": ["IKEY:6875935", "IKEY:1006304", "IKEY:6634132", "IKEY:7163925", "IKEY:5455822", "IKEY:5753898", "IKEY:6165141", "IKEY:6327239", "IKEY:5963691", "IKEY:4445666", "IKEY:6866849", "IKEY:56205", "IKEY:4359501", "IKEY:1628876", "IKEY:7892342", "IKEY:8017617", "IKEY:5290765", "IKEY:6183592", "IKEY:7534826", "IKEY:6875935", "IKEY:1006304", "IKEY:6634132", "IKEY:7163925", "IKEY:5455822", "IKEY:5753898", "IKEY:6165141", "IKEY:6327239", "IKEY:5963691", "IKEY:4445666", "IKEY:6866849", "IKEY:56205", "IKEY:4359501", "IKEY:1628876", "IKEY:7892342", "IKEY:8017617", "IKEY:5290765", "IKEY:6183592", "IKEY:7534826", "IKEY:6875935", "IKEY:1006304", "IKEY:6634132", "IKEY:7163925", "IKEY:5455822", "IKEY:5753898", "IKEY:6165141", "IKEY:6327239", "IKEY:5963691", "IKEY:4445666", "IKEY:6866849", "IKEY:56205", "IKEY:4359501", "IKEY:1628876", "IKEY:7892342", "IKEY:8017617", "IKEY:5290765", "IKEY:6183592", "IKEY:7534826", "10.1007/s12021-016-9310-0", "10.1007/s12021-010-9095-5", "10.1007/s12021-011-9121-2", "10.1111/j.1365-2818.2005.01466.x", "10.1007/BFb0056195", "10.1364/JOSAA.9.000154", "10.1111/j.1460-9568.2011.07671.x", "10.1111/j.1467-8659.2008.01220.x", "10.1007/s12021-016-9302-0", "10.1086/111605", "10.1002/cyto.a.20022", "10.1007/978-3-642-10520-3_9", "10.1016/j.compbiomed.2014.07.007", "10.1007/s12021-011-9116-z", "10.1016/j.neuron.2015.06.036", "10.1038/nbt.1612", "10.1098/rspa.1959.0200", "10.1364/JOSA.62.000055", "10.1016/j.ymeth.2016.12.015", "10.1007/s12021-014-9253-2", "10.1073/pnas.93.4.1591", "10.1007/978-0-387-45524-2_23", "10.1371/journal.pcbi.0010042", "10.1007/s12021-011-9122-1", "10.1007/s12021-011-9110-5", "10.1093/bioinformatics/btt170", "10.1007/s12021-011-9120-3", "10.1007/s12021-016-9310-0", "10.1007/s12021-010-9095-5", "10.1007/s12021-011-9121-2", "10.1111/j.1365-2818.2005.01466.x", "10.1007/BFb0056195", "10.1364/JOSAA.9.000154", "10.1111/j.1460-9568.2011.07671.x", "10.1111/j.1467-8659.2008.01220.x", "10.1007/s12021-016-9302-0", "10.1086/111605", "10.1002/cyto.a.20022", "10.1007/978-3-642-10520-3_9", "10.1016/j.compbiomed.2014.07.007", "10.1007/s12021-011-9116-z", "10.1016/j.neuron.2015.06.036", "10.1038/nbt.1612", "10.1098/rspa.1959.0200", "10.1364/JOSA.62.000055", "10.1016/j.ymeth.2016.12.015", "10.1007/s12021-014-9253-2", "10.1073/pnas.93.4.1591", "10.1007/978-0-387-45524-2_23", "10.1371/journal.pcbi.0010042", "10.1007/s12021-011-9122-1", "10.1007/s12021-011-9110-5", "10.1093/bioinformatics/btt170", "10.1007/s12021-011-9120-3", "10.1007/s12021-016-9310-0", "10.1007/s12021-010-9095-5", "10.1007/s12021-011-9121-2", "10.1111/j.1365-2818.2005.01466.x", "10.1007/BFb0056195", "10.1364/JOSAA.9.000154", "10.1111/j.1460-9568.2011.07671.x", "10.1111/j.1467-8659.2008.01220.x", "10.1007/s12021-016-9302-0", "10.1086/111605", "10.1002/cyto.a.20022", "10.1007/978-3-642-10520-3_9", "10.1016/j.compbiomed.2014.07.007", "10.1007/s12021-011-9116-z", "10.1016/j.neuron.2015.06.036", "10.1038/nbt.1612", "10.1098/rspa.1959.0200", "10.1364/JOSA.62.000055", "10.1016/j.ymeth.2016.12.015", "10.1007/s12021-014-9253-2", "10.1073/pnas.93.4.1591", "10.1007/978-0-387-45524-2_23", "10.1371/journal.pcbi.0010042", "10.1007/s12021-011-9122-1", "10.1007/s12021-011-9110-5", "10.1093/bioinformatics/btt170", "10.1007/s12021-011-9120-3"]}, "10.1109/TVCG.2018.2864690": {"doi": "10.1109/TVCG.2018.2864690", "author": ["M. Traor\u00e9", "C. Hurter", "A. Telea"], "title": "Interactive obstruction-free lensing for volumetric data visualization", "year": "2019", "abstract": "Occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects' vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we investigate a new technique which maintains the general structure of the investigated volumetric dataset while addressing occlusion issues. With our technique, the user interactively defines an area of interest where an occluded region or object is partially visible. Then our lens starts pushing at its border occluding objects, thus revealing hidden volumetric data. Next, the lens is modified with an extended field of view (fish-eye deformation) to better see the vicinity of the selected region. Finally, the user can freely explore the surroundings of the area under investigation within the lens. To provide real-time exploration, we implemented our lens using a GPU accelerated ray-casting framework to handle ray deformations, local lighting, and local viewpoint manipulation. We illustrate our technique with five application scenarios in baggage inspection, 3D fluid flow visualization, chest radiology, air traffic planning, and DTI fiber exploration.", "keywords": ["data visualisation", "image segmentation", "lenses", "ray tracing", "rendering (computer graphics)", "local lighting", "local viewpoint manipulation", "baggage inspection", "chest radiology", "air traffic planning", "DTI fiber exploration", "3D fluid flow visualization", "ray deformations", "GPU accelerated ray-casting framework", "real-time exploration", "fish-eye deformation", "hidden volumetric data", "lens", "occluded region", "partial occlusion", "volume segmentation", "transfer functions", "direct visualization", "volumetric data visualization", "interactive obstruction-free lensing", "Lenses", "Strain", "Data visualization", "Transfer functions", "Three-dimensional displays", "Animation", "Interaction techniques", "focus + context", "volume visualization", "volume rendering", "raycasting"], "referenced_by": ["IKEY:8781572"], "referencing": ["IKEY:4015467", "IKEY:595268", "IKEY:4015466", "IKEY:4376157", "IKEY:5416704", "IKEY:4483791", "IKEY:7042344", "IKEY:5290742", "IKEY:1372177", "IKEY:6787171", "IKEY:6065028", "IKEY:5290707", "IKEY:4069230", "IKEY:5613426", "IKEY:4015450", "IKEY:1250400", "IKEY:809865", "IKEY:1648236", "IKEY:6327262", "IKEY:7332955", "IKEY:7539643", "IKEY:7819413", "IKEY:7374742", "IKEY:7120994", "IKEY:4276082", "IKEY:4015467", "IKEY:595268", "IKEY:4015466", "IKEY:4376157", "IKEY:5416704", "IKEY:4483791", "IKEY:7042344", "IKEY:5290742", "IKEY:1372177", "IKEY:6787171", "IKEY:6065028", "IKEY:5290707", "IKEY:4069230", "IKEY:5613426", "IKEY:4015450", "IKEY:1250400", "IKEY:809865", "IKEY:1648236", "IKEY:6327262", "IKEY:7332955", "IKEY:7539643", "IKEY:7819413", "IKEY:7374742", "IKEY:7120994", "IKEY:4276082", "IKEY:4015467", "IKEY:595268", "IKEY:4015466", "IKEY:4376157", "IKEY:5416704", "IKEY:4483791", "IKEY:7042344", "IKEY:5290742", "IKEY:1372177", "IKEY:6787171", "IKEY:6065028", "IKEY:5290707", "IKEY:4069230", "IKEY:5613426", "IKEY:4015450", "IKEY:1250400", "IKEY:809865", "IKEY:1648236", "IKEY:6327262", "IKEY:7332955", "IKEY:7539643", "IKEY:7819413", "IKEY:7374742", "IKEY:7120994", "IKEY:4276082", "10.1145/1457515.1409107", "10.1145/1978942.1979233", "10.1145/2425296.2425325", "10.1145/989863.989871", "10.1145/345513.345271", "10.1145/1457515.1409107", "10.1145/1978942.1979233", "10.1145/2425296.2425325", "10.1145/989863.989871", "10.1145/345513.345271", "10.1145/1457515.1409107", "10.1145/1978942.1979233", "10.1145/2425296.2425325", "10.1145/989863.989871", "10.1145/345513.345271", "10.1007/s12031-007-0029-0", "10.2200/S00688ED1V01Y201512VIS006", "10.1016/j.trc.2014.03.005", "10.1111/j.1467-8659.2012.03079.x", "10.1007/978-1-4614-7657-3_19", "10.1111/cgf.12927", "10.1111/j.1467-8659.2006.00979.x", "10.1007/978-3-540-85412-8_16", "10.1057/ivs.2009.32", "10.1111/cgf.12871", "10.1007/s12031-007-0029-0", "10.2200/S00688ED1V01Y201512VIS006", "10.1016/j.trc.2014.03.005", "10.1111/j.1467-8659.2012.03079.x", "10.1007/978-1-4614-7657-3_19", "10.1111/cgf.12927", "10.1111/j.1467-8659.2006.00979.x", "10.1007/978-3-540-85412-8_16", "10.1057/ivs.2009.32", "10.1111/cgf.12871", "10.1007/s12031-007-0029-0", "10.2200/S00688ED1V01Y201512VIS006", "10.1016/j.trc.2014.03.005", "10.1111/j.1467-8659.2012.03079.x", "10.1007/978-1-4614-7657-3_19", "10.1111/cgf.12927", "10.1111/j.1467-8659.2006.00979.x", "10.1007/978-3-540-85412-8_16", "10.1057/ivs.2009.32", "10.1111/cgf.12871"]}, "10.1109/TVCG.2018.2864510": {"doi": "10.1109/TVCG.2018.2864510", "author": ["J. Weissenb\u00f6ck", "B. Fr\u00f6hler", "E. Gr\u00f6ller", "J. Kastner", "C. Heinzl"], "title": "Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves", "year": "2019", "abstract": "The comparison of many members of an ensemble is difficult, tedious, and error-prone, which is aggravated by often just subtle differences. In this paper, we introduce Dynamic Volume Lines for the interactive visual analysis and comparison of sets of 3D volumes. Each volume is linearized along a Hilbert space-filling curve into a 1D Hilbert line plot, which depicts the intensities over the Hilbert indices. We present a nonlinear scaling of these 1D Hilbert line plots based on the intensity variations in the ensemble of 3D volumes, which enables a more effective use of the available screen space. The nonlinear scaling builds the basis for our interactive visualization techniques. An interactive histogram heatmap of the intensity frequencies serves as overview visualization. When zooming in, the frequencies are replaced by detailed 1D Hilbert line plots and optional functional boxplots. To focus on important regions of the volume ensemble, nonlinear scaling is incorporated into the plots. An interactive scaling widget depicts the local ensemble variations. Our brushing and linking interface reveals, for example, regions with a high ensemble variation by showing the affected voxels in a 3D spatial view. We show the applicability of our concepts using two case studies on ensembles of 3D volumes resulting from tomographic reconstruction. In the first case study, we evaluate an artificial specimen from simulated industrial 3D X-ray computed tomography (XCT). In the second case study, a real-world XCT foam specimen is investigated. Our results show that Dynamic Volume Lines can identify regions with high local intensity variations, allowing the user to draw conclusions, for example, about the choice of reconstruction parameters. Furthermore, it is possible to detect ring artifacts in reconstructions volumes.", "keywords": ["computerised tomography", "data analysis", "data visualisation", "Hilbert spaces", "image reconstruction", "mechanical engineering computing", "interactive visual analysis", "Hilbert space-filling curve", "1D Hilbert line plot", "Hilbert indices", "nonlinear scaling", "available screen space", "interactive visualization techniques", "interactive histogram heatmap", "interactive scaling widget", "local ensemble variations", "high ensemble variation", "3D spatial view", "high local intensity variations", "reconstructions volumes", "visual comparison", "space-filling curves", "dynamic volume lines", "1D Hilbert line plots", "Three-dimensional displays", "Visualization", "Indexes", "Data visualization", "Histograms", "Two dimensional displays", "Task analysis", "Ensemble data", "comparative visualization", "visual analysis", "Hilbert curve", "nonlinear scaling", "X-ray computed tomography"], "referenced_by": ["IKEY:8794520", "IKEY:8986923"], "referencing": ["IKEY:6875990", "IKEY:577130", "IKEY:4492754", "IKEY:4159726", "IKEY:5401158", "IKEY:5290748", "IKEY:6875964", "IKEY:1532847", "IKEY:908985", "IKEY:5360497", "IKEY:7155419", "IKEY:6634107", "IKEY:7042491", "IKEY:6876043", "IKEY:545307", "IKEY:7883516", "IKEY:6634129", "IKEY:6875990", "IKEY:577130", "IKEY:4492754", "IKEY:4159726", "IKEY:5401158", "IKEY:5290748", "IKEY:6875964", "IKEY:1532847", "IKEY:908985", "IKEY:5360497", "IKEY:7155419", "IKEY:6634107", "IKEY:7042491", "IKEY:6876043", "IKEY:545307", "IKEY:7883516", "IKEY:6634129", "IKEY:6875990", "IKEY:577130", "IKEY:4492754", "IKEY:4159726", "IKEY:5401158", "IKEY:5290748", "IKEY:6875964", "IKEY:1532847", "IKEY:908985", "IKEY:5360497", "IKEY:7155419", "IKEY:6634107", "IKEY:7042491", "IKEY:6876043", "IKEY:545307", "IKEY:7883516", "IKEY:6634129", "10.1145/3002151.3002165", "10.1145/2362456.2362487", "10.1145/3002151.3002165", "10.1145/2362456.2362487", "10.1145/3002151.3002165", "10.1145/2362456.2362487", "10.1364/JOSAA.1.000612", "10.1111/cgf.12895", "10.1002/sta4.39", "10.1177/1473871611416549", "10.1016/j.polymertesting.2005.07.005", "10.1016/j.ipl.2007.08.034", "10.1111/cgf.13214", "10.1364/OE.19.013604", "10.1201/CRCPOLYMFOA", "10.1111/j.1467-8659.2012.03054.x", "10.1016/j.cag.2017.05.012", "10.2352/ISSN.2470-1173.2016.16.HVEI-133", "10.1103/PhysRevLett.98.108105", "10.1111/j.1467-8659.2012.03112.x", "10.2514/6.2017-0355", "10.1198/jcgs.2011.09224", "10.1111/cgf.13177", "10.1364/JOSAA.1.000612", "10.1111/cgf.12895", "10.1002/sta4.39", "10.1177/1473871611416549", "10.1016/j.polymertesting.2005.07.005", "10.1016/j.ipl.2007.08.034", "10.1111/cgf.13214", "10.1364/OE.19.013604", "10.1201/CRCPOLYMFOA", "10.1111/j.1467-8659.2012.03054.x", "10.1016/j.cag.2017.05.012", "10.2352/ISSN.2470-1173.2016.16.HVEI-133", "10.1103/PhysRevLett.98.108105", "10.1111/j.1467-8659.2012.03112.x", "10.2514/6.2017-0355", "10.1198/jcgs.2011.09224", "10.1111/cgf.13177", "10.1364/JOSAA.1.000612", "10.1111/cgf.12895", "10.1002/sta4.39", "10.1177/1473871611416549", "10.1016/j.polymertesting.2005.07.005", "10.1016/j.ipl.2007.08.034", "10.1111/cgf.13214", "10.1364/OE.19.013604", "10.1201/CRCPOLYMFOA", "10.1111/j.1467-8659.2012.03054.x", "10.1016/j.cag.2017.05.012", "10.2352/ISSN.2470-1173.2016.16.HVEI-133", "10.1103/PhysRevLett.98.108105", "10.1111/j.1467-8659.2012.03112.x", "10.2514/6.2017-0355", "10.1198/jcgs.2011.09224", "10.1111/cgf.13177"]}, "10.1109/TVCG.2018.2864841": {"doi": "10.1109/TVCG.2018.2864841", "author": ["M. Shih", "C. Rozhon", "K. Ma"], "title": "A Declarative Grammar of Flexible Volume Visualization Pipelines", "year": "2019", "abstract": "This paper presents a declarative grammar for conveniently and effectively specifying advanced volume visualizations. Existing methods for creating volume visualizations either lack the flexibility to specify sophisticated visualizations or are difficult to use for those unfamiliar with volume rendering implementation and parameterization. Our design provides the ability to quickly create expressive visualizations without knowledge of the volume rendering implementation. It attempts to capture aspects of those difficult but powerful methods while remaining flexible and easy to use. As a proof of concept, our current implementation of the grammar allows users to combine multiple data variables in various ways and define transfer functions for diverse input data. The grammar also has the ability to describe advanced shading effects and create animations. We demonstrate the power and flexibility of our approach using multiple practical volume visualizations.", "keywords": ["computer animation", "data visualisation", "grammars", "rendering (computer graphics)", "transfer functions", "declarative grammar", "flexible volume visualization pipelines", "volume rendering implementation", "transfer functions", "shading effects", "animation creation", "Data visualization", "Rendering (computer graphics)", "Pipelines", "Grammar", "Visualization", "DSL", "Image color analysis", "Volume visualization", "direct volume rendering", "declarative specification", "multivariate/multimodal volume data", "animation"], "referenced_by": ["IKEY:9308047"], "referencing": ["IKEY:1532788", "IKEY:5290720", "IKEY:6064996", "IKEY:4376160", "IKEY:6875916", "IKEY:5290762", "IKEY:6009025", "IKEY:7192663", "IKEY:1021579", "IKEY:235219", "IKEY:1372194", "IKEY:5307637", "IKEY:4376190", "IKEY:6876040", "IKEY:7539624", "IKEY:7192704", "IKEY:7429514", "IKEY:31462", "IKEY:7539599", "IKEY:1532788", "IKEY:5290720", "IKEY:6064996", "IKEY:4376160", "IKEY:6875916", "IKEY:5290762", "IKEY:6009025", "IKEY:7192663", "IKEY:1021579", "IKEY:235219", "IKEY:1372194", "IKEY:5307637", "IKEY:4376190", "IKEY:6876040", "IKEY:7539624", "IKEY:7192704", "IKEY:7429514", "IKEY:31462", "IKEY:7539599", "IKEY:1532788", "IKEY:5290720", "IKEY:6064996", "IKEY:4376160", "IKEY:6875916", "IKEY:5290762", "IKEY:6009025", "IKEY:7192663", "IKEY:1021579", "IKEY:235219", "IKEY:1372194", "IKEY:5307637", "IKEY:4376190", "IKEY:6876040", "IKEY:7539624", "IKEY:7192704", "IKEY:7429514", "IKEY:31462", "IKEY:7539599", "10.1145/2254064.2254079", "10.1145/280814.280950", "10.1145/1362622.1362654", "10.1145/2254064.2254079", "10.1145/280814.280950", "10.1145/1362622.1362654", "10.1145/2254064.2254079", "10.1145/280814.280950", "10.1145/1362622.1362654", "10.1111/j.1467-8659.2007.01095.x", "10.1111/1467-8659.00356", "10.1080/14685240802376389", "10.1016/j.parco.2007.09.001", "10.1111/j.1467-8659.2011.01952.x", "10.1007/978-3-7091-6756-4_9", "10.1111/j.1467-8659.2007.01095.x", "10.1111/1467-8659.00356", "10.1080/14685240802376389", "10.1016/j.parco.2007.09.001", "10.1111/j.1467-8659.2011.01952.x", "10.1007/978-3-7091-6756-4_9", "10.1111/j.1467-8659.2007.01095.x", "10.1111/1467-8659.00356", "10.1080/14685240802376389", "10.1016/j.parco.2007.09.001", "10.1111/j.1467-8659.2011.01952.x", "10.1007/978-3-7091-6756-4_9"]}, "10.1109/TVCG.2018.2864506": {"doi": "10.1109/TVCG.2018.2864506", "author": ["H. Zhang", "S. Frey", "H. Steeb", "D. Uribe", "T. Ertl", "W. Wang"], "title": "Visualization of Bubble Formation in Porous Media", "year": "2019", "abstract": "We present a visualization approach for the analysis of CO2 bubble-induced attenuation in porous rock formations. As a basis for this, we introduce customized techniques to extract CO2 bubbles and their surrounding porous structure from X-ray computed tomography data (XCT) measurements. To understand how the structure of porous media influences the occurrence and the shape of formed bubbles, we automatically classify and relate them in terms of morphology and geometric features, and further directly support searching for promising porous structures. To allow for the meaningful direct visual comparison of bubbles and their structures, we propose a customized registration technique considering the bubble shape as well as its points of contact with the porous media surface. With our quantitative extraction of geometric bubble features, we further support the analysis as well as the creation of a physical model. We demonstrate that our approach was successfully used to answer several research questions in the domain, and discuss its high practical relevance to identify critical seismic characteristics of fluid-saturated rock that govern its capability to store CO2.", "keywords": ["bubbles", "computerised tomography", "flow through porous media", "geophysical fluid dynamics", "geophysical techniques", "porous materials", "rocks", "seismic waves", "bubble formation", "visualization approach", "porous rock formations", "X-ray computed tomography data measurements", "bubble-induced attenuation", "porous structures", "geometric bubble features", "porous media surface", "bubble shape", "customized registration technique", "Data visualization", "Media", "Shape", "Visualization", "Morphology", "Feature extraction", "Data mining", "3D volume rendering", "bubble visualization", "porous media"], "referenced_by": [], "referencing": ["IKEY:1240258", "IKEY:4376171", "IKEY:4015450", "IKEY:5557813", "IKEY:6876035", "IKEY:6461882", "IKEY:924423", "IKEY:982886", "IKEY:6327208", "IKEY:1372190", "IKEY:6787162", "IKEY:7120994", "IKEY:906424", "IKEY:1240258", "IKEY:4376171", "IKEY:4015450", "IKEY:5557813", "IKEY:6876035", "IKEY:6461882", "IKEY:924423", "IKEY:982886", "IKEY:6327208", "IKEY:1372190", "IKEY:6787162", "IKEY:7120994", "IKEY:906424", "IKEY:1240258", "IKEY:4376171", "IKEY:4015450", "IKEY:5557813", "IKEY:6876035", "IKEY:6461882", "IKEY:924423", "IKEY:982886", "IKEY:6327208", "IKEY:1372190", "IKEY:6787162", "IKEY:7120994", "IKEY:906424", "10.1145/383259.383295", "10.1145/37401.37422", "10.1145/571647.571648", "10.1145/383259.383295", "10.1145/37401.37422", "10.1145/571647.571648", "10.1145/383259.383295", "10.1145/37401.37422", "10.1145/571647.571648", "10.1016/j.advwatres.2014.02.014", "10.1111/cgf.12605", "10.1016/0196-8904(93)90069-M", "10.5772/6866", "10.1016/j.cag.2010.05.001", "10.1111/cgf.13214", "10.1016/0262-8856(92)90076-F", "10.1063/1.4871486", "10.1063/1.4871489", "10.1126/science.1079033", "10.1017/CBO9780511626753", "10.1111/j.1467-8659.2009.01671.x", "10.1080/14786443309462277", "10.1017/jfm.2017.221", "10.1017/jfm.2016.401", "10.1002/2015GL063538", "10.1016/j.ijggc.2017.10.002", "10.1071/EG04025", "10.1016/j.advwatres.2014.02.014", "10.1111/cgf.12605", "10.1016/0196-8904(93)90069-M", "10.5772/6866", "10.1016/j.cag.2010.05.001", "10.1111/cgf.13214", "10.1016/0262-8856(92)90076-F", "10.1063/1.4871486", "10.1063/1.4871489", "10.1126/science.1079033", "10.1017/CBO9780511626753", "10.1111/j.1467-8659.2009.01671.x", "10.1080/14786443309462277", "10.1017/jfm.2017.221", "10.1017/jfm.2016.401", "10.1002/2015GL063538", "10.1016/j.ijggc.2017.10.002", "10.1071/EG04025", "10.1016/j.advwatres.2014.02.014", "10.1111/cgf.12605", "10.1016/0196-8904(93)90069-M", "10.5772/6866", "10.1016/j.cag.2010.05.001", "10.1111/cgf.13214", "10.1016/0262-8856(92)90076-F", "10.1063/1.4871486", "10.1063/1.4871489", "10.1126/science.1079033", "10.1017/CBO9780511626753", "10.1111/j.1467-8659.2009.01671.x", "10.1080/14786443309462277", "10.1017/jfm.2017.221", "10.1017/jfm.2016.401", "10.1002/2015GL063538", "10.1016/j.ijggc.2017.10.002", "10.1071/EG04025"]}, "10.1109/TVCG.2018.2864508": {"doi": "10.1109/TVCG.2018.2864508", "author": ["A. Sagrist\u00e0", "S. Jordan", "T. M\u00fcller", "F. Sadlo"], "title": "Gaia Sky: Navigating the Gaia Catalog", "year": "2019", "abstract": "In this paper, we present Gaia Sky, a free and open-source multiplatform 3D Universe system, developed since 2014 in the Data Processing and Analysis Consortium framework of ESA's Gaia mission. Gaia's data release 2 represents the largest catalog of the stars of our Galaxy, comprising 1.3 billion star positions, with parallaxes, proper motions, magnitudes, and colors. In this mission, Gaia Sky is the central tool for off-the-shelf visualization of these data, and for aiding production of outreach material. With its capabilities to effectively handle these data, to enable seamless navigation along the high dynamic range of distances, and at the same time to provide advanced visualization techniques including relativistic aberration and gravitational wave effects, currently no actively maintained cross-platform, modern, and open alternative exists.", "keywords": ["astrometry", "astronomical catalogues", "astronomical surveys", "astronomy computing", "data visualisation", "Galaxy", "public domain software", "Gaia Sky", "Gaia catalog", "open-source multiplatform 3D Universe system", "ESA Gaia mission", "Gaia data release", "data processing and analysis consortium framework", "advanced visualization techniques", "gravitational wave effects", "relativistic aberration", "Data visualization", "Three-dimensional displays", "Octrees", "Tools", "Solar system", "Open source software", "Astronomy visualization", "3D Universe software", "star catalog rendering", "Gaia mission"], "referenced_by": ["IKEY:8805462", "IKEY:8933671", "10.1111/cgf.13705"], "referencing": ["10.1111/cgf.13202", "10.21105/joss.00281", "10.1051/0004-6361/201732493", "10.1111/cgf.13202", "10.21105/joss.00281", "10.1051/0004-6361/201732493", "10.1111/cgf.13202", "10.21105/joss.00281", "10.1051/0004-6361/201732493"]}, "10.1109/TVCG.2018.2864806": {"doi": "10.1109/TVCG.2018.2864806", "author": ["M. Kern", "T. Hewson", "A. Sch\u00e4tler", "R. Westermann", "M. Rautenhaus"], "title": "Interactive 3D Visual Analysis of Atmospheric Fronts", "year": "2019", "abstract": "Atmospheric fronts play a central role in meteorology, as the boundaries between different air masses and as fundamental features of extra-tropical cyclones. They appear in numerous conceptual model depictions of extra-tropical weather systems. Conceptually, fronts are three-dimensional surfaces in space possessing an innate structural complexity, yet in meteorology, both manual and objective identification and depiction have historically focused on the structure in two dimensions. In this work, we -a team of visualization scientists and meteorologists-propose a novel visualization approach to analyze the three-dimensional structure of atmospheric fronts and related physical and dynamical processes. We build upon existing approaches to objectively identify fronts as lines in two dimensions and extend these to obtain frontal surfaces in three dimensions, using the magnitude of temperature change along the gradient of a moist potential temperature field as the primary identifying factor. We introduce the use of normal curves in the temperature gradient field to visualize a frontal zone (i.e., the transitional zone between the air masses) and the distribution of atmospheric variables in such zones. To enable for the first time a statistical analysis of frontal zones, we present a new approach to obtain the volume enclosed by a zone, by classifying grid boxes that intersect with normal curves emanating from a selected front. We introduce our method by means of an idealized numerical simulation and demonstrate its use with two real-world cases using numerical weather prediction data.", "keywords": ["atmospheric movements", "atmospheric techniques", "atmospheric temperature", "data visualisation", "meteorology", "numerical analysis", "statistical analysis", "storms", "weather forecasting", "wind", "moist potential temperature field", "temperature gradient field", "frontal zone", "atmospheric variables", "interactive 3d visual analysis", "atmospheric fronts", "extra-tropical cyclones", "extra-tropical weather systems", "three-dimensional surfaces", "innate structural complexity", "objective identification", "visualization scientists", "meteorologists", "novel visualization approach", "three-dimensional structure", "frontal surfaces", "air masses", "Three-dimensional displays", "Visualization", "Weather forecasting", "Cyclones", "Ocean temperature", "Two dimensional displays", "Meteorology", "Atmospheric Fronts", "Feature Detection"], "referenced_by": [], "referencing": ["IKEY:8017585", "IKEY:4475467", "IKEY:8126857", "IKEY:4376174", "IKEY:4276078", "IKEY:8017585", "IKEY:4475467", "IKEY:8126857", "IKEY:4376174", "IKEY:4276078", "IKEY:8017585", "IKEY:4475467", "IKEY:8126857", "IKEY:4376174", "IKEY:4276078", "10.1145/37401.37422", "10.1145/37401.37422", "10.1145/37401.37422", "10.1029/2010GL046451", "10.1002/qj.49710845609", "10.1007/978-94-015-8765-5", "10.1201/b10629", "10.1175/MWR3378.1", "10.1175/2008MWR2465.1", "10.1016/0734-189X(83)90094-4", "10.1017/S1350482798000553", "10.1002/met.204", "10.1175/MWR-D-12-00252.1", "10.1002/met.142", "10.1002/qj.49712051603", "10.1175/JAS3548.1", "10.1256/qj.04.157", "10.1175/1520-0477(1991)072&lt;0348:SFATFA&gt;2.0.CO;2", "10.1175/1520-0493(1993)121&lt;0889:TSAEOA&gt;2.0.CO;2", "10.1002/joc.1613", "10.1002/wea.2463", "10.1111/j.1467-8659.2011.01944.x", "10.1002/2014JD022305", "10.5194/gmd-8-2355-2015", "10.5194/gmd-8-2329-2015", "10.1175/1520-0493(1965)093&lt;0547:EINOFA&gt;2.3.CO;2", "10.1175/1520-0493(1999)127&lt;0945:APMOSM&gt;2.0.CO;2", "10.1175/1520-0477(1995)076&lt;0505:ACFDSA&gt;2.0.CO;2", "10.1002/2017GL076726", "10.1175/BAMS-D-17-0003.1", "10.1002/asl.660", "10.1002/qj.2584", "10.1175/1520-0493(1993)121&lt;0918:TOPIAM&gt;2.0.CO;2", "10.1175/2010BAMS3057.1", "10.1016/j.physd.2005.10.007", "10.1007/978-1-944970-33-8_10", "10.1175/BAMS-D-13-00155.1", "10.2514/2.744", "10.1029/2010GL046451", "10.1002/qj.49710845609", "10.1007/978-94-015-8765-5", "10.1201/b10629", "10.1175/MWR3378.1", "10.1175/2008MWR2465.1", "10.1016/0734-189X(83)90094-4", "10.1017/S1350482798000553", "10.1002/met.204", "10.1175/MWR-D-12-00252.1", "10.1002/met.142", "10.1002/qj.49712051603", "10.1175/JAS3548.1", "10.1256/qj.04.157", "10.1175/1520-0477(1991)072&lt;0348:SFATFA&gt;2.0.CO;2", "10.1175/1520-0493(1993)121&lt;0889:TSAEOA&gt;2.0.CO;2", "10.1002/joc.1613", "10.1002/wea.2463", "10.1111/j.1467-8659.2011.01944.x", "10.1002/2014JD022305", "10.5194/gmd-8-2355-2015", "10.5194/gmd-8-2329-2015", "10.1175/1520-0493(1965)093&lt;0547:EINOFA&gt;2.3.CO;2", "10.1175/1520-0493(1999)127&lt;0945:APMOSM&gt;2.0.CO;2", "10.1175/1520-0477(1995)076&lt;0505:ACFDSA&gt;2.0.CO;2", "10.1002/2017GL076726", "10.1175/BAMS-D-17-0003.1", "10.1002/asl.660", "10.1002/qj.2584", "10.1175/1520-0493(1993)121&lt;0918:TOPIAM&gt;2.0.CO;2", "10.1175/2010BAMS3057.1", "10.1016/j.physd.2005.10.007", "10.1007/978-1-944970-33-8_10", "10.1175/BAMS-D-13-00155.1", "10.2514/2.744", "10.1029/2010GL046451", "10.1002/qj.49710845609", "10.1007/978-94-015-8765-5", "10.1201/b10629", "10.1175/MWR3378.1", "10.1175/2008MWR2465.1", "10.1016/0734-189X(83)90094-4", "10.1017/S1350482798000553", "10.1002/met.204", "10.1175/MWR-D-12-00252.1", "10.1002/met.142", "10.1002/qj.49712051603", "10.1175/JAS3548.1", "10.1256/qj.04.157", "10.1175/1520-0477(1991)072&lt;0348:SFATFA&gt;2.0.CO;2", "10.1175/1520-0493(1993)121&lt;0889:TSAEOA&gt;2.0.CO;2", "10.1002/joc.1613", "10.1002/wea.2463", "10.1111/j.1467-8659.2011.01944.x", "10.1002/2014JD022305", "10.5194/gmd-8-2355-2015", "10.5194/gmd-8-2329-2015", "10.1175/1520-0493(1965)093&lt;0547:EINOFA&gt;2.3.CO;2", "10.1175/1520-0493(1999)127&lt;0945:APMOSM&gt;2.0.CO;2", "10.1175/1520-0477(1995)076&lt;0505:ACFDSA&gt;2.0.CO;2", "10.1002/2017GL076726", "10.1175/BAMS-D-17-0003.1", "10.1002/asl.660", "10.1002/qj.2584", "10.1175/1520-0493(1993)121&lt;0918:TOPIAM&gt;2.0.CO;2", "10.1175/2010BAMS3057.1", "10.1016/j.physd.2005.10.007", "10.1007/978-1-944970-33-8_10", "10.1175/BAMS-D-13-00155.1", "10.2514/2.744"]}, "10.1109/TVCG.2018.2864815": {"doi": "10.1109/TVCG.2018.2864815", "author": ["B. Ma", "A. Entezari"], "title": "An Interactive Framework for Visualization of Weather Forecast Ensembles", "year": "2019", "abstract": "Numerical Weather Prediction (NWP) ensembles are commonly used to assess the uncertainty and confidence in weather forecasts. Spaghetti plots are conventional tools for meteorologists to directly examine the uncertainty exhibited by ensembles, where they simultaneously visualize isocontours of all ensemble members. To avoid visual clutter in practical usages, one needs to select a small number of informative isovalues for visual analysis. Moreover, due to the complex topology and variation of ensemble isocontours, it is often a challenging task to interpret the spaghetti plot for even a single isovalue in large ensembles. In this paper, we propose an interactive framework for uncertainty visualization of weather forecast ensembles that significantly improves and expands the utility of spaghetti plots in ensemble analysis. Complementary to state-of-the-art methods, our approach provides a complete framework for visual exploration of ensemble isocontours, including isovalue selection, interactive isocontour variability exploration, and interactive sub-region selection and re-analysis. Our framework is built upon the high-density clustering paradigm, where the mode structure of the density function is represented as a hierarchy of nested subsets of the data. We generalize the high-density clustering for isocontours and propose a bandwidth selection method for estimating the density function of ensemble isocontours. We present novel visualizations based on high-density clustering results, called the mode plot and the simplified spaghetti plot. The proposed mode plot visually encodes the structure provided by the high-density clustering result and summarizes the distribution of ensemble isocontours. It also enables the selection of subsets of interesting isocontours, which are interactively highlighted in a linked spaghetti plot for providing spatial context. To provide an interpretable overview of the positional variability of isocontours, our system allows for selection of informative isovalues from the simplified spaghetti plot. Due to the spatial variability of ensemble isocontours, the system allows for interactive selection and focus on sub-regions for local uncertainty and clustering re-analysis. We examine a number of ensemble datasets to establish the utility of our approach and discuss its advantages over state-of-the-art visual analysis tools for ensemble data.", "keywords": ["data visualisation", "geophysics computing", "interactive systems", "pattern clustering", "weather forecasting", "spaghetti plot", "numerical weather prediction ensembles", "visual analysis tools", "density function", "high-density clustering paradigm", "interactive sub-region selection", "interactive isocontour variability exploration", "visual exploration", "uncertainty visualization", "ensemble isocontours", "visual clutter", "weather forecast ensembles", "interactive framework", "Data visualization", "Uncertainty", "Visualization", "Weather forecasting", "Atmospheric modeling", "Tools", "Spaghetti plots", "ensemble visualization", "uncertainty visualization", "high-density clustering", "ensemble forecasting"], "referenced_by": [], "referencing": ["IKEY:6634171", "IKEY:7192629", "IKEY:7539581", "IKEY:400568", "IKEY:6875990", "IKEY:7465271", "IKEY:7192675", "IKEY:7539342", "IKEY:7194852", "IKEY:7465272", "IKEY:6747370", "IKEY:8019883", "IKEY:8119816", "IKEY:7352365", "IKEY:6813969", "IKEY:6702500", "IKEY:5620906", "IKEY:5360497", "IKEY:7192710", "IKEY:7778257", "IKEY:5613483", "IKEY:7465251", "IKEY:6875976", "IKEY:7539323", "IKEY:6634129", "IKEY:6634171", "IKEY:7192629", "IKEY:7539581", "IKEY:400568", "IKEY:6875990", "IKEY:7465271", "IKEY:7192675", "IKEY:7539342", "IKEY:7194852", "IKEY:7465272", "IKEY:6747370", "IKEY:8019883", "IKEY:8119816", "IKEY:7352365", "IKEY:6813969", "IKEY:6702500", "IKEY:5620906", "IKEY:5360497", "IKEY:7192710", "IKEY:7778257", "IKEY:5613483", "IKEY:7465251", "IKEY:6875976", "IKEY:7539323", "IKEY:6634129", "IKEY:6634171", "IKEY:7192629", "IKEY:7539581", "IKEY:400568", "IKEY:6875990", "IKEY:7465271", "IKEY:7192675", "IKEY:7539342", "IKEY:7194852", "IKEY:7465272", "IKEY:6747370", "IKEY:8019883", "IKEY:8119816", "IKEY:7352365", "IKEY:6813969", "IKEY:6702500", "IKEY:5620906", "IKEY:5360497", "IKEY:7192710", "IKEY:7778257", "IKEY:5613483", "IKEY:7465251", "IKEY:6875976", "IKEY:7539323", "IKEY:6634129", "10.1145/3002151.3002165", "10.1145/37401.37422", "10.1145/3002151.3002165", "10.1145/37401.37422", "10.1145/3002151.3002165", "10.1145/37401.37422", "10.1111/j.1467-8659.2009.01689.x", "10.1080/01621459.2016.1228536", "10.1118/1.596225", "10.18637/jss.v021.i07", "10.1111/cgf.12898", "10.1111/j.1467-8659.2009.01697.x", "10.1016/j.cag.2017.01.006", "10.1007/s11222-013-9400-x", "10.1111/j.1467-8659.2011.01944.x", "10.1111/cgf.12100", "10.1111/j.1467-8659.2011.01942.x", "10.1007/978-3-642-32677-6_15", "10.5194/gmd-8-2329-2015", "10.1111/j.2517-6161.1991.tb01857.x", "10.1007/978-1-4899-3324-9", "10.1146/annurev-statistics-031017-100045", "10.1111/j.1467-8659.2009.01689.x", "10.1080/01621459.2016.1228536", "10.1118/1.596225", "10.18637/jss.v021.i07", "10.1111/cgf.12898", "10.1111/j.1467-8659.2009.01697.x", "10.1016/j.cag.2017.01.006", "10.1007/s11222-013-9400-x", "10.1111/j.1467-8659.2011.01944.x", "10.1111/cgf.12100", "10.1111/j.1467-8659.2011.01942.x", "10.1007/978-3-642-32677-6_15", "10.5194/gmd-8-2329-2015", "10.1111/j.2517-6161.1991.tb01857.x", "10.1007/978-1-4899-3324-9", "10.1146/annurev-statistics-031017-100045", "10.1111/j.1467-8659.2009.01689.x", "10.1080/01621459.2016.1228536", "10.1118/1.596225", "10.18637/jss.v021.i07", "10.1111/cgf.12898", "10.1111/j.1467-8659.2009.01697.x", "10.1016/j.cag.2017.01.006", "10.1007/s11222-013-9400-x", "10.1111/j.1467-8659.2011.01944.x", "10.1111/cgf.12100", "10.1111/j.1467-8659.2011.01942.x", "10.1007/978-3-642-32677-6_15", "10.5194/gmd-8-2329-2015", "10.1111/j.2517-6161.1991.tb01857.x", "10.1007/978-1-4899-3324-9", "10.1146/annurev-statistics-031017-100045"]}, "10.1109/TVCG.2018.2864768": {"doi": "10.1109/TVCG.2018.2864768", "author": ["L. Roy", "P. Kumar", "Y. Zhang", "E. Zhang"], "title": "Robust and Fast Extraction of 3D Symmetric Tensor Field Topology", "year": "2019", "abstract": "3D symmetric tensor fields appear in many science and engineering fields, and topology-driven analysis is important in many of these application domains, such as solid mechanics and fluid dynamics. Degenerate curves and neutral surfaces are important topological features in 3D symmetric tensor fields. Existing methods to extract degenerate curves and neutral surfaces often miss parts of the curves and surfaces, respectively. Moreover, these methods are computationally expensive due to the lack of knowledge of structures of degenerate curves and neutral surfaces.<;/p> <;p>In this paper, we provide theoretical analysis on the geometric and topological structures of degenerate curves and neutral surfaces of 3D linear tensor fields. These structures lead to parameterizations for degenerate curves and neutral surfaces that can not only provide more robust extraction of these features but also incur less computational cost.<;/p> <;p>We demonstrate the benefits of our approach by applying our degenerate curve and neutral surface detection techniques to solid mechanics simulation data sets.", "keywords": ["curve fitting", "data visualisation", "feature extraction", "geometry", "surface fitting", "tensors", "topology", "degenerate curve", "neutral surface detection techniques", "3D symmetric tensor field topology", "engineering fields", "topology-driven analysis", "geometric structures", "topological structures", "3D linear tensor fields", "topological features", "solid mechanics", "fluid dynamics", "parameterizations", "robust extraction", "Tensile stress", "Eigenvalues and eigenfunctions", "Three-dimensional displays", "Feature extraction", "Topology", "Solids", "Robustness", "Tensor field visualization", "3D symmetric tensor fields", "tensor field topology", "traceless tensors", "degenerate curve extraction", "neutral surface extraction"], "referenced_by": ["IKEY:8794517"], "referencing": ["IKEY:219447", "IKEY:5290754", "IKEY:582332", "IKEY:7286850", "IKEY:4658184", "IKEY:4015401", "IKEY:1372212", "IKEY:1432685", "IKEY:219447", "IKEY:5290754", "IKEY:582332", "IKEY:7286850", "IKEY:4658184", "IKEY:4015401", "IKEY:1372212", "IKEY:1432685", "IKEY:219447", "IKEY:5290754", "IKEY:582332", "IKEY:7286850", "IKEY:4658184", "IKEY:4015401", "IKEY:1372212", "IKEY:1432685", "10.1145/3130800.3130844", "10.1145/3130800.3130844", "10.1145/3130800.3130844", "10.1137/S0036139997318032", "10.1111/j.1467-8659.2012.03231.x", "10.1007/978-3-642-17286-1", "10.1137/S0036139997318032", "10.1111/j.1467-8659.2012.03231.x", "10.1007/978-3-642-17286-1", "10.1137/S0036139997318032", "10.1111/j.1467-8659.2012.03231.x", "10.1007/978-3-642-17286-1"]}, "10.1109/TVCG.2018.2864845": {"doi": "10.1109/TVCG.2018.2864845", "author": ["M. Ankele", "T. Schultz"], "title": "DT-MRI Streamsurfaces Revisited", "year": "2019", "abstract": "DT-MRI streamsurfaces, defined as surfaces that are everywhere tangential to the major and medium eigenvector fields, have been proposed as a tool for visualizing regions of predominantly planar behavior in diffusion tensor MRI. Even though it has long been known that their construction assumes that the involved eigenvector fields satisfy an integrability condition, it has never been tested systematically whether this condition is met in real-world data. We introduce a suitable and efficiently computable test to the visualization literature, demonstrate that it can be used to distinguish integrable from nonintegrable configurations in simulations, and apply it to whole-brain datasets of 15 healthy subjects. We conclude that streamsurface integrability is approximately satisfied in a substantial part of the brain, but not everywhere, including some regions of planarity. As a consequence, algorithms for streamsurface extraction should explicitly test local integrability. Finally, we propose a novel patch-based approach to streamsurface visualization that reduces visual artifacts, and is shown to more fully sample the extent of streamsurfaces.", "keywords": ["biodiffusion", "biomedical MRI", "brain", "data visualisation", "medical image processing", "streamsurface integrability", "streamsurface extraction", "visual artifacts", "DT-MRI streamsurfaces", "diffusion tensor MRI", "streamsurface visualization", "whole-brain dataset", "Diffusion tensor imaging", "Visualization", "Tensile stress", "Eigenvalues and eigenfunctions", "Indexes", "Tools", "Diffusion Tensor MRI", "streamsurfaces", "Frobenius theorem", "Lie bracket"], "referenced_by": [], "referencing": ["IKEY:7724004", "IKEY:4376175", "IKEY:235211", "IKEY:7286850", "IKEY:4376174", "IKEY:4376179", "IKEY:4840340", "IKEY:6183586", "IKEY:4658184", "IKEY:1260740", "IKEY:1432685", "IKEY:7724004", "IKEY:4376175", "IKEY:235211", "IKEY:7286850", "IKEY:4376174", "IKEY:4376179", "IKEY:4840340", "IKEY:6183586", "IKEY:4658184", "IKEY:1260740", "IKEY:1432685", "IKEY:7724004", "IKEY:4376175", "IKEY:235211", "IKEY:7286850", "IKEY:4376174", "IKEY:4376179", "IKEY:4840340", "IKEY:6183586", "IKEY:4658184", "IKEY:1260740", "IKEY:1432685", "10.1007/s11548-017-1593-6", "10.1007/978-3-319-73839-0_11", "10.1002/nbm.783", "10.1111/j.2517-6161.1995.tb02031.x", "10.1126/science.1223425", "10.1016/j.neuroimage.2011.09.015", "10.1002/nag.223", "10.1016/j.media.2007.07.005", "10.1006/jmre.2001.2452", "10.1002/nbm.3902", "10.1007/978-1-4471-6497-5_8", "10.1016/j.neuroimage.2013.05.057", "10.1016/j.neuroimage.2016.07.042", "10.1016/j.media.2017.03.007", "10.1002/mrm.22924", "10.1126/science.1215280", "10.1126/science.1223493", "10.1016/S1361-8415(02)00053-1", "10.1007/s11548-017-1593-6", "10.1007/978-3-319-73839-0_11", "10.1002/nbm.783", "10.1111/j.2517-6161.1995.tb02031.x", "10.1126/science.1223425", "10.1016/j.neuroimage.2011.09.015", "10.1002/nag.223", "10.1016/j.media.2007.07.005", "10.1006/jmre.2001.2452", "10.1002/nbm.3902", "10.1007/978-1-4471-6497-5_8", "10.1016/j.neuroimage.2013.05.057", "10.1016/j.neuroimage.2016.07.042", "10.1016/j.media.2017.03.007", "10.1002/mrm.22924", "10.1126/science.1215280", "10.1126/science.1223493", "10.1016/S1361-8415(02)00053-1", "10.1007/s11548-017-1593-6", "10.1007/978-3-319-73839-0_11", "10.1002/nbm.783", "10.1111/j.2517-6161.1995.tb02031.x", "10.1126/science.1223425", "10.1016/j.neuroimage.2011.09.015", "10.1002/nag.223", "10.1016/j.media.2007.07.005", "10.1006/jmre.2001.2452", "10.1002/nbm.3902", "10.1007/978-1-4471-6497-5_8", "10.1016/j.neuroimage.2013.05.057", "10.1016/j.neuroimage.2016.07.042", "10.1016/j.media.2017.03.007", "10.1002/mrm.22924", "10.1126/science.1215280", "10.1126/science.1223493", "10.1016/S1361-8415(02)00053-1"]}, "10.1109/TVCG.2018.2864846": {"doi": "10.1109/TVCG.2018.2864846", "author": ["F. Raith", "C. Blecha", "T. Nagel", "F. Parisio", "O. Kolditz", "F. G\u00fcnther", "M. Stommel", "G. Scheuermann"], "title": "Tensor Field Visualization using Fiber Surfaces of Invariant Space", "year": "2019", "abstract": "Scientific visualization developed successful methods for scalar and vector fields. For tensor fields, however, effective, interactive visualizations are still missing despite progress over the last decades. We present a general approach for the generation of separating surfaces in symmetric, second-order, three-dimensional tensor fields. These surfaces are defined as fiber surfaces of the invariant space, i.e. as pre-images of surfaces in the range of a complete set of invariants. This approach leads to a generalization of the fiber surface algorithm by Klacansky et al. [16] to three dimensions in the range. This is due to the fact that the invariant space is three-dimensional for symmetric second-order tensors over a spatial domain. We present an algorithm for surface construction for simplicial grids in the domain and simplicial surfaces in the invariant space. We demonstrate our approach by applying it to stress fields from component design in mechanical engineering.", "keywords": ["computational geometry", "data visualisation", "image processing", "tensors", "vectors", "symmetric tensor fields", "second-order tensor fields", "scalar fields", "pre-image surfaces", "simplicial surfaces", "surface construction", "fiber surface algorithm", "three-dimensional tensor fields", "interactive visualizations", "effective visualizations", "vector fields", "scientific visualization", "invariant space", "tensor field visualization", "Tensile stress", "Visualization", "Mechanical engineering", "Strain", "Geometry", "Neuroscience", "visualization", "tensor field", "invariants", "fiber surface", "interaction"], "referenced_by": ["IKEY:8781565"], "referencing": ["IKEY:219447", "IKEY:346326", "IKEY:4359059", "IKEY:7471499", "IKEY:6787161", "IKEY:489388", "IKEY:7286850", "IKEY:1250379", "IKEY:219447", "IKEY:346326", "IKEY:4359059", "IKEY:7471499", "IKEY:6787161", "IKEY:489388", "IKEY:7286850", "IKEY:1250379", "IKEY:219447", "IKEY:346326", "IKEY:4359059", "IKEY:7471499", "IKEY:6787161", "IKEY:489388", "IKEY:7286850", "IKEY:1250379", "10.1145/37402.37422", "10.1145/344779.344987", "10.1145/383259.383307", "10.1145/37402.37422", "10.1145/344779.344987", "10.1145/383259.383307", "10.1145/37402.37422", "10.1145/344779.344987", "10.1145/383259.383307", "10.1016/0167-8396(88)90013-1", "10.1111/cgf.12636", "10.1016/S0022-5096(00)00023-5", "10.1117/12.952885", "10.1007/978-3-642-27343-8_4", "10.1002/mrm.20741", "10.1201/b14581", "10.1111/cgf.12933", "10.1007/b106657_8", "10.1111/j.1467-8659.2012.03231.x", "10.1080/10867651.1997.10487472", "10.1016/j.ijrmms.2017.01.016", "10.1016/j.ijsolstr.2015.08.003", "10.1007/978-3-319-61358-1_4", "10.1016/0167-8396(88)90013-1", "10.1111/cgf.12636", "10.1016/S0022-5096(00)00023-5", "10.1117/12.952885", "10.1007/978-3-642-27343-8_4", "10.1002/mrm.20741", "10.1201/b14581", "10.1111/cgf.12933", "10.1007/b106657_8", "10.1111/j.1467-8659.2012.03231.x", "10.1080/10867651.1997.10487472", "10.1016/j.ijrmms.2017.01.016", "10.1016/j.ijsolstr.2015.08.003", "10.1007/978-3-319-61358-1_4", "10.1016/0167-8396(88)90013-1", "10.1111/cgf.12636", "10.1016/S0022-5096(00)00023-5", "10.1117/12.952885", "10.1007/978-3-642-27343-8_4", "10.1002/mrm.20741", "10.1201/b14581", "10.1111/cgf.12933", "10.1007/b106657_8", "10.1111/j.1467-8659.2012.03231.x", "10.1080/10867651.1997.10487472", "10.1016/j.ijrmms.2017.01.016", "10.1016/j.ijsolstr.2015.08.003", "10.1007/978-3-319-61358-1_4"]}, "10.1109/TVCG.2018.2864847": {"doi": "10.1109/TVCG.2018.2864847", "author": ["J. Beyer", "H. Mohammed", "M. Agus", "A. K. Al-Awami", "H. Pfister", "M. Hadwiger"], "title": "Culling for Extreme-Scale Segmentation Volumes: A Hybrid Deterministic and Probabilistic Approach", "year": "2019", "abstract": "With the rapid increase in raw volume data sizes, such as terabyte-sized microscopy volumes, the corresponding segmentation label volumes have become extremely large as well. We focus on integer label data, whose efficient representation in memory, as well as fast random data access, pose an even greater challenge than the raw image data. Often, it is crucial to be able to rapidly identify which segments are located where, whether for empty space skipping for fast rendering, or for spatial proximity queries. We refer to this process as culling. In order to enable efficient culling of millions of labeled segments, we present a novel hybrid approach that combines deterministic and probabilistic representations of label data in a data-adaptive hierarchical data structure that we call the label list tree. In each node, we adaptively encode label data using either a probabilistic constant-time access representation for fast conservative culling, or a deterministic logarithmic-time access representation for exact queries. We choose the best data structures for representing the labels of each spatial region while building the label list tree. At run time, we further employ a novel query-adaptive culling strategy. While filtering a query down the tree, we prune it successively, and in each node adaptively select the representation that is best suited for evaluating the pruned query, depending on its size. We show an analysis of the efficiency of our approach with several large data sets from connectomics, including a brain scan with more than 13 million labeled segments, and compare our method to conventional culling approaches. Our approach achieves significant reductions in storage size as well as faster query times.", "keywords": ["brain", "data structures", "image representation", "image segmentation", "medical image processing", "probability", "query processing", "rendering (computer graphics)", "trees (mathematics)", "terabyte-sized microscopy volumes", "integer label data", "fast random data access", "raw image data", "spatial proximity queries", "hybrid approach", "deterministic representations", "probabilistic representations", "data-adaptive hierarchical data structure", "label list tree", "constant-time access representation", "logarithmic-time access representation", "data structures", "query-adaptive culling strategy", "data sets", "extreme-scale segmentation", "memory representation", "rendering", "query times", "culling approaches", "segmentation label volumes", "conservative culling", "query prune", "Rendering (computer graphics)", "Data structures", "Image segmentation", "Probabilistic logic", "Data visualization", "Encoding", "Mice", "Hierarchical Culling", "Segmented Volume Data", "Bloom Filter", "Volume Rendering", "Spatial Queries"], "referenced_by": ["IKEY:8933631"], "referencing": ["IKEY:235231", "IKEY:6634132", "IKEY:6562713", "IKEY:5290766", "IKEY:851975", "IKEY:6327233", "IKEY:1250384", "IKEY:809908", "IKEY:5742370", "IKEY:1432687", "IKEY:480792", "IKEY:146377", "IKEY:964521", "IKEY:235231", "IKEY:6634132", "IKEY:6562713", "IKEY:5290766", "IKEY:851975", "IKEY:6327233", "IKEY:1250384", "IKEY:809908", "IKEY:5742370", "IKEY:1432687", "IKEY:480792", "IKEY:146377", "IKEY:964521", "IKEY:235231", "IKEY:6634132", "IKEY:6562713", "IKEY:5290766", "IKEY:851975", "IKEY:6327233", "IKEY:1250384", "IKEY:809908", "IKEY:5742370", "IKEY:1432687", "IKEY:480792", "IKEY:146377", "IKEY:964521", "10.1145/142750.143054", "10.1145/362686.362692", "10.1145/1507149.1507152", "10.1145/263407.263545", "10.1145/2674005.2674994", "10.1145/383259.383265", "10.1145/78973.78977", "10.1145/142750.143054", "10.1145/362686.362692", "10.1145/1507149.1507152", "10.1145/263407.263545", "10.1145/2674005.2674994", "10.1145/383259.383265", "10.1145/78973.78977", "10.1145/142750.143054", "10.1145/362686.362692", "10.1145/1507149.1507152", "10.1145/263407.263545", "10.1145/2674005.2674994", "10.1145/383259.383265", "10.1145/78973.78977", "10.14778/2350229.2350275", "10.1111/cgf.12605", "10.1007/PL00013406", "10.1002/spe.2325", "10.1002/pamm.200700637", "10.1201/b10629", "10.1111/j.1467-8659.2005.00855.x", "10.1016/j.cell.2015.06.054", "10.1016/j.media.2015.02.001", "10.1002/spe.2402", "10.1007/978-3-319-66182-7_89", "10.1364/BOE.2.002888", "10.1080/2151237X.2008.10129258", "10.1007/978-3-540-69497-7_23", "10.14778/2350229.2350275", "10.1111/cgf.12605", "10.1007/PL00013406", "10.1002/spe.2325", "10.1002/pamm.200700637", "10.1201/b10629", "10.1111/j.1467-8659.2005.00855.x", "10.1016/j.cell.2015.06.054", "10.1016/j.media.2015.02.001", "10.1002/spe.2402", "10.1007/978-3-319-66182-7_89", "10.1364/BOE.2.002888", "10.1080/2151237X.2008.10129258", "10.1007/978-3-540-69497-7_23", "10.14778/2350229.2350275", "10.1111/cgf.12605", "10.1007/PL00013406", "10.1002/spe.2325", "10.1002/pamm.200700637", "10.1201/b10629", "10.1111/j.1467-8659.2005.00855.x", "10.1016/j.cell.2015.06.054", "10.1016/j.media.2015.02.001", "10.1002/spe.2402", "10.1007/978-3-319-66182-7_89", "10.1364/BOE.2.002888", "10.1080/2151237X.2008.10129258", "10.1007/978-3-540-69497-7_23"]}, "10.1109/TVCG.2018.2864850": {"doi": "10.1109/TVCG.2018.2864850", "author": ["F. Wang", "I. Wald", "Q. Wu", "W. Usher", "C. R. Johnson"], "title": "CPU Isosurface Ray Tracing of Adaptive Mesh Refinement Data", "year": "2019", "abstract": "Adaptive mesh refinement (AMR) is a key technology for large-scale simulations that allows for adaptively changing the simulation mesh resolution, resulting in significant computational and storage savings. However, visualizing such AMR data poses a significant challenge due to the difficulties introduced by the hierarchical representation when reconstructing continuous field values. In this paper, we detail a comprehensive solution for interactive isosurface rendering of block-structured AMR data. We contribute a novel reconstruction strategy-the octant method-which is continuous, adaptive and simple to implement. Furthermore, we present a generally applicable hybrid implicit isosurface ray-tracing method, which provides better rendering quality and performance than the built-in sampling-based approach in OSPRay. Finally, we integrate our octant method and hybrid isosurface geometry into OSPRay as a module, providing the ability to create high-quality interactive visualizations combining volume and isosurface representations of BS-AMR data. We evaluate the rendering performance, memory consumption and quality of our method on two gigascale block-structured AMR datasets.", "keywords": ["computational geometry", "data visualisation", "interactive systems", "mesh generation", "microprocessor chips", "ray tracing", "rendering (computer graphics)", "CPU isosurface ray tracing", "adaptive mesh refinement data", "simulation mesh resolution", "continuous field values", "interactive isosurface rendering", "OSPRay", "octant method", "hybrid isosurface geometry", "BS-AMR data", "gigascale block-structured AMR datasets", "reconstruction strategy", "computational storage savings", "interactive visualizations", "Isosurfaces", "Rendering (computer graphics)", "Ray tracing", "Computational modeling", "Reconstruction algorithms", "AMR", "Isosurface", "Ray tracing", "Reconstruction strategy", "OSPRay"], "referenced_by": ["IKEY:8944267"], "referencing": ["IKEY:1238274", "IKEY:4658195", "IKEY:5742355", "IKEY:6675156", "IKEY:5290780", "IKEY:6064949", "IKEY:774839", "IKEY:745713", "IKEY:4376208", "IKEY:1471693", "IKEY:7539599", "IKEY:1238274", "IKEY:4658195", "IKEY:5742355", "IKEY:6675156", "IKEY:5290780", "IKEY:6064949", "IKEY:774839", "IKEY:745713", "IKEY:4376208", "IKEY:1471693", "IKEY:7539599", "IKEY:1238274", "IKEY:4658195", "IKEY:5742355", "IKEY:6675156", "IKEY:5290780", "IKEY:6064949", "IKEY:774839", "IKEY:745713", "IKEY:4376208", "IKEY:1471693", "IKEY:7539599", "10.1145/37401.37422", "10.1145/266638.266664", "10.1145/195826.195828", "10.1145/3139295.3139305", "10.1145/37401.37422", "10.1145/266638.266664", "10.1145/195826.195828", "10.1145/3139295.3139305", "10.1145/37401.37422", "10.1145/266638.266664", "10.1145/195826.195828", "10.1145/3139295.3139305", "10.1016/0021-9991(89)90035-1", "10.1016/0021-9991(84)90073-1", "10.1088/0264-9381/32/24/245011", "10.1016/j.jpdc.2014.07.001", "10.1016/j.cageo.2014.10.012", "10.2514/6.2014-0070", "10.1007/3-540-27039-6_24", "10.1007/s00366-006-0047-5", "10.1016/0021-9991(89)90035-1", "10.1016/0021-9991(84)90073-1", "10.1088/0264-9381/32/24/245011", "10.1016/j.jpdc.2014.07.001", "10.1016/j.cageo.2014.10.012", "10.2514/6.2014-0070", "10.1007/3-540-27039-6_24", "10.1007/s00366-006-0047-5", "10.1016/0021-9991(89)90035-1", "10.1016/0021-9991(84)90073-1", "10.1088/0264-9381/32/24/245011", "10.1016/j.jpdc.2014.07.001", "10.1016/j.cageo.2014.10.012", "10.2514/6.2014-0070", "10.1007/3-540-27039-6_24", "10.1007/s00366-006-0047-5"]}, "10.1109/TVCG.2018.2864432": {"doi": "10.1109/TVCG.2018.2864432", "author": ["G. Favelier", "N. Faraj", "B. Summa", "J. Tierny"], "title": "Persistence Atlas for Critical Point Variability in Ensembles", "year": "2019", "abstract": "This paper presents a new approach for the visualization and analysis of the spatial variability of features of interest represented by critical points in ensemble data. Our framework, called Persistence Atlas, enables the visualization of the dominant spatial patterns of critical points, along with statistics regarding their occurrence in the ensemble. The persistence atlas represents in the geometrical domain each dominant pattern in the form of a confidence map for the appearance of critical points. As a by-product, our method also provides 2-dimensional layouts of the entire ensemble, highlighting the main trends at a global level. Our approach is based on the new notion of Persistence Map, a measure of the geometrical density in critical points which leverages the robustness to noise of topological persistence to better emphasize salient features. We show how to leverage spectral embedding to represent the ensemble members as points in a low-dimensional Euclidean space, where distances between points measure the dissimilarities between critical point layouts and where statistical tasks, such as clustering, can be easily carried out. Further, we show how the notion of mandatory critical point can be leveraged to evaluate for each cluster confidence regions for the appearance of critical points. Most of the steps of this framework can be trivially parallelized and we show how to efficiently implement them. Extensive experiments demonstrate the relevance of our approach. The accuracy of the confidence regions provided by the persistence atlas is quantitatively evaluated and compared to a baseline strategy using an off-the-shelf clustering approach. We illustrate the importance of the persistence atlas in a variety of real-life datasets, where clear trends in feature layouts are identified and analyzed. We provide a lightweight VTK-based C++ implementation of our approach that can be used for reproduction purposes.", "keywords": ["data visualisation", "pattern clustering", "probability", "trees (mathematics)", "critical points", "critical point layouts", "mandatory critical point", "critical point variability", "Persistence Atlas", "lightweight VTK-based C++ implementation", "Market research", "Data visualization", "Layout", "Probability density function", "Extraterrestrial measurements", "Uncertainty", "Robustness", "Topological data analysis", "scalar data", "ensemble data"], "referenced_by": ["IKEY:8944935", "IKEY:8944365"], "referencing": ["10.1145/2582112.2582169", "10.1145/1542362.1542407", "10.1145/2535927", "10.1145/1064092.1064133", "10.1145/77635.77639", "10.1145/383259.383282", "10.1145/2582112.2582169", "10.1145/1542362.1542407", "10.1145/2535927", "10.1145/1064092.1064133", "10.1145/77635.77639", "10.1145/383259.383282", "10.1145/2582112.2582169", "10.1145/1542362.1542407", "10.1145/2535927", "10.1145/1064092.1064133", "10.1145/77635.77639", "10.1145/383259.383282", "10.1002/wics.101", "10.1080/00029890.1970.11992523", "10.1007/978-3-319-04099-8_10", "10.1002/jcc.25181", "10.1007/978-1-4471-6497-5_1", "10.1111/j.1467-8659.2009.01689.x", "10.1007/s00454-002-2885-2", "10.1111/cgf.12898", "10.1111/cgf.12359", "10.1111/cgf.12361", "10.1111/cgf.12933", "10.1111/cgf.12912", "10.1559/1523040054738936", "10.1137/0105003", "10.1111/cgf.13165", "10.1111/j.1467-8659.2009.01604.x", "10.1007/s003710050111", "10.1111/j.1467-8659.2012.03097.x", "10.1111/j.1467-8659.2011.01944.x", "10.1111/j.1467-8659.2012.03095.x", "10.1111/cgf.12100", "10.1615/Int.J.UncertaintyQuantification.2012003958", "10.1111/j.1467-8659.2011.01942.x", "10.1111/cgf.12360", "10.1126/science.290.5500.2319", "10.1007/s00454-014-9604-7", "10.1007/s11222-007-9033-z", "10.1002/wics.101", "10.1080/00029890.1970.11992523", "10.1007/978-3-319-04099-8_10", "10.1002/jcc.25181", "10.1007/978-1-4471-6497-5_1", "10.1111/j.1467-8659.2009.01689.x", "10.1007/s00454-002-2885-2", "10.1111/cgf.12898", "10.1111/cgf.12359", "10.1111/cgf.12361", "10.1111/cgf.12933", "10.1111/cgf.12912", "10.1559/1523040054738936", "10.1137/0105003", "10.1111/cgf.13165", "10.1111/j.1467-8659.2009.01604.x", "10.1007/s003710050111", "10.1111/j.1467-8659.2012.03097.x", "10.1111/j.1467-8659.2011.01944.x", "10.1111/j.1467-8659.2012.03095.x", "10.1111/cgf.12100", "10.1615/Int.J.UncertaintyQuantification.2012003958", "10.1111/j.1467-8659.2011.01942.x", "10.1111/cgf.12360", "10.1126/science.290.5500.2319", "10.1007/s00454-014-9604-7", "10.1007/s11222-007-9033-z", "10.1002/wics.101", "10.1080/00029890.1970.11992523", "10.1007/978-3-319-04099-8_10", "10.1002/jcc.25181", "10.1007/978-1-4471-6497-5_1", "10.1111/j.1467-8659.2009.01689.x", "10.1007/s00454-002-2885-2", "10.1111/cgf.12898", "10.1111/cgf.12359", "10.1111/cgf.12361", "10.1111/cgf.12933", "10.1111/cgf.12912", "10.1559/1523040054738936", "10.1137/0105003", "10.1111/cgf.13165", "10.1111/j.1467-8659.2009.01604.x", "10.1007/s003710050111", "10.1111/j.1467-8659.2012.03097.x", "10.1111/j.1467-8659.2011.01944.x", "10.1111/j.1467-8659.2012.03095.x", "10.1111/cgf.12100", "10.1615/Int.J.UncertaintyQuantification.2012003958", "10.1111/j.1467-8659.2011.01942.x", "10.1111/cgf.12360", "10.1126/science.290.5500.2319", "10.1007/s00454-014-9604-7", "10.1007/s11222-007-9033-z"]}, "10.1109/TVCG.2018.2864505": {"doi": "10.1109/TVCG.2018.2864505", "author": ["T. Athawale", "C. R. Johnson"], "title": "Probabilistic Asymptotic Decider for Topological Ambiguity Resolution in Level-Set Extraction for Uncertain 2D Data", "year": "2019", "abstract": "We present a framework for the analysis of uncertainty in isocontour extraction. The marching squares (MS) algorithm for isocontour reconstruction generates a linear topology that is consistent with hyperbolic curves of a piecewise bilinear interpolation. The saddle points of the bilinear interpolant cause topological ambiguity in isocontour extraction. The midpoint decider and the asymptotic decider are well-known mathematical techniques for resolving topological ambiguities. The latter technique investigates the data values at the cell saddle points for ambiguity resolution. The uncertainty in data, however, leads to uncertainty in underlying bilinear interpolation functions for the MS algorithm, and hence, their saddle points. In our work, we study the behavior of the asymptotic decider when data at grid vertices is uncertain. First, we derive closed-form distributions characterizing variations in the saddle point values for uncertain bilinear interpolants. The derivation assumes uniform and nonparametric noise models, and it exploits the concept of ratio distribution for analytic formulations. Next, the probabilistic asymptotic decider is devised for ambiguity resolution in uncertain data using distributions of the saddle point values derived in the first step. Finally, the confidence in probabilistic topological decisions is visualized using a colormapping technique. We demonstrate the higher accuracy and stability of the probabilistic asymptotic decider in uncertain data with regard to existing decision frameworks, such as deciders in the mean field and the probabilistic midpoint decider, through the isocontour visualization of synthetic and real datasets.", "keywords": ["data visualisation", "image colour analysis", "interpolation", "probability", "topology", "isocontour visualization", "probabilistic asymptotic decider", "topological ambiguity resolution", "level-set extraction", "uncertain 2d", "isocontour extraction", "marching squares algorithm", "isocontour reconstruction", "linear topology", "piecewise bilinear interpolation", "saddle points", "topological ambiguities", "data values", "cell saddle", "bilinear interpolation functions", "MS algorithm", "saddle point values", "uncertain bilinear interpolants", "probabilistic topological decisions", "probabilistic midpoint decider", "mathematical techniques", "bilinear interpolant", "nonparametric noise models", "analytic formulations", "colormapping technique", "Data visualization", "Uncertainty", "Probabilistic logic", "Two dimensional displays", "Mathematical model", "Topology", "Interpolation", "Isocontour visualization", "topological uncertainty", "marching squares", "asymptotic decider", "bilinear interpolation", "probabilistic computation"], "referenced_by": ["IKEY:8794517", "IKEY:9166741"], "referencing": ["IKEY:6634171", "IKEY:7192629", "IKEY:1183769", "IKEY:1310282", "IKEY:8017601", "IKEY:6064958", "IKEY:1310205", "IKEY:1231171", "IKEY:1028780", "IKEY:4376198", "IKEY:175782", "IKEY:7778257", "IKEY:6634129", "IKEY:6634171", "IKEY:7192629", "IKEY:1183769", "IKEY:1310282", "IKEY:8017601", "IKEY:6064958", "IKEY:1310205", "IKEY:1231171", "IKEY:1028780", "IKEY:4376198", "IKEY:175782", "IKEY:7778257", "IKEY:6634129", "IKEY:6634171", "IKEY:7192629", "IKEY:1183769", "IKEY:1310282", "IKEY:8017601", "IKEY:6064958", "IKEY:1310205", "IKEY:1231171", "IKEY:1028780", "IKEY:4376198", "IKEY:175782", "IKEY:7778257", "IKEY:6634129", "10.1145/37402.37422", "10.1145/37402.37422", "10.1145/37402.37422", "10.1007/978-1-4471-2804-5_6", "10.1016/S0925-7721(02)00093-7", "10.1016/S0097-8493(02)00055-9", "10.1002/sta4.39", "10.1111/cgf.12359", "10.1063/1.3490510", "10.1080/01621459.1996.10476701", "10.1198/jasa.2009.0108", "10.1111/j.1467-8659.2009.01604.x", "10.1111/cgf.12100", "10.1111/j.1467-8659.2011.01942.x", "10.1615/Int.J.UncertaintyQuantification.2012004074", "10.1615/Int.J.UncertaintyQuantification.2012003956", "10.1007/978-1-4471-2804-5_6", "10.1016/S0925-7721(02)00093-7", "10.1016/S0097-8493(02)00055-9", "10.1002/sta4.39", "10.1111/cgf.12359", "10.1063/1.3490510", "10.1080/01621459.1996.10476701", "10.1198/jasa.2009.0108", "10.1111/j.1467-8659.2009.01604.x", "10.1111/cgf.12100", "10.1111/j.1467-8659.2011.01942.x", "10.1615/Int.J.UncertaintyQuantification.2012004074", "10.1615/Int.J.UncertaintyQuantification.2012003956", "10.1007/978-1-4471-2804-5_6", "10.1016/S0925-7721(02)00093-7", "10.1016/S0097-8493(02)00055-9", "10.1002/sta4.39", "10.1111/cgf.12359", "10.1063/1.3490510", "10.1080/01621459.1996.10476701", "10.1198/jasa.2009.0108", "10.1111/j.1467-8659.2009.01604.x", "10.1111/cgf.12100", "10.1111/j.1467-8659.2011.01942.x", "10.1615/Int.J.UncertaintyQuantification.2012004074", "10.1615/Int.J.UncertaintyQuantification.2012003956"]}, "10.1109/TVCG.2018.2864827": {"doi": "10.1109/TVCG.2018.2864827", "author": ["K. Xu", "G. Chen"], "title": "Hexahedral Mesh Structure Visualization and Evaluation", "year": "2019", "abstract": "Understanding hexahedral (hex-) mesh structures is important for a number of hex-mesh generation and optimization tasks. However, due to various configurations of the singularities in a valid pure hex-mesh, the structure (or base complex) of the mesh can be arbitrarily complex. In this work, we present a first and effective method to help meshing practitioners understand the possible configurations in a valid 3D base complex for the characterization of their complexity. In particular, we propose a strategy to decompose the complex hex-mesh structure into multi-level sub-structures so that they can be studied separately, from which we identify a small set of the sub-structures that can most efficiently represent the whole mesh structure. Furthermore, from this set of sub-structures, we attempt to define the first metric for the quantification of the complexity of hex-mesh structure. To aid the exploration of the extracted multi-level structure information, we devise a visual exploration system coupled with a matrix view to help alleviate the common challenge of 3D data exploration (e.g., clutter and occlusion). We have applied our tool and metric to a large number of hex-meshes generated with different approaches to reveal different characteristics of these methods in terms of the mesh structures they can produce. We also use our metric to assess the existing structure simplification techniques in terms of their effectiveness.", "keywords": ["data visualisation", "mesh generation", "hexahedral mesh structure visualization", "hex-mesh generation", "optimization tasks", "valid pure hex-mesh", "meshing practitioners", "valid 3D base complex", "complex hex-mesh structure", "multilevel sub-structures", "hex-meshes", "structure simplification techniques", "multilevel structure information extraction", "Complexity theory", "Three-dimensional displays", "Visualization", "Periodic structures", "Optimization", "Splines (mathematics)", "Mesh generation", "hexahedral mesh", "base complex", "sheet decomposition", "complexity analysis"], "referenced_by": [], "referencing": ["IKEY:7226867", "IKEY:6654167", "IKEY:7226867", "IKEY:6654167", "IKEY:7226867", "IKEY:6654167", "10.1145/1141911.1141993", "10.1145/237170.237271", "10.1145/2897824.2925957", "10.1145/2766941", "10.1145/3072959.3073676", "10.1145/3130800.3130848", "10.1145/2602141", "10.1145/2070781.2024177", "10.1145/882262.882275", "10.1145/2366145.2366196", "10.1145/2508363.2508388", "10.1145/2930662", "10.1145/2070781.2024176", "10.1145/1141911.1141993", "10.1145/237170.237271", "10.1145/2897824.2925957", "10.1145/2766941", "10.1145/3072959.3073676", "10.1145/3130800.3130848", "10.1145/2602141", "10.1145/2070781.2024177", "10.1145/882262.882275", "10.1145/2366145.2366196", "10.1145/2508363.2508388", "10.1145/2930662", "10.1145/2070781.2024176", "10.1145/1141911.1141993", "10.1145/237170.237271", "10.1145/2897824.2925957", "10.1145/2766941", "10.1145/3072959.3073676", "10.1145/3130800.3130848", "10.1145/2602141", "10.1145/2070781.2024177", "10.1145/882262.882275", "10.1145/2366145.2366196", "10.1145/2508363.2508388", "10.1145/2930662", "10.1145/2070781.2024176", "10.1016/j.proeng.2015.10.123", "10.1111/j.1467-8659.2011.01868.x", "10.1111/cgf.12014", "10.1111/cgf.12959", "10.1016/j.cma.2007.04.007", "10.1111/j.1467-8659.2011.02015.x", "10.1016/j.cma.2004.10.008", "10.1002/nme.2470", "10.1007/s00366-010-0207-5", "10.1007/978-3-642-04319-2_5", "10.1111/j.1467-8659.2011.02014.x", "10.1016/j.cagd.2017.02.012", "10.1111/cgf.12710", "10.1007/BF01198732", "10.1007/s00366-008-0091-4", "10.1007/3-540-29090-7_24", "10.1007/s00366-015-0399-9", "10.1016/j.finel.2007.03.001", "10.1016/j.cma.2005.02.016", "10.1016/j.proeng.2015.10.123", "10.1111/j.1467-8659.2011.01868.x", "10.1111/cgf.12014", "10.1111/cgf.12959", "10.1016/j.cma.2007.04.007", "10.1111/j.1467-8659.2011.02015.x", "10.1016/j.cma.2004.10.008", "10.1002/nme.2470", "10.1007/s00366-010-0207-5", "10.1007/978-3-642-04319-2_5", "10.1111/j.1467-8659.2011.02014.x", "10.1016/j.cagd.2017.02.012", "10.1111/cgf.12710", "10.1007/BF01198732", "10.1007/s00366-008-0091-4", "10.1007/3-540-29090-7_24", "10.1007/s00366-015-0399-9", "10.1016/j.finel.2007.03.001", "10.1016/j.cma.2005.02.016", "10.1016/j.proeng.2015.10.123", "10.1111/j.1467-8659.2011.01868.x", "10.1111/cgf.12014", "10.1111/cgf.12959", "10.1016/j.cma.2007.04.007", "10.1111/j.1467-8659.2011.02015.x", "10.1016/j.cma.2004.10.008", "10.1002/nme.2470", "10.1007/s00366-010-0207-5", "10.1007/978-3-642-04319-2_5", "10.1111/j.1467-8659.2011.02014.x", "10.1016/j.cagd.2017.02.012", "10.1111/cgf.12710", "10.1007/BF01198732", "10.1007/s00366-008-0091-4", "10.1007/3-540-29090-7_24", "10.1007/s00366-015-0399-9", "10.1016/j.finel.2007.03.001", "10.1016/j.cma.2005.02.016"]}, "10.1109/TVCG.2018.2864848": {"doi": "10.1109/TVCG.2018.2864848", "author": ["A. Gyulassy", "P. Bremer", "V. Pascucci"], "title": "Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy", "year": "2019", "abstract": "Topological techniques have proven to be a powerful tool in the analysis and visualization of large-scale scientific data. In particular, the Morse-Smale complex and its various components provide a rich framework for robust feature definition and computation. Consequently, there now exist a number of approaches to compute Morse-Smale complexes for large-scale data in parallel. However, existing techniques are based on discrete concepts which produce the correct topological structure but are known to introduce grid artifacts in the resulting geometry. Here, we present a new approach that combines parallel streamline computation with combinatorial methods to construct a high-quality discrete Morse-Smale complex. In addition to being invariant to the orientation of the underlying grid, this algorithm allows users to selectively build a subset of features using high-quality geometry. In particular, a user may specifically select which ascending/descending manifolds are reconstructed with improved accuracy, focusing computational effort where it matters for subsequent analysis. This approach computes Morse-Smale complexes for larger data than previously feasible with significant speedups. We demonstrate and validate our approach using several examples from a variety of different scientific domains, and evaluate the performance of our method.", "keywords": ["data analysis", "data visualisation", "parallel processing", "shared memory systems", "large-scale scientific data", "shared-memory parallel computation", "improved accuracy", "high-quality discrete Morse-Smale complex", "robust feature definition", "Geometry", "Manifolds", "Feature extraction", "Robustness", "Isosurfaces", "Tools", "Morse complex", "Parallel Computation", "Topology", "Accurate Geometry"], "referenced_by": ["IKEY:8794517", "IKEY:8807223"], "referencing": ["IKEY:1298796", "IKEY:5128904", "IKEY:7874312", "IKEY:7874333", "IKEY:6327205", "IKEY:4658183", "IKEY:4376171", "IKEY:6875918", "IKEY:1634313", "IKEY:6064972", "IKEY:7192663", "IKEY:7013070", "IKEY:4015464", "IKEY:5620895", "IKEY:5766002", "IKEY:6104039", "IKEY:8194449", "IKEY:1298796", "IKEY:5128904", "IKEY:7874312", "IKEY:7874333", "IKEY:6327205", "IKEY:4658183", "IKEY:4376171", "IKEY:6875918", "IKEY:1634313", "IKEY:6064972", "IKEY:7192663", "IKEY:7013070", "IKEY:4015464", "IKEY:5620895", "IKEY:5766002", "IKEY:6104039", "IKEY:8194449", "IKEY:1298796", "IKEY:5128904", "IKEY:7874312", "IKEY:7874333", "IKEY:6327205", "IKEY:4658183", "IKEY:4376171", "IKEY:6875918", "IKEY:1634313", "IKEY:6064972", "IKEY:7192663", "IKEY:7013070", "IKEY:4015464", "IKEY:5620895", "IKEY:5766002", "IKEY:6104039", "IKEY:8194449", "10.1145/777792.777846", "10.1145/777792.777846", "10.1145/777792.777846", "10.1021/ar00109a003", "10.1021/jp981794v", "10.1080/14786445908642760", "10.1016/j.jsc.2016.03.006", "10.1007/s00454-003-2926-5", "10.1007/s00454-002-2885-2", "10.1080/14786447008640422", "10.1007/978-3-319-04099-8_6", "10.1016/j.cagd.2012.03.017", "10.1007/978-3-642-15014-2_9", "10.1021/ar00109a003", "10.1021/jp981794v", "10.1080/14786445908642760", "10.1016/j.jsc.2016.03.006", "10.1007/s00454-003-2926-5", "10.1007/s00454-002-2885-2", "10.1080/14786447008640422", "10.1007/978-3-319-04099-8_6", "10.1016/j.cagd.2012.03.017", "10.1007/978-3-642-15014-2_9", "10.1021/ar00109a003", "10.1021/jp981794v", "10.1080/14786445908642760", "10.1016/j.jsc.2016.03.006", "10.1007/s00454-003-2926-5", "10.1007/s00454-002-2885-2", "10.1080/14786447008640422", "10.1007/978-3-319-04099-8_6", "10.1016/j.cagd.2012.03.017", "10.1007/978-3-642-15014-2_9"]}, "10.1109/TVCG.2018.2864853": {"doi": "10.1109/TVCG.2018.2864853", "author": ["D. Hoang", "P. Klacansky", "H. Bhatia", "P. Bremer", "P. Lindstrom", "V. Pascucci"], "title": "A Study of the Trade-off Between Reducing Precision and Reducing Resolution for Data Analysis and Visualization", "year": "2019", "abstract": "There currently exist two dominant strategies to reduce data sizes in analysis and visualization: reducing the precision of the data, e.g., through quantization, or reducing its resolution, e.g., by subsampling. Both have advantages and disadvantages and both face fundamental limits at which the reduced information ceases to be useful. The paper explores the additional gains that could be achieved by combining both strategies. In particular, we present a common framework that allows us to study the trade-off in reducing precision and/or resolution in a principled manner. We represent data reduction schemes as progressive streams of bits and study how various bit orderings such as by resolution, by precision, etc., impact the resulting approximation error across a variety of data sets as well as analysis tasks. Furthermore, we compute streams that are optimized for different tasks to serve as lower bounds on the achievable error. Scientific data management systems can use the results presented in this paper as guidance on how to store and stream data to make efficient use of the limited storage and bandwidth in practice.", "keywords": ["data analysis", "data compression", "data reduction", "data visualisation", "optimisation", "reducing precision", "reducing resolution", "data analysis", "data reduction schemes", "bit orderings", "scientific data management systems", "approximation error", "data visualization", "data precision", "Task analysis", "Spatial resolution", "Transforms", "Data visualization", "Data analysis", "Rendering (computer graphics)", "data compression", "bit ordering", "multi-resolution", "data analysis"], "referenced_by": [], "referencing": ["IKEY:1095851", "IKEY:4203050", "IKEY:6532282", "IKEY:5928335", "IKEY:5290733", "IKEY:6675157", "IKEY:4376192", "IKEY:6337585", "IKEY:1183757", "IKEY:6327233", "IKEY:809908", "IKEY:7348075", "IKEY:6876024", "IKEY:4015488", "IKEY:1374281", "IKEY:1347192", "IKEY:1372216", "IKEY:6691717", "IKEY:710701", "IKEY:499834", "IKEY:1250385", "IKEY:6064978", "IKEY:7967203", "IKEY:6327475", "IKEY:4407698", "IKEY:7192734", "IKEY:6092314", "IKEY:1095851", "IKEY:4203050", "IKEY:6532282", "IKEY:5928335", "IKEY:5290733", "IKEY:6675157", "IKEY:4376192", "IKEY:6337585", "IKEY:1183757", "IKEY:6327233", "IKEY:809908", "IKEY:7348075", "IKEY:6876024", "IKEY:4015488", "IKEY:1374281", "IKEY:1347192", "IKEY:1372216", "IKEY:6691717", "IKEY:710701", "IKEY:499834", "IKEY:1250385", "IKEY:6064978", "IKEY:7967203", "IKEY:6327475", "IKEY:4407698", "IKEY:7192734", "IKEY:6092314", "IKEY:1095851", "IKEY:4203050", "IKEY:6532282", "IKEY:5928335", "IKEY:5290733", "IKEY:6675157", "IKEY:4376192", "IKEY:6337585", "IKEY:1183757", "IKEY:6327233", "IKEY:809908", "IKEY:7348075", "IKEY:6876024", "IKEY:4015488", "IKEY:1374281", "IKEY:1347192", "IKEY:1372216", "IKEY:6691717", "IKEY:710701", "IKEY:499834", "IKEY:1250385", "IKEY:6064978", "IKEY:7967203", "IKEY:6327475", "IKEY:4407698", "IKEY:7192734", "IKEY:6092314", "10.1145/2600212.2600217", "10.1145/1507149.1507152", "10.1145/2503210.2503283", "10.1145/2487228.2487235", "10.1145/147130.147152", "10.1145/582034.582036", "10.1145/356924.356930", "10.1145/197938.197963", "10.1145/2600212.2600217", "10.1145/1507149.1507152", "10.1145/2503210.2503283", "10.1145/2487228.2487235", "10.1145/147130.147152", "10.1145/582034.582036", "10.1145/356924.356930", "10.1145/197938.197963", "10.1145/2600212.2600217", "10.1145/1507149.1507152", "10.1145/2503210.2503283", "10.1145/2487228.2487235", "10.1145/147130.147152", "10.1145/582034.582036", "10.1145/356924.356930", "10.1145/197938.197963", "10.1111/cgf.12280", "10.1016/0021-9991(89)90035-1", "10.1088/1367-2630/9/8/301", "10.1002/cpa.3160450502", "10.1017/S0022112004009681", "10.1111/j.1467-8659.2012.03124.x", "10.1103/PhysRevLett.113.155005", "10.1016/j.cag.2003.10.018", "10.1111/1467-8659.00298", "10.1007/978-3-642-32820-6_83", "10.1214/aoms/1177729694", "10.1007/978-3-642-23400-2_34", "10.1111/cgf.13336", "10.1016/j.msea.2017.08.102", "10.1111/1467-8659.00497", "10.1214/aoms/1177730256", "10.1111/cgf.12102", "10.1007/BF00130487", "10.1177/1094342017737147", "10.1111/j.1467-8659.2011.01964.x", "10.1111/cgf.12280", "10.1016/0021-9991(89)90035-1", "10.1088/1367-2630/9/8/301", "10.1002/cpa.3160450502", "10.1017/S0022112004009681", "10.1111/j.1467-8659.2012.03124.x", "10.1103/PhysRevLett.113.155005", "10.1016/j.cag.2003.10.018", "10.1111/1467-8659.00298", "10.1007/978-3-642-32820-6_83", "10.1214/aoms/1177729694", "10.1007/978-3-642-23400-2_34", "10.1111/cgf.13336", "10.1016/j.msea.2017.08.102", "10.1111/1467-8659.00497", "10.1214/aoms/1177730256", "10.1111/cgf.12102", "10.1007/BF00130487", "10.1177/1094342017737147", "10.1111/j.1467-8659.2011.01964.x", "10.1111/cgf.12280", "10.1016/0021-9991(89)90035-1", "10.1088/1367-2630/9/8/301", "10.1002/cpa.3160450502", "10.1017/S0022112004009681", "10.1111/j.1467-8659.2012.03124.x", "10.1103/PhysRevLett.113.155005", "10.1016/j.cag.2003.10.018", "10.1111/1467-8659.00298", "10.1007/978-3-642-32820-6_83", "10.1214/aoms/1177729694", "10.1007/978-3-642-23400-2_34", "10.1111/cgf.13336", "10.1016/j.msea.2017.08.102", "10.1111/1467-8659.00497", "10.1214/aoms/1177730256", "10.1111/cgf.12102", "10.1007/BF00130487", "10.1177/1094342017737147", "10.1111/j.1467-8659.2011.01964.x"]}, "10.1109/TVCG.2018.2864656": {"doi": "10.1109/TVCG.2018.2864656", "author": ["S. Stoppel", "M. P. Erga", "S. Bruckner"], "title": "Firefly: Virtual Illumination Drones for Interactive Visualization", "year": "2019", "abstract": "Light specification in three dimensional scenes is a complex problem and several approaches have been presented that aim to automate this process. However, there are many scenarios where a static light setup is insufficient, as the scene content and camera position may change. Simultaneous manual control over the camera and light position imposes a high cognitive load on the user. To address this challenge, we introduce a novel approach for automatic scene illumination with Fireflies. Fireflies are intelligent virtual light drones that illuminate the scene by traveling on a closed path. The Firefly path automatically adapts to changes in the scene based on an outcome-oriented energy function. To achieve interactive performance, we employ a parallel rendering pipeline for the light path evaluations. We provide a catalog of energy functions for various application scenarios and discuss the applicability of our method on several examples.", "keywords": ["data visualisation", "pipeline processing", "rendering (computer graphics)", "automatic scene illumination", "intelligent virtual light drones", "Firefly path", "outcome-oriented energy function", "light path evaluations", "energy functions", "virtual illumination drones", "interactive visualization", "three dimensional scenes light specification", "parallel rendering pipeline", "Lighting", "Light sources", "Cameras", "Optimization", "Drones", "Geometry", "Task analysis", "Dynamic lighting design", "lighting drones"], "referenced_by": ["10.1016/j.comcom.2019.09.021"], "referencing": ["IKEY:7460033", "IKEY:6634097", "IKEY:1250395", "IKEY:4103345", "IKEY:1372208", "IKEY:1245266", "IKEY:6064956", "IKEY:6175015", "IKEY:7938224", "IKEY:6634193", "IKEY:7460033", "IKEY:6634097", "IKEY:1250395", "IKEY:4103345", "IKEY:1372208", "IKEY:1245266", "IKEY:6064956", "IKEY:6175015", "IKEY:7938224", "IKEY:6634193", "IKEY:7460033", "IKEY:6634097", "IKEY:1250395", "IKEY:4103345", "IKEY:1372208", "IKEY:1245266", "IKEY:6064956", "IKEY:6175015", "IKEY:7938224", "IKEY:6634193", "10.1145/1008653.1008665", "10.1145/2816795.2818106", "10.1145/2630099.2630105", "10.1145/2931002.2931015", "10.1145/1008653.1008665", "10.1145/2816795.2818106", "10.1145/2630099.2630105", "10.1145/2931002.2931015", "10.1145/1008653.1008665", "10.1145/2816795.2818106", "10.1145/2630099.2630105", "10.1145/2931002.2931015", "10.1111/j.1467-8659.2012.03114.x", "10.1007/978-3-7091-6809-7_28", "10.1007/978-3-540-74889-2_48", "10.1016/j.cub.2011.10.036", "10.1007/978-3-540-40014-1_2", "10.1111/cgf.13115", "10.1007/BF00133570", "10.1023/A:1008207113480", "10.1068/p260171", "10.3758/BF03206757", "10.1016/S0010-0277(01)00116-0", "10.1111/j.1365-2929.2006.02611.x", "10.1038/331163a0", "10.1167/16.3.9", "10.1111/1467-8659.00514", "10.1016/j.ress.2015.12.002", "10.1080/00401706.1987.10488205", "10.1371/journal.pone.0054549", "10.1007/978-94-015-7744-1", "10.1080/00949655.2017.1368080", "10.1111/j.1467-8659.2012.03114.x", "10.1007/978-3-7091-6809-7_28", "10.1007/978-3-540-74889-2_48", "10.1016/j.cub.2011.10.036", "10.1007/978-3-540-40014-1_2", "10.1111/cgf.13115", "10.1007/BF00133570", "10.1023/A:1008207113480", "10.1068/p260171", "10.3758/BF03206757", "10.1016/S0010-0277(01)00116-0", "10.1111/j.1365-2929.2006.02611.x", "10.1038/331163a0", "10.1167/16.3.9", "10.1111/1467-8659.00514", "10.1016/j.ress.2015.12.002", "10.1080/00401706.1987.10488205", "10.1371/journal.pone.0054549", "10.1007/978-94-015-7744-1", "10.1080/00949655.2017.1368080", "10.1111/j.1467-8659.2012.03114.x", "10.1007/978-3-7091-6809-7_28", "10.1007/978-3-540-74889-2_48", "10.1016/j.cub.2011.10.036", "10.1007/978-3-540-40014-1_2", "10.1111/cgf.13115", "10.1007/BF00133570", "10.1023/A:1008207113480", "10.1068/p260171", "10.3758/BF03206757", "10.1016/S0010-0277(01)00116-0", "10.1111/j.1365-2929.2006.02611.x", "10.1038/331163a0", "10.1167/16.3.9", "10.1111/1467-8659.00514", "10.1016/j.ress.2015.12.002", "10.1080/00401706.1987.10488205", "10.1371/journal.pone.0054549", "10.1007/978-94-015-7744-1", "10.1080/00949655.2017.1368080"]}, "10.1109/TVCG.2018.2864801": {"doi": "10.1109/TVCG.2018.2864801", "author": ["S. Hazarika", "S. Dutta", "H. Shen", "J. Chen"], "title": "CoDDA: A Flexible Copula-based Distribution Driven Analysis Framework for Large-Scale Multivariate Data", "year": "2019", "abstract": "CoDDA (Copula-based Distribution Driven Analysis) is a flexible framework for large-scale multivariate datasets. A common strategy to deal with large-scale scientific simulation data is to partition the simulation domain and create statistical data summaries. Instead of storing the high-resolution raw data from the simulation, storing the compact statistical data summaries results in reduced storage overhead and alleviated I/O bottleneck. Such summaries, often represented in the form of statistical probability distributions, can serve various post-hoc analysis and visualization tasks. However, for multivariate simulation data using standard multivariate distributions for creating data summaries is not feasible. They are either storage inefficient or are computationally expensive to be estimated in simulation time (in situ) for large number of variables. In this work, using copula functions, we propose a flexible multivariate distribution-based data modeling and analysis framework that offers significant data reduction and can be used in an in situ environment. The framework also facilitates in storing the associated spatial information along with the multivariate distributions in an efficient representation. Using the proposed multivariate data summaries, we perform various multivariate post-hoc analyses like query-driven visualization and sampling-based visualization. We evaluate our proposed method on multiple real-world multivariate scientific datasets. To demonstrate the efficacy of our framework in an in situ environment, we apply it on a large-scale flow simulation.", "keywords": ["data analysis", "data reduction", "data visualisation", "flow simulation", "probability", "statistical analysis", "statistical distributions", "statistical probability distributions", "multivariate simulation data", "standard multivariate distributions", "copula functions", "flexible multivariate distribution-based data modeling", "significant data reduction", "multivariate data summaries", "multivariate post-hoc analyses", "query-driven visualization", "real-world multivariate scientific datasets", "large-scale flow simulation", "CoDDA", "large-scale multivariate data", "flexible framework", "large-scale multivariate datasets", "large-scale scientific simulation data", "simulation domain", "high-resolution raw data", "compact statistical data summaries results", "reduced storage overhead", "flexible copula-based distribution driven analysis framework", "Data models", "Computational modeling", "Data visualization", "Analytical models", "Task analysis", "Histograms", "Probability distribution", "In situ processing", "Distribution-based", "Multivariate", "Query-driven", "Copula"], "referenced_by": ["IKEY:8805445"], "referencing": ["IKEY:7192629", "IKEY:1295321", "IKEY:6787168", "IKEY:7192672", "IKEY:7539561", "IKEY:7192664", "IKEY:8365977", "IKEY:8031585", "IKEY:6092322", "IKEY:7192675", "IKEY:5473228", "IKEY:6747357", "IKEY:8017601", "IKEY:4376165", "IKEY:7347634", "IKEY:1028780", "IKEY:7013204", "IKEY:7348071", "IKEY:1703376", "IKEY:5620906", "IKEY:4015447", "IKEY:6137392", "IKEY:6092313", "IKEY:6092178", "IKEY:8031590", "IKEY:7192723", "IKEY:7874311", "IKEY:7192629", "IKEY:1295321", "IKEY:6787168", "IKEY:7192672", "IKEY:7539561", "IKEY:7192664", "IKEY:8365977", "IKEY:8031585", "IKEY:6092322", "IKEY:7192675", "IKEY:5473228", "IKEY:6747357", "IKEY:8017601", "IKEY:4376165", "IKEY:7347634", "IKEY:1028780", "IKEY:7013204", "IKEY:7348071", "IKEY:1703376", "IKEY:5620906", "IKEY:4015447", "IKEY:6137392", "IKEY:6092313", "IKEY:6092178", "IKEY:8031590", "IKEY:7192723", "IKEY:7874311", "IKEY:7192629", "IKEY:1295321", "IKEY:6787168", "IKEY:7192672", "IKEY:7539561", "IKEY:7192664", "IKEY:8365977", "IKEY:8031585", "IKEY:6092322", "IKEY:7192675", "IKEY:5473228", "IKEY:6747357", "IKEY:8017601", "IKEY:4376165", "IKEY:7347634", "IKEY:1028780", "IKEY:7013204", "IKEY:7348071", "IKEY:1703376", "IKEY:5620906", "IKEY:4015447", "IKEY:6137392", "IKEY:6092313", "IKEY:6092178", "IKEY:8031590", "IKEY:7192723", "IKEY:7874311", "10.1145/2020408.2020509", "10.1145/1390156.1390215", "10.1145/2020408.2020509", "10.1145/1390156.1390215", "10.1145/2020408.2020509", "10.1145/1390156.1390215", "10.1111/cgf.12930", "10.2514/6.2006-418", "10.1115/1.2812968", "10.1080/13504860210136721a", "10.2307/2684359", "10.1016/B978-044450896-6.50010-8", "10.1111/j.1467-8659.2009.01429.x", "10.1007/978-3-540-74494-8_10", "10.1016/j.insmatheco.2006.11.011", "10.1111/j.1467-8659.2012.03096.x", "10.1137/15M1016308", "10.1111/j.1467-8659.2011.01944.x", "10.1111/cgf.12100", "10.1615/Int.J.UncertaintyQuantification.2012003958", "10.1111/j.1467-8659.2009.01677.x", "10.1111/j.1467-8659.2011.01964.x", "10.1111/cgf.12930", "10.2514/6.2006-418", "10.1115/1.2812968", "10.1080/13504860210136721a", "10.2307/2684359", "10.1016/B978-044450896-6.50010-8", "10.1111/j.1467-8659.2009.01429.x", "10.1007/978-3-540-74494-8_10", "10.1016/j.insmatheco.2006.11.011", "10.1111/j.1467-8659.2012.03096.x", "10.1137/15M1016308", "10.1111/j.1467-8659.2011.01944.x", "10.1111/cgf.12100", "10.1615/Int.J.UncertaintyQuantification.2012003958", "10.1111/j.1467-8659.2009.01677.x", "10.1111/j.1467-8659.2011.01964.x", "10.1111/cgf.12930", "10.2514/6.2006-418", "10.1115/1.2812968", "10.1080/13504860210136721a", "10.2307/2684359", "10.1016/B978-044450896-6.50010-8", "10.1111/j.1467-8659.2009.01429.x", "10.1007/978-3-540-74494-8_10", "10.1016/j.insmatheco.2006.11.011", "10.1111/j.1467-8659.2012.03096.x", "10.1137/15M1016308", "10.1111/j.1467-8659.2011.01944.x", "10.1111/cgf.12100", "10.1615/Int.J.UncertaintyQuantification.2012003958", "10.1111/j.1467-8659.2009.01677.x", "10.1111/j.1467-8659.2011.01964.x"]}, "10.1109/TVCG.2018.2864849": {"doi": "10.1109/TVCG.2018.2864849", "author": ["T. Luciani", "A. Burks", "C. Sugiyama", "J. Komperda", "G. E. Marai"], "title": "Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations", "year": "2019", "abstract": "Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: \u201cOverview first, zoom and filter, then details on demand\u201d. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model.", "keywords": ["computational fluid dynamics", "data visualisation", "Internet", "information seeking mantra", "seven-dimensional data points", "online Web-based exploration", "theoretical model", "computational back-end", "model instantiation", "domain experts", "viscous finger evolution", "scientific workflow theory", "information-driven tasks", "CFD", "computational fluid dynamics", "visualization research", "large-scale ensemble simulations", "Computational modeling", "Data visualization", "Feature extraction", "Context modeling", "Tracking", "Visualization", "Spatiotemporal phenomena", "theory", "visualization design", "details-first model", "discourse paper", "computational fluid dynamics"], "referenced_by": [], "referencing": ["IKEY:6112780", "IKEY:5128904", "IKEY:4376176", "IKEY:7368928", "IKEY:1509067", "IKEY:6875990", "IKEY:7192679", "IKEY:7194852", "IKEY:6747370", "IKEY:5290760", "IKEY:1231171", "IKEY:6185547", "IKEY:6065017", "IKEY:6767150", "IKEY:8017610", "IKEY:6634119", "IKEY:6876045", "IKEY:4035742", "IKEY:5290695", "IKEY:7348073", "IKEY:5360497", "IKEY:299407", "IKEY:6327248", "IKEY:1432687", "IKEY:545307", "IKEY:597796", "IKEY:4658174", "IKEY:6378962", "IKEY:7348066", "IKEY:1260740", "IKEY:6112780", "IKEY:5128904", "IKEY:4376176", "IKEY:7368928", "IKEY:1509067", "IKEY:6875990", "IKEY:7192679", "IKEY:7194852", "IKEY:6747370", "IKEY:5290760", "IKEY:1231171", "IKEY:6185547", "IKEY:6065017", "IKEY:6767150", "IKEY:8017610", "IKEY:6634119", "IKEY:6876045", "IKEY:4035742", "IKEY:5290695", "IKEY:7348073", "IKEY:5360497", "IKEY:299407", "IKEY:6327248", "IKEY:1432687", "IKEY:545307", "IKEY:597796", "IKEY:4658174", "IKEY:6378962", "IKEY:7348066", "IKEY:1260740", "IKEY:6112780", "IKEY:5128904", "IKEY:4376176", "IKEY:7368928", "IKEY:1509067", "IKEY:6875990", "IKEY:7192679", "IKEY:7194852", "IKEY:6747370", "IKEY:5290760", "IKEY:1231171", "IKEY:6185547", "IKEY:6065017", "IKEY:6767150", "IKEY:8017610", "IKEY:6634119", "IKEY:6876045", "IKEY:4035742", "IKEY:5290695", "IKEY:7348073", "IKEY:5360497", "IKEY:299407", "IKEY:6327248", "IKEY:1432687", "IKEY:545307", "IKEY:597796", "IKEY:4658174", "IKEY:6378962", "IKEY:7348066", "IKEY:1260740", "10.1145/1124772.1124921", "10.1145/1041613.1041614", "10.1145/800186.810616", "10.1145/1838544.1838551", "10.1145/1124772.1124921", "10.1145/1041613.1041614", "10.1145/800186.810616", "10.1145/1838544.1838551", "10.1145/1124772.1124921", "10.1145/1041613.1041614", "10.1145/800186.810616", "10.1145/1838544.1838551", "10.1016/B978-012387582-2/50038-1", "10.1016/j.cag.2007.01.030", "10.1111/j.1467-8659.2011.01940.x", "10.1016/B978-0-08-051581-6.50024-6", "10.1038/nature09837", "10.1201/9781315369228", "10.1002/(SICI)1097-4571(2000)51:4&lt;380::AID-ASI7&gt;3.0.CO;2-5", "10.1016/j.ijhcs.2011.02.007", "10.4028/www.scientific.net/AMM.869.9", "10.1007/978-3-319-15090-1_16", "10.1111/j.1467-8659.2008.01207.x", "10.1201/b17511", "10.1007/978-3-642-32677-6_15", "10.1088/1742-6596/180/1/012089", "10.1201/9781315281575", "10.1016/B978-012387582-2/50038-1", "10.1016/j.cag.2007.01.030", "10.1111/j.1467-8659.2011.01940.x", "10.1016/B978-0-08-051581-6.50024-6", "10.1038/nature09837", "10.1201/9781315369228", "10.1002/(SICI)1097-4571(2000)51:4&lt;380::AID-ASI7&gt;3.0.CO;2-5", "10.1016/j.ijhcs.2011.02.007", "10.4028/www.scientific.net/AMM.869.9", "10.1007/978-3-319-15090-1_16", "10.1111/j.1467-8659.2008.01207.x", "10.1201/b17511", "10.1007/978-3-642-32677-6_15", "10.1088/1742-6596/180/1/012089", "10.1201/9781315281575", "10.1016/B978-012387582-2/50038-1", "10.1016/j.cag.2007.01.030", "10.1111/j.1467-8659.2011.01940.x", "10.1016/B978-0-08-051581-6.50024-6", "10.1038/nature09837", "10.1201/9781315369228", "10.1002/(SICI)1097-4571(2000)51:4&lt;380::AID-ASI7&gt;3.0.CO;2-5", "10.1016/j.ijhcs.2011.02.007", "10.4028/www.scientific.net/AMM.869.9", "10.1007/978-3-319-15090-1_16", "10.1111/j.1467-8659.2008.01207.x", "10.1201/b17511", "10.1007/978-3-642-32677-6_15", "10.1088/1742-6596/180/1/012089", "10.1201/9781315281575"]}, "10.1109/TVCG.2018.2864808": {"doi": "10.1109/TVCG.2018.2864808", "author": ["J. Tao", "M. Imre", "C. Wang", "N. V. Chawla", "H. Guo", "G. Sever", "S. H. Kim"], "title": "Exploring Time-Varying Multivariate Volume Data Using Matrix of Isosurface Similarity Maps", "year": "2019", "abstract": "We present a novel visual representation and interface named the matrix of isosurface similarity maps (MISM) for effective exploration of large time-varying multivariate volumetric data sets. MISM synthesizes three types of similarity maps (i.e., self, temporal, and variable similarity maps) to capture the essential relationships among isosurfaces of different variables and time steps. Additionally, it serves as the main visual mapping and navigation tool for examining the vast number of isosurfaces and exploring the underlying time-varying multivariate data set. We present temporal clustering, variable grouping, and interactive filtering to reduce the huge exploration space of MISM. In conjunction with the isovalue and isosurface views, MISM allows users to identify important isosurfaces or isosurface pairs and compare them over space, time, and value range. More importantly, we introduce path recommendation that suggests, animates, and compares traversal paths for effectively exploring MISM under varied criteria and at different levels-of-detail. A silhouette-based method is applied to render multiple surfaces of interest in a visually succinct manner. We demonstrate the effectiveness of our approach with case studies of several time-varying multivariate data sets and an ensemble data set, and evaluate our work with two domain experts.", "keywords": ["data visualisation", "image filtering", "image representation", "pattern clustering", "isovalue", "isosurface views", "isosurface pairs", "time-varying multivariate volumetric data sets", "variable similarity maps", "variable grouping", "visual representation", "visual mapping", "time-varying multivariate volume data", "matrix of isosurface similarity maps", "MISM", "temporal similarity maps", "self similarity maps", "temporal clustering", "interactive filtering", "silhouette-based method", "Isosurfaces", "Visualization", "Rendering (computer graphics)", "Tools", "Space exploration", "Data mining", "Time-varying multivariate data visualization", "isosurface", "similarity map", "visual interface", "path recommendation"], "referenced_by": ["IKEY:8802285", "IKEY:8969969"], "referencing": ["IKEY:5232780", "IKEY:5887327", "IKEY:6634187", "IKEY:7465271", "IKEY:6327206", "IKEY:4658164", "IKEY:6064965", "IKEY:6596138", "IKEY:6171180", "IKEY:6064960", "IKEY:8031592", "IKEY:4658163", "IKEY:6185547", "IKEY:5290734", "IKEY:7192697", "IKEY:4475470", "IKEY:5401158", "IKEY:4015447", "IKEY:6634107", "IKEY:4658165", "IKEY:809910", "IKEY:1333660", "IKEY:5742378", "IKEY:4658174", "IKEY:4015446", "IKEY:1250402", "IKEY:5232780", "IKEY:5887327", "IKEY:6634187", "IKEY:7465271", "IKEY:6327206", "IKEY:4658164", "IKEY:6064965", "IKEY:6596138", "IKEY:6171180", "IKEY:6064960", "IKEY:8031592", "IKEY:4658163", "IKEY:6185547", "IKEY:5290734", "IKEY:7192697", "IKEY:4475470", "IKEY:5401158", "IKEY:4015447", "IKEY:6634107", "IKEY:4658165", "IKEY:809910", "IKEY:1333660", "IKEY:5742378", "IKEY:4658174", "IKEY:4015446", "IKEY:1250402", "IKEY:5232780", "IKEY:5887327", "IKEY:6634187", "IKEY:7465271", "IKEY:6327206", "IKEY:4658164", "IKEY:6064965", "IKEY:6596138", "IKEY:6171180", "IKEY:6064960", "IKEY:8031592", "IKEY:4658163", "IKEY:6185547", "IKEY:5290734", "IKEY:7192697", "IKEY:4475470", "IKEY:5401158", "IKEY:4015447", "IKEY:6634107", "IKEY:4658165", "IKEY:809910", "IKEY:1333660", "IKEY:5742378", "IKEY:4658174", "IKEY:4015446", "IKEY:1250402", "10.1145/237170.237216", "10.1145/37401.37422", "10.1145/237170.237216", "10.1145/37401.37422", "10.1145/237170.237216", "10.1145/37401.37422", "10.1111/j.1467-8659.2009.01689.x", "10.1175/1520-0493(2002)130&lt;2917:ABSFMN&gt;2.0.CO;2", "10.1126/science.1136800", "10.1177/1473871611416549", "10.1007/978-3-7091-6756-4_4", "10.1016/j.physleta.2006.08.058", "10.1111/cgf.12800", "10.1111/j.1467-8659.2010.01725.x", "10.1111/j.1467-8659.2009.01689.x", "10.1175/1520-0493(2002)130&lt;2917:ABSFMN&gt;2.0.CO;2", "10.1126/science.1136800", "10.1177/1473871611416549", "10.1007/978-3-7091-6756-4_4", "10.1016/j.physleta.2006.08.058", "10.1111/cgf.12800", "10.1111/j.1467-8659.2010.01725.x", "10.1111/j.1467-8659.2009.01689.x", "10.1175/1520-0493(2002)130&lt;2917:ABSFMN&gt;2.0.CO;2", "10.1126/science.1136800", "10.1177/1473871611416549", "10.1007/978-3-7091-6756-4_4", "10.1016/j.physleta.2006.08.058", "10.1111/cgf.12800", "10.1111/j.1467-8659.2010.01725.x"]}, "10.1109/TVCG.2018.2864817": {"doi": "10.1109/TVCG.2018.2864817", "author": ["M. Berenjkoub", "R. O. Monico", "R. S. Laramee", "G. Chen"], "title": "Visual Analysis of Spatia-temporal Relations of Pairwise Attributes in Unsteady Flow", "year": "2019", "abstract": "Despite significant advances in the analysis and visualization of unsteady flow, the interpretation of it's behavior still remains a challenge. In this work, we focus on the linear correlation and non-linear dependency of different physical attributes of unsteady flows to aid their study from a new perspective. Specifically, we extend the existing spatial correlation quantification, i.e. the Local Correlation Coefficient (LCC), to the spatio-temporal domain to study the correlation of attribute-pairs from both the Eulerian and Lagrangian views. To study the dependency among attributes, which need not be linear, we extend and compute the mutual information (MI) among attributes over time. To help visualize and interpret the derived correlation and dependency among attributes associated with a particle, we encode the correlation and dependency values on individual pathlines. Finally, to utilize the correlation and MI computation results to identify regions with interesting flow behavior, we propose a segmentation strategy of the flow domain based on the ranking of the strength of the attributes relations. We have applied our correlation and dependency metrics to a number of 2D and 3D unsteady flows with varying spatio-temporal kernel sizes to demonstrate and assess their effectiveness.", "keywords": ["data visualisation", "edge detection", "flow instability", "flow simulation", "image segmentation", "spatiotemporal phenomena", "statistical analysis", "visual analysis", "spatia-temporal relations", "pairwise attributes", "linear correlation", "nonlinear dependency", "spatio-temporal kernel", "unsteady flow visualization", "local correlation coefficient", "flow behavior", "LCC", "Eulerian views", "Lagrangian views", "mutual information", "MI computation", "spatial correlation quantification", "segmentation strategy", "Correlation", "Visualization", "Mutual information", "Measurement", "Data visualization", "Oceans", "Acceleration", "Unsteady flow", "correlation study", "mutual information"], "referenced_by": ["IKEY:8933578", "IKEY:9086231", "10.1111/cgf.13731", "10.1111/cgf.14093"], "referencing": ["IKEY:4607313", "IKEY:4015447", "IKEY:5613460", "IKEY:1372213", "IKEY:4459320", "IKEY:5613462", "IKEY:6774477", "IKEY:7192689", "IKEY:7864476", "IKEY:6183581", "IKEY:6881685", "IKEY:5742369", "IKEY:7552532", "IKEY:5613461", "IKEY:6634187", "IKEY:8031590", "IKEY:546101", "IKEY:6064972", "IKEY:6787136", "IKEY:4607313", "IKEY:4015447", "IKEY:5613460", "IKEY:1372213", "IKEY:4459320", "IKEY:5613462", "IKEY:6774477", "IKEY:7192689", "IKEY:7864476", "IKEY:6183581", "IKEY:6881685", "IKEY:5742369", "IKEY:7552532", "IKEY:5613461", "IKEY:6634187", "IKEY:8031590", "IKEY:546101", "IKEY:6064972", "IKEY:6787136", "IKEY:4607313", "IKEY:4015447", "IKEY:5613460", "IKEY:1372213", "IKEY:4459320", "IKEY:5613462", "IKEY:6774477", "IKEY:7192689", "IKEY:7864476", "IKEY:6183581", "IKEY:6881685", "IKEY:5742369", "IKEY:7552532", "IKEY:5613461", "IKEY:6634187", "IKEY:8031590", "IKEY:546101", "IKEY:6064972", "IKEY:6787136", "10.1145/3139295.3139298", "10.1145/584091.584093", "10.1145/3139295.3139298", "10.1145/584091.584093", "10.1145/3139295.3139298", "10.1145/584091.584093", "10.1063/1.1403336", "10.1007/978-3-540-88606-8_6", "10.1007/978-3-642-23175-9_11", "10.1111/cgf.12358", "10.1111/j.1467-8659.2009.01686.x", "10.1017/S0022112095000462", "10.1111/j.1467-8659.2011.01901.x", "10.1111/j.1467-8659.2003.00723.x", "10.1007/978-3-7091-6215-6_13", "10.1016/S0097-8493(02)00056-0", "10.1063/1.2740025", "10.1016/j.physd.2005.10.007", "10.1111/j.1467-8659.2008.01236.x", "10.1111/j.1467-8659.2009.01686.x", "10.1016/B978-012387582-2/50016-2", "10.1016/S0997-7546(99)80026-0", "10.1017/S0022112004002526", "10.1111/cgf.12335", "10.1201/9781315369228", "10.1214/ss/1177012580", "10.1201/9781315140919", "10.1146/annurev.fluid.28.1.477", "10.1016/j.physd.2005.10.007", "10.1016/j.combustflame.2005.09.017", "10.1017/S0022112093002903", "10.1017/S002211200999351X", "10.1063/1.3532039", "10.1063/1.1403336", "10.1007/978-3-540-88606-8_6", "10.1007/978-3-642-23175-9_11", "10.1111/cgf.12358", "10.1111/j.1467-8659.2009.01686.x", "10.1017/S0022112095000462", "10.1111/j.1467-8659.2011.01901.x", "10.1111/j.1467-8659.2003.00723.x", "10.1007/978-3-7091-6215-6_13", "10.1016/S0097-8493(02)00056-0", "10.1063/1.2740025", "10.1016/j.physd.2005.10.007", "10.1111/j.1467-8659.2008.01236.x", "10.1111/j.1467-8659.2009.01686.x", "10.1016/B978-012387582-2/50016-2", "10.1016/S0997-7546(99)80026-0", "10.1017/S0022112004002526", "10.1111/cgf.12335", "10.1201/9781315369228", "10.1214/ss/1177012580", "10.1201/9781315140919", "10.1146/annurev.fluid.28.1.477", "10.1016/j.physd.2005.10.007", "10.1016/j.combustflame.2005.09.017", "10.1017/S0022112093002903", "10.1017/S002211200999351X", "10.1063/1.3532039", "10.1063/1.1403336", "10.1007/978-3-540-88606-8_6", "10.1007/978-3-642-23175-9_11", "10.1111/cgf.12358", "10.1111/j.1467-8659.2009.01686.x", "10.1017/S0022112095000462", "10.1111/j.1467-8659.2011.01901.x", "10.1111/j.1467-8659.2003.00723.x", "10.1007/978-3-7091-6215-6_13", "10.1016/S0097-8493(02)00056-0", "10.1063/1.2740025", "10.1016/j.physd.2005.10.007", "10.1111/j.1467-8659.2008.01236.x", "10.1111/j.1467-8659.2009.01686.x", "10.1016/B978-012387582-2/50016-2", "10.1016/S0997-7546(99)80026-0", "10.1017/S0022112004002526", "10.1111/cgf.12335", "10.1201/9781315369228", "10.1214/ss/1177012580", "10.1201/9781315140919", "10.1146/annurev.fluid.28.1.477", "10.1016/j.physd.2005.10.007", "10.1016/j.combustflame.2005.09.017", "10.1017/S0022112093002903", "10.1017/S002211200999351X", "10.1063/1.3532039"]}, "10.1109/TVCG.2018.2864839": {"doi": "10.1109/TVCG.2018.2864839", "author": ["M. Hadwiger", "M. Mlejnek", "T. Theu\u00dfl", "P. Rautek"], "title": "Time-Dependent Flow seen through Approximate Observer Killing Fields", "year": "2019", "abstract": "Flow fields are usually visualized relative to a global observer, i.e., a single frame of reference. However, often no global frame can depict all flow features equally well. Likewise, objective criteria for detecting features such as vortices often use either a global reference frame, or compute a separate frame for each point in space and time. We propose the first general framework that enables choosing a smooth trade-off between these two extremes. Using global optimization to minimize specific differential geometric properties, we compute a time-dependent observer velocity field that describes the motion of a continuous field of observers adapted to the input flow. This requires developing the novel notion of an observed time derivative. While individual observers are restricted to rigid motions, overall we compute an approximate Killing field, corresponding to almost-rigid motion. This enables continuous transitions between different observers. Instead of focusing only on flow features, we furthermore develop a novel general notion of visualizing how all observers jointly perceive the input field. This in fact requires introducing the concept of an observation time, with respect to which a visualization is computed. We develop the corresponding notions of observed stream, path, streak, and time lines. For efficiency, these characteristic curves can be computed using standard approaches, by first transforming the input field accordingly. Finally, we prove that the input flow perceived by the observer field is objective. This makes derived flow features, such as vortices, objective as well.", "keywords": ["computational fluid dynamics", "vortices", "differential geometric properties", "Killing field", "continuous field", "time-dependent observer velocity field", "global optimization", "global reference frame", "global observer", "time-dependent flow", "Observers", "Visualization", "Optimization", "Standards", "Geometry", "Feature extraction", "Two dimensional displays", "Flow visualization", "observer frames of reference", "Killing vector fields", "infinitesimal isometries", "Lie derivatives", "objectivity"], "referenced_by": ["IKEY:8805446", "IKEY:9020213"], "referencing": ["IKEY:6365629", "IKEY:6774477", "IKEY:7465253", "IKEY:6610171", "IKEY:7192689", "IKEY:1021575", "IKEY:809896", "IKEY:4658155", "IKEY:4376212", "IKEY:5613462", "IKEY:4376209", "IKEY:6365629", "IKEY:6774477", "IKEY:7465253", "IKEY:6610171", "IKEY:7192689", "IKEY:1021575", "IKEY:809896", "IKEY:4658155", "IKEY:4376212", "IKEY:5613462", "IKEY:4376209", "IKEY:6365629", "IKEY:6774477", "IKEY:7465253", "IKEY:6610171", "IKEY:7192689", "IKEY:1021575", "IKEY:809896", "IKEY:4658155", "IKEY:4376212", "IKEY:5613462", "IKEY:4376209", "10.1145/344779.344859", "10.1145/2723158", "10.1145/166117.166151", "10.1145/1073204.1073323", "10.1145/1276377.1276457", "10.1145/566654.566646", "10.1145/344779.344859", "10.1145/2723158", "10.1145/166117.166151", "10.1145/1073204.1073323", "10.1145/1276377.1276457", "10.1145/566654.566646", "10.1145/344779.344859", "10.1145/2723158", "10.1145/166117.166151", "10.1145/1073204.1073323", "10.1145/1276377.1276457", "10.1145/566654.566646", "10.1007/978-1-4757-2063-1", "10.1111/cgf.12174", "10.1017/CBO9780511800955", "10.1111/j.1467-8659.2010.01779.x", "10.1111/cgf.12358", "10.1111/cgf.12427", "10.1007/978-1-4757-2201-7", "10.1017/CBO9781139061377", "10.1111/cgf.13319", "10.1017/S0022112004002526", "10.1017/jfm.2016.151", "10.1017/S0022112095000462", "10.1007/978-1-4419-9982-5", "10.1007/978-3-642-67220-0_32", "10.1007/978-1-4614-7732-7", "10.1007/978-3-319-26654-1", "10.1111/j.1467-8659.2011.02028.x", "10.2514/6.1995-1715", "10.1111/j.1467-8659.2012.03063.x", "10.1007/978-1-4757-2063-1", "10.1111/cgf.12174", "10.1017/CBO9780511800955", "10.1111/j.1467-8659.2010.01779.x", "10.1111/cgf.12358", "10.1111/cgf.12427", "10.1007/978-1-4757-2201-7", "10.1017/CBO9781139061377", "10.1111/cgf.13319", "10.1017/S0022112004002526", "10.1017/jfm.2016.151", "10.1017/S0022112095000462", "10.1007/978-1-4419-9982-5", "10.1007/978-3-642-67220-0_32", "10.1007/978-1-4614-7732-7", "10.1007/978-3-319-26654-1", "10.1111/j.1467-8659.2011.02028.x", "10.2514/6.1995-1715", "10.1111/j.1467-8659.2012.03063.x", "10.1007/978-1-4757-2063-1", "10.1111/cgf.12174", "10.1017/CBO9780511800955", "10.1111/j.1467-8659.2010.01779.x", "10.1111/cgf.12358", "10.1111/cgf.12427", "10.1007/978-1-4757-2201-7", "10.1017/CBO9781139061377", "10.1111/cgf.13319", "10.1017/S0022112004002526", "10.1017/jfm.2016.151", "10.1017/S0022112095000462", "10.1007/978-1-4419-9982-5", "10.1007/978-3-642-67220-0_32", "10.1007/978-1-4614-7732-7", "10.1007/978-3-319-26654-1", "10.1111/j.1467-8659.2011.02028.x", "10.2514/6.1995-1715", "10.1111/j.1467-8659.2012.03063.x"]}}