{"10.1109/TVCG.2018.2850079": {"doi": "10.1109/TVCG.2018.2850079", "author": ["L. De Floriani"], "title": "Editor's Note", "year": "2018", "abstract": "Presents the introductory editorial for this issue of the publication.", "keywords": [""], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2753255": {"doi": "10.1109/TVCG.2017.2753255", "author": ["J. Zhu", "Y. Guo", "H. Ma"], "title": "A Data-Driven Approach for Furniture and Indoor Scene Colorization", "year": "2018", "abstract": "We present a data-driven approach that colorizes 3D furniture models and indoor scenes by leveraging indoor images on the internet. Our approach is able to colorize the furniture automatically according to an example image. The core is to learn image-guided mesh segmentation to segment the model into different parts according to the image object. Given an indoor scene, the system supports colorization-by-example, and has the ability to recommend the colorization scheme that is consistent with a user-desired color theme. The latter is realized by formulating the problem as a Markov random field model that imposes user input as an additional constraint. Our system is able to imitate the colorization results for those scenes containing the same type of objects, but with spatially varied patterns. We contribute to the community a hierarchically organized image-model database with correspondences between each image and the corresponding model at the part-level. Our experiments and a user study show that our system produces perceptually convincing results comparable to those generated by interior designers.", "keywords": ["computer graphics", "furniture", "image colour analysis", "image segmentation", "Markov processes", "mesh generation", "visual databases", "example image", "image-guided mesh segmentation", "image object", "colorization-by-example", "colorization scheme", "user-desired color theme", "Markov random field model", "colorization results", "hierarchically organized image-model database", "data-driven approach", "furniture", "indoor scene colorization", "indoor images", "interior designers", "Image color analysis", "Three-dimensional displays", "Image segmentation", "Solid modeling", "Databases", "Layout", "Computational modeling", "Colorization", "interior design", "data-driven approach", "mesh segmentation"], "referenced_by": ["IKEY:8804204", "IKEY:8676327"], "referencing": ["IKEY:993558", "IKEY:765655", "IKEY:4135679", "IKEY:993558", "IKEY:765655", "IKEY:4135679", "IKEY:993558", "IKEY:765655", "IKEY:4135679", "10.1145/2010324.1964981", "10.1145/2010324.1964982", "10.1145/2366145.2366154", "10.1145/2461912.2462002", "10.1145/566654.566576", "10.1145/1015706.1015780", "10.1145/1141911.1142017", "10.1145/987657.987677", "10.1145/2461912.2461988", "10.1145/1073204.1073241", "10.1145/1141911.1141933", "10.1145/2366145.2366162", "10.1145/2816795.2818096", "10.1145/2980179.2982404", "10.1145/2366145.2366156", "10.1145/2366145.2366157", "10.1145/2366145.2366155", "10.1145/2661229.2661239", "10.1145/1364901.1364927", "10.1145/1778765.1778839", "10.1145/383259.383282", "10.1145/1882261.1866172", "10.1145/2010324.1964958", "10.1145/1531326.1531379", "10.1145/2682628", "10.1145/2010324.1964981", "10.1145/2010324.1964982", "10.1145/2366145.2366154", "10.1145/2461912.2462002", "10.1145/566654.566576", "10.1145/1015706.1015780", "10.1145/1141911.1142017", "10.1145/987657.987677", "10.1145/2461912.2461988", "10.1145/1073204.1073241", "10.1145/1141911.1141933", "10.1145/2366145.2366162", "10.1145/2816795.2818096", "10.1145/2980179.2982404", "10.1145/2366145.2366156", "10.1145/2366145.2366157", "10.1145/2366145.2366155", "10.1145/2661229.2661239", "10.1145/1364901.1364927", "10.1145/1778765.1778839", "10.1145/383259.383282", "10.1145/1882261.1866172", "10.1145/2010324.1964958", "10.1145/1531326.1531379", "10.1145/2682628", "10.1145/2010324.1964981", "10.1145/2010324.1964982", "10.1145/2366145.2366154", "10.1145/2461912.2462002", "10.1145/566654.566576", "10.1145/1015706.1015780", "10.1145/1141911.1142017", "10.1145/987657.987677", "10.1145/2461912.2461988", "10.1145/1073204.1073241", "10.1145/1141911.1141933", "10.1145/2366145.2366162", "10.1145/2816795.2818096", "10.1145/2980179.2982404", "10.1145/2366145.2366156", "10.1145/2366145.2366157", "10.1145/2366145.2366155", "10.1145/2661229.2661239", "10.1145/1364901.1364927", "10.1145/1778765.1778839", "10.1145/383259.383282", "10.1145/1882261.1866172", "10.1145/2010324.1964958", "10.1145/1531326.1531379", "10.1145/2682628", "10.1111/j.1467-8659.2005.00867.x", "10.1111/cgf.12498", "10.1111/j.1467-8659.2012.03021.x", "10.1111/j.1467-8659.2012.03022.x", "10.1023/B:VISI.0000022288.19776.77", "10.1007/s00371-007-0197-5", "10.1111/j.1467-8659.2007.01103.x", "10.1093/biomet/57.1.97", "10.1111/j.1467-8659.2005.00867.x", "10.1111/cgf.12498", "10.1111/j.1467-8659.2012.03021.x", "10.1111/j.1467-8659.2012.03022.x", "10.1023/B:VISI.0000022288.19776.77", "10.1007/s00371-007-0197-5", "10.1111/j.1467-8659.2007.01103.x", "10.1093/biomet/57.1.97", "10.1111/j.1467-8659.2005.00867.x", "10.1111/cgf.12498", "10.1111/j.1467-8659.2012.03021.x", "10.1111/j.1467-8659.2012.03022.x", "10.1023/B:VISI.0000022288.19776.77", "10.1007/s00371-007-0197-5", "10.1111/j.1467-8659.2007.01103.x", "10.1093/biomet/57.1.97"]}, "10.1109/TVCG.2017.2750689": {"doi": "10.1109/TVCG.2017.2750689", "author": ["Y. Wang", "D. Archambault", "C. E. Scheidegger", "H. Qu"], "title": "A Vector Field Design Approach to Animated Transitions", "year": "2018", "abstract": "Animated transitions can be effective in explaining and exploring a small number of visualizations where there are drastic changes in the scene over a short interval of time. This is especially true if data elements cannot be visually distinguished by other means. Current research in animated transitions has mainly focused on linear transitions (all elements follow straight line paths) or enhancing coordinated motion through bundling of linear trajectories. In this paper, we introduce animated transition design, a technique to build smooth, non-linear transitions for clustered data with either minimal or no user involvement. The technique is flexible and simple to implement, and has the additional advantage that it explicitly enhances coordinated motion and can avoid crowding, which are both important factors to support object tracking in a scene. We investigate its usability, provide preliminary evidence for the effectiveness of this technique through metric evaluations and user study and discuss limitations and future directions.", "keywords": ["computer animation", "data visualisation", "object tracking", "pattern clustering", "vectors", "nonlinear transitions", "coordinated motion", "vector field design approach", "data elements", "linear transitions", "linear trajectories", "visualizations", "animated transition design", "clustered data", "object tracking", "Animation", "Trajectory", "Data visualization", "Object tracking", "Target tracking", "Usability", "Information visualization", "animated transitions", "vector field design"], "referenced_by": ["IKEY:8846208", "IKEY:8848845"], "referencing": ["IKEY:4376146", "IKEY:6876010", "IKEY:4658123", "IKEY:4293020", "IKEY:1634320", "IKEY:6112753", "IKEY:6051431", "IKEY:7192693", "IKEY:4376146", "IKEY:6876010", "IKEY:4658123", "IKEY:4293020", "IKEY:1634320", "IKEY:6112753", "IKEY:6051431", "IKEY:7192693", "IKEY:4376146", "IKEY:6876010", "IKEY:4658123", "IKEY:4293020", "IKEY:1634320", "IKEY:6112753", "IKEY:6051431", "IKEY:7192693", "10.1145/1978942.1979233", "10.1145/2702123.2702476", "10.1145/37401.37407", "10.1145/1183287.1183290", "10.1145/1166253.1166280", "10.1145/944020.944025", "10.1145/364338.364400", "10.1145/1476793.1476838", "10.1145/1357054.1357122", "10.1145/2556288.2556987", "10.1145/2818143.2818167", "10.1145/1276377.1276447", "10.1145/1978942.1979233", "10.1145/2702123.2702476", "10.1145/37401.37407", "10.1145/1183287.1183290", "10.1145/1166253.1166280", "10.1145/944020.944025", "10.1145/364338.364400", "10.1145/1476793.1476838", "10.1145/1357054.1357122", "10.1145/2556288.2556987", "10.1145/2818143.2818167", "10.1145/1276377.1276447", "10.1145/1978942.1979233", "10.1145/2702123.2702476", "10.1145/37401.37407", "10.1145/1183287.1183290", "10.1145/1166253.1166280", "10.1145/944020.944025", "10.1145/364338.364400", "10.1145/1476793.1476838", "10.1145/1357054.1357122", "10.1145/2556288.2556987", "10.1145/2818143.2818167", "10.1145/1276377.1276447", "10.1111/cgf.12804", "10.1016/j.ins.2015.04.017", "10.1006/ijhc.2002.1017", "10.1016/0010-0285(92)90010-Y", "10.3758/PBR.15.4.802", "10.3758/s13414-011-0265-9", "10.3758/BF03198373", "10.1163/156856888X00122", "10.1111/1467-8659.00710", "10.1002/acp.1345", "10.3758/s13414-012-0369-x", "10.1037/0096-1523.31.2.235", "10.3758/BF03193740", "10.1080/13506280544000200", "10.1167/7.13.14", "10.1177/0956797610373935", "10.3758/PBR.15.2.390", "10.1006/cogp.1998.0698", "10.1111/cgf.12107", "10.1111/j.1469-1809.1936.tb02137.x", "10.1007/BF02344684", "10.1111/cgf.12804", "10.1016/j.ins.2015.04.017", "10.1006/ijhc.2002.1017", "10.1016/0010-0285(92)90010-Y", "10.3758/PBR.15.4.802", "10.3758/s13414-011-0265-9", "10.3758/BF03198373", "10.1163/156856888X00122", "10.1111/1467-8659.00710", "10.1002/acp.1345", "10.3758/s13414-012-0369-x", "10.1037/0096-1523.31.2.235", "10.3758/BF03193740", "10.1080/13506280544000200", "10.1167/7.13.14", "10.1177/0956797610373935", "10.3758/PBR.15.2.390", "10.1006/cogp.1998.0698", "10.1111/cgf.12107", "10.1111/j.1469-1809.1936.tb02137.x", "10.1007/BF02344684", "10.1111/cgf.12804", "10.1016/j.ins.2015.04.017", "10.1006/ijhc.2002.1017", "10.1016/0010-0285(92)90010-Y", "10.3758/PBR.15.4.802", "10.3758/s13414-011-0265-9", "10.3758/BF03198373", "10.1163/156856888X00122", "10.1111/1467-8659.00710", "10.1002/acp.1345", "10.3758/s13414-012-0369-x", "10.1037/0096-1523.31.2.235", "10.3758/BF03193740", "10.1080/13506280544000200", "10.1167/7.13.14", "10.1177/0956797610373935", "10.3758/PBR.15.2.390", "10.1006/cogp.1998.0698", "10.1111/cgf.12107", "10.1111/j.1469-1809.1936.tb02137.x", "10.1007/BF02344684"]}, "10.1109/TVCG.2017.2752166": {"doi": "10.1109/TVCG.2017.2752166", "author": ["Y. Lu", "H. Wang", "S. Landis", "R. Maciejewski"], "title": "A Visual Analytics Framework for Identifying Topic Drivers in Media Events", "year": "2018", "abstract": "Media data has been the subject of large scale analysis with applications of text mining being used to provide overviews of media themes and information flows. Such information extracted from media articles has also shown its contextual value of being integrated with other data, such as criminal records and stock market pricing. In this work, we explore linking textual media data with curated secondary textual data sources through user-guided semantic lexical matching for identifying relationships and data links. In this manner, critical information can be identified and used to annotate media timelines in order to provide a more detailed overview of events that may be driving media topics and frames. These linked events are further analyzed through an application of causality modeling to model temporal drivers between the data series. Such causal links are then annotated through automatic entity extraction which enables the analyst to explore persons, locations, and organizations that may be pertinent to the media topic of interest. To demonstrate the proposed framework, two media datasets and an armed conflict event dataset are explored.", "keywords": ["data analysis", "data mining", "data visualisation", "text analysis", "visual analytics framework", "text mining", "information flows", "textual media data", "curated secondary textual data sources", "user-guided semantic lexical matching", "causal links", "automatic entity extraction", "media datasets", "armed conflict event dataset", "media events topic drivers identification", "media timeline annotation", "data series temporal drivers", "Media", "Semantics", "Social network services", "Visual analytics", "Tools", "Time series analysis", "Semantic similarity", "media annotation", "visual analytics", "causality modeling", "social media"], "referenced_by": ["IKEY:8367769", "IKEY:8440116", "IKEY:8805463", "IKEY:8986917"], "referencing": ["10.1145/1645953.1646023", "10.1145/2470654.2481374", "10.1145/2305484.2305511", "10.1145/1124772.1124794", "10.1145/1385569.1385582", "10.1145/2556288.2557228", "10.1145/1459352.1459355", "10.1145/219717.219748", "10.1145/2207676.2207741", "10.1145/2254556.2254660", "10.1145/1645953.1646023", "10.1145/2470654.2481374", "10.1145/2305484.2305511", "10.1145/1124772.1124794", "10.1145/1385569.1385582", "10.1145/2556288.2557228", "10.1145/1459352.1459355", "10.1145/219717.219748", "10.1145/2207676.2207741", "10.1145/2254556.2254660", "10.1145/1645953.1646023", "10.1145/2470654.2481374", "10.1145/2305484.2305511", "10.1145/1124772.1124794", "10.1145/1385569.1385582", "10.1145/2556288.2557228", "10.1145/1459352.1459355", "10.1145/219717.219748", "10.1145/2207676.2207741", "10.1145/2254556.2254660", "10.1111/j.1467-8659.2012.03108.x", "10.1177/1473871615576925", "10.1016/j.cag.2013.11.003", "10.1016/j.ipm.2015.02.003", "10.1177/1473871611413180", "10.1007/978-3-540-71496-5_5", "10.3115/981732.981751", "10.3115/v1/P14-5010", "10.1371/journal.pone.0050474", "10.4135/9781412983600", "10.2307/1912791", "10.1175/BAMS-ExplainingExtremeEvents2015.1", "10.1515/peps-2016-0034", "10.1111/j.1467-8659.2012.03108.x", "10.1177/1473871615576925", "10.1016/j.cag.2013.11.003", "10.1016/j.ipm.2015.02.003", "10.1177/1473871611413180", "10.1007/978-3-540-71496-5_5", "10.3115/981732.981751", "10.3115/v1/P14-5010", "10.1371/journal.pone.0050474", "10.4135/9781412983600", "10.2307/1912791", "10.1175/BAMS-ExplainingExtremeEvents2015.1", "10.1515/peps-2016-0034", "10.1111/j.1467-8659.2012.03108.x", "10.1177/1473871615576925", "10.1016/j.cag.2013.11.003", "10.1016/j.ipm.2015.02.003", "10.1177/1473871611413180", "10.1007/978-3-540-71496-5_5", "10.3115/981732.981751", "10.3115/v1/P14-5010", "10.1371/journal.pone.0050474", "10.4135/9781412983600", "10.2307/1912791", "10.1175/BAMS-ExplainingExtremeEvents2015.1", "10.1515/peps-2016-0034"]}, "10.1109/TVCG.2017.2761820": {"doi": "10.1109/TVCG.2017.2761820", "author": ["H. Huang", "N. Lin", "L. Barrett", "D. Springer", "H. Wang", "M. Pomplun", "L. Yu"], "title": "Automatic Optimization of Wayfinding Design", "year": "2018", "abstract": "Wayfinding signs play an important role in guiding users to navigate in a virtual environment and in helping pedestrians to find their ways in a real-world architectural site. Conventionally, the wayfinding design of a virtual environment is created manually, so as the wayfinding design of a real-world architectural site. The many possible navigation scenarios, as well as the interplay between signs and human navigation, can make the manual design process overwhelming and non-trivial. As a result, creating a wayfinding design for a typical layout can take months to several years. In this paper, we introduce the Way to Go! approach for automatically generating a wayfinding design for a given layout. The designer simply has to specify some navigation scenarios; our approach will automatically generate an optimized wayfinding design with signs properly placed considering human agents' visibility and possibility of making mistakes during a navigation. We demonstrate the effectiveness of our approach in generating wayfinding designs for different layouts such as a train station, a downtown and a canyon. We evaluate our results by comparing different wayfinding designs and show that our optimized wayfinding design can guide pedestrians to their destinations effectively and efficiently. Our approach can also help the designer visualize the accessibility of a destination from different locations, and correct any \u201cblind zone\u201d with additional signs.", "keywords": ["design", "mobile computing", "optimisation", "pedestrians", "traffic engineering computing", "virtual reality", "wayfinding signs", "real-world architectural site", "optimized wayfinding design", "virtual environment", "user navigation", "Way to Go!", "human agent visibility", "pedestrian guidance", "automatic optimization", "mobile navigation system", "Navigation", "Virtual environments", "Visualization", "Layout", "Games", "Optimization", "Roads", "Wayfinding", "navigation", "procedural modeling", "level design", "spatial orientation"], "referenced_by": ["IKEY:8260971"], "referencing": []}, "10.1109/TVCG.2017.2754480": {"doi": "10.1109/TVCG.2017.2754480", "author": ["H. Liao", "Y. Wu", "L. Chen", "W. Chen"], "title": "Cluster-Based Visual Abstraction for Multivariate Scatterplots", "year": "2018", "abstract": "The use of scatterplots is an important method for multivariate data visualization. The point distribution on the scatterplot, along with variable values represented by each point, can help analyze underlying patterns in data. However, determining the multivariate data variation on a scatterplot generated using projection methods, such as multidimensional scaling, is difficult. Furthermore, the point distribution becomes unclear when the data scale is large and clutter problems occur. These conditions can significantly decrease the usability of scatterplots on multivariate data analysis. In this study, we present a cluster-based visual abstraction method to enhance the visualization of multivariate scatterplots. Our method leverages an adapted multilabel clustering method to provide abstractions of high quality for scatterplots. An image-based method is used to deal with large scale data problem. Furthermore, a suite of glyphs is designed to visualize the data at different levels of detail and support data exploration. The view coordination between the glyph-based visualization and the table lens can effectively enhance the multivariate data analysis. Through numerical evaluations for data abstraction quality, case studies and a user study, we demonstrate the effectiveness and usability of the proposed techniques for multivariate data analysis on scatterplots.", "keywords": ["data analysis", "data visualisation", "image processing", "pattern clustering", "data exploration", "large scale data problem", "data abstraction quality", "glyph-based visualization", "image-based method", "adapted multilabel clustering method", "cluster-based visual abstraction method", "multivariate data analysis", "projection methods", "multivariate data variation", "point distribution", "multivariate data visualization", "multivariate scatterplots", "Data visualization", "Data analysis", "Visualization", "Usability", "Clutter", "Clustering methods", "Lenses", "Data abstraction", "scatterplot", "glyph visualization", "multilabel optimization"], "referenced_by": ["IKEY:8440116", "IKEY:8736844", "IKEY:8794768", "IKEY:8812988", "IKEY:8490694", "IKEY:9146191"], "referencing": ["IKEY:7784854", "IKEY:6484064", "IKEY:663916", "IKEY:6155716", "IKEY:7194836", "IKEY:5290705", "IKEY:7192684", "IKEY:7192671", "IKEY:7192648", "IKEY:4015421", "IKEY:6064985", "IKEY:1320207", "IKEY:4015422", "IKEY:6875982", "IKEY:809863", "IKEY:809865", "IKEY:5708140", "IKEY:6327254", "IKEY:4126231", "IKEY:4015416", "IKEY:841119", "IKEY:969114", "IKEY:5290691", "IKEY:7784854", "IKEY:6484064", "IKEY:663916", "IKEY:6155716", "IKEY:7194836", "IKEY:5290705", "IKEY:7192684", "IKEY:7192671", "IKEY:7192648", "IKEY:4015421", "IKEY:6064985", "IKEY:1320207", "IKEY:4015422", "IKEY:6875982", "IKEY:809863", "IKEY:809865", "IKEY:5708140", "IKEY:6327254", "IKEY:4126231", "IKEY:4015416", "IKEY:841119", "IKEY:969114", "IKEY:5290691", "IKEY:7784854", "IKEY:6484064", "IKEY:663916", "IKEY:6155716", "IKEY:7194836", "IKEY:5290705", "IKEY:7192684", "IKEY:7192671", "IKEY:7192648", "IKEY:4015421", "IKEY:6064985", "IKEY:1320207", "IKEY:4015422", "IKEY:6875982", "IKEY:809863", "IKEY:809865", "IKEY:5708140", "IKEY:6327254", "IKEY:4126231", "IKEY:4015416", "IKEY:841119", "IKEY:969114", "IKEY:5290691", "10.1007/s11263-011-0437-z", "10.1057/ivs.2009.34", "10.1007/978-1-4684-5883-1_9", "10.1111/cgf.12639", "10.1016/j.cag.2011.01.011", "10.1142/S0218213011000061", "10.1016/j.procs.2013.05.319", "10.1007/s11263-011-0437-z", "10.1057/ivs.2009.34", "10.1007/978-1-4684-5883-1_9", "10.1111/cgf.12639", "10.1016/j.cag.2011.01.011", "10.1142/S0218213011000061", "10.1016/j.procs.2013.05.319", "10.1007/s11263-011-0437-z", "10.1057/ivs.2009.34", "10.1007/978-1-4684-5883-1_9", "10.1111/cgf.12639", "10.1016/j.cag.2011.01.011", "10.1142/S0218213011000061", "10.1016/j.procs.2013.05.319"]}, "10.1109/TVCG.2017.2751473": {"doi": "10.1109/TVCG.2017.2751473", "author": ["J. Ren", "J. Schneider", "M. Ovsjanikov", "P. Wonka"], "title": "Joint Graph Layouts for Visualizing Collections of Segmented Meshes", "year": "2018", "abstract": "We present a novel and efficient approach for computing joint graph layouts and then use it to visualize collections of segmented meshes. Our joint graph layout algorithm takes as input the adjacency matrices for a set of graphs along with partial, possibly soft, correspondences between nodes of different graphs. We then use a two stage procedure, where in the first step, we extend spectral graph drawing to include a consistency term so that a collection of graphs can be handled jointly. Our second step extends metric multi-dimensional scaling with stress majorization to the joint layout setting, while using the output of the spectral approach as initialization. Further, we discuss a user interface for exploring a collection of graphs. Finally, we show multiple example visualizations of graphs stemming from collections of segmented meshes and we present qualitative and quantitative comparisons with previous work.", "keywords": ["data visualisation", "graph theory", "matrix algebra", "spectral graphs", "adjacency matrices", "spectral graph drawing", "multi-dimensional scaling", "stress majorization", "joint layout setting", "joint graph layout algorithm", "joint graph layouts", "segmented meshes", "Layout", "Approximation algorithms", "Three-dimensional displays", "Stress", "Shape", "Algorithm design and analysis", "Optimization", "Multi-graph layout", "spectral graph layout", "multi-dimensional scaling", "topological exploration"], "referenced_by": [], "referencing": ["IKEY:5190876", "IKEY:1314504", "IKEY:5190876", "IKEY:1314504", "IKEY:5190876", "IKEY:1314504", "10.1145/774841.774844", "10.1145/2980179.2980238", "10.1145/2366145.2366154", "10.1145/774841.774844", "10.1145/2980179.2980238", "10.1145/2366145.2366154", "10.1145/774841.774844", "10.1145/2980179.2980238", "10.1145/2366145.2366154", "10.1007/3-540-45071-8_50", "10.1016/0020-0190(89)90102-6", "10.7155/jgaa.00104", "10.1002/spe.4380211102", "10.1111/j.1467-8659.2011.01898.x", "10.1007/978-3-642-18638-7_6", "10.1016/j.comgeo.2006.05.006", "10.7155/jgaa.00218", "10.1002/spe.958", "10.1016/j.comgeo.2008.05.003", "10.1287/mnsc.17.3.219", "10.1038/srep00196", "10.1007/3-540-45071-8_50", "10.1016/0020-0190(89)90102-6", "10.7155/jgaa.00104", "10.1002/spe.4380211102", "10.1111/j.1467-8659.2011.01898.x", "10.1007/978-3-642-18638-7_6", "10.1016/j.comgeo.2006.05.006", "10.7155/jgaa.00218", "10.1002/spe.958", "10.1016/j.comgeo.2008.05.003", "10.1287/mnsc.17.3.219", "10.1038/srep00196", "10.1007/3-540-45071-8_50", "10.1016/0020-0190(89)90102-6", "10.7155/jgaa.00104", "10.1002/spe.4380211102", "10.1111/j.1467-8659.2011.01898.x", "10.1007/978-3-642-18638-7_6", "10.1016/j.comgeo.2006.05.006", "10.7155/jgaa.00218", "10.1002/spe.958", "10.1016/j.comgeo.2008.05.003", "10.1287/mnsc.17.3.219", "10.1038/srep00196"]}, "10.1109/TVCG.2017.2759265": {"doi": "10.1109/TVCG.2017.2759265", "author": ["F. Fang", "M. Yi", "H. Feng", "S. Hu", "C. Xiao"], "title": "Narrative Collage of Image Collections by Scene Graph Recombination", "year": "2018", "abstract": "A narrative collage is an interesting image editing method for summarizing the main theme or storyline behind an image collection. We present a novel method to generate narrative images with plausible semantic scene structures. To achieve this goal, we introduce a layer graph and a scene graph to represent the relative depth order and semantic relationship between image objects, respectively. We first cluster the input image collection to select representative images, and then we extract a group of semantic salient objects from each representative image. Both layer graphs and scene graphs are constructed and combined according to our specific rules for reorganizing the extracted objects in every image. We design an energy model to appropriately locate every object on the final canvas. The experimental results show that our method can produce competitive narrative collage results and that it performs well on a wide range of image collections.", "keywords": ["graph theory", "image classification", "image representation", "pattern clustering", "scene graph recombination", "plausible semantic scene structures", "layer graph", "image objects", "semantic salient objects", "image collection", "image editing method", "energy model", "image representation", "Semantics", "Visualization", "Image segmentation", "Painting", "Layout", "Databases", "Image generation", "Narrative collage", "image collections", "image segmentation", "scene graphs", "image synthesis"], "referenced_by": [], "referencing": ["IKEY:730558", "IKEY:6871397", "IKEY:4408863", "IKEY:1000236", "IKEY:4359322", "IKEY:7180373", "IKEY:730558", "IKEY:6871397", "IKEY:4408863", "IKEY:1000236", "IKEY:4359322", "IKEY:7180373", "IKEY:730558", "IKEY:6871397", "IKEY:4408863", "IKEY:1000236", "IKEY:4359322", "IKEY:7180373", "10.1145/1141911.1141965", "10.1145/2070781.2024189", "10.1145/1778765.1778826", "10.1145/1778765.1778825", "10.1145/1276377.1276382", "10.1145/1618452.1618470", "10.1145/2070781.2024190", "10.1145/2601097.2601188", "10.1145/1015706.1015777", "10.1145/1015706.1015720", "10.1145/2185520.2185580", "10.1145/1141911.1141965", "10.1145/2070781.2024189", "10.1145/1778765.1778826", "10.1145/1778765.1778825", "10.1145/1276377.1276382", "10.1145/1618452.1618470", "10.1145/2070781.2024190", "10.1145/2601097.2601188", "10.1145/1015706.1015777", "10.1145/1015706.1015720", "10.1145/2185520.2185580", "10.1145/1141911.1141965", "10.1145/2070781.2024189", "10.1145/1778765.1778826", "10.1145/1778765.1778825", "10.1145/1276377.1276382", "10.1145/1618452.1618470", "10.1145/2070781.2024190", "10.1145/2601097.2601188", "10.1145/1015706.1015777", "10.1145/1015706.1015720", "10.1145/2185520.2185580", "10.1111/j.1467-9280.2009.02316.x", "10.1111/j.1467-8659.2012.03210.x", "10.1007/s00371-008-0282-4", "10.1016/j.cag.2012.02.010", "10.1111/j.1467-8659.2009.01615.x", "10.1007/s00371-013-0792-6", "10.1126/science.1136800", "10.1111/j.1467-8659.2010.01793.x", "10.1007/s11263-007-0090-8", "10.1111/j.1467-9280.2009.02316.x", "10.1111/j.1467-8659.2012.03210.x", "10.1007/s00371-008-0282-4", "10.1016/j.cag.2012.02.010", "10.1111/j.1467-8659.2009.01615.x", "10.1007/s00371-013-0792-6", "10.1126/science.1136800", "10.1111/j.1467-8659.2010.01793.x", "10.1007/s11263-007-0090-8", "10.1111/j.1467-9280.2009.02316.x", "10.1111/j.1467-8659.2012.03210.x", "10.1007/s00371-008-0282-4", "10.1016/j.cag.2012.02.010", "10.1111/j.1467-8659.2009.01615.x", "10.1007/s00371-013-0792-6", "10.1126/science.1136800", "10.1111/j.1467-8659.2010.01793.x", "10.1007/s11263-007-0090-8"]}, "10.1109/TVCG.2017.2747545": {"doi": "10.1109/TVCG.2017.2747545", "author": ["I. Viola", "T. Isenberg"], "title": "Pondering the Concept of Abstraction in (Illustrative) Visualization", "year": "2018", "abstract": "We explore the concept of abstraction as it is used in visualization, with the ultimate goal of understanding and formally defining it. Researchers so far have used the concept of abstraction largely by intuition without a precise meaning. This lack of specificity left questions on the characteristics of abstraction, its variants, its control, or its ultimate potential for visualization and, in particular, illustrative visualization mostly unanswered. In this paper we thus provide a first formalization of the abstraction concept and discuss how this formalization affects the application of abstraction in a variety of visualization scenarios. Based on this discussion, we derive a number of open questions still waiting to be answered, thus formulating a research agenda for the use of abstraction for the visual representation and exploration of data. This paper, therefore, is intended to provide a contribution to the discussion of the theoretical foundations of our field, rather than attempting to provide a completed and final theory.", "keywords": ["data visualisation", "abstraction concept", "formalization", "visualization scenarios", "visual representation", "illustrative visualization", "Data visualization", "Roads", "Visualization", "Water heating", "Spatial databases", "Rendering (computer graphics)", "Junctions", "Abstraction", "visual abstraction", "axes of abstraction", "abstraction space", "spatial data", "illustrative visualization", "stylization"], "referenced_by": ["10.1111/cgf.13434", "10.1111/cgf.13429"], "referencing": ["10.1145/882262.882352", "10.1145/383259.383286", "10.1145/2461912.2461964", "10.1145/1124728.1124751", "10.1145/566654.566650", "10.1145/1360612.1360699", "10.1145/237170.237216", "10.1145/2070781.2024165", "10.1145/1362550.1362587", "10.1145/1276377.1276400", "10.1145/1385569.1385639", "10.1145/22949.22950", "10.1145/1618452.1618483", "10.1145/1572614.1572617", "10.1145/2070781.2024219", "10.1145/2508244.2508258", "10.1145/1408626.1408633", "10.1145/987657.987669", "10.1145/238386.238398", "10.1145/2366145.2366185", "10.1145/1809939.1809951", "10.1145/882262.882352", "10.1145/383259.383286", "10.1145/2461912.2461964", "10.1145/1124728.1124751", "10.1145/566654.566650", "10.1145/1360612.1360699", "10.1145/237170.237216", "10.1145/2070781.2024165", "10.1145/1362550.1362587", "10.1145/1276377.1276400", "10.1145/1385569.1385639", "10.1145/22949.22950", "10.1145/1618452.1618483", "10.1145/1572614.1572617", "10.1145/2070781.2024219", "10.1145/2508244.2508258", "10.1145/1408626.1408633", "10.1145/987657.987669", "10.1145/238386.238398", "10.1145/2366145.2366185", "10.1145/1809939.1809951", "10.1145/882262.882352", "10.1145/383259.383286", "10.1145/2461912.2461964", "10.1145/1124728.1124751", "10.1145/566654.566650", "10.1145/1360612.1360699", "10.1145/237170.237216", "10.1145/2070781.2024165", "10.1145/1362550.1362587", "10.1145/1276377.1276400", "10.1145/1385569.1385639", "10.1145/22949.22950", "10.1145/1618452.1618483", "10.1145/1572614.1572617", "10.1145/2070781.2024219", "10.1145/2508244.2508258", "10.1145/1408626.1408633", "10.1145/987657.987669", "10.1145/238386.238398", "10.1145/2366145.2366185", "10.1145/1809939.1809951", "10.1080/00401706.1987.10488204", "10.1111/j.1467-8659.2009.01687.x", "10.1037/0033-295X.94.2.115", "10.1007/978-1-4471-6497-5_1", "10.1111/j.1467-8659.2008.01244.x", "10.1111/cgf.13070", "10.1016/j.compenvurbsys.2009.07.003", "10.1177/1473871611416549", "10.1007/BF01901041", "10.1016/j.str.2005.01.012", "10.1016/j.cag.2015.06.008", "10.1007/978-3-642-11577-6_18", "10.1179/1743277412Y.0000000007", "10.2312/exp.20161067", "10.1111/j.1467-8659.2008.01233.x", "10.1111/j.1467-8659.2008.01240.x", "10.1111/j.1467-8659.2008.01322.x", "10.1186/1471-2105-15-345", "10.1007/978-3-540-70823-0_1", "10.1111/cgf.12119", "10.1007/978-3-319-24523-2_5", "10.1111/cgf.12370", "10.1111/j.1467-8659.2008.01239.x", "10.1201/b17511", "10.1038/nbt.1558", "10.1111/cgf.12349", "10.1111/j.1467-8659.2011.01901.x", "10.1007/978-1-4615-5047-1_25", "10.1016/j.cag.2015.02.001", "10.1111/j.1467-8659.2012.03081.x", "10.1007/978-1-4020-8658-8", "10.2312/vcbm.20161267", "10.1007/978-3-642-59847-0", "10.2312/VisSym/EuroVis05/303-310", "10.1038/nrneph.2010.55", "10.1006/ijhc.2002.1017", "10.1111/j.1467-8659.2011.01917.x", "10.1016/j.cag.2010.05.011", "10.1016/B978-0-12-381464-7.00018-1", "10.1063/1.881394", "10.1080/00401706.1987.10488204", "10.1111/j.1467-8659.2009.01687.x", "10.1037/0033-295X.94.2.115", "10.1007/978-1-4471-6497-5_1", "10.1111/j.1467-8659.2008.01244.x", "10.1111/cgf.13070", "10.1016/j.compenvurbsys.2009.07.003", "10.1177/1473871611416549", "10.1007/BF01901041", "10.1016/j.str.2005.01.012", "10.1016/j.cag.2015.06.008", "10.1007/978-3-642-11577-6_18", "10.1179/1743277412Y.0000000007", "10.2312/exp.20161067", "10.1111/j.1467-8659.2008.01233.x", "10.1111/j.1467-8659.2008.01240.x", "10.1111/j.1467-8659.2008.01322.x", "10.1186/1471-2105-15-345", "10.1007/978-3-540-70823-0_1", "10.1111/cgf.12119", "10.1007/978-3-319-24523-2_5", "10.1111/cgf.12370", "10.1111/j.1467-8659.2008.01239.x", "10.1201/b17511", "10.1038/nbt.1558", "10.1111/cgf.12349", "10.1111/j.1467-8659.2011.01901.x", "10.1007/978-1-4615-5047-1_25", "10.1016/j.cag.2015.02.001", "10.1111/j.1467-8659.2012.03081.x", "10.1007/978-1-4020-8658-8", "10.2312/vcbm.20161267", "10.1007/978-3-642-59847-0", "10.2312/VisSym/EuroVis05/303-310", "10.1038/nrneph.2010.55", "10.1006/ijhc.2002.1017", "10.1111/j.1467-8659.2011.01917.x", "10.1016/j.cag.2010.05.011", "10.1016/B978-0-12-381464-7.00018-1", "10.1063/1.881394", "10.1080/00401706.1987.10488204", "10.1111/j.1467-8659.2009.01687.x", "10.1037/0033-295X.94.2.115", "10.1007/978-1-4471-6497-5_1", "10.1111/j.1467-8659.2008.01244.x", "10.1111/cgf.13070", "10.1016/j.compenvurbsys.2009.07.003", "10.1177/1473871611416549", "10.1007/BF01901041", "10.1016/j.str.2005.01.012", "10.1016/j.cag.2015.06.008", "10.1007/978-3-642-11577-6_18", "10.1179/1743277412Y.0000000007", "10.2312/exp.20161067", "10.1111/j.1467-8659.2008.01233.x", "10.1111/j.1467-8659.2008.01240.x", "10.1111/j.1467-8659.2008.01322.x", "10.1186/1471-2105-15-345", "10.1007/978-3-540-70823-0_1", "10.1111/cgf.12119", "10.1007/978-3-319-24523-2_5", "10.1111/cgf.12370", "10.1111/j.1467-8659.2008.01239.x", "10.1201/b17511", "10.1038/nbt.1558", "10.1111/cgf.12349", "10.1111/j.1467-8659.2011.01901.x", "10.1007/978-1-4615-5047-1_25", "10.1016/j.cag.2015.02.001", "10.1111/j.1467-8659.2012.03081.x", "10.1007/978-1-4020-8658-8", "10.2312/vcbm.20161267", "10.1007/978-3-642-59847-0", "10.2312/VisSym/EuroVis05/303-310", "10.1038/nrneph.2010.55", "10.1006/ijhc.2002.1017", "10.1111/j.1467-8659.2011.01917.x", "10.1016/j.cag.2010.05.011", "10.1016/B978-0-12-381464-7.00018-1", "10.1063/1.881394"]}, "10.1109/TVCG.2017.2755646": {"doi": "10.1109/TVCG.2017.2755646", "author": ["X. He", "H. Wang", "E. Wu"], "title": "Projective Peridynamics for Modeling Versatile Elastoplastic Materials", "year": "2018", "abstract": "Unified simulation of versatile elastoplastic materials and different dimensions offers many advantages in animation production, contact handling, and hardware acceleration. The unstructured particle representation is particularly suitable for this task, thanks to its simplicity. However, previous meshless techniques either need too much computational cost for addressing stability issues, or lack physical meanings and fail to generate interesting deformation behaviors, such as the Poisson effect. In this paper, we study the development of an elastoplastic model under the state-based peridynamics framework, which uses integrals rather than partial derivatives in its formulation. To model elasticity, we propose a unique constitutive model and an efficient iterative simulator solved in a projective dynamics way. To handle plastic behaviors, we incorporate our simulator with the Drucker-Prager yield criterion and a reference position update scheme, both of which are implemented under peridynamics. Finally, we show how to strengthen the simulator by position-based constraints and spatially varying stiffness models, to achieve incompressibility, particle redistribution, cohesion, and friction effects in viscoelastic and granular flows. Our experiments demonstrate that our unified, meshless simulator is flexible, efficient, robust, and friendly with parallel computing.", "keywords": ["deformation", "elastoplasticity", "friction", "granular flow", "iterative methods", "viscoelasticity", "elastoplastic model", "state-based peridynamics framework", "plastic behaviors", "Drucker-Prager yield criterion", "reference position update scheme", "position-based constraints", "stiffness models", "particle redistribution", "meshless simulator", "projective peridynamics", "unified simulation", "unstructured particle representation", "constitutive model", "iterative simulator", "versatile elastoplastic materials", "friction effects", "viscoelastic flow", "granular flow", "Computational modeling", "Deformable models", "Elasticity", "Mathematical model", "Robustness", "Plastics", "Dynamics", "Peridynamics", "projective dynamics", "position-based dynamics", "elasticity", "plasticity", "viscoelasticity", "granular flows"], "referenced_by": [], "referencing": ["IKEY:4027054", "IKEY:4027054", "IKEY:4027054", "10.1145/1778765.1778776", "10.1145/1073204.1073296", "10.1145/2601097.2601116", "10.1145/1599470.1599488", "10.1145/2019406.2019410", "10.1145/2560795", "10.1145/2461912.2461948", "10.1145/1073204.1073298", "10.1145/2766996", "10.1145/2601097.2601176", "10.1145/2751541", "10.1145/2897824.2925906", "10.1145/2786784.2786798", "10.1145/3072959.3073623", "10.1145/2461912.2461984", "10.1145/2601097.2601152", "10.1145/2766969", "10.1145/1073204.1073216", "10.1145/2816795.2818063", "10.1145/1028523.1028541", "10.1145/2766981", "10.1145/2682630", "10.1145/1882261.1866195", "10.1145/2019406.2019409", "10.1145/2185520.2335413", "10.1145/1778765.1778776", "10.1145/1073204.1073296", "10.1145/2601097.2601116", "10.1145/1599470.1599488", "10.1145/2019406.2019410", "10.1145/2560795", "10.1145/2461912.2461948", "10.1145/1073204.1073298", "10.1145/2766996", "10.1145/2601097.2601176", "10.1145/2751541", "10.1145/2897824.2925906", "10.1145/2786784.2786798", "10.1145/3072959.3073623", "10.1145/2461912.2461984", "10.1145/2601097.2601152", "10.1145/2766969", "10.1145/1073204.1073216", "10.1145/2816795.2818063", "10.1145/1028523.1028541", "10.1145/2766981", "10.1145/2682630", "10.1145/1882261.1866195", "10.1145/2019406.2019409", "10.1145/2185520.2335413", "10.1145/1778765.1778776", "10.1145/1073204.1073296", "10.1145/2601097.2601116", "10.1145/1599470.1599488", "10.1145/2019406.2019410", "10.1145/2560795", "10.1145/2461912.2461948", "10.1145/1073204.1073298", "10.1145/2766996", "10.1145/2601097.2601176", "10.1145/2751541", "10.1145/2897824.2925906", "10.1145/2786784.2786798", "10.1145/3072959.3073623", "10.1145/2461912.2461984", "10.1145/2601097.2601152", "10.1145/2766969", "10.1145/1073204.1073216", "10.1145/2816795.2818063", "10.1145/1028523.1028541", "10.1145/2766981", "10.1145/2682630", "10.1145/1882261.1866195", "10.1145/2019406.2019409", "10.1145/2185520.2335413", "10.1002/cav.162", "10.1002/cav.412", "10.1016/j.jvcir.2007.01.005", "10.1016/S0022-5096(99)00029-0", "10.1007/s10659-007-9125-1", "10.1016/j.cma.2013.04.012", "10.1007/978-3-7091-7486-9_5", "10.1111/cgf.12987", "10.1016/j.gmod.2005.03.007", "10.1006/jcph.2000.6439", "10.1016/j.cpc.2012.02.032", "10.1080/00018730500167855", "10.1002/nag.674", "10.1111/j.1467-8659.2010.01832.x", "10.1002/cav.162", "10.1002/cav.412", "10.1016/j.jvcir.2007.01.005", "10.1016/S0022-5096(99)00029-0", "10.1007/s10659-007-9125-1", "10.1016/j.cma.2013.04.012", "10.1007/978-3-7091-7486-9_5", "10.1111/cgf.12987", "10.1016/j.gmod.2005.03.007", "10.1006/jcph.2000.6439", "10.1016/j.cpc.2012.02.032", "10.1080/00018730500167855", "10.1002/nag.674", "10.1111/j.1467-8659.2010.01832.x", "10.1002/cav.162", "10.1002/cav.412", "10.1016/j.jvcir.2007.01.005", "10.1016/S0022-5096(99)00029-0", "10.1007/s10659-007-9125-1", "10.1016/j.cma.2013.04.012", "10.1007/978-3-7091-7486-9_5", "10.1111/cgf.12987", "10.1016/j.gmod.2005.03.007", "10.1006/jcph.2000.6439", "10.1016/j.cpc.2012.02.032", "10.1080/00018730500167855", "10.1002/nag.674", "10.1111/j.1467-8659.2010.01832.x"]}, "10.1109/TVCG.2017.2756634": {"doi": "10.1109/TVCG.2017.2756634", "author": ["G. Chen", "C. Ma", "Z. Fan", "X. Cui", "H. Liao"], "title": "Real-Time Lens Based Rendering Algorithm for Super-Multiview Integral Photography without Image Resampling", "year": "2018", "abstract": "We propose a computer generated integral photography (CGIP) method that employs a lens based rendering (LBR) algorithm for super-multiview displays to achieve higher frame rates and better image quality without pixel resampling or view interpolation. The algorithm can utilize both fixed and programmable graphics pipelines to accelerate CGIP rendering and inter-perspective antialiasing. Two hardware prototypes were fabricated with two high-resolution liquid crystal displays and micro-lens arrays (MLA). Qualitative and quantitative experiments were performed to evaluate the feasibility of the proposed algorithm. To the best of our knowledge, the proposed LBR method outperforms state-of-the-art CGIP algorithms relative to rendering speed and image quality with our super-multiview hardware configurations. A demonstration experiment was also conducted to reveal the interactivity of a super-multiview display utilizing the proposed algorithm.", "keywords": ["antialiasing", "digital photography", "image resolution", "liquid crystal displays", "microlenses", "rendering (computer graphics)", "super-multiview integral photography", "super-multiview display", "image quality", "fixed graphics pipelines", "programmable graphics pipelines", "CGIP rendering", "inter-perspective antialiasing", "high-resolution liquid crystal displays", "microlens arrays", "super-multiview hardware configurations", "Real-time Lens Based Rendering Algorithm", "computer generated integral photography", "Rendering (computer graphics)", "Lenses", "IP networks", "Three-dimensional displays", "Real-time systems", "Image quality", "Geometry", "Lens based rendering", "integral photography", "super-multiview display", "GPU"], "referenced_by": ["IKEY:8939803"], "referencing": ["IKEY:768575", "IKEY:1492263", "IKEY:5415615", "IKEY:6716056", "IKEY:5674031", "IKEY:7148099", "IKEY:6783720", "IKEY:6905752", "IKEY:4388083", "IKEY:1388233", "IKEY:7470595", "IKEY:4342598", "IKEY:768575", "IKEY:1492263", "IKEY:5415615", "IKEY:6716056", "IKEY:5674031", "IKEY:7148099", "IKEY:6783720", "IKEY:6905752", "IKEY:4388083", "IKEY:1388233", "IKEY:7470595", "IKEY:4342598", "IKEY:768575", "IKEY:1492263", "IKEY:5415615", "IKEY:6716056", "IKEY:5674031", "IKEY:7148099", "IKEY:6783720", "IKEY:6905752", "IKEY:4388083", "IKEY:1388233", "IKEY:7470595", "IKEY:4342598", "10.1145/1186954.1187005", "10.1145/2669024.2669041", "10.1145/1179849.1179983", "10.1145/1186954.1187005", "10.1145/2669024.2669041", "10.1145/1179849.1179983", "10.1145/1186954.1187005", "10.1145/2669024.2669041", "10.1145/1179849.1179983", "10.1364/AO.52.000546", "10.1117/12.589613", "10.1364/OE.22.031448", "10.1364/OE.23.006007", "10.1364/OE.19.000704", "10.1007/978-3-540-30136-3_57", "10.1051/jphystap:019080070082100", "10.1143/JJAP.17.1683", "10.1093/ietisy/e90-1.1.233", "10.1364/OE.21.010070", "10.1364/OE.20.000732", "10.1364/AO.52.008411", "10.1364/OE.25.000330", "10.1364/AO.52.000546", "10.1117/12.589613", "10.1364/OE.22.031448", "10.1364/OE.23.006007", "10.1364/OE.19.000704", "10.1007/978-3-540-30136-3_57", "10.1051/jphystap:019080070082100", "10.1143/JJAP.17.1683", "10.1093/ietisy/e90-1.1.233", "10.1364/OE.21.010070", "10.1364/OE.20.000732", "10.1364/AO.52.008411", "10.1364/OE.25.000330", "10.1364/AO.52.000546", "10.1117/12.589613", "10.1364/OE.22.031448", "10.1364/OE.23.006007", "10.1364/OE.19.000704", "10.1007/978-3-540-30136-3_57", "10.1051/jphystap:019080070082100", "10.1143/JJAP.17.1683", "10.1093/ietisy/e90-1.1.233", "10.1364/OE.21.010070", "10.1364/OE.20.000732", "10.1364/AO.52.008411", "10.1364/OE.25.000330"]}, "10.1109/TVCG.2017.2750671": {"doi": "10.1109/TVCG.2017.2750671", "author": ["W. Lai", "Y. Huang", "N. Joshi", "C. Buehler", "M. Yang", "S. B. Kang"], "title": "Semantic-Driven Generation of Hyperlapse from 360 Degree Video", "year": "2018", "abstract": "We present a system for converting a fully panoramic (360 degree) video into a normal field-of-view (NFOV) hyperlapse for an optimal viewing experience. Our system exploits visual saliency and semantics to non-uniformly sample in space and time for generating hyperlapses. In addition, users can optionally choose objects of interest for customizing the hyperlapses. We first stabilize an input 360 degree video by smoothing the rotation between adjacent frames and then compute regions of interest and saliency scores. An initial hyperlapse is generated by optimizing the saliency and motion smoothness followed by the saliency-aware frame selection. We further smooth the result using an efficient 2D video stabilization approach that adaptively selects the motion model to generate the final hyperlapse. We validate the design of our system by showing results for a variety of scenes and comparing against the state-of-the-art method through a large-scale user study.", "keywords": ["image sequences", "motion estimation", "optimisation", "video cameras", "video signal processing", "motion smoothness", "visual saliency", "2D video stabilization", "panoramic video", "360 degree video", "NFOV", "optimal view", "visual semantics", "frame selection", "normal field-of-view hyperlapse", "Cameras", "Semantics", "Two dimensional displays", "Visualization", "Three-dimensional displays", "Computational modeling", "Rendering (computer graphics)", "360 degree videos", "hyperlapse", "video stabilization", "semantic segmentation", "spatial-temporal saliency"], "referenced_by": ["IKEY:8624247", "IKEY:8676301", "IKEY:8954175", "IKEY:8911454", "IKEY:9009101", "IKEY:9053175", "IKEY:9093615", "IKEY:9093330", "IKEY:9121469", "IKEY:8931644", "IKEY:9284734"], "referencing": ["IKEY:7532977", "IKEY:1634345", "IKEY:5995525", "IKEY:1234090", "IKEY:730558", "IKEY:7532977", "IKEY:1634345", "IKEY:5995525", "IKEY:1234090", "IKEY:730558", "IKEY:7532977", "IKEY:1634345", "IKEY:5995525", "IKEY:1234090", "IKEY:730558", "10.1145/2745197.2745202", "10.1145/2980179.2980257", "10.1145/2601097.2601195", "10.1145/2766954", "10.1145/2980179.2982405", "10.1145/1531326.1531350", "10.1145/1899404.1899408", "10.1145/2461912.2461995", "10.1145/1778765.1778827", "10.1145/2010324.1964983", "10.1145/358669.358692", "10.1145/2745197.2745202", "10.1145/2980179.2980257", "10.1145/2601097.2601195", "10.1145/2766954", "10.1145/2980179.2982405", "10.1145/1531326.1531350", "10.1145/1899404.1899408", "10.1145/2461912.2461995", "10.1145/1778765.1778827", "10.1145/2010324.1964983", "10.1145/358669.358692", "10.1145/2745197.2745202", "10.1145/2980179.2980257", "10.1145/2601097.2601195", "10.1145/2766954", "10.1145/2980179.2982405", "10.1145/1531326.1531350", "10.1145/1899404.1899408", "10.1145/2461912.2461995", "10.1145/1778765.1778827", "10.1145/2010324.1964983", "10.1145/358669.358692", "10.1007/BF02294361", "10.1007/978-3-642-15561-1_56", "10.1007/BF02294361", "10.1007/978-3-642-15561-1_56", "10.1007/BF02294361", "10.1007/978-3-642-15561-1_56"]}, "10.1109/TVCG.2017.2750681": {"doi": "10.1109/TVCG.2017.2750681", "author": ["J. Tao", "C. Wang"], "title": "Semi-Automatic Generation of Stream Surfaces via Sketching", "year": "2018", "abstract": "We present a semi-automatic approach for stream surface generation. Our approach is based on the conjecture that good seeding curves can be inferred from a set of streamlines. Given a set of densely traced streamlines over the flow field, we design a sketch-based interface that allows users to describe their perceived flow patterns through drawing simple strokes directly on top of the streamline visualization results. Based on the 2D stroke, we identify a 3D seeding curve and generate a stream surface that captures the flow pattern of streamlines at the outermost layer. Then, we remove the streamlines whose patterns are covered by the stream surface. Repeating this process, users can peel the flow by replacing the streamlines with customized surfaces layer by layer. Furthermore, we propose an optimization scheme to identify the optimal seeding curve in the neighborhood of an original seeding curve based on surface quality measures. To support interactive optimization, we design a parallel surface quality estimation strategy that estimates the quality of a seeding curve without generating the surface. Our sketch-based interface leverages an intuitive painting metaphor which most users are familiar with. We present results using multiple data sets to show the effectiveness of our approach.", "keywords": ["computational geometry", "data visualisation", "optimisation", "solid modelling", "semiautomatic generation", "stream surface generation", "good seeding curves", "densely traced streamlines", "sketch-based interface", "perceived flow patterns", "flow pattern", "customized surfaces layer", "optimal seeding curve", "parallel surface quality estimation strategy", "Surface treatment", "Visualization", "Two dimensional displays", "Streaming media", "Three-dimensional displays", "Data visualization", "Shape", "Flow visualization", "sketch-based interface", "human perception", "seeding curves", "stream surfaces"], "referenced_by": ["IKEY:8532319"], "referencing": ["IKEY:398875", "IKEY:1372195", "IKEY:235211", "IKEY:964506", "IKEY:4658156", "IKEY:6915327", "IKEY:5613472", "IKEY:6244795", "IKEY:5613500", "IKEY:4658155", "IKEY:398877", "IKEY:398875", "IKEY:1372195", "IKEY:235211", "IKEY:964506", "IKEY:4658156", "IKEY:6915327", "IKEY:5613472", "IKEY:6244795", "IKEY:5613500", "IKEY:4658155", "IKEY:398877", "IKEY:398875", "IKEY:1372195", "IKEY:235211", "IKEY:964506", "IKEY:4658156", "IKEY:6915327", "IKEY:5613472", "IKEY:6244795", "IKEY:5613500", "IKEY:4658155", "IKEY:398877", "10.1145/3002151.3002158", "10.1145/1629739.1629748", "10.1145/1268517.1268564", "10.1145/3002151.3002158", "10.1145/1629739.1629748", "10.1145/1268517.1268564", "10.1145/3002151.3002158", "10.1145/1629739.1629748", "10.1145/1268517.1268564", "10.2514/6.1983-1735", "10.14569/IJACSA.2015.060417", "10.1023/B:VISI.0000029664.99615.94", "10.1111/j.1467-8659.2010.01650.x", "10.1016/j.cag.2012.07.006", "10.1111/j.1467-8659.2012.03102.x", "10.1016/j.cag.2015.01.002", "10.1111/j.1467-8659.2009.01462.x", "10.1111/cgf.12031", "10.1111/cgf.12356", "10.1111/j.1467-8659.2012.03115.x", "10.2514/6.1983-1735", "10.14569/IJACSA.2015.060417", "10.1023/B:VISI.0000029664.99615.94", "10.1111/j.1467-8659.2010.01650.x", "10.1016/j.cag.2012.07.006", "10.1111/j.1467-8659.2012.03102.x", "10.1016/j.cag.2015.01.002", "10.1111/j.1467-8659.2009.01462.x", "10.1111/cgf.12031", "10.1111/cgf.12356", "10.1111/j.1467-8659.2012.03115.x", "10.2514/6.1983-1735", "10.14569/IJACSA.2015.060417", "10.1023/B:VISI.0000029664.99615.94", "10.1111/j.1467-8659.2010.01650.x", "10.1016/j.cag.2012.07.006", "10.1111/j.1467-8659.2012.03102.x", "10.1016/j.cag.2015.01.002", "10.1111/j.1467-8659.2009.01462.x", "10.1111/cgf.12031", "10.1111/cgf.12356", "10.1111/j.1467-8659.2012.03115.x"]}, "10.1109/TVCG.2017.2758362": {"doi": "10.1109/TVCG.2017.2758362", "author": ["W. Chen", "Z. Huang", "F. Wu", "M. Zhu", "H. Guan", "R. Maciejewski"], "title": "VAUD: A Visual Analysis Approach for Exploring Spatio-Temporal Urban Data", "year": "2018", "abstract": "Urban data is massive, heterogeneous, and spatio-temporal, posing a substantial challenge for visualization and analysis. In this paper, we design and implement a novel visual analytics approach, Visual Analyzer for Urban Data (VAUD), that supports the visualization, querying, and exploration of urban data. Our approach allows for cross-domain correlation from multiple data sources by leveraging spatial-temporal and social inter-connectedness features. Through our approach, the analyst is able to select, filter, aggregate across multiple data sources and extract information that would be hidden to a single data subset. To illustrate the effectiveness of our approach, we provide case studies on a real urban dataset that contains the cyber-, physical-, and social- information of 14 million citizens over 22 days.", "keywords": ["data analysis", "data visualisation", "VAUD", "Visual analysis approach", "spatio-temporal Urban Data", "massive spatio-temporal", "Visual Analyzer", "multiple data sources", "spatial-temporal inter-connectedness features", "social inter-connectedness features", "single data subset", "urban dataset", "visual analytics approach", "Cognition", "Data visualization", "Visual analytics", "Public transportation", "Trajectory", "Urban areas", "Urban data", "visual analysis", "visual reasoning", "heterogeneous", "spatio-temporal"], "referenced_by": ["IKEY:8731543", "IKEY:8603812", "IKEY:8764395", "IKEY:8513838", "IKEY:8801911", "IKEY:8846208", "IKEY:8807351", "IKEY:8807303", "IKEY:8807274", "IKEY:9308623"], "referencing": ["IKEY:7534822", "IKEY:6361385", "IKEY:6875954", "IKEY:7120975", "IKEY:6876004", "IKEY:6634127", "IKEY:6875983", "IKEY:4653466", "IKEY:6185547", "IKEY:6634137", "IKEY:1377177", "IKEY:7345576", "IKEY:6875986", "IKEY:6327262", "IKEY:6634154", "IKEY:1703364", "IKEY:7042486", "IKEY:7954057", "IKEY:6634174", "IKEY:6876014", "IKEY:6876029", "IKEY:6876008", "IKEY:7359138", "IKEY:7534822", "IKEY:6361385", "IKEY:6875954", "IKEY:7120975", "IKEY:6876004", "IKEY:6634127", "IKEY:6875983", "IKEY:4653466", "IKEY:6185547", "IKEY:6634137", "IKEY:1377177", "IKEY:7345576", "IKEY:6875986", "IKEY:6327262", "IKEY:6634154", "IKEY:1703364", "IKEY:7042486", "IKEY:7954057", "IKEY:6634174", "IKEY:6876014", "IKEY:6876029", "IKEY:6876008", "IKEY:7359138", "IKEY:7534822", "IKEY:6361385", "IKEY:6875954", "IKEY:7120975", "IKEY:6876004", "IKEY:6634127", "IKEY:6875983", "IKEY:4653466", "IKEY:6185547", "IKEY:6634137", "IKEY:1377177", "IKEY:7345576", "IKEY:6875986", "IKEY:6327262", "IKEY:6634154", "IKEY:1703364", "IKEY:7042486", "IKEY:7954057", "IKEY:6634174", "IKEY:6876014", "IKEY:6876029", "IKEY:6876008", "IKEY:7359138", "10.1145/1807167.1807197", "10.1145/248448.248465", "10.1145/2629592", "10.1145/1807167.1807197", "10.1145/248448.248465", "10.1145/2629592", "10.1145/1807167.1807197", "10.1145/248448.248465", "10.1145/2629592", "10.1016/S1045-926X(03)00046-6", "10.1177/1473871612457601", "10.1111/j.1467-8659.2011.01957.x", "10.5220/0005716900480059", "10.1057/palgrave.ivs.9500097", "10.1080/136588100415710", "10.1111/j.1467-8306.1994.tb01869.x", "10.1007/s10707-013-0198-7", "10.1007/978-3-642-23808-6_25", "10.1007/978-3-319-10605-2_27", "10.1016/S1045-926X(03)00046-6", "10.1177/1473871612457601", "10.1111/j.1467-8659.2011.01957.x", "10.5220/0005716900480059", "10.1057/palgrave.ivs.9500097", "10.1080/136588100415710", "10.1111/j.1467-8306.1994.tb01869.x", "10.1007/s10707-013-0198-7", "10.1007/978-3-642-23808-6_25", "10.1007/978-3-319-10605-2_27", "10.1016/S1045-926X(03)00046-6", "10.1177/1473871612457601", "10.1111/j.1467-8659.2011.01957.x", "10.5220/0005716900480059", "10.1057/palgrave.ivs.9500097", "10.1080/136588100415710", "10.1111/j.1467-8306.1994.tb01869.x", "10.1007/s10707-013-0198-7", "10.1007/978-3-642-23808-6_25", "10.1007/978-3-319-10605-2_27"]}, "10.1109/TVCG.2017.2754257": {"doi": "10.1109/TVCG.2017.2754257", "author": ["J. Grubert", "Y. Itoh", "K. Moser", "J. E. Swan"], "title": "A Survey of Calibration Methods for Optical See-Through Head-Mounted Displays", "year": "2018", "abstract": "Optical see-through head-mounted displays (OST HMDs) are a major output medium for Augmented Reality, which have seen significant growth in popularity and usage among the general public due to the growing release of consumer-oriented models, such as the Microsoft Hololens. Unlike Virtual Reality headsets, OST HMDs inherently support the addition of computer-generated graphics directly into the light path between a user's eyes and their view of the physical world. As with most Augmented and Virtual Reality systems, the physical position of an OST HMD is typically determined by an external or embedded 6-Degree-of-Freedom tracking system. However, in order to properly render virtual objects, which are perceived as spatially aligned with the physical environment, it is also necessary to accurately measure the position of the user's eyes within the tracking system's coordinate frame. For over 20 years, researchers have proposed various calibration methods to determine this needed eye position. However, to date, there has not been a comprehensive overview of these procedures and their requirements. Hence, this paper surveys the field of calibration methods for OST HMDs. Specifically, it provides insights into the fundamentals of calibration techniques, and presents an overview of both manual and automatic approaches, as well as evaluation methods and metrics. Finally, it also identifies opportunities for future research.", "keywords": ["augmented reality", "calibration", "helmet mounted displays", "rendering (computer graphics)", "consumer-oriented models", "Microsoft Hololens", "Virtual Reality headsets", "OST HMD", "computer-generated graphics", "Augmented Reality systems", "Virtual Reality systems", "physical position", "6-Degree-of-Freedom tracking system", "virtual objects", "physical environment", "calibration methods", "eye position", "calibration techniques", "evaluation methods", "head-mounted displays", "output medium", "Cameras", "Resists", "Calibration", "Three-dimensional displays", "Mathematical model", "Glass", "Rendering (computer graphics)", "Augmented reality", "head-mounted displays", "optical see-through calibration"], "referenced_by": [], "referencing": ["IKEY:7829412", "IKEY:1525184", "IKEY:880940", "IKEY:970524", "IKEY:6712903", "IKEY:7523375", "IKEY:7165643", "IKEY:6948424", "IKEY:7064856", "IKEY:7328058", "IKEY:380772", "IKEY:803809", "IKEY:6165140", "IKEY:7523376", "IKEY:6549353", "IKEY:7383304", "IKEY:6671761", "IKEY:7021939", "IKEY:6802070", "IKEY:7460047", "IKEY:1310091", "IKEY:7012105", "IKEY:1451379", "IKEY:1087109", "IKEY:880938", "IKEY:7829412", "IKEY:1525184", "IKEY:880940", "IKEY:970524", "IKEY:6712903", "IKEY:7523375", "IKEY:7165643", "IKEY:6948424", "IKEY:7064856", "IKEY:7328058", "IKEY:380772", "IKEY:803809", "IKEY:6165140", "IKEY:7523376", "IKEY:6549353", "IKEY:7383304", "IKEY:6671761", "IKEY:7021939", "IKEY:6802070", "IKEY:7460047", "IKEY:1310091", "IKEY:7012105", "IKEY:1451379", "IKEY:1087109", "IKEY:880938", "IKEY:7829412", "IKEY:1525184", "IKEY:880940", "IKEY:970524", "IKEY:6712903", "IKEY:7523375", "IKEY:7165643", "IKEY:6948424", "IKEY:7064856", "IKEY:7328058", "IKEY:380772", "IKEY:803809", "IKEY:6165140", "IKEY:7523376", "IKEY:6549353", "IKEY:7383304", "IKEY:6671761", "IKEY:7021939", "IKEY:6802070", "IKEY:7460047", "IKEY:1310091", "IKEY:7012105", "IKEY:1451379", "IKEY:1087109", "IKEY:880938", "10.1145/1450579.1450610", "10.1145/192161.192199", "10.1145/323663.323692", "10.1145/2735711.2735787", "10.1145/3072959.3073624", "10.1145/3072959.3073590", "10.1145/1450579.1450610", "10.1145/192161.192199", "10.1145/323663.323692", "10.1145/2735711.2735787", "10.1145/3072959.3073624", "10.1145/3072959.3073590", "10.1145/1450579.1450610", "10.1145/192161.192199", "10.1145/323663.323692", "10.1145/2735711.2735787", "10.1145/3072959.3073624", "10.1145/3072959.3073590", "10.1177/154193121005402814", "10.1561/1100000049", "10.1016/j.jneumeth.2008.05.015", "10.1016/S0166-4115(08)62386-9", "10.1177/027836499501400301", "10.1364/OE.22.013896", "10.1364/OE.21.030993", "10.1097/OPX.0000000000000326", "10.1207/s15327108ijap0303_3", "10.1007/978-3-642-87512-0_18", "10.1007/BFb0067700", "10.1162/pres.1996.5.1.122", "10.1162/pres.1995.4.1.1", "10.1162/105474602317473213", "10.1177/154193121005402814", "10.1561/1100000049", "10.1016/j.jneumeth.2008.05.015", "10.1016/S0166-4115(08)62386-9", "10.1177/027836499501400301", "10.1364/OE.22.013896", "10.1364/OE.21.030993", "10.1097/OPX.0000000000000326", "10.1207/s15327108ijap0303_3", "10.1007/978-3-642-87512-0_18", "10.1007/BFb0067700", "10.1162/pres.1996.5.1.122", "10.1162/pres.1995.4.1.1", "10.1162/105474602317473213", "10.1177/154193121005402814", "10.1561/1100000049", "10.1016/j.jneumeth.2008.05.015", "10.1016/S0166-4115(08)62386-9", "10.1177/027836499501400301", "10.1364/OE.22.013896", "10.1364/OE.21.030993", "10.1097/OPX.0000000000000326", "10.1207/s15327108ijap0303_3", "10.1007/978-3-642-87512-0_18", "10.1007/BFb0067700", "10.1162/pres.1996.5.1.122", "10.1162/pres.1995.4.1.1", "10.1162/105474602317473213"]}}