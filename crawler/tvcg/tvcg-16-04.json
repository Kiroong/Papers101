{"10.1109/TVCG.2016.2518158": {"doi": "10.1109/TVCG.2016.2518158", "author": ["M. Volante", "S. V. Babu", "H. Chaturvedi", "N. Newsome", "E. Ebrahimi", "T. Roy", "S. B. Daily", "T. Fasolino"], "title": "Effects of Virtual Human Appearance Fidelity on Emotion Contagion in Affective Inter-Personal Simulations", "year": "2016", "abstract": "Realistic versus stylized depictions of virtual humans in simulated inter-personal situations and their ability to elicit emotional responses in users has been an open question for artists and researchers alike. We empirically evaluated the effects of near visually realistic vs. non-realistic stylized appearance of virtual humans on the emotional response of participants in a medical virtual reality system that was designed to educate users in recognizing the signs and symptoms of patient deterioration. In a between-subjects experiment protocol, participants interacted with one of three different appearances of a virtual patient, namely visually realistic, cartoon-shaded and charcoal-sketch like conditions in a mixed reality simulation. Emotional impact were measured via a combination of quantitative objective measures were gathered using skin Electrodermal Activity (EDA) sensors, and quantitative subjective measures such as the Differential Emotion Survey (DES IV), Positive and Negative Affect Schedule (PANAS), and Social Presence questionnaire. The emotional states of the participants were analyzed across four distinct time steps during which the medical condition of the virtual patient deteriorated (an emotionally stressful interaction), and were contrasted to a baseline affective state. Objective EDA results showed that in all three conditions, male participants exhibited greater levels of arousal as compared to female participants. We found that negative affect levels were significantly lower in the visually realistic condition, as compared to the stylized appearance conditions. Furthermore, in emotional dimensions of interest-excitement, surprise, anger, fear and guilt participants in all conditions responded similarly. However, in social emotional constructs of shyness, presence, perceived personality, and enjoyment-joy, we found that participants responded differently in the visually realistic condition as compared to the cartoon and sketch conditions. Our study suggests that virtual human appearance can affect not only critical emotional reactions in affective inter-oersonal trainina scenarios. but also users' oerceotions of oersonalitv and social characteristic of the virtual interlocutors.", "keywords": ["computer animation", "emotion recognition", "human factors", "medical computing", "psychology", "virtual reality", "virtual human appearance fidelity", "emotion contagion", "affective interpersonal simulations", "simulated interpersonal situations", "emotional responses", "nonrealistic stylized appearance", "medical virtual reality system", "patient deterioration symptoms", "cartoon-shaded conditions", "charcoal-sketch like conditions", "mixed reality simulation", "skin electrodermal activity sensors", "skin EDA sensors", "differential emotion survey", "positive and negative affect schedule", "PANAS", "social presence questionnaire", "female participants", "visually realistic condition", "emotional dimensions", "shyness", "enjoyment-joy", "interpersonal training scenarios", "Rendering (computer graphics)", "Visualization", "Electronic mail", "Solid modeling", "Training", "Animation", "Atmospheric measurements", "Virtual/Digital Characters", "Visual Fidelity", "Emotion Contagion", "Virtual/Digital Characters", "Visual Fidelity", "Emotion Contagion", "Psychology", "User Studies", "Computer Graphics", "Emotions", "Ergonomics", "Facial Expression", "Female", "Humans", "Imaging, Three-Dimensional", "Interpersonal Relations", "Male", "User-Computer Interface"], "referenced_by": ["10.1109/TVCG.2018.2794638", "10.1109/SeGAH.2018.8401353", "10.1109/VR.2018.8446364", "10.1109/ISMAR-Adjunct.2018.00029", "10.1109/VR.2019.8797719", "10.1109/VR46266.2020.00049", "10.1109/TLT.2019.2913408", "10.1145/3383195", "10.1007/s11042-016-3650-5", "10.1016/j.colegn.2016.09.008", "10.1080/0144929X.2017.1386714", "10.3389/fict.2017.00021", "10.1111/cgf.13169", "10.3389/fict.2016.00029", "10.3389/fpsyg.2019.00186", "10.3389/frobt.2019.00008", "10.29034/ijmra.v10n1a19", "10.1007/978-3-030-26649-3_16", "10.1007/s12652-020-01858-7", "10.1007/s12193-020-00341-z", "10.1007/978-3-030-34444-3_7", "10.1016/j.smhl.2020.100142", "10.3390/electronics9101623"], "referencing": ["10.1109/VR.2015.7223346", "10.1109/TBME.2009.2038487", "10.1109/TVCG.2013.35", "10.1109/MCG.2009.55", "10.1109/VR.2015.7223346", "10.1109/TBME.2009.2038487", "10.1109/TVCG.2013.35", "10.1109/MCG.2009.55", "10.1109/VR.2015.7223346", "10.1109/TBME.2009.2038487", "10.1109/TVCG.2013.35", "10.1109/MCG.2009.55", "10.1145/1823738.1823740", "10.1145/2628257.2628267", "10.1145/2024676.2024678", "10.1145/2804408.2804413", "10.1145/1240624.1240861", "10.1145/2628257.2628270", "10.1145/1823738.1823740", "10.1145/2628257.2628267", "10.1145/2024676.2024678", "10.1145/2804408.2804413", "10.1145/1240624.1240861", "10.1145/2628257.2628270", "10.1145/1823738.1823740", "10.1145/2628257.2628267", "10.1145/2024676.2024678", "10.1145/2804408.2804413", "10.1145/1240624.1240861", "10.1145/2628257.2628270", "10.1177/0146167203029007002", "10.1162/105474605774785235", "10.1007/978-3-642-39351-8_45", "10.1016/j.compedu.2005.11.010", "10.1007/11550617_33", "10.1016/j.chb.2008.12.026", "10.1007/978-3-642-33197-8_42", "10.1007/978-3-642-24571-8_6", "10.1016/j.ijhcs.2004.11.009", "10.1016/j.ijhcs.2004.11.009", "10.1016/j.chb.2014.01.033", "10.1007/978-3-319-09767-1_49", "10.1111/j.1525-1497.2006.00306.x", "10.1007/978-3-642-33197-8_8", "10.1037/a0022582", "10.1016/0301-0511(96)05183-6", "10.1037/0022-3514.54.6.1063", "10.1177/0146167203029007002", "10.1162/105474605774785235", "10.1007/978-3-642-39351-8_45", "10.1016/j.compedu.2005.11.010", "10.1007/11550617_33", "10.1016/j.chb.2008.12.026", "10.1007/978-3-642-33197-8_42", "10.1007/978-3-642-24571-8_6", "10.1016/j.ijhcs.2004.11.009", "10.1016/j.ijhcs.2004.11.009", "10.1016/j.chb.2014.01.033", "10.1007/978-3-319-09767-1_49", "10.1111/j.1525-1497.2006.00306.x", "10.1007/978-3-642-33197-8_8", "10.1037/a0022582", "10.1016/0301-0511(96)05183-6", "10.1037/0022-3514.54.6.1063", "10.1177/0146167203029007002", "10.1162/105474605774785235", "10.1007/978-3-642-39351-8_45", "10.1016/j.compedu.2005.11.010", "10.1007/11550617_33", "10.1016/j.chb.2008.12.026", "10.1007/978-3-642-33197-8_42", "10.1007/978-3-642-24571-8_6", "10.1016/j.ijhcs.2004.11.009", "10.1016/j.ijhcs.2004.11.009", "10.1016/j.chb.2014.01.033", "10.1007/978-3-319-09767-1_49", "10.1111/j.1525-1497.2006.00306.x", "10.1007/978-3-642-33197-8_8", "10.1037/a0022582", "10.1016/0301-0511(96)05183-6", "10.1037/0022-3514.54.6.1063"]}, "10.1109/TVCG.2016.2518405": {"doi": "10.1109/TVCG.2016.2518405", "author": ["A. Robb", "A. Kleinsmith", "A. Cordar", "C. White", "S. Lampotang", "A. Wendling", "B. Lok"], "title": "Do Variations in Agency Indirectly Affect Behavior with Others? An Analysis of Gaze Behavior", "year": "2016", "abstract": "In a group setting, it is possible for attributes of one group member to indirectly affect how other group members are perceived. In this paper, we explore whether one group member's agency (e.g. if they are real or virtual) can indirectly affect behavior with other group members. We also consider whether variations in the agency of a group member directly affects behavior with that group member. To do so, we examined gaze behavior during a team training exercise, in which sixty-nine nurses worked with a surgeon and an anesthesiologist to prepare a simulated patient for surgery. The agency of the surgeon and the anesthesiologist were varied between conditions. Nurses' gaze behavior was coded using videos of their interactions. Agency was observed to directly affect behavior, such that participants spent more time gazing at virtual teammates than human teammates. However, participants continued to obey polite gaze norms with virtual teammates. In contrast, agency was not observed to indirectly affect gaze behavior. The presence of a second human did not affect participants' gaze behavior with virtual teammates.", "keywords": ["human computer interaction", "patient treatment", "surgery", "virtual reality", "gaze behavior analysis", "group member agency", "surgery", "virtual teammate", "team training exercise", "Surgery", "Face", "Training", "Videos", "Measurement", "Data models", "Robots", "Virtual humans", "Gaze", "Agency", "Virtual humans", "Gaze", "Agency", "Adult", "Aged", "Computer Graphics", "Female", "Fixation, Ocular", "Humans", "Interpersonal Relations", "Male", "Middle Aged", "Psychology, Social", "User-Computer Interface", "Young Adult"], "referenced_by": ["10.1109/VR.2017.7892242", "10.1109/VR.2018.8446364", "10.3389/fict.2016.00017"], "referencing": ["10.1145/566654.566629", "10.1145/2724731", "10.1145/365024.365119", "10.1145/2070719.2070726", "10.1145/566654.566629", "10.1145/2724731", "10.1145/365024.365119", "10.1145/2070719.2070726", "10.1145/566654.566629", "10.1145/2724731", "10.1145/365024.365119", "10.1145/2070719.2070726", "10.1007/978-3-642-40415-3_22", "10.1177/0146167203029007002", "10.1037/0012-1649.38.3.438", "10.3758/BF03195338", "10.1111/j.2044-8309.1981.tb00492.x", "10.3758/BF03211385", "10.1177/0146167202238369", "10.1371/journal.pone.0071569", "10.1007/978-3-319-21996-7_48", "10.1007/978-3-540-74997-4_27", "10.1016/j.chb.2014.04.043", "10.1348/000712608X371762", "10.3115/1075096.1075166", "10.1007/11550617_21", "10.1016/j.chb.2015.05.043", "10.1177/0956797613497969", "10.1007/978-3-642-23974-8_24", "10.1007/978-3-642-40415-3_22", "10.1177/0146167203029007002", "10.1037/0012-1649.38.3.438", "10.3758/BF03195338", "10.1111/j.2044-8309.1981.tb00492.x", "10.3758/BF03211385", "10.1177/0146167202238369", "10.1371/journal.pone.0071569", "10.1007/978-3-319-21996-7_48", "10.1007/978-3-540-74997-4_27", "10.1016/j.chb.2014.04.043", "10.1348/000712608X371762", "10.3115/1075096.1075166", "10.1007/11550617_21", "10.1016/j.chb.2015.05.043", "10.1177/0956797613497969", "10.1007/978-3-642-23974-8_24", "10.1007/978-3-642-40415-3_22", "10.1177/0146167203029007002", "10.1037/0012-1649.38.3.438", "10.3758/BF03195338", "10.1111/j.2044-8309.1981.tb00492.x", "10.3758/BF03211385", "10.1177/0146167202238369", "10.1371/journal.pone.0071569", "10.1007/978-3-319-21996-7_48", "10.1007/978-3-540-74997-4_27", "10.1016/j.chb.2014.04.043", "10.1348/000712608X371762", "10.3115/1075096.1075166", "10.1007/11550617_21", "10.1016/j.chb.2015.05.043", "10.1177/0956797613497969", "10.1007/978-3-642-23974-8_24"]}, "10.1109/TVCG.2016.2518421": {"doi": "10.1109/TVCG.2016.2518421", "author": ["A. Rungta", "C. Schissler", "R. Mehra", "C. Malloy", "M. Lin", "D. Manocha"], "title": "SynCoPation: Interactive Synthesis-Coupled Sound Propagation", "year": "2016", "abstract": "Recent research in sound simulation has focused on either sound synthesis or sound propagation, and many standalone algorithms have been developed for each domain. We present a novel technique for coupling sound synthesis with sound propagation to automatically generate realistic aural content for virtual environments. Our approach can generate sounds from rigid-bodies based on the vibration modes and radiation coefficients represented by the single-point multipole expansion. We present a mode-adaptive propagation algorithm that uses a perceptual Hankel function approximation technique to achieve interactive runtime performance. The overall approach allows for high degrees of dynamism - it can support dynamic sources, dynamic listeners, and dynamic directivity simultaneously. We have integrated our system with the Unity game engine and demonstrate the effectiveness of this fully-automatic technique for audio content creation in complex indoor and outdoor scenes. We conducted a preliminary, online user-study to evaluate whether our Hankel function approximation causes any perceptible loss of audio quality. The results indicate that the subjects were unable to distinguish between the audio rendered using the approximate function and audio rendered using the full Hankel function in the Cathedral, Tuscany, and the Game benchmarks.", "keywords": ["approximation theory", "computer games", "Hankel matrices", "interactive systems", "virtual reality", "SynCoPation", "interactive synthesis-coupled sound propagation", "sound simulation", "sound synthesis", "virtual environments", "vibration modes", "radiation coefficients", "single-point multipole expansion", "perceptual Hankel function approximation technique", "Unity game engine", "Games", "Vibrations", "Solid modeling", "Mathematical model", "Boundary conditions", "Acoustics", "Engines", "Sound Synthesis", "Sound Propagation", "Physically-based Modeling", "Sound Synthesis", "Sound Propagation", "Physically-based Modeling"], "referenced_by": ["10.1145/2943779", "10.1007/s00371-017-1383-8", "10.46373/hafebid.782639"], "referencing": ["10.1109/78.553485", "10.1109/TVCG.2014.38", "10.1109/TVCG.2015.2391858", "10.1109/ISMAR.2014.6948409", "10.1109/TVCG.2013.26", "10.1109/78.553485", "10.1109/TVCG.2014.38", "10.1109/TVCG.2015.2391858", "10.1109/ISMAR.2014.6948409", "10.1109/TVCG.2013.26", "10.1109/78.553485", "10.1109/TVCG.2014.38", "10.1109/TVCG.2015.2391858", "10.1109/ISMAR.2014.6948409", "10.1109/TVCG.2013.26", "10.1145/2077341.2077348", "10.1145/1618452.1618465", "10.1145/280814.280818", "10.1145/1141911.1141983", "10.1145/1805964.1805965", "10.1145/545261.545290", "10.1145/1111411.1111429", "10.1145/2601097.2601184", "10.1145/2159616.2159618", "10.1145/1358628.1358969", "10.1145/2601097.2601216", "10.1145/1631272.1631311", "10.1145/383259.383323", "10.1145/1015706.1015710", "10.1145/383259.383322", "10.1145/1531326.1531343", "10.1145/2010324.1964933", "10.1145/2077341.2077348", "10.1145/1618452.1618465", "10.1145/280814.280818", "10.1145/1141911.1141983", "10.1145/1805964.1805965", "10.1145/545261.545290", "10.1145/1111411.1111429", "10.1145/2601097.2601184", "10.1145/2159616.2159618", "10.1145/1358628.1358969", "10.1145/2601097.2601216", "10.1145/1631272.1631311", "10.1145/383259.383323", "10.1145/1015706.1015710", "10.1145/383259.383322", "10.1145/1531326.1531343", "10.1145/2010324.1964933", "10.1145/2077341.2077348", "10.1145/1618452.1618465", "10.1145/280814.280818", "10.1145/1141911.1141983", "10.1145/1805964.1805965", "10.1145/545261.545290", "10.1145/1111411.1111429", "10.1145/2601097.2601184", "10.1145/2159616.2159618", "10.1145/1358628.1358969", "10.1145/2601097.2601216", "10.1145/1631272.1631311", "10.1145/383259.383323", "10.1145/1015706.1015710", "10.1145/383259.383322", "10.1145/1531326.1531343", "10.1145/2010324.1964933", "10.1080/17470210701814451", "10.1155/2007/70540", "10.1121/1.426873", "10.1016/S0010-0277(01)00151-2", "10.1121/1.2766781", "10.1016/0378-5955(79)90025-X", "10.1007/s10055-015-0267-3", "10.1016/j.ijhcs.2009.07.007", "10.1121/1.398336", "10.1080/17470210701814451", "10.1155/2007/70540", "10.1121/1.426873", "10.1016/S0010-0277(01)00151-2", "10.1121/1.2766781", "10.1016/0378-5955(79)90025-X", "10.1007/s10055-015-0267-3", "10.1016/j.ijhcs.2009.07.007", "10.1121/1.398336", "10.1080/17470210701814451", "10.1155/2007/70540", "10.1121/1.426873", "10.1016/S0010-0277(01)00151-2", "10.1121/1.2766781", "10.1016/0378-5955(79)90025-X", "10.1007/s10055-015-0267-3", "10.1016/j.ijhcs.2009.07.007", "10.1121/1.398336"]}, "10.1109/TVCG.2016.2518134": {"doi": "10.1109/TVCG.2016.2518134", "author": ["C. Schissler", "A. Nicholls", "R. Mehra"], "title": "Efficient HRTF-based Spatial Audio for Area and Volumetric Sources", "year": "2016", "abstract": "We present a novel spatial audio rendering technique to handle sound sources that can be represented by either an area or a volume in VR environments. As opposed to point-sampled sound sources, our approach projects the area-volumetric source to the spherical domain centered at the listener and represents this projection area compactly using the spherical harmonic (SH) basis functions. By representing the head-related transfer function (HRTF) in the same basis, we demonstrate that spatial audio which corresponds to an area-volumetric source can be efficiently computed as a dot product of the SH coefficients of the projection area and the HRTF. This results in an efficient technique whose computational complexity and memory requirements are independent of the complexity of the sound source. Our approach can support dynamic area-volumetric sound sources at interactive rates. We evaluate the performance of our technique in large complex VR environments and demonstrate significant improvement over the naive point-sampling technique. We also present results of a user evaluation, conducted to quantify the subjective preference of the user for our approach over the point-sampling approach in VR environments.", "keywords": ["audio signal processing", "rendering (computer graphics)", "virtual reality", "HRTF", "spatial audio rendering technique", "VR environments", "point sampled sound sources", "area-volumetric source", "spherical harmonic", "head related transfer function", "spatial audio", "computational complexity", "memory requirements", "sound source complexity", "interactive rates", "virtual reality", "Ear", "Harmonic analysis", "Rendering (computer graphics)", "Three-dimensional displays", "Virtual environments", "Transfer functions", "Spatial audio", "HRTF", "area sources", "volumetric sources", "spherical harmonics", "Spatial audio", "HRTF", "area sources", "volumetric sources", "spherical harmonics"], "referenced_by": ["10.1109/SIVE.2017.7901610", "10.1109/MCG.2018.193142628", "10.1109/SIVE.2018.8577195", "10.1109/CyberC.2018.00051", "10.1109/TVCG.2019.2898787", "10.1109/ACCESS.2019.2921388", "10.1109/ICMEW.2019.00075", "10.1109/SII46433.2020.9025981", "10.1145/2943779", "10.1145/3197517.3201391", "10.1145/3272127.3275100", "10.1002/cav.1756", "10.1007/978-3-319-65708-0_8", "10.3390/sym9090189", "10.3390/app7050532", "10.3390/s17051141", "10.3390/sym9050078", "10.15701/kcgs.2017.23.5.39", "10.3390/sym10040109", "10.2478/cjece-2018-0020", "10.3390/sym11040476", "10.1121/1.5096178", "10.1007/s11042-019-08220-w", "10.3390/sym12010053", "10.1080/09298215.2019.1708413", "10.1371/journal.pone.0241498", "10.3390/electronics9111863", "10.9728/dcs.2020.21.10.1759", "10.1002/cav.1985", "10.3390/acoustics3010003"], "referencing": ["10.1109/TVCG.2014.38", "10.1109/JSTSP.2015.2421876", "10.1109/VR.2006.33", "10.1109/TVCG.2014.38", "10.1109/JSTSP.2015.2421876", "10.1109/VR.2006.33", "10.1109/TVCG.2014.38", "10.1109/JSTSP.2015.2421876", "10.1109/VR.2006.33", "10.1145/325165.325171", "10.1145/964965.808590", "10.1145/325165.325171", "10.1145/964965.808590", "10.1145/325165.325171", "10.1145/964965.808590", "10.1111/cgf.12259", "10.1121/1.382599", "10.1121/1.413219", "10.1121/1.423749", "10.1162/pres.1996.5.3.290", "10.1121/1.428321", "10.1121/1.2434761", "10.1016/0003-682X(92)90046-U", "10.1142/9789814299312_0028", "10.1121/1.3278605", "10.1007/978-3-642-57963-9_6", "10.1121/1.422547", "10.1111/cgf.12259", "10.1121/1.382599", "10.1121/1.413219", "10.1121/1.423749", "10.1162/pres.1996.5.3.290", "10.1121/1.428321", "10.1121/1.2434761", "10.1016/0003-682X(92)90046-U", "10.1142/9789814299312_0028", "10.1121/1.3278605", "10.1007/978-3-642-57963-9_6", "10.1121/1.422547", "10.1111/cgf.12259", "10.1121/1.382599", "10.1121/1.413219", "10.1121/1.423749", "10.1162/pres.1996.5.3.290", "10.1121/1.428321", "10.1121/1.2434761", "10.1016/0003-682X(92)90046-U", "10.1142/9789814299312_0028", "10.1121/1.3278605", "10.1007/978-3-642-57963-9_6", "10.1121/1.422547"]}, "10.1109/TVCG.2016.2518038": {"doi": "10.1109/TVCG.2016.2518038", "author": ["P. Lincoln", "A. Blate", "M. Singh", "T. Whitted", "A. State", "A. Lastra", "H. Fuchs"], "title": "From Motion to Photons in 80 Microseconds: Towards Minimal Latency for Virtual and Augmented Reality", "year": "2016", "abstract": "We describe an augmented reality, optical see-through display based on a DMD chip with an extremely fast (16 kHz) binary update rate. We combine the techniques of post-rendering 2-D offsets and just-in-time tracking updates with a novel modulation technique for turning binary pixels into perceived gray scale. These processing elements, implemented in an FPGA, are physically mounted along with the optical display elements in a head tracked rig through which users view synthetic imagery superimposed on their real environment. The combination of mechanical tracking at near-zero latency with reconfigurable display processing has given us a measured average of 80 \u03bcs of end-to-end latency (from head motion to change in photons from the display) and also a versatile test platform for extremely-low-latency display systems. We have used it to examine the trade-offs between image quality and cost (i.e. power and logical complexity) and have found that quality can be maintained with a fairly simple display modulation scheme.", "keywords": ["augmented reality", "computer displays", "field programmable gate arrays", "rendering (computer graphics)", "minimal latency", "augmented reality", "virtual reality", "optical see-through display", "DMD chip", "binary update rate", "post-rendering 2-D offsets", "just-in-time tracking updates", "modulation technique", "binary pixels", "perceived gray scale", "FPGA", "optical display elements", "head tracked rig", "synthetic imagery", "mechanical tracking", "near-zero latency", "reconfigurable display processing", "end-to-end latency", "extremely-low-latency display systems", "image quality", "display modulation scheme", "Rendering (computer graphics)", "Field programmable gate arrays", "Tracking", "Modulation", "Graphics processing units", "Delays", "Optical imaging", "Augmented reality", "latency", "display modulation", "Augmented reality", "latency", "display modulation"], "referenced_by": ["10.1109/3DUI.2017.7893317", "10.1109/ISMAR-Adjunct.2016.0072", "10.1109/ISMAR-Adjunct.2017.61", "10.1109/ISMAR.2017.19", "10.1109/TVCG.2016.2592910", "10.1109/TVCG.2017.2656979", "10.1109/TVCG.2017.2734427", "10.1109/ISMAR.2017.26", "10.1109/TVCG.2017.2754257", "10.1109/TVCG.2018.2868570", "10.1109/CVPR.2018.00507", "10.1109/ACCESS.2018.2888700", "10.1109/TVCG.2019.2898741", "10.1109/TVCG.2019.2899233", "10.1109/ISMAR-Adjunct.2018.00050", "10.1109/VR.2019.8797850", "10.1109/ConTEL.2019.8848531", "10.1109/TVCG.2019.2932224", "10.1109/TVCG.2019.2932248", "10.1109/MMSP.2019.8901715", "10.1109/MCG.2020.2980183", "10.1145/3272127.3275015", "10.1007/978-3-319-54502-8_8", "10.3390/s17051112", "10.1111/cgf.13128", "10.3389/fict.2016.00034", "10.3390/electronics7090171", "10.1007/978-3-030-13940-7_2", "10.1364/OE.27.009258", "10.3390/electronics8070815", "10.1002/jsid.848", "10.1364/OE.380858", "10.1007/978-3-030-52575-0_20", "10.1364/OE.401778"], "referencing": ["10.1109/79.482138", "10.1109/38.403828", "10.1109/ISMAR.2008.4637329", "10.1109/TVCG.2009.75", "10.1109/ISMAR.2014.6948427", "10.1109/79.482138", "10.1109/38.403828", "10.1109/ISMAR.2008.4637329", "10.1109/TVCG.2009.75", "10.1109/ISMAR.2014.6948427", "10.1109/79.482138", "10.1109/38.403828", "10.1109/ISMAR.2008.4637329", "10.1109/TVCG.2009.75", "10.1109/ISMAR.2014.6948427", "10.1145/192161.192195", "10.1145/253284.253306", "10.1145/253284.253292", "10.1145/218380.218398", "10.1145/199404.199407", "10.1145/344779.344979", "10.1145/192161.192192", "10.1145/280814.280882", "10.1145/1450579.1450605", "10.1145/192161.192195", "10.1145/253284.253306", "10.1145/253284.253292", "10.1145/218380.218398", "10.1145/199404.199407", "10.1145/344779.344979", "10.1145/192161.192192", "10.1145/280814.280882", "10.1145/1450579.1450605", "10.1145/192161.192195", "10.1145/253284.253306", "10.1145/253284.253292", "10.1145/218380.218398", "10.1145/199404.199407", "10.1145/344779.344979", "10.1145/192161.192192", "10.1145/280814.280882", "10.1145/1450579.1450605", "10.1162/pres.1997.6.4.355", "10.1147/sj.41.0025", "10.1177/0018720811428734", "10.1162/pres.1997.6.4.413", "10.1117/12.273880", "10.1007/978-3-7091-6809-7_3", "10.1162/pres.1997.6.4.355", "10.1147/sj.41.0025", "10.1177/0018720811428734", "10.1162/pres.1997.6.4.413", "10.1117/12.273880", "10.1007/978-3-7091-6809-7_3", "10.1162/pres.1997.6.4.355", "10.1147/sj.41.0025", "10.1177/0018720811428734", "10.1162/pres.1997.6.4.413", "10.1117/12.273880", "10.1007/978-3-7091-6809-7_3"]}, "10.1109/TVCG.2016.2518079": {"doi": "10.1109/TVCG.2016.2518079", "author": ["S. Friston", "A. Steed", "S. Tilbury", "G. Gaydadjiev"], "title": "Construction and Evaluation of an Ultra Low Latency Frameless Renderer for VR", "year": "2016", "abstract": "Latency - the delay between a user's action and the response to this action - is known to be detrimental to virtual reality. Latency is typically considered to be a discrete value characterising a delay, constant in time and space - but this characterisation is incomplete. Latency changes across the display during scan-out, and how it does so is dependent on the rendering approach used. In this study, we present an ultra-low latency real-time ray-casting renderer for virtual reality, implemented on an FPGA. Our renderer has a latency of ~1 ms from `tracker to pixel'. Its frameless nature means that the region of the display with the lowest latency immediately follows the scan-beam. This is in contrast to frame-based systems such as those using typical GPUs, for which the latency increases as scan-out proceeds. Using a series of high and low speed videos of our system in use, we confirm its latency of ~1 ms. We examine how the renderer performs when driving a traditional sequential scan-out display on a readily available HMD, the Oculus Rift DK2. We contrast this with an equivalent apparatus built using a GPU. Using captured human head motion and a set of image quality measures, we assess the ability of these systems to faithfully recreate the stimuli of an ideal virtual reality system - one with a zero latency tracker, renderer and display running at 1 kHz. Finally, we examine the results of these quality measures, and how each rendering approach is affected by velocity of movement and display persistence. We find that our system, with a lower average latency, can more faithfully draw what the ideal virtual reality system would. Further, we find that with low display persistence, the sensitivity to velocity of both systems is lowered, but that it is much lower for ours.", "keywords": ["field programmable gate arrays", "graphics processing units", "virtual reality", "ultra low latency frameless renderer", "VR", "virtual reality", "discrete value", "rendering approach", "FPGA", "sequential scan out display", "Oculus Rift DK2", "GPU", "human head motion", "image quality measurement", "virtual reality system", "Rendering (computer graphics)", "Hardware", "Virtual reality", "Image quality", "Delays", "Ray tracing", "Graphics processing units", "Low Latency", "Frameless Rendering", "Image Quality", "Ray Casting", "Hardware Acceleration", "Low Latency", "Frameless Rendering", "Image Quality", "Ray Casting", "Hardware Acceleration"], "referenced_by": ["10.1109/CISP-BMEI.2017.8301926", "10.1109/ACCESS.2018.2888700", "10.1109/TCSVT.2019.2898732", "10.1145/3306346.3323033", "10.1080/1206212X.2017.1397341", "10.1163/22134808-00002545", "10.1111/cgf.13150", "10.1007/978-3-030-13803-5_8", "10.1007/978-3-030-13803-5_2", "10.1002/jsid.848", "10.1016/j.micpro.2020.103773"], "referencing": ["10.1109/ISMAR.2014.6948427", "10.1109/ISMAR.2014.6948427", "10.1109/ISMAR.2014.6948427", "10.1145/15886.15889", "10.1145/1198555.1198763", "10.1145/253284.253292", "10.1145/2380116.2380174", "10.1145/344779.344979", "10.1145/192161.192192", "10.1145/311535.311569", "10.1145/15886.15889", "10.1145/1198555.1198763", "10.1145/253284.253292", "10.1145/2380116.2380174", "10.1145/344779.344979", "10.1145/192161.192192", "10.1145/311535.311569", "10.1145/15886.15889", "10.1145/1198555.1198763", "10.1145/253284.253292", "10.1145/2380116.2380174", "10.1145/344779.344979", "10.1145/192161.192192", "10.1145/311535.311569", "10.1177/0018720811428734", "10.1162/pres_a_00023", "10.1007/BF00247595", "10.1167/13.7.6", "10.1111/1467-8659.00550", "10.1111/j.1467-8659.2010.01840.x", "10.1177/1071181311551451", "10.1007/978-3-319-14249-4_29", "10.1889/1.1985127", "10.1016/S0165-1684(98)00125-X", "10.1177/0018720811428734", "10.1162/pres_a_00023", "10.1007/BF00247595", "10.1167/13.7.6", "10.1111/1467-8659.00550", "10.1111/j.1467-8659.2010.01840.x", "10.1177/1071181311551451", "10.1007/978-3-319-14249-4_29", "10.1889/1.1985127", "10.1016/S0165-1684(98)00125-X", "10.1177/0018720811428734", "10.1162/pres_a_00023", "10.1007/BF00247595", "10.1167/13.7.6", "10.1111/1467-8659.00550", "10.1111/j.1467-8659.2010.01840.x", "10.1177/1071181311551451", "10.1007/978-3-319-14249-4_29", "10.1889/1.1985127", "10.1016/S0165-1684(98)00125-X"]}, "10.1109/TVCG.2016.2518137": {"doi": "10.1109/TVCG.2016.2518137", "author": ["C. Schatzschneider", "G. Bruder", "F. Steinicke"], "title": "Who turned the clock? Effects of Manipulated Zeitgebers, Cognitive Load and Immersion on Time Estimation", "year": "2016", "abstract": "Current virtual reality (VR) technologies have enormous potential to allow humans to experience computer-generated immersive virtual environments (IVEs). Many of these IVEs support near-natural audiovisual stimuli similar to the stimuli generated in our physical world. However, decades of VR research have been devoted to exploring and understand differences between perception and action in such IVEs compared to real-world perception and action. Although, significant differences have been revealed for spatiotemporal perception between IVEs and the physical world such as distance underestimation, there is still a scarcity of knowledge about the reasons for such perceptual discrepancies, in particular regarding the perception of temporal durations in IVEs. In this article, we explore the effects of manipulated zeitgebers, cognitive load and immersion on time estimation as yet unexplored factors of spatiotemporal perception in IVEs. We present an experiment in which we analyze human sensitivity to temporal durations while experiencing an immersive head-mounted display (HMO) environment. We found that manipulations of external zeitgebers caused by a natural or unnatural movement of the virtual sun had a significant effect on time judgments. Moreover, using the dual-task paradigm the results show that increased spatial and verbal cognitive load resulted in a significant shortening of judged time as well as an interaction with the external zeitgebers. Finally, we discuss the implications for the design of near-natural computer-generated virtual worlds.", "keywords": ["helmet mounted displays", "virtual reality", "manipulated zeitgebers", "cognitive load", "time estimation", "virtual reality technologies", "computer-generated immersive virtual environments", "IVE", "near-natural audiovisual stimuli", "physical world", "VR research", "distance underestimation", "perceptual discrepancies", "temporal durations", "immersive head-mounted display environment", "HMD", "dual-task paradigm", "verbal cognitive load", "near-natural computer-generated virtual worlds", "Sun", "Estimation", "Clocks", "Virtual environments", "Games", "Circadian rhythm", "Sensitivity", "Time perception", "cognitive load", "virtual environments", "Time perception", "cognitive load", "virtual environments"], "referenced_by": ["10.1109/TVCG.2017.2657235", "10.1109/TVCG.2018.2793698", "10.1109/VR.2019.8797977", "10.1109/ISMAR.2019.00019", "10.1109/TVCG.2020.2973498", "10.1109/VR46266.2020.00070", "10.1109/VR46266.2020.00068", "10.3389/fict.2016.00029", "10.1016/j.chb.2019.01.005", "10.1177/0265378820963155"], "referencing": ["10.1109/TVCG.2015.2391864", "10.1109/3DUI.2009.4811208", "10.1109/IEMBS.2006.259562", "10.1109/TVCG.2015.2391864", "10.1109/3DUI.2009.4811208", "10.1109/IEMBS.2006.259562", "10.1109/TVCG.2015.2391864", "10.1109/3DUI.2009.4811208", "10.1109/IEMBS.2006.259562", "10.1145/2671015.2671026", "10.1145/2659766.2659767", "10.1145/2671015.2671026", "10.1145/2659766.2659767", "10.1145/2671015.2671026", "10.1145/2659766.2659767", "10.3109/07420528709078534", "10.3758/BF03210698", "10.1007/BF00586611", "10.1146/annurev-psych-120710-100422", "10.1016/S0079-7421(08)60452-1", "10.1007/978-3-540-73331-7_27", "10.1016/j.actpsy.2010.03.006", "10.3758/BF03198848", "10.3758/BF03210238", "10.1152/japplphysiol.00165.2011", "10.1080/17470210802321984", "10.1016/j.tics.2007.09.008", "10.1016/j.conb.2008.06.002", "10.3758/BF03210211", "10.1007/978-3-662-06085-8_8", "10.1016/0013-4694(93)90119-G", "10.1016/j.cpr.2006.07.001", "10.1080/00221309.1942.10545184", "10.1007/BF00345235", "10.1016/j.tics.2008.04.002", "10.2114/jpa2.26.95", "10.1207/s15327108ijap0303_3", "10.1016/j.neulet.2008.04.051", "10.1207/S15326985EP3801_8", "10.3109/07420529409067793", "10.1016/j.cub.2006.12.011", "10.1007/s00520-010-0852-7", "10.3758/BF03199347", "10.1016/j.chb.2008.12.002", "10.1089/cpb.2006.9994", "10.1016/S0966-6362(01)00156-4", "10.3109/07420528709078534", "10.3758/BF03210698", "10.1007/BF00586611", "10.1146/annurev-psych-120710-100422", "10.1016/S0079-7421(08)60452-1", "10.1007/978-3-540-73331-7_27", "10.1016/j.actpsy.2010.03.006", "10.3758/BF03198848", "10.3758/BF03210238", "10.1152/japplphysiol.00165.2011", "10.1080/17470210802321984", "10.1016/j.tics.2007.09.008", "10.1016/j.conb.2008.06.002", "10.3758/BF03210211", "10.1007/978-3-662-06085-8_8", "10.1016/0013-4694(93)90119-G", "10.1016/j.cpr.2006.07.001", "10.1080/00221309.1942.10545184", "10.1007/BF00345235", "10.1016/j.tics.2008.04.002", "10.2114/jpa2.26.95", "10.1207/s15327108ijap0303_3", "10.1016/j.neulet.2008.04.051", "10.1207/S15326985EP3801_8", "10.3109/07420529409067793", "10.1016/j.cub.2006.12.011", "10.1007/s00520-010-0852-7", "10.3758/BF03199347", "10.1016/j.chb.2008.12.002", "10.1089/cpb.2006.9994", "10.1016/S0966-6362(01)00156-4", "10.3109/07420528709078534", "10.3758/BF03210698", "10.1007/BF00586611", "10.1146/annurev-psych-120710-100422", "10.1016/S0079-7421(08)60452-1", "10.1007/978-3-540-73331-7_27", "10.1016/j.actpsy.2010.03.006", "10.3758/BF03198848", "10.3758/BF03210238", "10.1152/japplphysiol.00165.2011", "10.1080/17470210802321984", "10.1016/j.tics.2007.09.008", "10.1016/j.conb.2008.06.002", "10.3758/BF03210211", "10.1007/978-3-662-06085-8_8", "10.1016/0013-4694(93)90119-G", "10.1016/j.cpr.2006.07.001", "10.1080/00221309.1942.10545184", "10.1007/BF00345235", "10.1016/j.tics.2008.04.002", "10.2114/jpa2.26.95", "10.1207/s15327108ijap0303_3", "10.1016/j.neulet.2008.04.051", "10.1207/S15326985EP3801_8", "10.3109/07420529409067793", "10.1016/j.cub.2006.12.011", "10.1007/s00520-010-0852-7", "10.3758/BF03199347", "10.1016/j.chb.2008.12.002", "10.1089/cpb.2006.9994", "10.1016/S0966-6362(01)00156-4"]}, "10.1109/TVCG.2016.2518133": {"doi": "10.1109/TVCG.2016.2518133", "author": ["J. Baumeister", "J. Dorrian", "S. Banks", "A. Chatburn", "R. T. Smith", "M. A. Carskadon", "K. Lushington", "B. H. Thomas"], "title": "Augmented Reality as a Countermeasure for Sleep Deprivation", "year": "2016", "abstract": "Sleep deprivation is known to have serious deleterious effects on executive functioning and job performance. Augmented reality has an ability to place pertinent information at the fore, guiding visual focus and reducing instructional complexity. This paper presents a study to explore how spatial augmented reality instructions impact procedural task performance on sleep deprived users. The user study was conducted to examine performance on a procedural task at six time points over the course of a night of total sleep deprivation. Tasks were provided either by spatial augmented reality-based projections or on an adjacent monitor. The results indicate that participant errors significantly increased with the monitor condition when sleep deprived. The augmented reality condition exhibited a positive influence with participant errors and completion time having no significant increase when sleep deprived. The results of our study show that spatial augmented reality is an effective sleep deprivation countermeasure under laboratory conditions.", "keywords": ["augmented reality", "patient monitoring", "sleep", "job performance", "instructional complexity", "spatial augmented reality instructions", "sleep deprived users", "procedural task", "total sleep deprivation", "spatial augmented reality-based projections", "condition monitoring", "Sleep", "Augmented reality", "Monitoring", "Australia", "Safety", "Biomedical monitoring", "Visualization", "Spatial augmented reality", "sleep deprivation", "procedural task performance", "Spatial augmented reality", "sleep deprivation", "procedural task performance"], "referenced_by": ["10.1109/TVCG.2017.2735098"], "referencing": ["10.1109/ISMAR.2013.6671826", "10.1109/ISMAR.2009.5336486", "10.1109/ISMAR.2011.6092386", "10.1109/ISMAR.2014.6948425", "10.1109/ISMAR.2013.6671762", "10.1109/ISMAR.2006.297803", "10.1109/ISMAR.2013.6671826", "10.1109/ISMAR.2009.5336486", "10.1109/ISMAR.2011.6092386", "10.1109/ISMAR.2014.6948425", "10.1109/ISMAR.2013.6671762", "10.1109/ISMAR.2006.297803", "10.1109/ISMAR.2013.6671826", "10.1109/ISMAR.2009.5336486", "10.1109/ISMAR.2011.6092386", "10.1109/ISMAR.2014.6948425", "10.1109/ISMAR.2013.6671762", "10.1109/ISMAR.2006.297803", "10.1145/642625.642626", "10.1145/642625.642626", "10.1145/642625.642626", "10.1177/1094428104263672", "10.1136/oem.2004.017632", "10.1056/NEJM199005033221801", "10.1016/j.smrv.2005.03.002", "10.1038/nrn2762", "10.1210/jc.2009-2430", "10.1590/S0034-89102011005000059", "10.3109/03009749709065709", "10.1016/j.smrv.2006.11.001", "10.1055/s-2005-867080", "10.1016/S0002-9610(03)00183-1", "10.1093/occmed/kqg047", "10.1007/BFb0056282", "10.1518/001872098779480578", "10.1007/s11548-009-0365-3", "10.1006/obhd.1999.2827", "10.1037/1076-898X.6.3.236", "10.1007/s10055-010-0179-1", "10.1038/sj.npp.1301534", "10.1111/j.1365-2869.1995.tb00230.x", "10.1080/00207540601064773", "10.1136/bmj.316.7139.1236", "10.1046/j.1365-2869.2002.00309.x", "10.1016/j.phrs.2010.04.002", "10.1007/978-0-387-77405-3_39", "10.1016/S0140-6736(98)00034-8", "10.1080/0267837031000155949", "10.1016/S0076-6879(04)84010-2", "10.5271/sjweh.3146", "10.1016/0001-6918(77)90012-9", "10.1136/oem.57.10.649", "10.1177/1094428104263672", "10.1136/oem.2004.017632", "10.1056/NEJM199005033221801", "10.1016/j.smrv.2005.03.002", "10.1038/nrn2762", "10.1210/jc.2009-2430", "10.1590/S0034-89102011005000059", "10.3109/03009749709065709", "10.1016/j.smrv.2006.11.001", "10.1055/s-2005-867080", "10.1016/S0002-9610(03)00183-1", "10.1093/occmed/kqg047", "10.1007/BFb0056282", "10.1518/001872098779480578", "10.1007/s11548-009-0365-3", "10.1006/obhd.1999.2827", "10.1037/1076-898X.6.3.236", "10.1007/s10055-010-0179-1", "10.1038/sj.npp.1301534", "10.1111/j.1365-2869.1995.tb00230.x", "10.1080/00207540601064773", "10.1136/bmj.316.7139.1236", "10.1046/j.1365-2869.2002.00309.x", "10.1016/j.phrs.2010.04.002", "10.1007/978-0-387-77405-3_39", "10.1016/S0140-6736(98)00034-8", "10.1080/0267837031000155949", "10.1016/S0076-6879(04)84010-2", "10.5271/sjweh.3146", "10.1016/0001-6918(77)90012-9", "10.1136/oem.57.10.649", "10.1177/1094428104263672", "10.1136/oem.2004.017632", "10.1056/NEJM199005033221801", "10.1016/j.smrv.2005.03.002", "10.1038/nrn2762", "10.1210/jc.2009-2430", "10.1590/S0034-89102011005000059", "10.3109/03009749709065709", "10.1016/j.smrv.2006.11.001", "10.1055/s-2005-867080", "10.1016/S0002-9610(03)00183-1", "10.1093/occmed/kqg047", "10.1007/BFb0056282", "10.1518/001872098779480578", "10.1007/s11548-009-0365-3", "10.1006/obhd.1999.2827", "10.1037/1076-898X.6.3.236", "10.1007/s10055-010-0179-1", "10.1038/sj.npp.1301534", "10.1111/j.1365-2869.1995.tb00230.x", "10.1080/00207540601064773", "10.1136/bmj.316.7139.1236", "10.1046/j.1365-2869.2002.00309.x", "10.1016/j.phrs.2010.04.002", "10.1007/978-0-387-77405-3_39", "10.1016/S0140-6736(98)00034-8", "10.1080/0267837031000155949", "10.1016/S0076-6879(04)84010-2", "10.5271/sjweh.3146", "10.1016/0001-6918(77)90012-9", "10.1136/oem.57.10.649"]}, "10.1109/TVCG.2016.2518135": {"doi": "10.1109/TVCG.2016.2518135", "author": ["A. Steed", "S. Frlston", "M. M. Lopez", "J. Drummond", "Y. Pan", "D. Swapp"], "title": "An \u2018In the Wild\u2019 Experiment on Presence and Embodiment using Consumer Virtual Reality Equipment", "year": "2016", "abstract": "Consumer virtual reality systems are now becoming widely available. We report on a study on presence and embodiment within virtual reality that was conducted `in the wild', in that data was collected from devices owned by consumers in uncontrolled settings, not in a traditional laboratory setting. Users of Samsung Gear VR and Google Cardboard devices were invited by web pages and email invitation to download and run an app that presented a scenario where the participant would sit in a bar watching a singer. Each participant saw one of eight variations of the scenario: with or without a self-avatar; singer inviting the participant to tap along or not; singer looking at the participant or not. Despite the uncontrolled situation of the experiment, results from an in-app questionnaire showed tentative evidence that a self-avatar had a positive effect on self-report of presence and embodiment, and that the singer inviting the participant to tap along had a negative effect on self-report of embodiment. We discuss the limitations of the study and the platforms, and the potential for future open virtual reality experiments.", "keywords": ["human factors", "virtual reality", "consumer virtual reality equipment", "Samsung Gear VR", "Google cardboard devices", "Web pages", "self-avatar", "self-report", "Virtual reality", "Data collection", "Rubber", "Gears", "Google", "Guidelines", "Ethics", "virtual reality", "consumer equipment", "head-mounted display", "presence", "embodiment", "self-avatar", "virtual reality", "consumer equipment", "head-mounted display", "presence", "embodiment", "self-avatar"], "referenced_by": ["10.1109/ICME.2017.8019388", "10.1109/MMSP.2017.8122249", "10.1109/ICUFN.2017.7993736", "10.1109/TVCG.2017.2767590", "10.1109/ICALIP.2018.8455477", "10.1109/ACCESS.2019.2933014", "10.1109/TVCG.2019.2934803", "10.1109/ACCESS.2020.3015556", "10.1109/ISMAR50242.2020.00072", "10.1145/3209661", "10.1145/3083187.3083210", "10.1145/3329119", "10.1145/3389210", "10.1145/3406098", "10.1002/cav.1804", "10.1088/1361-665X/aa6b64", "10.3390/computers7010015", "10.1587/transinf.2017MUP0011", "10.3389/frobt.2018.00026", "10.1080/17511321.2018.1475418", "10.3389/frobt.2018.00112", "10.1080/10447318.2018.1541546", "10.3390/informatics6020018", "10.3390/app9163384", "10.3389/fneur.2019.01061", "10.1371/journal.pone.0227629", "10.1002/cav.1920", "10.1177/2158244020922878", "10.3390/electronics9091530", "10.1007/978-3-030-62655-6_15", "10.3389/frvir.2020.561558", "10.1016/j.micpro.2020.103516"], "referencing": ["10.1145/1978942.1979185", "10.1145/2207676.2208338", "10.1145/1851600.1851671", "10.1145/2492494.2492511", "10.1145/2077451.2077458", "10.1145/2470654.2466245", "10.1145/2639189.2639239", "10.1145/1450579.1450614", "10.1145/311535.311589", "10.1145/1978942.1979185", "10.1145/2207676.2208338", "10.1145/1851600.1851671", "10.1145/2492494.2492511", "10.1145/2077451.2077458", "10.1145/2470654.2466245", "10.1145/2639189.2639239", "10.1145/1450579.1450614", "10.1145/311535.311589", "10.1145/1978942.1979185", "10.1145/2207676.2208338", "10.1145/1851600.1851671", "10.1145/2492494.2492511", "10.1145/2077451.2077458", "10.1145/2470654.2466245", "10.1145/2639189.2639239", "10.1145/1450579.1450614", "10.1145/311535.311589", "10.1007/978-3-319-07632-4_40", "10.1525/bio.2009.59.11.9", "10.1038/35784", "10.1162/pres.1992.1.2.262", "10.4018/jmhci.2011100105", "10.1038/nsmb.2119", "10.1162/105474601300343612", "10.1371/journal.pone.0010381", "10.1089/109493101300117884", "10.1057/jit.2010.25", "10.1098/rstb.2009.0138", "10.3389/neuro.09.006.2008", "10.1162/105474600566925", "10.1162/pres.1994.3.2.130", "10.1162/pres.1997.6.6.603", "10.1162/105474600566989", "10.1162/105474698565686", "10.1007/978-3-319-07632-4_40", "10.1525/bio.2009.59.11.9", "10.1038/35784", "10.1162/pres.1992.1.2.262", "10.4018/jmhci.2011100105", "10.1038/nsmb.2119", "10.1162/105474601300343612", "10.1371/journal.pone.0010381", "10.1089/109493101300117884", "10.1057/jit.2010.25", "10.1098/rstb.2009.0138", "10.3389/neuro.09.006.2008", "10.1162/105474600566925", "10.1162/pres.1994.3.2.130", "10.1162/pres.1997.6.6.603", "10.1162/105474600566989", "10.1162/105474698565686", "10.1007/978-3-319-07632-4_40", "10.1525/bio.2009.59.11.9", "10.1038/35784", "10.1162/pres.1992.1.2.262", "10.4018/jmhci.2011100105", "10.1038/nsmb.2119", "10.1162/105474601300343612", "10.1371/journal.pone.0010381", "10.1089/109493101300117884", "10.1057/jit.2010.25", "10.1098/rstb.2009.0138", "10.3389/neuro.09.006.2008", "10.1162/105474600566925", "10.1162/pres.1994.3.2.130", "10.1162/pres.1997.6.6.603", "10.1162/105474600566989", "10.1162/105474698565686"]}, "10.1109/TVCG.2016.2518318": {"doi": "10.1109/TVCG.2016.2518318", "author": ["J. B. Madsen", "M. Tatzqern", "C. B. Madsen", "D. Schmalstieg", "D. Kalkofen"], "title": "Temporal Coherence Strategies for Augmented Reality Labeling", "year": "2016", "abstract": "Temporal coherence of annotations is an important factor in augmented reality user interfaces and for information visualization. In this paper, we empirically evaluate four different techniques for annotation. Based on these findings, we follow up with subjective evaluations in a second experiment. Results show that presenting annotations in object space or image space leads to a significant difference in task performance. Furthermore, there is a significant interaction between rendering space and update frequency of annotations. Participants improve significantly in locating annotations, when annotations are presented in object space, and view management update rate is limited. In a follow-up experiment, participants appear to be more satisfied with limited update rate in comparison to a continuous update rate of the view management system.", "keywords": ["augmented reality", "data visualisation", "rendering (computer graphics)", "user interfaces", "temporal coherence strategies", "augmented reality labeling", "augmented reality user interfaces", "information visualization", "image space", "object space", "rendering space", "annotation update frequency", "view management update rate", "Layout", "Three-dimensional displays", "Image resolution", "Coherence", "Force", "Animation", "Data visualization"], "referenced_by": ["10.1109/VR.2017.7892321", "10.1109/ISMAR-Adjunct.2016.0033", "10.1109/TVCG.2018.2868587", "10.1007/978-3-319-40621-3_26", "10.1016/j.cag.2017.03.003", "10.1177/1473871618799500", "10.1007/978-3-030-11051-2_62", "10.3934/ElectrEng.2019.1.71", "10.1111/cgf.13729", "10.3390/s19194330"], "referencing": ["10.1109/TVCG.2006.136", "10.1109/TVCG.2007.70539", "10.1109/VR.2014.6802046", "10.1109/TVCG.2006.136", "10.1109/TVCG.2007.70539", "10.1109/VR.2014.6802046", "10.1109/TVCG.2006.136", "10.1109/TVCG.2007.70539", "10.1109/VR.2014.6802046", "10.1145/502360.502363", "10.1145/108844.108883", "10.1145/1054972.1055078", "10.1145/502360.502363", "10.1145/108844.108883", "10.1145/1054972.1055078", "10.1145/502360.502363", "10.1145/108844.108883", "10.1145/1054972.1055078", "10.1177/1473871611413180", "10.1007/978-3-540-24678-7_10", "10.1007/11536482_10", "10.1559/152304075784313304", "10.1007/978-3-642-02115-2_4", "10.1177/1473871611413180", "10.1007/978-3-540-24678-7_10", "10.1007/11536482_10", "10.1559/152304075784313304", "10.1007/978-3-642-02115-2_4", "10.1177/1473871611413180", "10.1007/978-3-540-24678-7_10", "10.1007/11536482_10", "10.1559/152304075784313304", "10.1007/978-3-642-02115-2_4"]}, "10.1109/TVCG.2016.2518136": {"doi": "10.1109/TVCG.2016.2518136", "author": ["S. Takeda", "D. Iwai", "K. Sato"], "title": "Inter-reflection Compensation of Immersive Projection Display by Spatio-Temporal Screen Reflectance Modulation", "year": "2016", "abstract": "We propose a novel inter-reflection compensation technique for immersive projection displays wherein we spatially modulate the reflectance pattern on the screen to improve the compensation performance of conventional methods. As the luminance of light reflected on a projection surface is mathematically represented as the multiplication of the illuminance of incident light and the surface reflectance, we can reduce undesirable intensity elevation because of inter-reflections by decreasing surface reflectance. Based on this principle, we improve conventional inter-reflection compensation techniques by applying reflectance pattern modulation. We realize spatial reflectance modulation of a projection screen by painting it with a photochromic compound, which changes its color (i.e., the reflectance of the screen) when ultraviolet (UV) light is applied and by controlling UV irradiation with a UV LED array placed behind the screen. The main contribution of this paper is a computational model to optimize a reflectance pattern for the accurate reproduction of a target appearance by decreasing the intensity elevation caused by inter-reflection while maintaining the maximum intensity of the target appearance. Through simulation and physical experiments, we demonstrate the feasibility of the proposed model and confirm its advantage over conventional methods.", "keywords": ["brightness", "computer displays", "LED displays", "ultraviolet radiation effects", "interreflection compensation technique", "immersive projection display", "spatio-temporal screen reflectance modulation", "reflectance pattern modulation", "light luminance", "incident light illuminance", "surface reflectance", "intensity elevation", "surface reflectance", "ultraviolet light", "UV irradiation", "UV LED array", "Modulation", "Light emitting diodes", "Image color analysis", "Computational modeling", "Shape", "Light sources", "Cameras", "Reverse radiosity", "inter-reflection compensation", "immersive projection display", "Reverse radiosity", "inter-reflecttdion compensation", "immersive projection display"], "referenced_by": ["10.1109/ICCV.2019.00726", "10.1111/cgf.13387", "10.4018/978-1-7998-2433-6.ch016"], "referencing": ["10.1109/VR.2006.34", "10.1109/TVCG.2010.104", "10.1109/TIP.2015.2478388", "10.1109/TVCG.2015.2391861", "10.1109/TVCG.2012.321", "10.1109/TCSVT.2014.2309832", "10.1109/ISMAR.2011.6092393", "10.1109/TIP.2003.819861", "10.1109/VR.2006.34", "10.1109/TVCG.2010.104", "10.1109/TIP.2015.2478388", "10.1109/TVCG.2015.2391861", "10.1109/TVCG.2012.321", "10.1109/TCSVT.2014.2309832", "10.1109/ISMAR.2011.6092393", "10.1109/TIP.2003.819861", "10.1109/VR.2006.34", "10.1109/TVCG.2010.104", "10.1109/TIP.2015.2478388", "10.1109/TVCG.2015.2391861", "10.1109/TVCG.2012.321", "10.1109/TCSVT.2014.2309832", "10.1109/ISMAR.2011.6092393", "10.1109/TIP.2003.819861", "10.1145/2508363.2508416", "10.1145/1409060.1409103", "10.1145/800031.808601", "10.1145/1882261.1866166", "10.1145/1730804.1730821", "10.1145/2503713.2503720", "10.1145/1180495.1180549", "10.1145/2508363.2508416", "10.1145/1409060.1409103", "10.1145/800031.808601", "10.1145/1882261.1866166", "10.1145/1730804.1730821", "10.1145/2503713.2503720", "10.1145/1180495.1180549", "10.1145/2508363.2508416", "10.1145/1409060.1409103", "10.1145/800031.808601", "10.1145/1882261.1866166", "10.1145/1730804.1730821", "10.1145/2503713.2503720", "10.1145/1180495.1180549", "10.1039/C4CC10294K", "10.1111/j.1467-8659.2008.01175.x", "10.1007/s10055-014-0250-4", "10.1364/OE.22.013492", "10.1002/pola.25912", "10.1007/s10055-010-0168-4", "10.1007/s11263-011-0467-6", "10.1007/978-3-7091-6242-2_9", "10.1111/j.1467-8659.2009.01608.x", "10.1137/0913035", "10.1039/C4CC10294K", "10.1111/j.1467-8659.2008.01175.x", "10.1007/s10055-014-0250-4", "10.1364/OE.22.013492", "10.1002/pola.25912", "10.1007/s10055-010-0168-4", "10.1007/s11263-011-0467-6", "10.1007/978-3-7091-6242-2_9", "10.1111/j.1467-8659.2009.01608.x", "10.1137/0913035", "10.1039/C4CC10294K", "10.1111/j.1467-8659.2008.01175.x", "10.1007/s10055-014-0250-4", "10.1364/OE.22.013492", "10.1002/pola.25912", "10.1007/s10055-010-0168-4", "10.1007/s11263-011-0467-6", "10.1007/978-3-7091-6242-2_9", "10.1111/j.1467-8659.2009.01608.x", "10.1137/0913035"]}, "10.1109/TVCG.2016.2518138": {"doi": "10.1109/TVCG.2016.2518138", "author": ["S. Lee", "H. Hua"], "title": "Effects of Configuration of Optical Combiner on Near-Field Depth Perception in Optical See-Through Head-Mounted Displays", "year": "2016", "abstract": "The ray-shift phenomenon means the apparent distance shift in the display image plane between virtual and physical objects. It is caused by the difference in the refraction of virtual display and see-through optical paths derived from optical combiners that are necessary to provide a see-through capability in optical see-through head-mounted displays. In this work, through a human-subject experiment, we investigated the effects of ray-shift phenomenon induced by the optical combiner on depth perception for near-field distances (40 cm-100 cm). In our experiment, we considered three different configurations of optical combiner: horizontal-tilt and vertical-tilt configurations (using plate beamsplitters horizontally and vertically tilted by 45\u00b0, respectively), and non-tilt configuration (using rectangular solid waveguides). Participants' depth perception errors in these configurations were compared with those in an ordinary condition (i.e., the condition where physical objects are directly shown without the displays) and theoretically estimated ones. According to the experimental results, the measured percentage depth perception errors were similar to the theoretically estimated ones, where the amount of estimated percentage depth errors was greater than 0.3%. Furthermore, the participants showed significantly larger depth perception errors in the horizontal-tilt configuration than in an ordinary condition, while no large errors were found in the vertical-tilt configuration. In the non-tilt configuration, the results were dependent on the thickness of optical combiner and target distance.", "keywords": ["helmet mounted displays", "light refraction", "optical beam splitters", "rectangular waveguides", "optical combiner configuration", "near-field depth perception", "optical see-through head-mounted displays", "ray-shift phenomenon", "display image plane", "physical objects", "virtual objects", "near-field distances", "vertical-tilt configurations", "horizontal-tilt configurations", "plate beamsplitters", "participant depth perception errors", "Adaptive optics", "Optical imaging", "Optical refraction", "Optical distortion", "Optical waveguides", "Optical variables control", "Three-dimensional displays", "Ray-shift phenomenon", "near-field depth perception", "optical combiner", "optical see-through head-mounted display", "augmented reality", "Ray-shift phenomenon", "near-field depth perception", "optical combiner", "optical see-through head-mounted display", "augmented reality"], "referenced_by": ["10.1109/VR.2019.8798335"], "referencing": ["10.1109/JDT.2006.879846", "10.1109/TVCG.2015.2391859", "10.1109/ISMAR.2015.14", "10.1109/TVCG.2012.45", "10.1109/JDT.2014.2386216", "10.1109/JDT.2006.879846", "10.1109/TVCG.2015.2391859", "10.1109/ISMAR.2015.14", "10.1109/TVCG.2012.45", "10.1109/JDT.2014.2386216", "10.1109/JDT.2006.879846", "10.1109/TVCG.2015.2391859", "10.1109/ISMAR.2015.14", "10.1109/TVCG.2012.45", "10.1109/JDT.2014.2386216", "10.1145/1577755.1577762", "10.1145/1836248.1836277", "10.1145/1577755.1577762", "10.1145/1836248.1836277", "10.1145/1577755.1577762", "10.1145/1836248.1836277", "10.1162/pres.1997.6.4.355", "10.1364/AO.48.002655", "10.1518/001872098779591278", "10.1167/8.3.33", "10.1364/OE.21.030993", "10.1162/PRES_a_00048", "10.1162/105474602321050730", "10.1177/154193129403800413", "10.1364/AO.47.002888", "10.1162/pres.1997.6.4.355", "10.1364/AO.48.002655", "10.1518/001872098779591278", "10.1167/8.3.33", "10.1364/OE.21.030993", "10.1162/PRES_a_00048", "10.1162/105474602321050730", "10.1177/154193129403800413", "10.1364/AO.47.002888", "10.1162/pres.1997.6.4.355", "10.1364/AO.48.002655", "10.1518/001872098779591278", "10.1167/8.3.33", "10.1364/OE.21.030993", "10.1162/PRES_a_00048", "10.1162/105474602321050730", "10.1177/154193129403800413", "10.1364/AO.47.002888"]}, "10.1109/TVCG.2016.2518099": {"doi": "10.1109/TVCG.2016.2518099", "author": ["B. Jackson", "D. F. Keefe"], "title": "Lift-Off: Using Reference Imagery and Freehand Sketching to Create 3D Models in VR", "year": "2016", "abstract": "Three-dimensional modeling has long been regarded as an ideal application for virtual reality (VR), but current VR-based 3D modeling tools suffer from two problems that limit creativity and applicability: (1) the lack of control for freehand modeling, and (2) the difficulty of starting from scratch. To address these challenges, we present Lift-Off, an immersive 3D interface for creating complex models with a controlled, handcrafted style. Artists start outside of VR with 2D sketches, which are then imported and positioned in VR. Then, using a VR interface built on top of image processing algorithms, 2D curves within the sketches are selected interactively and \u201clifted\u201d into space to create a 3D scaffolding for the model. Finally, artists sweep surfaces along these curves to create 3D models. Evaluations are presented for both long-term users and for novices who each created a 3D sailboat model from the same starting sketch. Qualitative results are positive, with the visual style of the resulting models of animals and other organic subjects as well as architectural models matching what is possible with traditional fine art media. In addition, quantitative data from logging features built into the software are used to characterize typical tool use and suggest areas for further refinement of the interface.", "keywords": ["art", "image processing", "user interfaces", "virtual reality", "reference imagery", "freehand sketching", "virtual reality", "VR-based 3D modeling tool", "Lift-Off", "scratch", "immersive 3D interface", "handcrafted style", "2D sketch", "VR interface", "image processing algorithm", "2D curve", "3D scaffolding", "3D sailboat model", "Three-dimensional displays", "Solid modeling", "Computational modeling", "User interfaces", "Surface treatment", "Art", "Shape", "Immersive 3D Modeling", "Virtual Reality", "3D User Interfaces", "Sketch-based Modeling", "Immersive 3D Modeling", "Virtual Reality", "3D User Interfaces", "Sketch-based Modeling", "Animals", "Art", "Artiodactyla", "Computer Graphics", "Equipment Design", "Humans", "Imaging, Three-Dimensional", "Models, Theoretical", "User-Computer Interface"], "referenced_by": ["10.1109/3DUI.2017.7893332", "10.1109/ICALIP.2018.8455477", "10.1109/ISMAR-Adjunct.2018.00098", "10.1109/VR.2019.8798200", "10.1109/ACCESS.2019.2939427", "10.1109/VRW50115.2020.00287", "10.1109/CoG47356.2020.9231769", "10.1145/3009939.3009956", "10.1145/3306346.3322970", "10.1002/cav.1764", "10.1007/978-981-10-7299-4_1", "10.1016/j.cag.2017.04.002", "10.1016/j.cag.2017.03.003", "10.1177/1687814018783636", "10.1080/10447318.2018.1514163", "10.1016/j.autcon.2019.03.009", "10.1002/cav.1880", "10.3389/frobt.2019.00061", "10.1016/j.cag.2019.09.006", "10.1115/1.4045142", "10.1016/j.cad.2019.102789", "10.1017/dsd.2020.61", "10.1016/j.autcon.2020.103311", "10.1016/j.destud.2020.100965", "10.1007/s11042-020-10033-1", "10.1007/978-3-030-62807-9_24"], "referencing": ["10.1109/3DUI.2013.6550244", "10.1109/TVCG.2013.121", "10.1109/TVCG.2008.31", "10.1109/MCG.2005.34", "10.1109/TVCG.2007.1060", "10.1109/3DUI.2013.6550247", "10.1109/3DUI.2012.6184195", "10.1109/3DUI.2013.6550244", "10.1109/TVCG.2013.121", "10.1109/TVCG.2008.31", "10.1109/MCG.2005.34", "10.1109/TVCG.2007.1060", "10.1109/3DUI.2013.6550247", "10.1109/3DUI.2012.6184195", "10.1109/3DUI.2013.6550244", "10.1109/TVCG.2013.121", "10.1109/TVCG.2008.31", "10.1109/MCG.2005.34", "10.1109/TVCG.2007.1060", "10.1109/3DUI.2013.6550247", "10.1109/3DUI.2012.6184195", "10.1145/1622176.1622189", "10.1145/300523.300536", "10.1145/147156.147182", "10.1145/360303.360329", "10.1145/210079.210087", "10.1145/503376.503398", "10.1145/364338.364370", "10.1145/1281500.1281541", "10.1145/1242073.1242205", "10.1145/365024.365114", "10.1145/985692.985767", "10.1145/505008.505041", "10.1145/1450579.1450627", "10.1145/1449715.1449741", "10.1145/1015999.1016012", "10.1145/1622176.1622189", "10.1145/300523.300536", "10.1145/147156.147182", "10.1145/360303.360329", "10.1145/210079.210087", "10.1145/503376.503398", "10.1145/364338.364370", "10.1145/1281500.1281541", "10.1145/1242073.1242205", "10.1145/365024.365114", "10.1145/985692.985767", "10.1145/505008.505041", "10.1145/1450579.1450627", "10.1145/1449715.1449741", "10.1145/1015999.1016012", "10.1145/1622176.1622189", "10.1145/300523.300536", "10.1145/147156.147182", "10.1145/360303.360329", "10.1145/210079.210087", "10.1145/503376.503398", "10.1145/364338.364370", "10.1145/1281500.1281541", "10.1145/1242073.1242205", "10.1145/365024.365114", "10.1145/985692.985767", "10.1145/505008.505041", "10.1145/1450579.1450627", "10.1145/1449715.1449741", "10.1145/1015999.1016012", "10.1007/BF00133570", "10.1162/LEON_a_00261", "10.1016/j.cag.2015.02.004", "10.1016/j.cag.2008.09.013", "10.1207/s15327590ijhc2002_1", "10.1037/a0027395", "10.1007/BF00133570", "10.1162/LEON_a_00261", "10.1016/j.cag.2015.02.004", "10.1016/j.cag.2008.09.013", "10.1207/s15327590ijhc2002_1", "10.1037/a0027395", "10.1007/BF00133570", "10.1162/LEON_a_00261", "10.1016/j.cag.2015.02.004", "10.1016/j.cag.2008.09.013", "10.1207/s15327590ijhc2002_1", "10.1037/a0027395"]}, "10.1109/TVCG.2016.2518086": {"doi": "10.1109/TVCG.2016.2518086", "author": ["S. Pick", "B. Weyers", "B. Hentschel", "T. W. Kuhlen"], "title": "Design and Evaluation of Data Annotation Workflows for CAVE-like Virtual Environments", "year": "2016", "abstract": "Data annotation finds increasing use in Virtual Reality applications with the goal to support the data analysis process, such as architectural reviews. In this context, a variety of different annotation systems for application to immersive virtual environments have been presented. While many interesting interaction designs for the data annotation workflow have emerged from them, important details and evaluations are often omitted. In particular, we observe that the process of handling metadata to interactively create and manage complex annotations is often not covered in detail. In this paper, we strive to improve this situation by focusing on the design of data annotation workflows and their evaluation. We propose a workflow design that facilitates the most important annotation operations, i.e., annotation creation, review, and modification. Our workflow design is easily extensible in terms of supported annotation and metadata types as well as interaction techniques, which makes it suitable for a variety of application scenarios. To evaluate it, we have conducted a user study in a CAVE-like virtual environment in which we compared our design to two alternatives in terms of a realistic annotation creation task. Our design obtained good results in terms of task performance and user experience.", "keywords": ["data analysis", "human computer interaction", "meta data", "virtual reality", "virtual environment", "virtual reality application", "data analysis process", "data annotation system", "metadata handling process", "data annotation workflow design", "interaction technique", "Metadata", "Three-dimensional displays", "Visualization", "Virtual environments", "Context", "Layout", "Data analysis", "Virtual reality", "data annotation", "interaction design", "user study", "Virtual reality", "data annotation", "interaction design", "user study"], "referenced_by": ["10.1109/VR.2017.7892310", "10.1109/VR.2017.7892277", "10.1109/VR.2019.8798216", "10.1109/ISMAR.2019.00030", "10.1007/978-3-319-47452-6_4", "10.1007/978-981-10-7635-0_26"], "referencing": ["10.1109/TVCG.2013.31", "10.1109/VRAIS.1996.490533", "10.1109/VISUAL.1994.346309", "10.1109/HAVE.2006.283798", "10.1109/VISUAL.1992.235203", "10.1109/ISMAR.2008.4637326", "10.1109/TVCG.2013.31", "10.1109/VRAIS.1996.490533", "10.1109/VISUAL.1994.346309", "10.1109/HAVE.2006.283798", "10.1109/VISUAL.1992.235203", "10.1109/ISMAR.2008.4637326", "10.1109/TVCG.2013.31", "10.1109/VRAIS.1996.490533", "10.1109/VISUAL.1994.346309", "10.1109/HAVE.2006.283798", "10.1109/VISUAL.1992.235203", "10.1109/ISMAR.2008.4637326", "10.1145/502360.502363", "10.1145/571985.572017", "10.1145/1008653.1008669", "10.1145/293701.293715", "10.1145/1149941.1149967", "10.1145/1753326.1753524", "10.1145/502716.502733", "10.1145/1101616.1101626", "10.1145/2671015.2671029", "10.1145/502360.502363", "10.1145/571985.572017", "10.1145/1008653.1008669", "10.1145/293701.293715", "10.1145/1149941.1149967", "10.1145/1753326.1753524", "10.1145/502716.502733", "10.1145/1101616.1101626", "10.1145/2671015.2671029", "10.1145/502360.502363", "10.1145/571985.572017", "10.1145/1008653.1008669", "10.1145/293701.293715", "10.1145/1149941.1149967", "10.1145/1753326.1753524", "10.1145/502716.502733", "10.1145/1101616.1101626", "10.1145/2671015.2671029", "10.1016/S0166-4115(08)62386-9", "10.1007/s11554-009-0141-1", "10.1299/jsmeb.48.252", "10.1007/978-3-540-89350-9_6", "10.1016/j.procir.2012.07.055", "10.1016/j.cag.2009.06.001", "10.1016/S0166-4115(08)62386-9", "10.1007/s11554-009-0141-1", "10.1299/jsmeb.48.252", "10.1007/978-3-540-89350-9_6", "10.1016/j.procir.2012.07.055", "10.1016/j.cag.2009.06.001", "10.1016/S0166-4115(08)62386-9", "10.1007/s11554-009-0141-1", "10.1299/jsmeb.48.252", "10.1007/978-3-540-89350-9_6", "10.1016/j.procir.2012.07.055", "10.1016/j.cag.2009.06.001"]}, "10.1109/TVCG.2016.2518298": {"doi": "10.1109/TVCG.2016.2518298", "author": ["S. Freitag", "B. Weyers", "T. W. Kuhlen"], "title": "Examining Rotation Gain in CAVE-like Virtual Environments", "year": "2016", "abstract": "When moving through a tracked immersive virtual environment, it is sometimes useful to deviate from the normal one-to-one mapping of real to virtual motion. One option is the application of rotation gain, where the virtual rotation of a user around the vertical axis is amplified or reduced by a factor. Previous research in head-mounted display environments has shown that rotation gain can go unnoticed to a certain extent, which is exploited in redirected walking techniques. Furthermore, it can be used to increase the effective field of regard in projection systems. However, rotation gain has never been studied in CAVE systems, yet. In this work, we present an experiment with 87 participants examining the effects of rotation gain in a CAVE-like virtual environment. The results show no significant effects of rotation gain on simulator sickness, presence, or user performance in a cognitive task, but indicate that there is a negative influence on spatial knowledge especially for inexperienced users. In secondary results, we could confirm results of previous work and demonstrate that they also hold for CAVE environments, showing a negative correlation between simulator sickness and presence, cognitive performance and spatial knowledge, a positive correlation between presence and spatial knowledge, a mitigating influence of experience with 3D applications and previous CAVE exposure on simulator sickness, and a higher incidence of simulator sickness in women.", "keywords": ["cognitive systems", "helmet mounted displays", "virtual reality", "rotation gain", "CAVE-like virtual environments", "tracked immersive virtual environment", "virtual rotation", "head-mounted display environments", "redirected walking techniques", "projection systems", "simulator sickness", "user performance", "cognitive task", "cognitive performance", "Legged locomotion", "Head", "Virtual environments", "Visualization", "Tracking", "Space exploration", "Delays", "Rotation gain", "virtual environments", "virtual reality", "CAVE", "redirected walking", "user study", "Rotation gain", "virtual environments", "virtual reality", "CAVE", "redirected walking", "user study"], "referenced_by": ["10.1109/TVCG.2016.2601607", "10.1109/VR.2017.7892228", "10.1109/WEVR.2017.7957707", "10.1109/VR.2018.8447553", "10.1109/TVCG.2019.2898782", "10.1109/VR.2019.8797837", "10.1109/VR.2019.8798334", "10.1109/TVCG.2020.2973498", "10.1109/TVCG.2018.2887379", "10.1007/s10055-016-0285-9", "10.1016/B978-0-12-800965-9.16001-5", "10.1080/10447318.2020.1778351", "10.1007/978-3-030-59342-1_4", "10.1016/j.neulet.2020.135589"], "referencing": ["10.1109/TVCG.2015.2391851", "10.1109/TVCG.2012.55", "10.1109/TVCG.2015.2391864", "10.1109/TVCG.2014.34", "10.1109/TVCG.2008.191", "10.1109/TVCG.2011.289", "10.1109/TVCG.2009.62", "10.1109/VR.2011.5759455", "10.1109/TVCG.2009.93", "10.1109/TVCG.2005.92", "10.1109/TVCG.2015.2391851", "10.1109/TVCG.2012.55", "10.1109/TVCG.2015.2391864", "10.1109/TVCG.2014.34", "10.1109/TVCG.2008.191", "10.1109/TVCG.2011.289", "10.1109/TVCG.2009.62", "10.1109/VR.2011.5759455", "10.1109/TVCG.2009.93", "10.1109/TVCG.2005.92", "10.1109/TVCG.2015.2391851", "10.1109/TVCG.2012.55", "10.1109/TVCG.2015.2391864", "10.1109/TVCG.2014.34", "10.1109/TVCG.2008.191", "10.1109/TVCG.2011.289", "10.1109/TVCG.2009.62", "10.1109/VR.2011.5759455", "10.1109/TVCG.2009.93", "10.1109/TVCG.2005.92", "10.1145/129888.129892", "10.1145/1450579.1450612", "10.1145/2043603.2043604", "10.1145/1394281.1394310", "10.1145/333329.333344", "10.1145/364338.364339", "10.1145/1970378.1970384", "10.1145/210079.210084", "10.1145/1450579.1450611", "10.1145/311535.311589", "10.1145/1272582.1272590", "10.1145/129888.129892", "10.1145/1450579.1450612", "10.1145/2043603.2043604", "10.1145/1394281.1394310", "10.1145/333329.333344", "10.1145/364338.364339", "10.1145/1970378.1970384", "10.1145/210079.210084", "10.1145/1450579.1450611", "10.1145/311535.311589", "10.1145/1272582.1272590", "10.1145/129888.129892", "10.1145/1450579.1450612", "10.1145/2043603.2043604", "10.1145/1394281.1394310", "10.1145/333329.333344", "10.1145/364338.364339", "10.1145/1970378.1970384", "10.1145/210079.210084", "10.1145/1450579.1450611", "10.1145/311535.311589", "10.1145/1272582.1272590", "10.1162/pres.15.6.699", "10.1177/154193129403801803", "10.1162/pres.17.3.283", "10.1016/j.displa.2012.10.007", "10.1162/105474699566152", "10.1016/S0166-4115(08)62386-9", "10.1007/s00221-004-2191-8", "10.1207/s15327108ijap0303_3", "10.1177/154193129804202110", "10.1162/PRES_a_00152", "10.1111/j.1467-9280.2006.01728.x", "10.1518/hfes.45.3.504.27254", "10.1162/105474600566989", "10.1038/215", "10.1146/annurev.ps.38.020187.000245", "10.1162/105474698565686", "10.1162/pres.15.6.699", "10.1177/154193129403801803", "10.1162/pres.17.3.283", "10.1016/j.displa.2012.10.007", "10.1162/105474699566152", "10.1016/S0166-4115(08)62386-9", "10.1007/s00221-004-2191-8", "10.1207/s15327108ijap0303_3", "10.1177/154193129804202110", "10.1162/PRES_a_00152", "10.1111/j.1467-9280.2006.01728.x", "10.1518/hfes.45.3.504.27254", "10.1162/105474600566989", "10.1038/215", "10.1146/annurev.ps.38.020187.000245", "10.1162/105474698565686", "10.1162/pres.15.6.699", "10.1177/154193129403801803", "10.1162/pres.17.3.283", "10.1016/j.displa.2012.10.007", "10.1162/105474699566152", "10.1016/S0166-4115(08)62386-9", "10.1007/s00221-004-2191-8", "10.1207/s15327108ijap0303_3", "10.1177/154193129804202110", "10.1162/PRES_a_00152", "10.1111/j.1467-9280.2006.01728.x", "10.1518/hfes.45.3.504.27254", "10.1162/105474600566989", "10.1038/215", "10.1146/annurev.ps.38.020187.000245", "10.1162/105474698565686"]}, "10.1109/TVCG.2016.2518338": {"doi": "10.1109/TVCG.2016.2518338", "author": ["C. H\u00e4nel", "B. Weyers", "B. Hentschel", "T. W. Kuhlen"], "title": "Visual Quality Adjustment for Volume Rendering in a Head-Tracked Virtual Environment", "year": "2016", "abstract": "To avoid simulator sickness and improve presence in immersive virtual environments (IVEs), high frame rates and low latency are required. In contrast, volume rendering applications typically strive for high visual quality that induces high computational load and, thus, leads to low frame rates. To evaluate this trade-off in IVEs, we conducted a controlled user study with 53 participants. Search and count tasks were performed in a CAVE with varying volume rendering conditions which are applied according to viewer position updates corresponding to head tracking. The results of our study indicate that participants preferred the rendering condition with continuous adjustment of the visual quality over an instantaneous adjustment which guaranteed for low latency and over no adjustment providing constant high visual quality but rather low frame rates. Within the continuous condition, the participants showed best task performance and felt less disturbed by effects of the visualization during movements. Our findings provide a good basis for further evaluations of how to accelerate volume rendering in IVEs according to user's preferences.", "keywords": ["data visualisation", "rendering (computer graphics)", "virtual reality", "simulator sickness", "immersive virtual environments", "computational load", "CAVE", "varying volume rendering conditions", "viewer position updates", "head tracking", "continuous visual quality adjustment", "task performance", "IVE", "user preferences", "head-tracked virtual environment", "Visualization", "Rendering (computer graphics)", "Virtual environments", "Data visualization", "Tracking", "Head", "Volume rendering", "CAVE", "immersive virtual environment", "level of detail", "latency", "Volume rendering", "CAVE", "immersive virtual environment", "level of detail", "latency"], "referenced_by": ["10.1109/PacificVis.2018.00035", "10.1109/TVCG.2018.2848906", "10.1109/TVCG.2019.2934370", "10.1016/j.opelre.2018.02.005", "10.1111/cgf.13302"], "referencing": ["10.1109/VR.1999.756954", "10.1109/TVCG.2014.2346319", "10.1109/TVCG.2012.240", "10.1109/TVCG.2012.42", "10.1109/38.403827", "10.1109/TVCG.2007.15", "10.1109/TVCG.2005.92", "10.1109/VR.1999.756954", "10.1109/TVCG.2014.2346319", "10.1109/TVCG.2012.240", "10.1109/TVCG.2012.42", "10.1109/38.403827", "10.1109/TVCG.2007.15", "10.1109/TVCG.2005.92", "10.1109/VR.1999.756954", "10.1109/TVCG.2014.2346319", "10.1109/TVCG.2012.240", "10.1109/TVCG.2012.42", "10.1109/38.403827", "10.1109/TVCG.2007.15", "10.1109/TVCG.2005.92", "10.1145/229459.229467", "10.1145/360349.360354", "10.1145/280814.280832", "10.1145/166117.166149", "10.1145/237170.237216", "10.1145/333329.333344", "10.1145/169059.169431", "10.1145/1315184.1315209", "10.1145/229459.229467", "10.1145/360349.360354", "10.1145/280814.280832", "10.1145/166117.166149", "10.1145/237170.237216", "10.1145/333329.333344", "10.1145/169059.169431", "10.1145/1315184.1315209", "10.1145/229459.229467", "10.1145/360349.360354", "10.1145/280814.280832", "10.1145/166117.166149", "10.1145/237170.237216", "10.1145/333329.333344", "10.1145/169059.169431", "10.1145/1315184.1315209", "10.1177/154193120304702001", "10.1177/0018720811428734", "10.1080/15213269.2015.1015740", "10.1016/S0166-4115(08)62386-9", "10.1207/s15327108ijap0303_3", "10.1162/PRES_a_00152", "10.1007/BF02009713", "10.1111/j.1467-9280.2006.01728.x", "10.1007/978-3-7091-6221-7_19", "10.1518/hfes.45.3.504.27254", "10.1007/11428831_115", "10.1038/nrn2776", "10.1177/154193120304702001", "10.1177/0018720811428734", "10.1080/15213269.2015.1015740", "10.1016/S0166-4115(08)62386-9", "10.1207/s15327108ijap0303_3", "10.1162/PRES_a_00152", "10.1007/BF02009713", "10.1111/j.1467-9280.2006.01728.x", "10.1007/978-3-7091-6221-7_19", "10.1518/hfes.45.3.504.27254", "10.1007/11428831_115", "10.1038/nrn2776", "10.1177/154193120304702001", "10.1177/0018720811428734", "10.1080/15213269.2015.1015740", "10.1016/S0166-4115(08)62386-9", "10.1207/s15327108ijap0303_3", "10.1162/PRES_a_00152", "10.1007/BF02009713", "10.1111/j.1467-9280.2006.01728.x", "10.1007/978-3-7091-6221-7_19", "10.1518/hfes.45.3.504.27254", "10.1007/11428831_115", "10.1038/nrn2776"]}, "10.1109/TVCG.2016.2518098": {"doi": "10.1109/TVCG.2016.2518098", "author": ["L. Greunke", "A. Sadagic"], "title": "Taking Immersive VR Leap in Training of Landing Signal Officers", "year": "2016", "abstract": "A major training device used to train all Landing Signal Officers (LSOs) for several decades has been the Landing Signal Officer Trainer, Device 2H111. This simulator, located in Oceana, VA, is contained within a two story tall room; it consists of several large screens and a physical rendition of the actual instruments used by LSOs in their operational environment. The young officers who serve in this specialty will typically encounter this system for only a short period of formal instruction (six one-hour long sessions), leaving multiple gaps in training. While experience with 2H111 is extremely valuable for all LSO officers, the amount of time they can spend using this training device is undeniably too short. The need to provide LSOs with an unlimited number of training opportunities unrestricted by location and time, married with recent advancements in commercial off the shelf (COTS) immersive technologies, provided an ideal platform to create a lightweight training solution that would fill those gaps and extend beyond the capabilities currently offered in the 2H111 simulator. This paper details our efforts on task analysis, surveying of user domain, mapping of 2H111 training capabilities to new prototype system to ensure its support of major training objectives of 2H111, design and development of prototype training system, and a feasibility study that included tests of technical system performance and informal testing with trainees at the LSO Schoolhouse. The results achieved in this effort indicate that the time for LSO training to make the leap to immersive VR has decidedly come.", "keywords": ["aerospace computing", "aircraft", "computer based training", "immersive VR leap", "major training device", "LSO", "landing signal officer trainer", "physical rendition", "actual instruments", "operational environment", "formal instruction", "commercial off the shelf", "COTS immersive technologies", "prototype training system", "Training", "Prototypes", "Instruments", "Aircraft", "Object recognition", "Visualization", "Navigation", "military applications", "HMD", "3D interaction", "usability", "military applications", "HMD", "3D interaction", "usability"], "referenced_by": ["10.1109/MCG.2016.112", "10.1109/BDVA.2017.8114627", "10.1109/MCG.2018.021951633", "10.1109/ICALIP.2018.8455477", "10.1109/VR.2019.8798112", "10.1109/ICSGEA.2019.00013", "10.1109/SVR.2019.00021", "10.1109/SVR51698.2020.00071", "10.1007/978-3-319-60591-3_21", "10.1080/10447318.2017.1286768", "10.3389/feduc.2019.00080", "10.1007/978-3-030-33723-0_10", "10.1007/s10055-020-00467-1", "10.1007/s10758-020-09489-9"], "referencing": ["10.1109/MCG.2009.134", "10.1109/VRAIS.1998.658417", "10.1109/38.799740", "10.1109/MCG.2009.134", "10.1109/VRAIS.1998.658417", "10.1109/38.799740", "10.1109/MCG.2009.134", "10.1109/VRAIS.1998.658417", "10.1109/38.799740", "10.1145/1012551.1012558", "10.1145/257874.257889", "10.1145/333329.333344", "10.1145/1012551.1012558", "10.1145/257874.257889", "10.1145/333329.333344", "10.1145/1012551.1012558", "10.1145/257874.257889", "10.1145/333329.333344", "10.1037/0090-5550.46.3.296", "10.1067/msy.2002.125723", "10.1136/gut.2009.191825", "10.1162/pres.19.2.131", "10.1016/j.firesaf.2012.01.004", "10.1162/pres.16.3.318", "10.1097/00000658-200210000-00008", "10.1162/1054746042545292", "10.1162/1054746042545238", "10.1016/j.displa.2013.01.001", "10.1518/001872006778606877", "10.1016/j.displa.2007.09.005", "10.1162/105474602760204309", "10.1037/0090-5550.46.3.296", "10.1067/msy.2002.125723", "10.1136/gut.2009.191825", "10.1162/pres.19.2.131", "10.1016/j.firesaf.2012.01.004", "10.1162/pres.16.3.318", "10.1097/00000658-200210000-00008", "10.1162/1054746042545292", "10.1162/1054746042545238", "10.1016/j.displa.2013.01.001", "10.1518/001872006778606877", "10.1016/j.displa.2007.09.005", "10.1162/105474602760204309", "10.1037/0090-5550.46.3.296", "10.1067/msy.2002.125723", "10.1136/gut.2009.191825", "10.1162/pres.19.2.131", "10.1016/j.firesaf.2012.01.004", "10.1162/pres.16.3.318", "10.1097/00000658-200210000-00008", "10.1162/1054746042545292", "10.1162/1054746042545238", "10.1016/j.displa.2013.01.001", "10.1518/001872006778606877", "10.1016/j.displa.2007.09.005", "10.1162/105474602760204309"]}, "10.1109/TVCG.2016.2529158": {"doi": "10.1109/TVCG.2016.2529158", "author": [""], "title": "Conference Author Index", "year": "2016", "abstract": "Presents the conference author index.", "keywords": [""], "referenced_by": [], "referencing": []}}