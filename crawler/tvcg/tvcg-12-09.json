{"10.1109/TVCG.2011.265": {"doi": "10.1109/TVCG.2011.265", "author": ["H. Bhatia", "S. Jadhav", "P. Bremer", "G. Chen", "J. A. Levine", "L. G. Nonato", "V. Pascucci"], "title": "Flow Visualization with Quantified Spatial and Temporal Errors Using Edge Maps", "year": "2012", "abstract": "Robust analysis of vector fields has been established as an important tool for deriving insights from the complex systems these fields model. Traditional analysis and visualization techniques rely primarily on computing streamlines through numerical integration. The inherent numerical errors of such approaches are usually ignored, leading to inconsistencies that cause unreliable visualizations and can ultimately prevent in-depth analysis. We propose a new representation for vector fields on surfaces that replaces numerical integration through triangles with maps from the triangle boundaries to themselves. This representation, called edge maps, permits a concise description of flow behaviors and is equivalent to computing all possible streamlines at a user defined error threshold. Independent of this error streamlines computed using edge maps are guaranteed to be consistent up to floating point precision, enabling the stable extraction of features such as the topological skeleton. Furthermore, our representation explicitly stores spatial and temporal errors which we use to produce more informative visualizations. This work describes the construction of edge maps, the error quantification, and a refinement procedure to adhere to a user defined error bound. Finally, we introduce new visualizations using the additional information provided by edge maps to indicate the uncertainty involved in computing streamlines and topological structures.", "keywords": ["error analysis", "feature extraction", "flow visualisation", "topology", "vectors", "flow visualization unreliability", "quantified spatial error", "quantified temporal error", "edge maps", "robust analysis", "vector fields", "complex systems", "numerical errors", "triangle boundaries", "flow behaviors", "error threshold", "error streamlines", "floating point precision", "feature extraction", "topological skeleton", "explicit storage", "error quantification", "refinement procedure", "user-defined error bound", "Visualization", "Image edge detection", "Linear approximation", "Uncertainty", "Data visualization", "Skeleton", "Vector fields", "error quantification", "edge maps."], "referenced_by": ["10.1109/PACIFICVIS.2016.7465273", "10.1109/SIBGRAPI.2013.48", "10.1109/TVCG.2012.147", "10.1109/TVCG.2013.229", "10.1109/TVCG.2016.2599016", "10.1109/TVCG.2017.2743918", "10.1109/SIBGRAPI.2015.31", "10.1109/TVCG.2017.2750689", "10.1109/TVCG.2018.2864432", "10.1109/TVCG.2019.2934313", "10.1109/TVCG.2019.2934256", "10.1109/TVCG.2018.2879866", "10.1007/s12650-018-0474-6", "10.1111/cgf.12100", "10.1111/cgf.12914", "10.2514/6.2016-1927", "10.1016/j.cag.2019.03.005", "10.1007/978-3-642-32677-6_15", "10.1007/978-3-319-04099-8_3", "10.1111/j.1467-8659.2012.03087.x", "10.1111/j.1467-8659.2012.03097.x", "10.1111/j.1467-8659.2012.03104.x"], "referencing": ["10.1109/TVCG.2007.1021", "10.1109/TVCG.2008.33", "10.1109/TVCG.2008.133", "10.1109/TVCG.2007.70552", "10.1109/2.35197", "10.1109/VISUAL.1992.235211", "10.1109/MCG.2003.1231171", "10.1109/TVCG.2006.186", "10.1109/VISUAL.2004.59", "10.1109/VISUAL.1998.745291", "10.1109/2945.817352", "10.1109/TVCG.2010.235", "10.1109/VISUAL.2001.964506", "10.1109/2945.694953", "10.1109/TVCG.2011.88", "10.1109/TVCG.2004.39", "10.1109/2945.928168", "10.1109/2945.537309", "10.1145/1531326.1531383", "10.1145/1276377.1276447", "10.1145/1356682.1356683", "10.1145/566654.566646", "10.1145/1183287.1183290", "10.1007/s00454-003-2926-5", "10.1016/j.cagd.2005.06.004", "10.1016/j.combustflame.2005.09.018", "10.1007/978-3-642-23175-9_10", "10.1111/1467-8659.00655", "10.1007/978-3-540-70823-0_1", "10.1007/s10652-009-9154-3", "10.1111/j.1467-8659.2009.01604.x", "10.1007/s003710050111", "10.1111/j.1467-8659.2011.01934.x"]}, "10.1109/TVCG.2012.80": {"doi": "10.1109/TVCG.2012.80", "author": ["H. Guo", "H. Xiao", "X. Yuan"], "title": "Scalable Multivariate Volume Visualization and Analysis Based on Dimension Projection and Parallel Coordinates", "year": "2012", "abstract": "In this paper, we present an effective and scalable system for multivariate volume data visualization and analysis with a novel transfer function interface design that tightly couples parallel coordinates plots (PCP) and MDS-based dimension projection plots. In our system, the PCP visualizes the data distribution of each variate (dimension) and the MDS plots project features. They are integrated seamlessly to provide flexible feature classification without context switching between different data presentations during the user interaction. The proposed interface enables users to identify relevant correlation clusters and assign optical properties with lassos, magic wand, and other tools. Furthermore, direct sketching on the volume rendered images has been implemented to probe and edit features. With our system, users can interactively analyze multivariate volumetric data sets by navigating and exploring feature spaces in unified PCP and MDS plots. To further support large-scale multivariate volume data visualization and analysis, Scalable Pivot MDS (SPMDS), parallel adaptive continuous PCP rendering, as well as parallel rendering techniques are developed and integrated into our visualization system. Our experiments show that the system is effective in multivariate volume data visualization and its performance is highly scalable for data sets with different sizes and number of variates.", "keywords": ["data visualisation", "pattern classification", "rendering (computer graphics)", "scalable multivariate volume visualization", "dimension projection", "parallel coordinates", "multivariate volume data visualization", "transfer function interface design", "parallel coordinates plots", "MDS-based dimension projection plots", "flexible feature classification", "context switching", "data presentations", "user interaction", "optical properties", "lassos", "magic wand", "direct sketching", "volume rendered images", "multivariate volumetric data sets", "MDS plots", "PCP plots", "scalable pivot MDS", "parallel adaptive continuous PCP rendering", "Data visualization", "Rendering (computer graphics)", "Transfer functions", "Algorithm design and analysis", "Vegetation", "Correlation", "Multivariate volume", "transfer function", "parallel coordinates", "dimension projection", "user-interface design", "parallel visualization."], "referenced_by": ["10.1109/ACCESS.2016.2601339", "10.1109/ACCESS.2017.2696739", "10.1109/CADGRAPHICS.2015.45", "10.1109/LDAV.2014.7013202", "10.1109/PACIFICVIS.2017.8031588", "10.1109/PacificVis.2014.15", "10.1109/TVCG.2014.2346416", "10.1109/TVCG.2015.2467431", "10.1109/TVCG.2017.2661309", "10.1109/PacificVis.2014.41", "10.1109/TVCG.2013.133", "10.1109/TVCG.2018.2864808", "10.1109/JSYST.2018.2874102", "10.1109/PacificVis.2019.00041", "10.1109/SciVis.2018.8823605", "10.1007/s00371-015-1070-6", "10.1007/s00371-017-1359-8", "10.1007/s12650-016-0387-1", "10.1111/cgf.12380", "10.1111/cgf.12755", "10.1111/cgf.12934", "10.3390/ijgi7070266", "10.1016/j.visinf.2018.12.005", "10.1111/cgf.13731", "10.1007/s12650-019-00584-3", "10.1007/978-3-030-34110-7_26"], "referencing": ["10.1109/MCSE.2007.42", "10.1109/TVCG.2008.131", "10.1109/TVCG.2008.162", "10.1109/TVCG.2009.189", "10.1109/PACIFICVIS.2009.4906854", "10.1109/PACIFICVIS.2010.5429615", "10.1109/TVCG.2009.131", "10.1109/MCSE.2008.88", "10.1109/TVCG.2002.1021579", "10.1109/38.511", "10.1109/MCG.2007.129", "10.1109/38.291532", "10.1109/TVCG.2009.185", "10.1109/PACIFICVIS.2009.4906857", "10.1109/TVCG.2010.207", "10.1109/38.920623", "10.1109/TVCG.2006.148", "10.1109/PCCGA.2002.1167880", "10.1109/TVCG.2005.38", "10.1109/34.88573", "10.1109/VISUAL.1996.567800", "10.1109/MCG.2010.55", "10.1109/TVCG.2009.179", "10.1109/TVCG.2006.72", "10.1109/TVCG.2010.192", "10.1145/1654059.1654064", "10.1111/j.1467-8659.2009.01478.x", "10.1007/978-3-540-70904-6_6", "10.1111/j.1467-8659.2009.01666.x", "10.1007/BF01898350", "10.1111/j.1467-8659.2008.01239.x", "10.1111/j.1467-8659.2011.01958.x", "10.1007/BF02288916"]}, "10.1109/TVCG.2012.96": {"doi": "10.1109/TVCG.2012.96", "author": ["P. Riehmann", "H. Gruendl", "M. Potthast", "M. Trenkmann", "B. Stein", "B. Froehlich"], "title": "WORDGRAPH: Keyword-in-Context Visualization for NETSPEAK's Wildcard Search", "year": "2012", "abstract": "The WORDGRAPH helps writers in visually choosing phrases while writing a text. It checks for the commonness of phrases and allows for the retrieval of alternatives by means of wildcard queries. To support such queries, we implement a scalable retrieval engine, which returns high-quality results within milliseconds using a probabilistic retrieval strategy. The results are displayed as WORDGRAPH visualization or as a textual list. The graphical interface provides an effective means for interactive exploration of search results using filter techniques, query expansion, and navigation. Our observations indicate that, of three investigated retrieval tasks, the textual interface is sufficient for the phrase verification task, wherein both interfaces support context-sensitive word choice, and the WORDGRAPH best supports the exploration of a phrase's context or the underlying corpus. Our user study confirms these observations and shows that WORDGRAPH is generally the preferred interface over the textual result list for queries containing multiple wildcards.", "keywords": ["data visualisation", "information retrieval", "probability", "WORDGRAPH", "keyword-in-context visualization", "NETSPEAK wildcard search", "visually choosing phrases", "wildcard queries", "scalable retrieval engine", "probabilistic retrieval strategy", "graphical interface", "interactive exploration", "filter techniques", "query expansion", "query navigation", "phrase context", "underlying corpus", "Visualization", "Google", "Navigation", "Engines", "Layout", "Indexes", "Information visualization", "visual queries", "text visualization", "information retrieval", "Web n-grams", "wildcard search."], "referenced_by": ["10.1109/TVCG.2016.2598590", "10.1109/VAST.2017.8585505", "10.1109/TVCG.2018.2824822", "10.1007/978-3-319-59090-5_1", "10.1111/cgf.12618", "10.2991/978-94-6239-186-4_2"], "referencing": ["10.1109/TVCG.2009.165", "10.1109/TVCG.2008.172", "10.1109/INFVIS.2002.1173148", "10.1109/TSMC.1981.4308636", "10.1145/1449715.1449736", "10.1145/989863.989941", "10.1145/1963405.1963423", "10.1145/1060745.1060811", "10.1145/1871437.1871527", "10.1145/1277741.1277787", "10.1126/science.1199644", "10.3115/1225753.1225762", "10.1007/978-3-642-04128-0_61"]}, "10.1109/TVCG.2011.288": {"doi": "10.1109/TVCG.2011.288", "author": ["D. Mashima", "S. Kobourov", "Y. Hu"], "title": "Visualizing Dynamic Data with Maps", "year": "2012", "abstract": "Maps offer a familiar way to present geographic data (continents, countries), and additional information (topography, geology), can be displayed with the help of contours and heat-map overlays. In this paper, we consider visualizing large-scale dynamic relational data by taking advantage of the geographic map metaphor. We describe a map-based visualization system which uses animation to convey dynamics in large data sets, and which aims to preserve the viewer's mental map while also offering readable views at all times. Our system is fully functional and has been used to visualize user traffic on the Internet radio station last.fm, as well as TV-viewing patterns from an IPTV service. All map images in this paper are available in high-resolution at [CHECK END OF SENTENCE] as are several movies illustrating the dynamic visualization.", "keywords": ["data visualisation", "dynamic programming", "geographic information systems", "dynamic data visualisation", "maps", "geographic data", "heat map overlays", "large scale dynamic relational data", "geographic map metaphor", "map based visualization system", "Internet radio station", "TV-viewing patterns", "IPTV service", "Data visualization", "Layout", "Animation", "Measurement", "Clustering algorithms", "Heuristic algorithms", "Data mining", "Information interface and presentation", "multimedia information systems", "dynamic visualization", "graph drawing", "spatialization", "map-based visualization."], "referenced_by": ["10.1109/COMST.2016.2610963", "10.1109/ICON.2013.6781992", "10.1109/TMM.2016.2614229", "10.1109/TVCG.2017.2745280", "10.1109/VAST.2016.7883510", "10.1109/VAST.2017.8585638", "10.1109/VISUAL.2019.8933654", "10.1145/2801040.2801056", "10.1145/3183347", "10.1145/3213769", "10.1007/978-3-319-06793-3_8", "10.1007/s00371-013-0892-3", "10.1007/s11409-014-9112-4", "10.1007/s41095-016-0049-1", "10.1016/j.cor.2016.09.018", "10.1016/j.elerap.2015.10.001", "10.1016/j.jvlc.2015.10.003", "10.1016/j.jvlc.2017.09.002", "10.1111/cgf.12512", "10.1111/cgf.12791", "10.1587/transcom.E97.B.730", "10.4018/978-1-4666-8450-8.ch007", "10.4236/jgis.2016.84037", "10.1016/j.omega.2018.07.008", "10.1111/cgf.13668", "10.1007/s11390-020-0271-2", "10.35595/2414-9179-2020-1-26-400-409"], "referencing": ["10.1109/TVCG.2009.122", "10.1109/2945.841119", "10.1109/TVCG.2008.125", "10.1109/TVCG.2008.155", "10.1109/INFVIS.1995.528686", "10.1145/1148493.1148509", "10.1145/774841.774844", "10.1145/1639714.1639784", "10.1002/spe.4380211102", "10.1007/978-3-642-00219-9_20", "10.1002/1097-024X(200009)30:11&lt;1203::AID-SPE338&gt;3.3.CO;2-E", "10.14714/CP44.516", "10.1073/pnas.0601602103", "10.1007/BFb0021824", "10.1111/j.1467-8659.2009.01452.x", "10.1559/152304003100011081"]}, "10.1109/TVCG.2011.277": {"doi": "10.1109/TVCG.2011.277", "author": ["C. Benthin", "I. Wald", "S. Woop", "M. Ernst", "W. R. Mark"], "title": "Combining Single and Packet-Ray Tracing for Arbitrary Ray Distributions on the Intel MIC Architecture", "year": "2012", "abstract": "Wide-SIMD hardware is power and area efficient, but it is challenging to efficiently map ray tracing algorithms to such hardware especially when the rays are incoherent. The two most commonly used schemes are either packet tracing, or relying on a separate traversal stack for each SIMD lane. Both work great for coherent rays, but suffer when rays are incoherent: The former experiences a dramatic loss of SIMD utilization once rays diverge; the latter requires a large local storage, and generates multiple incoherent streams of memory accesses that present challenges for the memory system. In this paper, we introduce a single-ray tracing scheme for incoherent rays that uses just one traversal stack on 16-wide SIMD hardware. It uses a bounding-volume hierarchy with a branching factor of four as the acceleration structure, exploits four-wide SIMD in each box and primitive intersection test, and uses 16-wide SIMD by always performing four such node or primitive tests in parallel. We then extend this scheme to a hybrid tracing scheme that automatically adapts to varying ray coherence by starting out with a 16-wide packet scheme and switching to the new single-ray scheme as soon as rays diverge. We show that on the Intel Many Integrated Core architecture this hybrid scheme consistently, and over a wide range of scenes and ray distributions, outperforms both packet and single-ray tracing.", "keywords": ["multiprocessing systems", "parallel architectures", "ray tracing", "packet-ray tracing", "arbitrary ray distributions", "Intel MIC architecture", "traversal stack", "SIMD lane", "SIMD utilization", "multiple incoherent streams", "memory accesses", "single-ray tracing scheme", "16-wide SIMD hardware", "bounding-volume hierarchy", "branching factor", "primitive intersection test", "hybrid tracing scheme", "Intel many integrated core architecture", "Kernel", "Vectors", "Ray tracing", "Registers", "Memory management", "Hardware", "Ray tracing", "SIMD processors."], "referenced_by": ["10.1109/HPCC.and.EUC.2013.84", "10.1109/HiPC.2015.54", "10.1109/IPDPS.2014.88", "10.1109/IPDPSW.2013.216", "10.1109/JSTARS.2016.2628019", "10.1109/JSTARS.2017.2725743", "10.1109/TMM.2017.2697825", "10.1145/2601097.2601199", "10.1145/2601097.2601222", "10.1145/2629634", "10.1145/3170492.3136044", "10.1145/3212069.3212071", "10.1007/s00371-017-1403-8", "10.1007/s11042-014-2371-x", "10.1007/s11390-015-1542-1", "10.1016/B978-0-12-800645-0.50027-0", "10.1016/j.cag.2017.07.011", "10.1016/j.jpdc.2014.09.005", "10.1016/j.jpdc.2017.01.001", "10.1111/cgf.12259", "10.1111/cgf.13071", "10.1177/1094342014524807", "10.1631/FITEE.1500251", "10.1016/j.jocs.2018.06.005", "10.1007/978-3-319-94959-8_4", "10.1007/978-3-662-44917-2_63", "10.1016/j.optcom.2019.03.007", "10.1111/cgf.12158"], "referencing": ["10.1109/RT.2008.4634618", "10.1109/RT.2008.4634620", "10.1109/MCG.1987.276983", "10.1109/RT.2008.4634622", "10.1109/RT.2008.4634633", "10.1109/RT.2008.4634619", "10.1109/RT.2006.280208", "10.1109/RT.2006.280217", "10.1109/RT.2006.280218", "10.1109/RT.2006.280219", "10.1145/1572769.1572792", "10.1145/1468075.1468082", "10.1145/358876.358882", "10.1145/800031.808590", "10.1145/15886.15902", "10.1145/1572769.1572793", "10.1111/1467-8659.00508", "10.1111/j.1467-8659.2008.01261.x", "10.1007/978-3-642-56046-0_19"]}, "10.1109/TVCG.2011.158": {"doi": "10.1109/TVCG.2011.158", "author": ["Y. Park", "V. Lepetit", "W. Woo"], "title": "Handling Motion-Blur in 3D Tracking and Rendering for Augmented Reality", "year": "2012", "abstract": "The contribution of this paper is two-fold. First, we show how to extend the ESM algorithm to handle motion blur in 3D object tracking. ESM is a powerful algorithm for template matching-based tracking, but it can fail under motion blur. We introduce an image formation model that explicitly consider the possibility of blur, and shows its results in a generalization of the original ESM algorithm. This allows to converge faster, more accurately and more robustly even under large amount of blur. Our second contribution is an efficient method for rendering the virtual objects under the estimated motion blur. It renders two images of the object under 3D perspective, and warps them to create many intermediate images. By fusing these images we obtain a final image for the virtual objects blurred consistently with the captured image. Because warping is much faster than 3D rendering, we can create realistically blurred images at a very low computational cost.", "keywords": ["augmented reality", "image matching", "image motion analysis", "image restoration", "object tracking", "rendering (computer graphics)", "solid modelling", "motion-blur", "augmented reality", "ESM algorithm", "3D object tracking", "template matching-based tracking", "image formation model", "virtual objects", "intermediate images", "image fusion", "3D rendering", "Tracking", "Rendering (computer graphics)", "Three dimensional displays", "Cameras", "Jacobian matrices", "Robustness", "Computational modeling", "Augmented reality", "computer vision", "object tracking", "object detection", "motion-blur", "efficient second-order minimization."], "referenced_by": ["10.1109/ECBS-EERC.2013.17", "10.1109/ISUVR.2012.18", "10.1109/TVCG.2013.94", "10.1109/TVCG.2015.2513408", "10.1109/GCCE.2018.8574481", "10.1007/s11042-018-5834-7", "10.1016/j.cviu.2017.03.005", "10.1007/978-3-642-53842-1_28", "10.1007/s11280-018-0592-z", "10.1007/978-3-319-29451-3_36"], "referencing": ["10.1109/ISMAR.2006.297817", "10.1109/ISMAR.2006.297815", "10.1109/TVCG.2009.210", "10.1109/ISMAR.2009.5336487", "10.1109/ISMAR.2009.5336480", "10.1023/B:VISI.0000029664.99615.94", "10.1007/978-3-540-24673-2_38", "10.1007/978-3-540-88688-4_59", "10.1016/j.imavis.2004.02.007", "10.1023/B:VISI.0000011205.11775.fd", "10.1177/0278364907080252"]}, "10.1109/TVCG.2011.276": {"doi": "10.1109/TVCG.2011.276", "author": ["L. G. Zagorchev", "A. A. Goshtasby"], "title": "A Curvature-Adaptive Implicit Surface Reconstruction for Irregularly Spaced Points", "year": "2012", "abstract": "A curvature-adaptive implicit surface reconstruction for noisy and irregularly spaced points in 3D is introduced. The reconstructed surface traces the zero crossings of a signed field obtained from the sum of first-derivative anisotropic Gaussians centered at the points. The standard deviations of the anisotropic Gaussians are adapted to surface curvatures estimated from local data. A key characteristic of the formulation is its ability to smooth more along edges than across them, thereby preserving shape details while smoothing noise. The behavior of the proposed method under various density and organization of points is investigated and surface reconstruction results are compared with those obtained by well-known methods in the literature.", "keywords": ["Gaussian processes", "smoothing methods", "solid modelling", "curvature-adaptive implicit surface reconstruction", "irregularly spaced points", "noisy spaced points", "3D surface reconstruction", "signed field zero crossings", "first-derivative anisotropic Gaussians", "standard deviations", "surface curvatures", "local data", "shape details preservation", "noise smoothing", "computer graphics", "Surface reconstruction", "Surface treatment", "Shape", "Image reconstruction", "Smoothing methods", "Surface roughness", "Rough surfaces", "Computer graphics", "surface reconstruction", "implicit surface", "point cloud", "smoothness parameter."], "referenced_by": ["10.1109/ICASSP.2016.7471812", "10.1109/ICSensT.2013.6727635", "10.1109/TIFS.2014.2378146", "10.1109/ICIP.2019.8803384", "10.1145/3197517.3201337", "10.1002/9781119171744.ch8", "10.1007/978-981-10-6502-6_30", "10.1007/s00371-017-1370-0", "10.1007/s11431-016-6072-8", "10.1016/j.cviu.2018.01.009", "10.1190/segam2014-1447.1", "10.1371/journal.pone.0120151", "10.3390/math7100912"], "referencing": ["10.1109/TVCG.2003.1175093", "10.1109/2945.817351", "10.1109/TPAMI.1986.4767851", "10.1109/34.23112", "10.1109/TVCG.2003.1175097", "10.1109/38.909016", "10.1109/34.368173", "10.1109/SMA.2001.923379", "10.1109/SMI.2004.1314527", "10.1109/VISUAL.2004.28", "10.1109/VISUAL.2004.87", "10.1109/SMI.2003.1199611", "10.1109/TVCG.2009.208", "10.1109/34.57680", "10.1109/34.44401", "10.1109/34.85659", "10.1109/TPAMI.2004.1273934", "10.1109/TVCG.2002.1044520", "10.1145/376957.376986", "10.1145/357306.357310", "10.1145/357346.357349", "10.1145/383259.383266", "10.1145/237170.237269", "10.1145/174462.156635", "10.1145/1073204.1073227", "10.1145/1275808.1276406", "10.1145/1057432.1057434", "10.1145/127719.122742", "10.1145/122718.122743", "10.1145/566570.566585", "10.1145/1201775.882293", "10.1145/1186562.1015816", "10.1145/192161.192241", "10.1145/571647.571650", "10.1145/1102351.1102469", "10.1111/j.1467-8659.2006.00994.x", "10.1016/j.gmod.2006.09.007", "10.1007/978-3-540-33259-6_6", "10.1016/0010-4485(95)96800-2", "10.1007/s00371-004-0247-1", "10.1016/0167-8655(88)90080-3", "10.1006/cviu.1998.0664", "10.1016/j.cag.2004.08.009", "10.1016/j.cagd.2005.06.010", "10.1016/j.cag.2006.07.021", "10.1111/j.1467-8659.2009.01388.x", "10.1023/A:1008036829907", "10.1016/j.cviu.2005.07.003", "10.1007/0-387-21810-6_19", "10.1006/cviu.2000.0875"]}, "10.1109/TVCG.2011.262": {"doi": "10.1109/TVCG.2011.262", "author": ["S. Okaniwa", "A. Nasri", "H. Lin", "A. Abbas", "Y. Kineri", "T. Maekawa"], "title": "Uniform B-Spline Curve Interpolation with Prescribed Tangent and Curvature Vectors", "year": "2012", "abstract": "This paper presents a geometric algorithm for the generation of uniform cubic B-spline curves interpolating a sequence of data points under tangent and curvature vectors constraints. To satisfy these constraints, knot insertion is used to generate additional control points which are progressively repositioned using corresponding geometric rules. Compared to existing schemes, our approach is capable of handling plane as well as space curves, has local control, and avoids the solution of the typical linear system. The effectiveness of the proposed algorithm is illustrated through several comparative examples. Applications of the method in NC machining and shape design are also outlined.", "keywords": ["computational geometry", "interpolation", "splines (mathematics)", "uniform B-spline curve interpolation", "prescribed tangent", "curvature vectors", "geometric algorithm", "data point sequence", "curvature vectors constraints", "knot insertion", "handling plane", "space curves", "linear system", "NC machining", "shape design", "Spline", "Interpolation", "Equations", "Aerospace electronics", "Vectors", "Educational institutions", "Electronic mail", "B-spline curve", "interpolation", "tangent", "curvature vector", "parametric curve."], "referenced_by": ["10.1007/s00371-016-1282-4", "10.1016/j.cad.2014.05.001", "10.1016/j.cad.2016.04.001", "10.1016/j.cad.2017.10.002", "10.1016/j.cagd.2012.03.007", "10.1016/j.cagd.2016.10.002", "10.1016/j.cam.2017.06.013", "10.1080/02286203.2016.1142282", "10.1080/02286203.2017.1309260", "10.1155/2014/285045", "10.1016/j.cad.2018.04.009", "10.2534/jjasnaoe.27.149", "10.1007/s11424-018-7443-y", "10.2174/1872212113666190416154017", "10.1007/s11276-019-02224-y", "10.1016/j.cag.2020.05.012", "10.1177/0954411920908969", "10.1007/s00500-020-05114-0"], "referencing": ["10.1007/s00371-010-0441-2", "10.1007/978-3-642-48952-5", "10.1360/02yf0529", "10.1016/j.cad.2006.12.008", "10.3722/cadaps.2008.539-547", "10.1016/j.cad.2009.02.005", "10.1016/j.cad.2010.01.006", "10.1007/978-3-642-59223-2", "10.1007/978-3-662-04919-8", "10.1016/0010-4485(95)00080-1", "10.1016/0167-8396(87)90002-1", "10.1016/S0167-8396(01)00053-X", "10.1016/0167-8396(94)00034-P", "10.1016/0167-8396(96)00004-0", "10.1016/S0097-8493(02)00082-1", "10.1007/s003710100155"]}, "10.1109/TVCG.2011.264": {"doi": "10.1109/TVCG.2011.264", "author": ["D. Kim", "S. W. Lee", "O. Song", "H. Ko"], "title": "Baroclinic Turbulence with Varying Density and Temperature", "year": "2012", "abstract": "The explosive or volcanic scenes in motion pictures involve complex turbulent flow as its temperature and density vary in space. To simulate this turbulent flow of an inhomogeneous fluid, we propose a simple and efficient framework. Instead of explicitly computing the complex motion of this fluid dynamical instability, we first approximate the average motion of the fluid. Then, the high-resolution dynamics is computed using our new extended version of the vortex particle method with baroclinity. This baroclinity term makes turbulent effects by generating new vortex particles according to temperature/density distributions. Using our method, we efficiently simulated a complex scene with varying density and temperature.", "keywords": ["computational fluid dynamics", "computer animation", "flow instability", "turbulence", "vortices", "baroclinic turbulence", "varying density", "varying temperature", "volcanic scenes", "motion pictures", "complex turbulent flow", "inhomogeneous fluid", "complex motion", "fluid dynamical instability", "high-resolution dynamics", "vortex particle", "baroclinity term", "turbulent effects", "vortex particles", "Mathematical model", "Equations", "Computational modeling", "Nonhomogeneous media", "Force", "Computer graphics", "Heating", "Fluid animation", "variable density", "turbulent flow", "vortex particle method."], "referenced_by": ["10.1109/TVCG.2013.95", "10.1109/TVCG.2017.2665551", "10.1145/3072959.3073606", "10.1145/2601097.2601152", "10.1145/2461912.2461991", "10.1002/cav.1574", "10.1002/cav.1699", "10.1007/s00371-017-1353-1", "10.1007/s11042-014-1992-4", "10.1002/cav.1834", "10.3390/sym10100502", "10.1007/s42452-020-03200-4"], "referencing": ["10.1109/TVCG.2007.3", "10.1145/1360612.1360649", "10.1145/1409060.1409119", "10.1145/311535.311548", "10.1145/383259.383260", "10.1145/1073204.1073282", "10.1145/1073368.1073406", "10.1145/1276377.1276435", "10.1145/1618452.1618467", "10.1145/1141911.1141960", "10.1145/1276377.1276436", "10.1007/978-94-017-0075-7", "10.1017/S002211207400190X", "10.1063/1.1289503", "10.1115/HT2003-47548", "10.1155/2011/984363", "10.1016/j.ijthermalsci.2009.04.011", "10.1016/0010-2180(93)90090-P", "10.1017/S0022112073002016", "10.1016/0021-9991(88)90082-4", "10.1007/s10915-007-9166-4", "10.1111/j.1467-8659.2008.01144.x", "10.1017/S002211206800087X", "10.1017/CBO9780511608827", "10.1017/S0022112076001365", "10.1111/j.1467-8659.2009.01563.x"]}, "10.1109/TVCG.2011.273": {"doi": "10.1109/TVCG.2011.273", "author": ["I. Yeh", "W. Lin", "T. Lee", "H. Han", "J. Lee", "M. Kim"], "title": "Social-Event-Driven Camera Control for Multicharacter Animations", "year": "2012", "abstract": "In a virtual world, a group of virtual characters can interact with each other, and these characters may leave a group to join another. The interaction among individuals and groups often produces interesting events in a sequence of animation. The goal of this paper is to discover social events involving mutual interactions or group activities in multicharacter animations and automatically plan a smooth camera motion to view interesting events suggested by our system or relevant events specified by a user. Inspired by sociology studies, we borrow the knowledge in Proxemics, social force, and social network analysis to model the dynamic relation among social events and the relation among the participants within each event. By analyzing the variation of relation strength among participants and spatiotemporal correlation among events, we discover salient social events in a motion clip and generate an overview video of these events with smooth camera motion using a simulated annealing optimization method. We tested our approach on different motions performed by multiple characters. Our user study shows that our results are preferred in 66.19 percent of the comparisons with those by the camera control approach without event analysis and are comparable (51.79 percent) to professional results by an artist.", "keywords": ["cameras", "computer animation", "virtual reality", "social event driven camera control", "multicharacter animations", "virtual world", "virtual characters", "social events", "group activities", "mutual interactions", "smooth camera motion", "social network analysis", "social force", "Proxemics", "spatiotemporal correlation", "motion clip", "simulated annealing optimization method", "Cameras", "Trajectory", "Animation", "Social network services", "Force", "Particle measurements", "Atmospheric measurements", "MOCAP", "multicharacter animation", "event analysis", "social network analysis.", "Algorithms", "Computer Graphics", "Female", "Humans", "Imaging, Three-Dimensional", "Male", "Social Behavior", "Video Games"], "referenced_by": ["10.1109/TMM.2016.2612124", "10.1145/2766965", "10.1111/cgf.12206", "10.1002/cav.1884"], "referencing": ["10.1145/1186822.1073246", "10.1145/1457515.1409068", "10.1145/1665817.1665820", "10.1145/290747.290773", "10.1145/237170.237259", "10.1145/1401843.1401875", "10.1145/1531326.1531385", "10.1111/j.1467-8659.2009.01629.x", "10.1080/00222500701373251", "10.1111/1467-8659.00510", "10.1103/PhysRevE.51.4282", "10.1142/S0219525907001355", "10.1007/s00371-008-0228-x", "10.1007/s00371-009-0337-1", "10.1111/j.1467-8659.2009.01412.x", "10.1017/CBO9780511815478"]}, "10.1109/TVCG.2011.157": {"doi": "10.1109/TVCG.2011.157", "author": ["A. Asthana", "M. de la Hunty", "A. Dhall", "R. Goecke"], "title": "Facial Performance Transfer via Deformable Models and Parametric Correspondence", "year": "2012", "abstract": "The issue of transferring facial performance from one person's face to another's has been an area of interest for the movie industry and the computer graphics community for quite some time. In recent years, deformable face models, such as the Active Appearance Model (AAM), have made it possible to track and synthesize faces in real time. Not surprisingly, deformable face model-based approaches for facial performance transfer have gained tremendous interest in the computer vision and graphics community. In this paper, we focus on the problem of real-time facial performance transfer using the AAM framework. We propose a novel approach of learning the mapping between the parameters of two completely independent AAMs, using them to facilitate the facial performance transfer in a more realistic manner than previous approaches. The main advantage of modeling this parametric correspondence is that it allows a \"meaningful\u201d transfer of both the nonrigid shape and texture across faces irrespective of the speakers' gender, shape, and size of the faces, and illumination conditions. We explore linear and nonlinear methods for modeling the parametric correspondence between the AAMs and show that the sparse linear regression method performs the best. Moreover, we show the utility of the proposed framework for a cross-language facial performance transfer that is an area of interest for the movie dubbing industry.", "keywords": ["cinematography", "image texture", "regression analysis", "solid modelling", "parametric correspondence", "computer graphics community", "active appearance model", "deformable face model-based approaches", "computer vision", "nonrigid shape", "nonrigid texture", "sparse linear regression method", "cross-language facial performance transfer", "movie dubbing industry", "Face", "Shape", "Computational modeling", "Active appearance model", "Training", "Deformable models", "Solid modeling", "Active appearance models", "facial performance transfer", "face modeling and animation.", "Algorithms", "Computer Graphics", "Computer Simulation", "Face", "Female", "Humans", "Imaging, Three-Dimensional", "Male"], "referenced_by": ["10.1109/ACII.2013.111", "10.1109/CVPR.2014.240", "10.1109/ICME.2012.160", "10.1109/THMS.2016.2599495", "10.1109/TMM.2018.2871417", "10.1007/s11042-014-2125-9", "10.1155/2013/506752", "10.1155/2014/810185", "10.1117/12.2049921", "10.7874/jao.2018.00318", "10.1007/978-3-319-25958-1_13"], "referencing": ["10.1109/AFGR.1998.670965", "10.1109/JSTSP.2007.910971", "10.1109/TIP.2003.819861", "10.1145/280814.280825", "10.1145/383259.383290", "10.1145/383259.383289", "10.1145/1073368.1073388", "10.1145/1322192.1322217", "10.1145/1399504.1360637", "10.1145/1073204.1073209", "10.1145/1186562.1015736", "10.1111/1467-8659.t01-1-00712", "10.1023/A:1008074226832", "10.1002/cpa.20132", "10.1017/CBO9780511811685", "10.1007/978-3-642-17534-3_60"]}, "10.1109/TVCG.2011.279": {"doi": "10.1109/TVCG.2011.279", "author": ["H. Lam", "E. Bertini", "P. Isenberg", "C. Plaisant", "S. Carpendale"], "title": "Empirical Studies in Information Visualization: Seven Scenarios", "year": "2012", "abstract": "We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one's own study.", "keywords": ["data visualisation", "empirical studies", "information visualization", "seven scenarios", "visual data analysis", "visual data reasoning", "user performance evaluation", "evaluating user experience", "evaluating environments", "evaluating communication", "evaluating visualization algorithms", "evaluating collaborative data analysis", "visualization publications", "Data visualization", "Visualization", "Data analysis", "Encoding", "Systematics", "Taxonomy", "Electronic mail", "Information visualization", "evaluation."], "referenced_by": ["10.1007/978-3-319-58071-5_28", "10.1007/978-3-319-60922-5_28", "10.1007/978-3-319-66435-4_5", "10.1007/978-3-319-74860-3_9", "10.1007/s00371-013-0892-3", "10.1007/s11192-015-1830-0", "10.1007/s11390-013-1383-8", "10.1007/s11548-018-1741-7", "10.1007/s13748-016-0089-x", "10.1007/s41060-016-0016-z", "10.1016/j.artmed.2015.05.008", "10.1016/j.cag.2013.10.009", "10.1016/j.cie.2017.01.025", "10.1016/j.cose.2017.02.003", "10.1016/j.dss.2016.02.001", "10.1016/j.dss.2017.09.007", "10.1016/j.proeng.2016.01.308", "10.1016/j.visinf.2018.02.001", "10.1057/s41303-017-0060-3", "10.1080/01629778.2018.1455719", "10.1080/10618600.2017.1383264", "10.1080/13658816.2017.1325488", "10.1080/17538947.2014.927536", "10.1080/23729333.2017.1288534", "10.1080/23729333.2017.1302910", "10.1111/cgf.12091", "10.1111/cgf.12378", "10.1111/cgf.12380", "10.1111/cgf.12613", "10.1111/cgf.12632"], "referencing": ["IKEY:1382894", "IKEY:5290691", "IKEY:5290725", "IKEY:5613431", "IKEY:4376146", "IKEY:4658128", "IKEY:5185485", "IKEY:5652880", "IKEY:4376133", "IKEY:5290695", "IKEY:4909117", "IKEY:4376134", "IKEY:1703371", "IKEY:1249031", "IKEY:1510530", "IKEY:4376149", "IKEY:1382897", "IKEY:4376131", "IKEY:4376132", "IKEY:1382894", "IKEY:5290691", "IKEY:5290725", "IKEY:5613431", "IKEY:4376146", "IKEY:4658128", "IKEY:5185485", "IKEY:5652880", "IKEY:4376133", "IKEY:5290695", "IKEY:4909117", "IKEY:4376134", "IKEY:1703371", "IKEY:1249031", "IKEY:1510530", "IKEY:4376149", "IKEY:1382897", "IKEY:4376131", "IKEY:4376132", "IKEY:1382894", "IKEY:5290691", "IKEY:5290725", "IKEY:5613431", "IKEY:4376146", "IKEY:4658128", "IKEY:5185485", "IKEY:5652880", "IKEY:4376133", "IKEY:5290695", "IKEY:4909117", "IKEY:4376134", "IKEY:1703371", "IKEY:1249031", "IKEY:1510530", "IKEY:4376149", "IKEY:1382897", "IKEY:4376131", "IKEY:4376132", "10.1145/571647.571649", "10.1145/1358628.1358955", "10.1145/1357054.1357074", "10.1145/62266.62273", "10.1145/1240624.1240781", "10.1145/371578.371593", "10.1145/1357054.1357245", "10.1145/1377966.1377974", "10.1145/503112.503114", "10.1145/1357054.1357127", "10.1145/1377966.1377969", "10.1145/1140491.1140515", "10.1145/1031607.1031626", "10.1145/503457.503458", "10.1145/966930.966932", "10.1145/989863.989880", "10.1145/288392.288596", "10.1145/1168149.1168158", "10.1145/1377966.1377975", "10.1145/192844.193066", "10.1145/1168149.1168162", "10.1145/571647.571649", "10.1145/1358628.1358955", "10.1145/1357054.1357074", "10.1145/62266.62273", "10.1145/1240624.1240781", "10.1145/371578.371593", "10.1145/1357054.1357245", "10.1145/1377966.1377974", "10.1145/503112.503114", "10.1145/1357054.1357127", "10.1145/1377966.1377969", "10.1145/1140491.1140515", "10.1145/1031607.1031626", "10.1145/503457.503458", "10.1145/966930.966932", "10.1145/989863.989880", "10.1145/288392.288596", "10.1145/1168149.1168158", "10.1145/1377966.1377975", "10.1145/192844.193066", "10.1145/1168149.1168162", "10.1145/571647.571649", "10.1145/1358628.1358955", "10.1145/1357054.1357074", "10.1145/62266.62273", "10.1145/1240624.1240781", "10.1145/371578.371593", "10.1145/1357054.1357245", "10.1145/1377966.1377974", "10.1145/503112.503114", "10.1145/1357054.1357127", "10.1145/1377966.1377969", "10.1145/1140491.1140515", "10.1145/1031607.1031626", "10.1145/503457.503458", "10.1145/966930.966932", "10.1145/989863.989880", "10.1145/288392.288596", "10.1145/1168149.1168158", "10.1145/1377966.1377975", "10.1145/192844.193066", "10.1145/1168149.1168162", "10.1080/014492998119328", "10.1007/3-540-45348-2_14", "10.1057/palgrave.ivs.9500005", "10.1006/ijhc.2000.0422", "10.1057/ivs.2009.16", "10.1057/palgrave.ivs.9500081", "10.1057/palgrave.ivs.9500173", "10.3127/ajis.v7i2.267", "10.1111/j.1467-8659.2008.01222.x", "10.1007/978-3-540-71949-6_2", "10.1162/1054746053890279", "10.1111/j.1467-8659.2008.01231.x", "10.1057/palgrave.ivs.9500075", "10.1057/palgrave.ivs.9500047", "10.1177/1473871611413099", "10.1057/palgrave.ivs.9500065", "10.1006/ijhc.2000.0419", "10.1057/palgrave.ivs.9500145", "10.1080/014492998119328", "10.1007/3-540-45348-2_14", "10.1057/palgrave.ivs.9500005", "10.1006/ijhc.2000.0422", "10.1057/ivs.2009.16", "10.1057/palgrave.ivs.9500081", "10.1057/palgrave.ivs.9500173", "10.3127/ajis.v7i2.267", "10.1111/j.1467-8659.2008.01222.x", "10.1007/978-3-540-71949-6_2", "10.1162/1054746053890279", "10.1111/j.1467-8659.2008.01231.x", "10.1057/palgrave.ivs.9500075", "10.1057/palgrave.ivs.9500047", "10.1177/1473871611413099", "10.1057/palgrave.ivs.9500065", "10.1006/ijhc.2000.0419", "10.1057/palgrave.ivs.9500145", "10.1080/014492998119328", "10.1007/3-540-45348-2_14", "10.1057/palgrave.ivs.9500005", "10.1006/ijhc.2000.0422", "10.1057/ivs.2009.16", "10.1057/palgrave.ivs.9500081", "10.1057/palgrave.ivs.9500173", "10.3127/ajis.v7i2.267", "10.1111/j.1467-8659.2008.01222.x", "10.1007/978-3-540-71949-6_2", "10.1162/1054746053890279", "10.1111/j.1467-8659.2008.01231.x", "10.1057/palgrave.ivs.9500075", "10.1057/palgrave.ivs.9500047", "10.1177/1473871611413099", "10.1057/palgrave.ivs.9500065", "10.1006/ijhc.2000.0419", "10.1057/palgrave.ivs.9500145"]}, "10.1109/TVCG.2011.268": {"doi": "10.1109/TVCG.2011.268", "author": ["P. Rosen", "V. Popescu"], "title": "Simplification of Node Position Data ;for Interactive Visualization of Dynamic Data Sets", "year": "2012", "abstract": "We propose to aid the interactive visualization of time-varying spatial data sets by simplifying node position data over the entire simulation as opposed to over individual states. Our approach is based on two observations. The first observation is that the trajectory of some nodes can be approximated well without recording the position of the node for every state. The second observation is that there are groups of nodes whose motion from one state to the next can be approximated well with a single transformation. We present data set simplification techniques that take advantage of this node data redundancy. Our techniques are general, supporting many types of simulations, they achieve good compression factors, and they allow rigorous control of the maximum node position approximation error. We demonstrate our approach in the context of finite element analysis data, of liquid flow simulation data, and of fusion simulation data.", "keywords": ["approximation theory", "data visualisation", "finite element analysis", "interactive systems", "node position data", "interactive visualization", "dynamic data sets", "time-varying spatial data sets", "data set simplification techniques", "node data redundancy", "good compression factors", "maximum node position approximation error", "finite element analysis data", "Trajectory", "Data models", "Data visualization", "Clustering algorithms", "Encoding", "Approximation methods", "Computational modeling", "Simplification of node positions", "trajectory simplification", "trajectory clustering", "rigid body decomposition", "interactive visualization", "simulation data compression.", "Algorithms", "Computer Graphics", "Computer Simulation", "Humans", "Image Processing, Computer-Assisted", "Motor Vehicles"], "referenced_by": ["IKEY:6815027", "IKEY:6689392", "IKEY:6671915", "10.1007/s11432-014-5116-6"], "referencing": ["IKEY:764870", "IKEY:1183768", "IKEY:1402170", "IKEY:4515862", "IKEY:4015488", "IKEY:1607248", "IKEY:1056489", "IKEY:764870", "IKEY:1183768", "IKEY:1402170", "IKEY:4515862", "IKEY:4015488", "IKEY:1607248", "IKEY:1056489", "IKEY:764870", "IKEY:1183768", "IKEY:1402170", "IKEY:4515862", "IKEY:4015488", "IKEY:1607248", "IKEY:1056489", "10.1145/218380.218391", "10.1145/280814.280836", "10.1145/344779.344924", "10.1145/274363.274365", "10.1145/1137856.1137902", "10.1145/383259.383281", "10.1145/1037957.1037961", "10.1145/1247480.1247546", "10.1145/300523.300533", "10.1145/1073368.1073398", "10.1145/1073204.1073206", "10.1145/505008.505023", "10.1145/1028523.1028547", "10.1145/214762.214771", "10.1145/218380.218391", "10.1145/280814.280836", "10.1145/344779.344924", "10.1145/274363.274365", "10.1145/1137856.1137902", "10.1145/383259.383281", "10.1145/1037957.1037961", "10.1145/1247480.1247546", "10.1145/300523.300533", "10.1145/1073368.1073398", "10.1145/1073204.1073206", "10.1145/505008.505023", "10.1145/1028523.1028547", "10.1145/214762.214771", "10.1145/218380.218391", "10.1145/280814.280836", "10.1145/344779.344924", "10.1145/274363.274365", "10.1145/1137856.1137902", "10.1145/383259.383281", "10.1145/1037957.1037961", "10.1145/1247480.1247546", "10.1145/300523.300533", "10.1145/1073368.1073398", "10.1145/1073204.1073206", "10.1145/505008.505023", "10.1145/1028523.1028547", "10.1145/214762.214771", "10.1111/j.1467-8659.2005.00872.x", "10.1006/gmod.2002.0575", "10.1016/j.patcog.2005.01.025", "10.1007/978-3-642-15880-3_25", "10.1111/1467-8659.00581", "10.1111/1467-8659.00433", "10.1016/j.cag.2003.10.002", "10.1111/j.1467-8659.2009.01374.x", "10.1016/j.cad.2004.09.015", "10.1016/S0146-664X(72)80017-0", "10.3138/FM57-6770-U75U-7727", "10.1111/j.1467-8659.2005.00872.x", "10.1006/gmod.2002.0575", "10.1016/j.patcog.2005.01.025", "10.1007/978-3-642-15880-3_25", "10.1111/1467-8659.00581", "10.1111/1467-8659.00433", "10.1016/j.cag.2003.10.002", "10.1111/j.1467-8659.2009.01374.x", "10.1016/j.cad.2004.09.015", "10.1016/S0146-664X(72)80017-0", "10.3138/FM57-6770-U75U-7727", "10.1111/j.1467-8659.2005.00872.x", "10.1006/gmod.2002.0575", "10.1016/j.patcog.2005.01.025", "10.1007/978-3-642-15880-3_25", "10.1111/1467-8659.00581", "10.1111/1467-8659.00433", "10.1016/j.cag.2003.10.002", "10.1111/j.1467-8659.2009.01374.x", "10.1016/j.cad.2004.09.015", "10.1016/S0146-664X(72)80017-0", "10.3138/FM57-6770-U75U-7727"]}, "10.1109/TVCG.2011.272": {"doi": "10.1109/TVCG.2011.272", "author": ["A. Gyulassy", "N. Kotava", "M. Kim", "C. D. Hansen", "H. Hagen", "V. Pascucci"], "title": "Direct Feature Visualization Using Morse-Smale Complexes", "year": "2012", "abstract": "In this paper, we characterize the range of features that can be extracted from an Morse-Smale complex and describe a unified query language to extract them. We provide a visual dictionary to guide users when defining features in terms of these queries. We demonstrate our topology-rich visualization pipeline in a tool that interactively queries the MS complex to extract features at multiple resolutions, assigns rendering attributes, and combines traditional volume visualization with the extracted features. The flexibility and power of this approach is illustrated with examples showing novel features.", "keywords": ["data visualisation", "dictionaries", "query languages", "rendering (computer graphics)", "direct feature visualization", "Morse-Smale complexes", "unified query language", "visual dictionary", "topology-rich visualization pipeline", "MS complex", "rendering attributes", "traditional volume visualization", "Feature extraction", "Manifolds", "Data visualization", "Geometry", "Vectors", "Visualization", "Data structures", "Volume visualization", "applications", "feature detection", "topology."], "referenced_by": ["IKEY:6875918", "IKEY:7150427", "IKEY:8944363", "10.1145/2666310.2666412", "10.1002/jcc.25181", "10.1007/978-3-319-24726-7_9", "10.1007/978-3-319-44684-4_19", "10.1007/978-3-319-44684-4_8", "10.1007/978-3-319-44684-4_9", "10.1016/j.cag.2015.05.007", "10.1016/j.cag.2017.05.015", "10.1093/mnras/stw2862", "10.1111/cgf.12123", "10.1111/cgf.12361", "10.1111/cgf.12596", "10.1111/cgf.12933", "10.1587/transinf.2017EDL8188", "10.1016/j.cad.2018.09.002", "10.1088/2051-672X/ab70e8", "10.1016/j.commatsci.2020.109782"], "referencing": ["IKEY:468400", "IKEY:1021579", "IKEY:4658153", "IKEY:4906854", "IKEY:4015460", "IKEY:1407860", "IKEY:1372235", "IKEY:5290727", "IKEY:4069241", "IKEY:1298796", "IKEY:1634313", "IKEY:1310275", "IKEY:4658183", "IKEY:4015464", "IKEY:5128904", "IKEY:4376171", "IKEY:468400", "IKEY:1021579", "IKEY:4658153", "IKEY:4906854", "IKEY:4015460", "IKEY:1407860", "IKEY:1372235", "IKEY:5290727", "IKEY:4069241", "IKEY:1298796", "IKEY:1634313", "IKEY:1310275", "IKEY:4658183", "IKEY:4015464", "IKEY:5128904", "IKEY:4376171", "IKEY:468400", "IKEY:1021579", "IKEY:4658153", "IKEY:4906854", "IKEY:4015460", "IKEY:1407860", "IKEY:1372235", "IKEY:5290727", "IKEY:4069241", "IKEY:1298796", "IKEY:1634313", "IKEY:1310275", "IKEY:4658183", "IKEY:4015464", "IKEY:5128904", "IKEY:4376171", "10.1145/964965.808594", "10.1145/54852.378484", "10.1145/990002.990007", "10.1145/777792.777846", "10.1145/777792.777845", "10.1145/964965.808594", "10.1145/54852.378484", "10.1145/990002.990007", "10.1145/777792.777846", "10.1145/777792.777845", "10.1145/964965.808594", "10.1145/54852.378484", "10.1145/990002.990007", "10.1145/777792.777846", "10.1145/777792.777845", "10.1016/j.parco.2007.09.001", "10.1016/S0925-7721(02)00093-7", "10.1016/j.comgeo.2004.05.002", "10.1111/1467-8659.00697", "10.1002/0470020288", "10.2307/1970311", "10.2307/1970239", "10.1007/s00454-003-2926-5", "10.1080/10586458.2005.10128941", "10.1006/aima.1997.1650", "10.1007/b106657_2", "10.1086/432646", "10.1016/j.parco.2007.09.001", "10.1016/S0925-7721(02)00093-7", "10.1016/j.comgeo.2004.05.002", "10.1111/1467-8659.00697", "10.1002/0470020288", "10.2307/1970311", "10.2307/1970239", "10.1007/s00454-003-2926-5", "10.1080/10586458.2005.10128941", "10.1006/aima.1997.1650", "10.1007/b106657_2", "10.1086/432646", "10.1016/j.parco.2007.09.001", "10.1016/S0925-7721(02)00093-7", "10.1016/j.comgeo.2004.05.002", "10.1111/1467-8659.00697", "10.1002/0470020288", "10.2307/1970311", "10.2307/1970239", "10.1007/s00454-003-2926-5", "10.1080/10586458.2005.10128941", "10.1006/aima.1997.1650", "10.1007/b106657_2", "10.1086/432646"]}, "10.1109/TVCG.2011.269": {"doi": "10.1109/TVCG.2011.269", "author": ["J. Reininghaus", "J. Kasten", "T. Weinkauf", "I. Hotz"], "title": "Efficient Computation of Combinatorial Feature Flow Fields", "year": "2012", "abstract": "We propose a combinatorial algorithm to track critical points of 2D time-dependent scalar fields. Existing tracking algorithms such as Feature Flow Fields apply numerical schemes utilizing derivatives of the data, which makes them prone to noise and involve a large number of computational parameters. In contrast, our method is robust against noise since it does not require derivatives, interpolation, and numerical integration. Furthermore, we propose an importance measure that combines the spatial persistence of a critical point with its temporal evolution. This leads to a time-aware feature hierarchy, which allows us to discriminate important from spurious features. Our method requires only a single, easy-to-tune computational parameter and is naturally formulated in an out-of-core fashion, which enables the analysis of large data sets. We apply our method to synthetic data and data sets from computational fluid dynamics and compare it to the stabilized continuous Feature Flow Field tracking algorithm.", "keywords": ["combinatorial mathematics", "computational fluid dynamics", "flow visualisation", "numerical analysis", "combinatorial feature flow field computation", "combinatorial algorithm", "critical points tracking", "2D time-dependent scalar fields", "tracking algorithms", "numerical schemes", "computational parameters", "noise robustness", "importance measure", "spatial persistence", "temporal evolution", "time-aware feature hierarchy", "computational fluid dynamics", "flow visualization", "Feature extraction", "Algorithm design and analysis", "Joining processes", "Manifolds", "Noise measurement", "Jacobian matrices", "Noise", "Flow visualization", "graph algorithms."], "referenced_by": ["IKEY:7164122", "IKEY:6064972", "IKEY:7117431", "IKEY:8303701", "IKEY:8739196", "IKEY:8827410", "IKEY:8944363", "10.1049/el.2015.4361", "10.1007/978-3-319-44684-4_2", "10.1111/cgf.12596", "10.1111/cgf.12933", "10.1007/978-3-319-04099-8_2", "10.1111/cgf.12109", "10.1007/978-3-030-43036-8_10"], "referencing": ["IKEY:4376176", "IKEY:299407", "IKEY:4015464", "IKEY:597796", "IKEY:1541996", "IKEY:5128904", "IKEY:1372214", "IKEY:4658183", "IKEY:5766002", "IKEY:5487517", "IKEY:4376212", "IKEY:4376176", "IKEY:299407", "IKEY:4015464", "IKEY:597796", "IKEY:1541996", "IKEY:5128904", "IKEY:1372214", "IKEY:4658183", "IKEY:5766002", "IKEY:5487517", "IKEY:4376212", "IKEY:4376176", "IKEY:299407", "IKEY:4015464", "IKEY:597796", "IKEY:1541996", "IKEY:5128904", "IKEY:1372214", "IKEY:4658183", "IKEY:5766002", "IKEY:5487517", "IKEY:4376212", "10.1145/378583.378626", "10.1145/1177352.1177355", "10.1145/1137856.1137877", "10.1145/378583.378626", "10.1145/1177352.1177355", "10.1145/1137856.1137877", "10.1145/378583.378626", "10.1145/1177352.1177355", "10.1145/1137856.1137877", "10.1007/PL00004638", "10.1111/j.1467-8659.2003.00723.x", "10.1007/978-3-7091-6803-5_7", "10.1111/1467-8659.00625", "10.1007/978-3-642-15014-2_20", "10.1016/S0097-8493(02)00056-0", "10.1017/CBO9781139106962.003", "10.1016/j.comgeo.2007.11.001", "10.1016/S0012-365X(99)00258-7", "10.1007/978-3-642-15582-6_35", "10.1006/aima.1997.1650", "10.1007/s00454-002-2885-2", "10.1515/JNETDY.2008.006", "10.2514/6.2003-59", "10.1111/j.1467-8659.2009.01686.x", "10.1007/PL00004638", "10.1111/j.1467-8659.2003.00723.x", "10.1007/978-3-7091-6803-5_7", "10.1111/1467-8659.00625", "10.1007/978-3-642-15014-2_20", "10.1016/S0097-8493(02)00056-0", "10.1017/CBO9781139106962.003", "10.1016/j.comgeo.2007.11.001", "10.1016/S0012-365X(99)00258-7", "10.1007/978-3-642-15582-6_35", "10.1006/aima.1997.1650", "10.1007/s00454-002-2885-2", "10.1515/JNETDY.2008.006", "10.2514/6.2003-59", "10.1111/j.1467-8659.2009.01686.x", "10.1007/PL00004638", "10.1111/j.1467-8659.2003.00723.x", "10.1007/978-3-7091-6803-5_7", "10.1111/1467-8659.00625", "10.1007/978-3-642-15014-2_20", "10.1016/S0097-8493(02)00056-0", "10.1017/CBO9781139106962.003", "10.1016/j.comgeo.2007.11.001", "10.1016/S0012-365X(99)00258-7", "10.1007/978-3-642-15582-6_35", "10.1006/aima.1997.1650", "10.1007/s00454-002-2885-2", "10.1515/JNETDY.2008.006", "10.2514/6.2003-59", "10.1111/j.1467-8659.2009.01686.x"]}, "10.1109/TVCG.2011.280": {"doi": "10.1109/TVCG.2011.280", "author": ["R. Bramon", "I. Boada", "A. Bardera", "J. Rodriguez", "M. Feixas", "J. Puig", "M. Sbert"], "title": "Multimodal Data Fusion Based on Mutual Information", "year": "2012", "abstract": "Multimodal visualization aims at fusing different data sets so that the resulting combination provides more information and understanding to the user. To achieve this aim, we propose a new information-theoretic approach that automatically selects the most informative voxels from two volume data sets. Our fusion criteria are based on the information channel created between the two input data sets that permit us to quantify the information associated with each intensity value. This specific information is obtained from three different ways of decomposing the mutual information of the channel. In addition, an assessment criterion based on the information content of the fused data set can be used to analyze and modify the initial selection of the voxels by weighting the contribution of each data set to the final result. The proposed approach has been integrated in a general framework that allows for the exploration of volumetric data models and the interactive change of some parameters of the fused data set. The proposed approach has been evaluated on different medical data sets with very promising results.", "keywords": ["content management", "data visualisation", "medical computing", "sensor fusion", "mutual information-based multimodal data fusion", "multimodal data visualization", "information-theoretic approach", "informative voxels", "information channel", "intensity value", "mutual information decomposition", "assessment criterion", "information content", "volumetric data models exploration", "medical data sets", "Transfer functions", "Data visualization", "Rendering (computer graphics)", "Mutual information", "Biomedical imaging", "Image color analysis", "Data models", "Multimodal visualization", "image fusion", "information theory", "mutual information."], "referenced_by": ["IKEY:6516552", "IKEY:6987279", "IKEY:6531058", "IKEY:6977960", "IKEY:6634187", "IKEY:7368928", "IKEY:8451409", "IKEY:8673763", "10.1145/3134472.3134507", "10.1007/s00371-013-0833-1", "10.1007/s10044-017-0616-9", "10.1007/s11265-016-1151-4", "10.1016/j.sigpro.2013.07.006", "10.1111/cgf.13306", "10.2200/S00560ED1V01Y201312CGR015", "10.3390/e19050187", "10.1117/12.2043186", "10.3390/e20070540", "10.1016/j.eswa.2019.05.016", "10.3390/e21070699", "10.1007/s11432-018-9740-7", "10.1162/neco_a_01273", "10.1016/j.ins.2020.06.072"], "referencing": ["IKEY:563664", "IKEY:1216223", "IKEY:4806563", "IKEY:4015449", "IKEY:4658174", "IKEY:4376204", "IKEY:594025", "IKEY:511", "IKEY:1359734", "IKEY:4376190", "IKEY:563664", "IKEY:1216223", "IKEY:4806563", "IKEY:4015449", "IKEY:4658174", "IKEY:4376204", "IKEY:594025", "IKEY:511", "IKEY:1359734", "IKEY:4376190", "IKEY:563664", "IKEY:1216223", "IKEY:4806563", "IKEY:4015449", "IKEY:4658174", "IKEY:4376204", "IKEY:594025", "IKEY:511", "IKEY:1359734", "IKEY:4376190", "10.1145/1462055.1462056", "10.1145/1462055.1462056", "10.1145/1462055.1462056", "10.1111/1467-8659.00356", "10.1088/0031-9155/46/3/201", "10.1007/3-540-46080-2_11", "10.1111/j.1467-8659.2009.01429.x", "10.1016/j.scriptamat.2008.11.004", "10.1016/j.imavis.2005.02.004", "10.1016/j.cag.2010.01.006", "10.1111/j.1467-8659.2009.01689.x", "10.1148/radiology.172.3.2788893", "10.1002/0471200611", "10.1088/0954-898X/10/4/303", "10.1016/j.biosystems.2006.04.009", "10.1088/0954-898X/10/4/303", "10.1111/1467-8659.00356", "10.1088/0031-9155/46/3/201", "10.1007/3-540-46080-2_11", "10.1111/j.1467-8659.2009.01429.x", "10.1016/j.scriptamat.2008.11.004", "10.1016/j.imavis.2005.02.004", "10.1016/j.cag.2010.01.006", "10.1111/j.1467-8659.2009.01689.x", "10.1148/radiology.172.3.2788893", "10.1002/0471200611", "10.1088/0954-898X/10/4/303", "10.1016/j.biosystems.2006.04.009", "10.1088/0954-898X/10/4/303", "10.1111/1467-8659.00356", "10.1088/0031-9155/46/3/201", "10.1007/3-540-46080-2_11", "10.1111/j.1467-8659.2009.01429.x", "10.1016/j.scriptamat.2008.11.004", "10.1016/j.imavis.2005.02.004", "10.1016/j.cag.2010.01.006", "10.1111/j.1467-8659.2009.01689.x", "10.1148/radiology.172.3.2788893", "10.1002/0471200611", "10.1088/0954-898X/10/4/303", "10.1016/j.biosystems.2006.04.009", "10.1088/0954-898X/10/4/303"]}}