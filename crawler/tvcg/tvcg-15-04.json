{"10.1109/TVCG.2015.2391858": {"doi": "10.1109/TVCG.2015.2391858", "author": ["R. Mehra", "A. Rungta", "A. Golas", "M. Lin", "D. Manocha"], "title": "WAVE: Interactive Wave-based Sound Propagation for Virtual Environments", "year": "2015", "abstract": "We present an interactive wave-based sound propagation system that generates accurate, realistic sound in virtual environments for dynamic (moving) sources and listeners. We propose a novel algorithm to accurately solve the wave equation for dynamic sources and listeners using a combination of precomputation techniques and GPU-based runtime evaluation. Our system can handle large environments typically used in VR applications, compute spatial sound corresponding to listener's motion (including head tracking) and handle both omnidirectional and directional sources, all at interactive rates. As compared to prior wave-based techniques applied to large scenes with moving sources, we observe significant improvement in runtime memory. The overall sound-propagation and rendering system has been integrated with the Half-Life 2 game engine, Oculus-Rift head-mounted display, and the Xbox game controller to enable users to experience high-quality acoustic effects (e.g., amplification, diffraction low-passing, high-order scattering) and spatial audio, based on their interactions in the VR application. We provide the results of preliminary user evaluations, conducted to study the impact of wave-based acoustic effects and spatial audio on users' navigation performance in virtual environments.", "keywords": ["acoustic wave propagation", "graphics processing units", "rendering (computer graphics)", "virtual reality", "wave equations", "WAVE", "interactive wave-based sound propagation", "virtual environments", "dynamic sources", "wave equation", "GPU-based runtime evaluation", "VR applications", "omnidirectional sources", "rendering system", "Half-Life 2 game engine", "Oculus-Rift head-mounted display", "Xbox game controller", "high-quality acoustic effects", "spatial audio", "wave-based acoustic effects", "user navigation performance", "Runtime", "Acoustics", "Vectors", "Transfer functions", "Virtual environments", "Linear systems", "Navigation", "Sound propagation", "dynamic sources", "spatial sound", "Sound propagation", "dynamic sources", "directivity", "spatial sound", "Helmholtz equation", "Acoustic Stimulation", "Adult", "Algorithms", "Computer Graphics", "Female", "Humans", "Male", "Sound", "User-Computer Interface", "Video Games", "Young Adult"], "referenced_by": ["IKEY:7384541", "IKEY:7835714", "IKEY:8307458", "IKEY:8642450", "IKEY:8643846", "IKEY:8998401", "IKEY:8998301", "IKEY:9089553", "10.1145/2947508", "10.1145/3197517.3201339", "10.1007/s00371-017-1383-8", "10.1016/j.buildenv.2016.06.028", "10.1177/2331216518800871", "10.1299/jamdsm.2018jamdsm0126", "10.1121/1.5109396", "10.1007/s40869-019-00086-0", "10.1016/j.buildenv.2019.106553", "10.1080/09298215.2019.1708413", "10.1016/j.apacoust.2020.107280"], "referencing": ["IKEY:969552", "IKEY:4494749", "IKEY:6788010", "IKEY:6777442", "IKEY:6788050", "IKEY:1667649", "IKEY:4907060", "IKEY:969552", "IKEY:4494749", "IKEY:6788010", "IKEY:6777442", "IKEY:6788050", "IKEY:1667649", "IKEY:4907060", "IKEY:969552", "IKEY:4494749", "IKEY:6788010", "IKEY:6777442", "IKEY:6788050", "IKEY:1667649", "IKEY:4907060", "10.1145/280814.280818", "10.1145/1179352.1141983", "10.1145/2451236.2451245", "10.1145/2601097.2601184", "10.1145/1833349.1778805", "10.1145/2601097.2601216", "10.1145/1631272.1631311", "10.1145/383259.383323", "10.1145/2508363.2508420", "10.1145/280814.280818", "10.1145/1179352.1141983", "10.1145/2451236.2451245", "10.1145/2601097.2601184", "10.1145/1833349.1778805", "10.1145/2601097.2601216", "10.1145/1631272.1631311", "10.1145/383259.383323", "10.1145/2508363.2508420", "10.1145/280814.280818", "10.1145/1179352.1141983", "10.1145/2451236.2451245", "10.1145/2601097.2601184", "10.1145/1833349.1778805", "10.1145/2601097.2601216", "10.1145/1631272.1631311", "10.1145/383259.383323", "10.1145/2508363.2508420", "10.1007/978-3-540-85035-9_27", "10.1121/1.390983", "10.1016/j.enganabound.2004.12.001", "10.1142/9789812772572_0043", "10.1250/ast.29.191", "10.1007/978-0-387-09517-2", "10.1121/1.426873", "10.1250/ast.24.42", "10.1121/1.3278605", "10.3813/AAA.918132", "10.1121/1.428071", "10.1121/1.2164987", "10.1121/1.3009552", "10.1007/978-3-540-85035-9_27", "10.1121/1.390983", "10.1016/j.enganabound.2004.12.001", "10.1142/9789812772572_0043", "10.1250/ast.29.191", "10.1007/978-0-387-09517-2", "10.1121/1.426873", "10.1250/ast.24.42", "10.1121/1.3278605", "10.3813/AAA.918132", "10.1121/1.428071", "10.1121/1.2164987", "10.1121/1.3009552", "10.1007/978-3-540-85035-9_27", "10.1121/1.390983", "10.1016/j.enganabound.2004.12.001", "10.1142/9789812772572_0043", "10.1250/ast.29.191", "10.1007/978-0-387-09517-2", "10.1121/1.426873", "10.1250/ast.24.42", "10.1121/1.3278605", "10.3813/AAA.918132", "10.1121/1.428071", "10.1121/1.2164987", "10.1121/1.3009552"]}, "10.1109/TVCG.2015.2391865": {"doi": "10.1109/TVCG.2015.2391865", "author": ["Y. Visell"], "title": "Fast Physically Accurate Rendering of Multimodal Signatures of Distributed Fracture in Heterogeneous Materials", "year": "2015", "abstract": "This paper proposes a fast, physically accurate method for synthesizing multimodal, acoustic and haptic, signatures of distributed fracture in quasi-brittle heterogeneous materials, such as wood, granular media, or other fiber composites. Fracture processes in these materials are challenging to simulate with existing methods, due to the prevalence of large numbers of disordered, quasi-random spatial degrees of freedom, representing the complex physical state of a sample over the geometric volume of interest. Here, I develop an algorithm for simulating such processes, building on a class of statistical lattice models of fracture that have been widely investigated in the physics literature. This algorithm is enabled through a recently published mathematical construction based on the inverse transform method of random number sampling. It yields a purely time domain stochastic jump process representing stress fluctuations in the medium. The latter can be readily extended by a mean field approximation that captures the averaged constitutive (stress-strain) behavior of the material. Numerical simulations and interactive examples demonstrate the ability of these algorithms to generate physically plausible acoustic and haptic signatures of fracture in complex, natural materials interactively at audio sampling rates.", "keywords": ["fracture", "inverse transforms", "rendering (computer graphics)", "virtual reality", "accurate rendering", "multimodal signatures", "distributed fracture", "quasibrittle heterogeneous materials", "granular media", "fiber composites", "fracture processes", "complex physical state", "geometric volume", "statistical lattice models", "physics literature", "mathematical construction", "inverse transform method", "random number sampling", "time domain stochastic jump process", "stress fluctuations", "mean field approximation", "averaged constitutive", "stress-strain behavior", "numerical simulations", "haptic signatures", "natural materials", "audio sampling rates", "Load modeling", "Materials", "Stress", "Computational modeling", "Rendering (computer graphics)", "Numerical models", "Mathematical model", "Crowd simulation", "Interaction", "Action", "Physical simulation", "multimodal rendering", "virtual reality"], "referenced_by": ["IKEY:8547505"], "referencing": ["IKEY:6197190", "IKEY:6788060", "IKEY:6197190", "IKEY:6788060", "IKEY:6197190", "IKEY:6788060", "10.1145/1073368.1073379", "10.1145/1360612.1360648", "10.1145/311535.311550", "10.1145/1599470.1599492", "10.1145/1599470.1599492", "10.1145/1778765.1778806", "10.1145/1186822.1073298", "10.1145/1073368.1073379", "10.1145/1360612.1360648", "10.1145/311535.311550", "10.1145/1599470.1599492", "10.1145/1599470.1599492", "10.1145/1778765.1778806", "10.1145/1186822.1073298", "10.1145/1073368.1073379", "10.1145/1360612.1360648", "10.1145/311535.311550", "10.1145/1599470.1599492", "10.1145/1599470.1599492", "10.1145/1778765.1778806", "10.1145/1186822.1073298", "10.1080/00018730300741518", "10.1103/PhysRevLett.96.118002", "10.1016/j.ijsolstr.2005.06.063", "10.1103/PhysRevLett.95.138001", "10.1007/978-1-4613-8643-8", "10.1016/S0378-4371(03)00141-9", "10.1121/1.2149839", "10.1016/0375-9601(94)90511-8", "10.1103/PhysRevLett.89.205501", "10.1103/PhysRevE.64.066122", "10.1016/j.physa.2004.08.039", "10.1103/PhysRevE.65.046148", "10.1007/s003710050128", "10.1103/PhysRevE.56.2615", "10.1520/STP28343S", "10.1007/PL00011084", "10.1002/cav.412", "10.1016/j.ecoleng.2009.02.005", "10.1016/j.cag.2008.01.003", "10.1016/j.earscirev.2012.02.009", "10.1016/j.commatsci.2008.09.004", "10.1007/978-3-7091-6240-8_11", "10.1103/PhysRevE.58.2161", "10.1103/PhysRevLett.79.949", "10.1007/BF01900837", "10.1103/RevModPhys.82.499", "10.1103/PhysRevE.85.011903", "10.3189/002214309790794869", "10.1103/PhysRevE.83.046126", "10.1111/1467-8659.t01-1-00202", "10.1007/BF01908877", "10.1080/00018730300741518", "10.1103/PhysRevLett.96.118002", "10.1016/j.ijsolstr.2005.06.063", "10.1103/PhysRevLett.95.138001", "10.1007/978-1-4613-8643-8", "10.1016/S0378-4371(03)00141-9", "10.1121/1.2149839", "10.1016/0375-9601(94)90511-8", "10.1103/PhysRevLett.89.205501", "10.1103/PhysRevE.64.066122", "10.1016/j.physa.2004.08.039", "10.1103/PhysRevE.65.046148", "10.1007/s003710050128", "10.1103/PhysRevE.56.2615", "10.1520/STP28343S", "10.1007/PL00011084", "10.1002/cav.412", "10.1016/j.ecoleng.2009.02.005", "10.1016/j.cag.2008.01.003", "10.1016/j.earscirev.2012.02.009", "10.1016/j.commatsci.2008.09.004", "10.1007/978-3-7091-6240-8_11", "10.1103/PhysRevE.58.2161", "10.1103/PhysRevLett.79.949", "10.1007/BF01900837", "10.1103/RevModPhys.82.499", "10.1103/PhysRevE.85.011903", "10.3189/002214309790794869", "10.1103/PhysRevE.83.046126", "10.1111/1467-8659.t01-1-00202", "10.1007/BF01908877", "10.1080/00018730300741518", "10.1103/PhysRevLett.96.118002", "10.1016/j.ijsolstr.2005.06.063", "10.1103/PhysRevLett.95.138001", "10.1007/978-1-4613-8643-8", "10.1016/S0378-4371(03)00141-9", "10.1121/1.2149839", "10.1016/0375-9601(94)90511-8", "10.1103/PhysRevLett.89.205501", "10.1103/PhysRevE.64.066122", "10.1016/j.physa.2004.08.039", "10.1103/PhysRevE.65.046148", "10.1007/s003710050128", "10.1103/PhysRevE.56.2615", "10.1520/STP28343S", "10.1007/PL00011084", "10.1002/cav.412", "10.1016/j.ecoleng.2009.02.005", "10.1016/j.cag.2008.01.003", "10.1016/j.earscirev.2012.02.009", "10.1016/j.commatsci.2008.09.004", "10.1007/978-3-7091-6240-8_11", "10.1103/PhysRevE.58.2161", "10.1103/PhysRevLett.79.949", "10.1007/BF01900837", "10.1103/RevModPhys.82.499", "10.1103/PhysRevE.85.011903", "10.3189/002214309790794869", "10.1103/PhysRevE.83.046126", "10.1111/1467-8659.t01-1-00202", "10.1007/BF01908877"]}, "10.1109/TVCG.2015.2391863": {"doi": "10.1109/TVCG.2015.2391863", "author": ["A. Talvas", "M. Marchal", "C. Duriez", "M. A. Otaduy"], "title": "Aggregate Constraints for Virtual Manipulation with Soft Fingers", "year": "2015", "abstract": "Interactive dexterous manipulation of virtual objects remains a complex challenge that requires both appropriate hand models and accurate physically-based simulation of interactions. In this paper, we propose an approach based on novel aggregate constraints for simulating dexterous grasping using soft fingers. Our approach aims at improving the computation of contact mechanics when many contact points are involved, by aggregating the multiple contact constraints into a minimal set of constraints. We also introduce a method for non-uniform pressure distribution over the contact surface, to adapt the response when touching sharp edges. We use the Coulomb-Contensou friction model to efficiently simulate tangential and torsional friction. We show through different use cases that our aggregate constraint formulation is well-suited for simulating interactively dexterous manipulation of virtual objects through soft fingers, and efficiently reduces the computation time of constraint solving.", "keywords": ["constraint handling", "control engineering computing", "dexterous manipulators", "friction", "mechanical contact", "solid modelling", "torsion", "virtual reality", "aggregate constraints", "virtual manipulation", "soft fingers", "interactive dexterous manipulation", "virtual objects", "hand models", "physically-based simulation", "dexterous grasping", "contact mechanics", "contact points", "contact constraints", "nonuniform pressure distribution", "contact surface", "Coulomb-Contensou friction model", "tangential friction", "torsional friction", "constraint solving", "Friction", "Aggregates", "Grasping", "Computational modeling", "Solid modeling", "Force", "Deformable models", "Physically-based simulation", "grasping", "dexterous manipulation", "constraint computation", "virtual deformable hand.", "Physically-based simulation", "grasping", "dexterous manipulation", "constraint computation", "virtual deformable hand", "Algorithms", "Computer Graphics", "Computer Simulation", "Fingers", "Humans", "Imaging, Three-Dimensional", "Models, Biological", "User-Computer Interface"], "referenced_by": ["IKEY:7504687", "IKEY:8448284", "IKEY:8447555", "IKEY:8540015", "IKEY:8392385", "IKEY:8798155", "IKEY:8967526", "IKEY:9089499", "IKEY:9089572", "IKEY:9110072", "10.1002/9781119341031.ch3", "10.1016/j.media.2016.06.040", "10.1016/j.cag.2018.04.004", "10.1007/978-3-319-27863-6_74", "10.1111/cgf.13885", "10.3724/SP.J.2096-5796.2019.0008"], "referencing": ["IKEY:1287172", "IKEY:1492758", "IKEY:4145178", "IKEY:1541998", "IKEY:5945492", "IKEY:5759430", "IKEY:6184183", "IKEY:1191285", "IKEY:6790508", "IKEY:5444819", "IKEY:4135652", "IKEY:4390938", "IKEY:6548388", "IKEY:1406951", "IKEY:6550206", "IKEY:1287172", "IKEY:1492758", "IKEY:4145178", "IKEY:1541998", "IKEY:5945492", "IKEY:5759430", "IKEY:6184183", "IKEY:1191285", "IKEY:6790508", "IKEY:5444819", "IKEY:4135652", "IKEY:4390938", "IKEY:6548388", "IKEY:1406951", "IKEY:6550206", "IKEY:1287172", "IKEY:1492758", "IKEY:4145178", "IKEY:1541998", "IKEY:5945492", "IKEY:5759430", "IKEY:6184183", "IKEY:1191285", "IKEY:6790508", "IKEY:5444819", "IKEY:4135652", "IKEY:4390938", "IKEY:6548388", "IKEY:1406951", "IKEY:6550206", "10.1145/1778765.1778819", "10.1145/127719.122722", "10.1145/192161.192168", "10.1145/237170.237226", "10.1145/74334.74335", "10.1145/1028523.1028541", "10.1145/2070752.2024197", "10.1145/1141911.1141969", "10.1145/383259.383263", "10.1145/1028523.1028539", "10.1145/1360612.1360682", "10.1145/2185520.2185537", "10.1145/311625.312171", "10.1145/1778765.1778819", "10.1145/127719.122722", "10.1145/192161.192168", "10.1145/237170.237226", "10.1145/74334.74335", "10.1145/1028523.1028541", "10.1145/2070752.2024197", "10.1145/1141911.1141969", "10.1145/383259.383263", "10.1145/1028523.1028539", "10.1145/1360612.1360682", "10.1145/2185520.2185537", "10.1145/311625.312171", "10.1145/1778765.1778819", "10.1145/127719.122722", "10.1145/192161.192168", "10.1145/237170.237226", "10.1145/74334.74335", "10.1145/1028523.1028541", "10.1145/2070752.2024197", "10.1145/1141911.1141969", "10.1145/383259.383263", "10.1145/1028523.1028539", "10.1145/1360612.1360682", "10.1145/2185520.2185537", "10.1145/311625.312171", "10.1111/cgf.12272", "10.1007/978-3-662-12200-6_15", "10.1007/8415_2012_125", "10.1111/j.1467-8659.2007.01046.x", "10.1177/027836499601500603", "10.1016/S0997-7538(03)00025-1", "10.1111/j.1467-8659.2009.01396.x", "10.1016/S1524-0703(03)00045-6", "10.1111/cgf.12272", "10.1007/978-3-662-12200-6_15", "10.1007/8415_2012_125", "10.1111/j.1467-8659.2007.01046.x", "10.1177/027836499601500603", "10.1016/S0997-7538(03)00025-1", "10.1111/j.1467-8659.2009.01396.x", "10.1016/S1524-0703(03)00045-6", "10.1111/cgf.12272", "10.1007/978-3-662-12200-6_15", "10.1007/8415_2012_125", "10.1111/j.1467-8659.2007.01046.x", "10.1177/027836499601500603", "10.1016/S0997-7538(03)00025-1", "10.1111/j.1467-8659.2009.01396.x", "10.1016/S1524-0703(03)00045-6"]}, "10.1109/TVCG.2015.2391861": {"doi": "10.1109/TVCG.2015.2391861", "author": ["D. Iwai", "S. Mihara", "K. Sato"], "title": "Extended Depth-of-Field Projector by Fast Focal Sweep Projection", "year": "2015", "abstract": "A simple and cost-efficient method for extending a projector's depth-of-field (DOF) is proposed. By leveraging liquid lens technology, we can periodically modulate the focal length of a projector at a frequency that is higher than the critical flicker fusion (CFF) frequency. Fast periodic focal length modulation results in forward and backward sweeping of focusing distance. Fast focal sweep projection makes the point spread function (PSF) of each projected pixel integrated over a sweep period (IPSF; integrated PSF) nearly invariant to the distance from the projector to the projection surface as long as it is positioned within sweep range. This modulation is not perceivable by human observers. Once we compensate projection images for the IPSF, the projected results can be focused at any point within the range. Consequently, the proposed method requires only a single offline PSF measurement; thus, it is an open-loop process. We have proved the approximate invariance of the projector's IPSF both numerically and experimentally. Through experiments using a prototype system, we have confirmed that the image quality of the proposed method is superior to that of normal projection with fixed focal length. In addition, we demonstrate that a structured light pattern projection technique using the proposed method can measure the shape of an object with large depth variances more accurately than normal projection techniques.", "keywords": ["display instrumentation", "lenses", "optical modulation", "optical projectors", "optical transfer function", "extended depth-of-field projector", "fast focal sweep projection", "DOF", "critical flicker fusion frequency", "CFF frequency", "fast periodic focal length modulation", "backward sweeping", "forward sweeping", "integrated point spread function", "IPSF", "projection image compensation", "open-loop process", "structured light pattern projection technique", "liquid lens technology", "Focusing", "Frequency modulation", "Lenses", "Cameras", "Computational modeling", "Semiconductor device measurement", "Projection display", "extended depth-of-field projector", "focal sweep", "immersive virtual reality", "spatial augmented reality"], "referenced_by": ["IKEY:7460049", "IKEY:7383338", "IKEY:7831400", "IKEY:8007248", "IKEY:8368469", "IKEY:8509574", "IKEY:8327511", "IKEY:8642529", "IKEY:8747333", "IKEY:8999805", "IKEY:8624466", "IKEY:9191236", "10.1145/3072959.3073594", "10.1145/3130800.3130892", "10.1007/978-3-319-30285-0_10", "10.1016/j.dsp.2017.07.014", "10.1364/AO.55.005931", "10.2493/jjspe.83.494", "10.3390/mti1040022", "10.1541/ieejjournal.139.34", "10.1007/978-3-030-13940-7_2", "10.1117/12.2506958", "10.3390/s19061409", "10.1016/j.rinp.2019.102433", "10.1007/s10043-019-00517-3", "10.1038/s41598-019-48900-z", "10.1364/OL.382431"], "referencing": ["IKEY:970539", "IKEY:1634329", "IKEY:1640992", "IKEY:6909824", "IKEY:5432211", "IKEY:6528302", "IKEY:1284395", "IKEY:970539", "IKEY:1634329", "IKEY:1640992", "IKEY:6909824", "IKEY:5432211", "IKEY:6528302", "IKEY:1284395", "IKEY:970539", "IKEY:1634329", "IKEY:1640992", "IKEY:6909824", "IKEY:5432211", "IKEY:6528302", "IKEY:1284395", "10.1145/2508363.2508416", "10.1145/1805964.1805966", "10.1145/1141911.1141974", "10.1145/2508363.2508416", "10.1145/1805964.1805966", "10.1145/1141911.1141974", "10.1145/2508363.2508416", "10.1145/1805964.1805966", "10.1145/1141911.1141974", "10.1111/j.1467-8659.2008.01175.x", "10.1016/0030-4018(72)90243-X", "10.1364/OE.19.000353", "10.1007/978-3-540-88693-8_5", "10.1007/s10055-010-0168-4", "10.1016/j.patcog.2003.10.002", "10.1111/j.1467-8659.2008.01175.x", "10.1016/0030-4018(72)90243-X", "10.1364/OE.19.000353", "10.1007/978-3-540-88693-8_5", "10.1007/s10055-010-0168-4", "10.1016/j.patcog.2003.10.002", "10.1111/j.1467-8659.2008.01175.x", "10.1016/0030-4018(72)90243-X", "10.1364/OE.19.000353", "10.1007/978-3-540-88693-8_5", "10.1007/s10055-010-0168-4", "10.1016/j.patcog.2003.10.002"]}, "10.1109/TVCG.2015.2391859": {"doi": "10.1109/TVCG.2015.2391859", "author": ["Y. Itoh", "G. Klinker"], "title": "Light-Field Correction for Spatial Calibration of Optical See-Through Head-Mounted Displays", "year": "2015", "abstract": "A critical requirement for AR applications with Optical See-Through Head-Mounted Displays (OST-HMD) is to project 3D information correctly into the current viewpoint of the user - more particularly, according to the user's eye position. Recently-proposed interaction-free calibration methods [16], [17] automatically estimate this projection by tracking the user's eye position, thereby freeing users from tedious manual calibrations. However, the method is still prone to contain systematic calibration errors. Such errors stem from eye-/HMD-related factors and are not represented in the conventional eye-HMD model used for HMD calibration. This paper investigates one of these factors - the fact that optical elements of OST-HMDs distort incoming world-light rays before they reach the eye, just as corrective glasses do. Any OST-HMD requires an optical element to display a virtual screen. Each such optical element has different distortions. Since users see a distorted world through the element, ignoring this distortion degenerates the projection quality. We propose a light-field correction method, based on a machine learning technique, which compensates the world-scene distortion caused by OST-HMD optics. We demonstrate that our method reduces the systematic error and significantly increases the calibration accuracy of the interaction-free calibration.", "keywords": ["calibration", "helmet mounted displays", "learning (artificial intelligence)", "three-dimensional displays", "spatial calibration", "optical see-through head-mounted display", "AR application", "OST-HMD", "interaction-free calibration method", "systematic calibration error", "eye-HMD model", "optical element", "world-light ray", "light-field correction method", "machine learning technique", "Optical distortion", "Cameras", "Calibration", "Three-dimensional displays", "Optical imaging", "Adaptive optics", "Lenses", "OST-HMD", "calibration", "undistortion", "optical see-through display", "light field", "INDICA", "SPAAM", "eye tracking", "Calibration", "Computer Graphics", "Equipment Design", "Eye Movements", "Head", "Humans", "Optics and Photonics", "User-Computer Interface"], "referenced_by": ["IKEY:7460049", "IKEY:7532570", "IKEY:7938227", "IKEY:8088495", "IKEY:7328058", "IKEY:8022901", "IKEY:7012105", "IKEY:7383324", "IKEY:7414488", "IKEY:7523375", "IKEY:8052554", "IKEY:8456571", "IKEY:8456568", "IKEY:8798107", "IKEY:8951967", "IKEY:9105134", "10.1016/j.ijleo.2016.12.069", "10.3169/itej.69.825", "10.1117/1.OE.57.6.063106", "10.1002/jsid.728", "10.1117/12.2500432", "10.1002/jsid.747"], "referencing": ["IKEY:1240703", "IKEY:1383039", "IKEY:1570633", "IKEY:4250459", "IKEY:6948424", "IKEY:6948446", "IKEY:7021939", "IKEY:1383044", "IKEY:7012105", "IKEY:4060955", "IKEY:6790650", "IKEY:1512357", "IKEY:888718", "IKEY:6948427", "IKEY:1240703", "IKEY:1383039", "IKEY:1570633", "IKEY:4250459", "IKEY:6948424", "IKEY:6948446", "IKEY:7021939", "IKEY:1383044", "IKEY:7012105", "IKEY:4060955", "IKEY:6790650", "IKEY:1512357", "IKEY:888718", "IKEY:6948427", "IKEY:1240703", "IKEY:1383039", "IKEY:1570633", "IKEY:4250459", "IKEY:6948424", "IKEY:6948446", "IKEY:7021939", "IKEY:1383044", "IKEY:7012105", "IKEY:4060955", "IKEY:6790650", "IKEY:1512357", "IKEY:888718", "IKEY:6948427", "10.1145/192161.192199", "10.1145/218380.218496", "10.1145/2601097.2601122", "10.1145/1275808.1276427", "10.1145/237170.237199", "10.1145/192161.192199", "10.1145/218380.218496", "10.1145/2601097.2601122", "10.1145/1275808.1276427", "10.1145/237170.237199", "10.1145/192161.192199", "10.1145/218380.218496", "10.1145/2601097.2601122", "10.1145/1275808.1276427", "10.1145/237170.237199", "10.1007/PL00013269", "10.1016/j.jneumeth.2008.05.015", "10.1016/S0097-8493(01)00119-4", "10.1016/j.suronc.2011.07.002", "10.1561/0600000023", "10.1007/PL00013269", "10.1016/j.jneumeth.2008.05.015", "10.1016/S0097-8493(01)00119-4", "10.1016/j.suronc.2011.07.002", "10.1561/0600000023", "10.1007/PL00013269", "10.1016/j.jneumeth.2008.05.015", "10.1016/S0097-8493(01)00119-4", "10.1016/j.suronc.2011.07.002", "10.1561/0600000023"]}, "10.1109/TVCG.2015.2391857": {"doi": "10.1109/TVCG.2015.2391857", "author": ["A. Plopski", "Y. Itoh", "C. Nitschke", "K. Kiyokawa", "G. Klinker", "H. Takemura"], "title": "Corneal-Imaging Calibration for Optical See-Through Head-Mounted Displays", "year": "2015", "abstract": "In recent years optical see-through head-mounted displays (OST-HMDs) have moved from conceptual research to a market of mass-produced devices with new models and applications being released continuously. It remains challenging to deploy augmented reality (AR) applications that require consistent spatial visualization. Examples include maintenance, training and medical tasks, as the view of the attached scene camera is shifted from the user's view. A calibration step can compute the relationship between the HMD-screen and the user's eye to align the digital content. However, this alignment is only viable as long as the display does not move, an assumption that rarely holds for an extended period of time. As a consequence, continuous recalibration is necessary. Manual calibration methods are tedious and rarely support practical applications. Existing automated methods do not account for user-specific parameters and are error prone. We propose the combination of a pre-calibrated display with a per-frame estimation of the user's cornea position to estimate the individual eye center and continuously recalibrate the system. With this, we also obtain the gaze direction, which allows for instantaneous uncalibrated eye gaze tracking, without the need for additional hardware and complex illumination. Contrary to existing methods, we use simple image processing and do not rely on iris tracking, which is typically noisy and can be ambiguous. Evaluation with simulated and real data shows that our approach achieves a more accurate and stable eye pose estimation, which results in an improved and practical calibration with a largely improved distribution of projection error.", "keywords": ["augmented reality", "calibration", "data visualisation", "eye", "gaze tracking", "helmet mounted displays", "natural scenes", "pose estimation", "optical see-through head mounted display", "OST-HMD screen", "mass produced device", "augmented reality", "consistent spatial visualization", "scene camera", "user view", "continuous recalibration", "manual calibration method", "user specific parameters", "precalibrated display", "per-frame estimation", "user cornea position estimation", "gaze direction", "instantaneous uncalibrated eye gaze tracking", "image processing", "eye pose estimation", "projection error distribution", "corneal imaging calibration", "Calibration", "Cornea", "Cameras", "Estimation", "Iris", "Three-dimensional displays", "OST-HMD calibration", "optical see-through", "eye pose estimation", "OST-HMD calibration", "eye pose estimation", "corneal imaging", "optical see-through", "Calibration", "Computer Graphics", "Cornea", "Diagnostic Techniques, Ophthalmological", "Eye Movements", "Head", "Humans", "Imaging, Three-Dimensional"], "referenced_by": ["IKEY:7460047", "IKEY:8003267", "IKEY:8120296", "IKEY:7938227", "IKEY:8088448", "IKEY:8088495", "IKEY:7328058", "IKEY:7781771", "IKEY:7988648", "IKEY:7556132", "IKEY:7064856", "IKEY:7435333", "IKEY:7523375", "IKEY:7523376", "IKEY:7504693", "IKEY:7504739", "IKEY:7504755", "IKEY:7892268", "IKEY:8004539", "IKEY:8052554", "IKEY:8613747", "IKEY:8699217", "IKEY:8968101", "IKEY:9090625", "IKEY:9105134", "IKEY:9151986", "IKEY:9291377", "10.1145/3025453.3025685", "10.1145/3414685.3417820", "10.1002/9781118976005.ch21", "10.1002/9781119341031.ch6", "10.1007/978-3-319-08234-9_78-1", "10.1007/978-3-319-08234-9_78-2", "10.1007/978-3-319-40651-0_3", "10.1007/978-3-319-58877-3_44", "10.1007/978-3-319-70010-6_31", "10.1007/s10055-018-0341-8", "10.3169/itej.69.825", "10.3390/electronics5030059", "10.4018/978-1-5225-3290-3.ch001", "10.4018/978-1-5225-5469-1.ch033", "10.1117/1.OE.57.6.063106", "10.1002/jsid.728", "10.1002/rcs.1969", "10.1587/transinf.2018EDP7184", "10.1007/s11045-019-00639-6", "10.9746/sicetr.55.491", "10.3390/app10010193", "10.3389/frobt.2020.572001"], "referencing": ["IKEY:6619028", "IKEY:5759432", "IKEY:5207653", "IKEY:4531151", "IKEY:183317", "IKEY:6224570", "IKEY:880940", "IKEY:1634506", "IKEY:4770110", "IKEY:6948424", "IKEY:7064856", "IKEY:6948425", "IKEY:6948446", "IKEY:6671263", "IKEY:6162910", "IKEY:1310091", "IKEY:1541298", "IKEY:4637353", "IKEY:5539799", "IKEY:6130505", "IKEY:6790650", "IKEY:4567549", "IKEY:6619028", "IKEY:5759432", "IKEY:5207653", "IKEY:4531151", "IKEY:183317", "IKEY:6224570", "IKEY:880940", "IKEY:1634506", "IKEY:4770110", "IKEY:6948424", "IKEY:7064856", "IKEY:6948425", "IKEY:6948446", "IKEY:6671263", "IKEY:6162910", "IKEY:1310091", "IKEY:1541298", "IKEY:4637353", "IKEY:5539799", "IKEY:6130505", "IKEY:6790650", "IKEY:4567549", "IKEY:6619028", "IKEY:5759432", "IKEY:5207653", "IKEY:4531151", "IKEY:183317", "IKEY:6224570", "IKEY:880940", "IKEY:1634506", "IKEY:4770110", "IKEY:6948424", "IKEY:7064856", "IKEY:6948425", "IKEY:6948446", "IKEY:6671263", "IKEY:6162910", "IKEY:1310091", "IKEY:1541298", "IKEY:4637353", "IKEY:5539799", "IKEY:6130505", "IKEY:6790650", "IKEY:4567549", "10.1145/237170.237272", "10.1145/1785455.1785480", "10.1145/1186562.1015783", "10.1145/237170.237272", "10.1145/1785455.1785480", "10.1145/1186562.1015783", "10.1145/237170.237272", "10.1145/1785455.1785480", "10.1145/1186562.1015783", "10.1007/s11263-006-6274-9", "10.5244/C.26.22", "10.1016/j.cviu.2011.02.008", "10.2197/ipsjtcva.5.1", "10.1111/j.1749-6632.2009.03858.x", "10.1007/978-3-540-88682-2_48", "10.1093/ietisy/e88-d.10.2277", "10.1007/s11263-006-6274-9", "10.5244/C.26.22", "10.1016/j.cviu.2011.02.008", "10.2197/ipsjtcva.5.1", "10.1111/j.1749-6632.2009.03858.x", "10.1007/978-3-540-88682-2_48", "10.1093/ietisy/e88-d.10.2277", "10.1007/s11263-006-6274-9", "10.5244/C.26.22", "10.1016/j.cviu.2011.02.008", "10.2197/ipsjtcva.5.1", "10.1111/j.1749-6632.2009.03858.x", "10.1007/978-3-540-88682-2_48", "10.1093/ietisy/e88-d.10.2277"]}, "10.1109/TVCG.2015.2391856": {"doi": "10.1109/TVCG.2015.2391856", "author": ["K. Moser", "Y. Itoh", "K. Oshima", "J. E. Swan", "G. Klinker", "C. Sandor"], "title": "Subjective Evaluation of a Semi-Automatic Optical See-Through Head-Mounted Display Calibration Technique", "year": "2015", "abstract": "With the growing availability of optical see-through (OST) head-mounted displays (HMDs) there is a present need for robust, uncomplicated, and automatic calibration methods suited for non-expert users. This work presents the results of a user study which both objectively and subjectively examines registration accuracy produced by three OST HMD calibration methods: (1) SPAAM, (2) Degraded SPAAM, and (3) Recycled INDICA, a recently developed semi-automatic calibration method. Accuracy metrics used for evaluation include subject provided quality values and error between perceived and absolute registration coordinates. Our results show all three calibration methods produce very accurate registration in the horizontal direction but caused subjects to perceive the distance of virtual objects to be closer than intended. Surprisingly, the semi-automatic calibration method produced more accurate registration vertically and in perceived object distance overall. User assessed quality values were also the highest for Recycled INDICA, particularly when objects were shown at distance. The results of this study confirm that Recycled INDICA is capable of producing equal or superior on-screen registration compared to common OST HMD calibration methods. We also identify a potential hazard in using reprojection error as a quantitative analysis technique to predict registration accuracy. We conclude with discussing the further need for examining INDICA calibration in binocular HMD systems, and the present possibility for creation of a closed-loop continuous calibration method for OST Augmented Reality.", "keywords": ["augmented reality", "calibration", "helmet mounted displays", "semiautomatic optical see-through head-mounted display calibration technique", "OST HMD calibration method", "quality value assessment", "recycled INDICA", "degraded SPAAM", "hazard", "quantitative analysis technique", "binocular HMD system", "closed-loop continuous calibration method", "augmented reality", "Calibration", "Cameras", "Accuracy", "Visualization", "Hardware", "Head", "Calibration", "user study", "OST HMD", "INDICA", "SPAAM", "eye tracking", "Calibration", "user study", "OST HMD", "INDICA", "SPAAM", "eye tracking", "Adult", "Algorithms", "Analysis of Variance", "Calibration", "Computer Graphics", "Equipment Design", "Eye Movements", "Female", "Humans", "Male", "User-Computer Interface", "Young Adult"], "referenced_by": ["IKEY:7460047", "IKEY:7756124", "IKEY:7328104", "IKEY:7064856", "IKEY:7435333", "IKEY:7504739", "IKEY:8052554", "IKEY:8446429", "IKEY:8613747", "IKEY:8409318", "10.1002/9781118976005.ch21", "10.1007/s10055-018-0341-8", "10.1016/j.cag.2017.02.001", "10.1117/1.OE.57.6.063106", "10.1002/jsid.728", "10.1080/24725854.2018.1493244", "10.1007/s11045-019-00639-6"], "referencing": ["IKEY:5759432", "IKEY:781532", "IKEY:183317", "IKEY:4441708", "IKEY:1115086", "IKEY:4538849", "IKEY:6948424", "IKEY:380772", "IKEY:803809", "IKEY:4637329", "IKEY:6162910", "IKEY:970525", "IKEY:1310091", "IKEY:1383044", "IKEY:1240699", "IKEY:880938", "IKEY:5759432", "IKEY:781532", "IKEY:183317", "IKEY:4441708", "IKEY:1115086", "IKEY:4538849", "IKEY:6948424", "IKEY:380772", "IKEY:803809", "IKEY:4637329", "IKEY:6162910", "IKEY:970525", "IKEY:1310091", "IKEY:1383044", "IKEY:1240699", "IKEY:880938", "IKEY:5759432", "IKEY:781532", "IKEY:183317", "IKEY:4441708", "IKEY:1115086", "IKEY:4538849", "IKEY:6948424", "IKEY:380772", "IKEY:803809", "IKEY:4637329", "IKEY:6162910", "IKEY:970525", "IKEY:1310091", "IKEY:1383044", "IKEY:1240699", "IKEY:880938", "10.1177/154193121005402814", "10.2197/ipsjtcva.5.1", "10.1016/j.jneumeth.2011.05.011", "10.1177/154193121005402814", "10.2197/ipsjtcva.5.1", "10.1016/j.jneumeth.2011.05.011", "10.1177/154193121005402814", "10.2197/ipsjtcva.5.1", "10.1016/j.jneumeth.2011.05.011"]}, "10.1109/TVCG.2015.2391860": {"doi": "10.1109/TVCG.2015.2391860", "author": ["Y. Jang", "S. Noh", "H. J. Chang", "T. Kim", "W. Woo"], "title": "3D Finger CAPE: Clicking Action and Position Estimation under Self-Occlusions in Egocentric Viewpoint", "year": "2015", "abstract": "In this paper we present a novel framework for simultaneous detection of click action and estimation of occluded fingertip positions from egocentric viewed single-depth image sequences. For the detection and estimation, a novel probabilistic inference based on knowledge priors of clicking motion and clicked position is presented. Based on the detection and estimation results, we were able to achieve a fine resolution level of a bare hand-based interaction with virtual objects in egocentric viewpoint. Our contributions include: (i) a rotation and translation invariant finger clicking action and position estimation using the combination of 2D image-based fingertip detection with 3D hand posture estimation in egocentric viewpoint. (ii) a novel spatio-temporal random forest, which performs the detection and estimation efficiently in a single framework. We also present (iii) a selection process utilizing the proposed clicking action detection and position estimation in an arm reachable AR/VR space, which does not require any additional device. Experimental results show that the proposed method delivers promising performance under frequent self-occlusions in the process of selecting objects in AR/VR space whilst wearing an egocentric-depth camera-attached HMD.", "keywords": ["augmented reality", "human computer interaction", "image sequences", "inference mechanisms", "object detection", "pose estimation", "random processes", "3D finger CAPE", "clicking action detection", "occluded fingertip position estimation", "self-occlusions", "egocentric viewed single-depth image sequences", "probabilistic inference", "bare hand-based interaction", "rotation invariant finger clicking action", "translation invariant finger clicking action", "2D image-based fingertip detection", "3D hand posture estimation", "spatiotemporal random forest", "arm reachable AR/VR space", "egocentric-depth camera-attached HMD", "Three-dimensional displays", "Estimation", "Joints", "Vectors", "Feature extraction", "Thumb", "Hand tracking", "spatio-temporal forest", "selection", "augmented reality", "computer vision", "self-occlusion", "clicking action detection", "fingertip position estimation", "Adult", "Algorithms", "Computer Graphics", "Fingers", "Humans", "Imaging, Three-Dimensional", "Male", "User-Computer Interface", "Young Adult"], "referenced_by": ["10.1145/2788940.2788953", "10.1145/2897824.2925883", "10.1007/978-3-319-39862-4_13", "10.1007/978-3-319-58697-7_31", "10.1007/s00779-016-0987-8", "10.1016/j.cviu.2016.01.010", "10.1016/j.humov.2017.11.002", "10.1016/j.patcog.2017.09.001", "10.1007/978-3-030-00764-5_24", "10.1007/s42486-018-0002-8", "10.1007/978-3-030-11024-6_15", "10.1016/j.patcog.2019.04.026", "10.1371/journal.pone.0222751", "10.3390/app9214652", "10.3390/s19194330", "10.1049/iet-cvi.2018.5480", "10.1007/978-3-030-33720-9_36", "10.1016/j.ijhcs.2020.102433", "10.1007/s00371-020-01908-3", "10.1155/2020/8432840", "10.1088/1742-6596/1631/1/012014", "10.3390/app10196850", "10.1007/978-3-030-58610-2_8"], "referencing": ["IKEY:6165145", "IKEY:6550205", "IKEY:5719617", "IKEY:5206740", "IKEY:6948431", "IKEY:5759431", "IKEY:4270162", "IKEY:6553778", "IKEY:6319261", "IKEY:6798834", "IKEY:840674", "IKEY:4781204", "IKEY:4587628", "IKEY:5444787", "IKEY:6671771", "IKEY:6909541", "IKEY:5360488", "IKEY:6909879", "IKEY:6751512", "IKEY:5539883", "IKEY:5995488", "IKEY:6165145", "IKEY:6550205", "IKEY:5719617", "IKEY:5206740", "IKEY:6948431", "IKEY:5759431", "IKEY:4270162", "IKEY:6553778", "IKEY:6319261", "IKEY:6798834", "IKEY:840674", "IKEY:4781204", "IKEY:4587628", "IKEY:5444787", "IKEY:6671771", "IKEY:6909541", "IKEY:5360488", "IKEY:6909879", "IKEY:6751512", "IKEY:5539883", "IKEY:5995488", "IKEY:6165145", "IKEY:6550205", "IKEY:5719617", "IKEY:5206740", "IKEY:6948431", "IKEY:5759431", "IKEY:4270162", "IKEY:6553778", "IKEY:6319261", "IKEY:6798834", "IKEY:840674", "IKEY:4781204", "IKEY:4587628", "IKEY:5444787", "IKEY:6671771", "IKEY:6909541", "IKEY:5360488", "IKEY:6909879", "IKEY:6751512", "IKEY:5539883", "IKEY:5995488", "10.1145/2449396.2449435", "10.1145/2380116.2380139", "10.1145/2512349.2512824", "10.1145/2393347.2396312", "10.1145/2448196.2448232", "10.1145/2380116.2380135", "10.1145/2072298.2071961", "10.1145/2449396.2449435", "10.1145/2380116.2380139", "10.1145/2512349.2512824", "10.1145/2393347.2396312", "10.1145/2448196.2448232", "10.1145/2380116.2380135", "10.1145/2072298.2071961", "10.1145/2449396.2449435", "10.1145/2380116.2380139", "10.1145/2512349.2512824", "10.1145/2393347.2396312", "10.1145/2448196.2448232", "10.1145/2380116.2380135", "10.1145/2072298.2071961", "10.5244/C.25.101", "10.1002/sam.10128", "10.1080/10447318.2011.555297", "10.5244/C.25.101", "10.1002/sam.10128", "10.1080/10447318.2011.555297", "10.5244/C.25.101", "10.1002/sam.10128", "10.1080/10447318.2011.555297"]}, "10.1109/TVCG.2015.2391855": {"doi": "10.1109/TVCG.2015.2391855", "author": ["A. Robb", "A. Cordar", "S. Lampotang", "C. White", "A. Wendling", "B. Lok"], "title": "Teaming Up with Virtual Humans: How Other People Change Our Perceptions of and Behavior with Virtual Teammates", "year": "2015", "abstract": "In this paper we present a study exploring whether the physical presence of another human changes how people perceive and behave with virtual teammates. We conducted a study (n = 69) in which nurses worked with a simulated health care team to prepare a patient for surgery. The agency of participants' teammates was varied between conditions; participants either worked with a virtual surgeon and a virtual anesthesiologist, a human confederate playing a surgeon and a virtual anesthesiologist, or a virtual surgeon and a human confederate playing an anesthesiologist. While participants perceived the human confederates to have more social presence (p <; 0.01), participants did not preferentially agree with their human team members. We also observed an interaction effect between agency and behavioral realism. Participants experienced less social presence from the virtual anesthesiologist, whose behavior was less in line with participants' expectations, when a human surgeon was present.", "keywords": ["behavioural sciences computing", "health care", "human computer interaction", "medical computing", "surgery", "telemedicine", "virtual reality", "virtual human", "virtual teammates", "health care", "surgery", "virtual surgeon", "virtual anesthesiologist", "interaction effect", "social presence", "Surgery", "Training", "Avatars", "Virtual environments", "Virtual groups", "Mathematical model", "Speech", "Virtual/digital characters", "mixed reality", "training", "user studies", "Virtual/digital characters", "mixed reality", "training", "user studies", "Adult", "Aged", "Anesthesiology", "Computer Graphics", "Female", "General Surgery", "Humans", "Male", "Middle Aged", "Patient Care Team", "Social Perception", "User-Computer Interface"], "referenced_by": ["IKEY:8714726", "10.1002/pfi.21777", "10.1016/j.chb.2016.12.059", "10.3389/fict.2016.00017", "10.1007/978-3-030-04110-6_1", "10.1007/978-3-030-28845-7_7"], "referencing": ["IKEY:6797229", "IKEY:6681487", "IKEY:4811201", "IKEY:4480757", "IKEY:1159607", "IKEY:4967565", "IKEY:6479207", "IKEY:6787863", "IKEY:6797229", "IKEY:6681487", "IKEY:4811201", "IKEY:4480757", "IKEY:1159607", "IKEY:4967565", "IKEY:6479207", "IKEY:6787863", "IKEY:6797229", "IKEY:6681487", "IKEY:4811201", "IKEY:4480757", "IKEY:1159607", "IKEY:4967565", "IKEY:6479207", "IKEY:6787863", "10.1145/1178823.1178858", "10.1145/642611.642703", "10.1145/259963.260288", "10.1145/1178823.1178858", "10.1145/642611.642703", "10.1145/259963.260288", "10.1145/1178823.1178858", "10.1145/642611.642703", "10.1145/259963.260288", "10.1177/0146167203029007002", "10.1207/S15327965PLI1302_01", "10.1007/978-3-642-04380-2_62", "10.1016/j.chb.2014.04.043", "10.1111/0022-4537.00153", "10.1002/ir.101", "10.1007/978-3-540-85483-8_12", "10.1007/978-3-642-33197-8_30", "10.1016/j.chb.2010.06.012", "10.1177/0146167203029007002", "10.1207/S15327965PLI1302_01", "10.1007/978-3-642-04380-2_62", "10.1016/j.chb.2014.04.043", "10.1111/0022-4537.00153", "10.1002/ir.101", "10.1007/978-3-540-85483-8_12", "10.1007/978-3-642-33197-8_30", "10.1016/j.chb.2010.06.012", "10.1177/0146167203029007002", "10.1207/S15327965PLI1302_01", "10.1007/978-3-642-04380-2_62", "10.1016/j.chb.2014.04.043", "10.1111/0022-4537.00153", "10.1002/ir.101", "10.1007/978-3-540-85483-8_12", "10.1007/978-3-642-33197-8_30", "10.1016/j.chb.2010.06.012"]}, "10.1109/TVCG.2015.2391862": {"doi": "10.1109/TVCG.2015.2391862", "author": ["J. Bruneau", "A. Olivier", "J. Pettr\u00e9"], "title": "Going Through, Going Around: A Study on Individual Avoidance of Groups", "year": "2015", "abstract": "When avoiding a group, a walker has two possibilities: either he goes through it or around it. Going through very dense groups or around huge ones would not seem natural and could break any sense of presence in a virtual environment. This paper aims to enable crowd simulators to handle such situations correctly. To this end, we need to understand how real humans decide to go through or around groups. As a first hypothesis, we apply the Principle of Minimum Energy (PME) on different group sizes and density. According to this principle, a walker should go around small and dense groups whereas he should go through large and sparse groups. Such principle has already been used for crowd simulation; the novelty here is to apply it to decide on a global avoidance strategy instead of local adaptations only. Our study quantifies decision thresholds. However, PME leaves some inconclusive situations for which the two solutions paths have similar energetic costs. In a second part, we propose an experiment to corroborate PME decisions thresholds with real observations. As controlling the factors of an experiment with many people is extremely hard, we propose to use Virtual Reality as a new method to observe human behavior. This work represents the first crowd simulation algorithm component directly designed from a VR-based study. We also consider the role of secondary factors in inconclusive situations. We show the influence of the group appearance and direction of relative motion in the decision process. Finally, we draw some guidelines to integrate our conclusions to existing crowd simulators and show an example of such integration. We evaluate the achieved improvements.", "keywords": ["computer animation", "decision making", "virtual reality", "individual avoidance strategy", "crowd simulation algorithm", "principle of minimum energy", "PME decision threshold", "virtual reality", "VR", "Trajectory", "Virtual environments", "Solid modeling", "Collision avoidance", "Algorithm design and analysis", "Biological system modeling", "Crowd simulation", "Interaction", "Perception", "Action", "Groups", "Virtual Reality", "Computer Graphics", "Computer Simulation", "Crowding", "Humans", "Interpersonal Relations", "User-Computer Interface"], "referenced_by": ["IKEY:7460045", "IKEY:8267290", "IKEY:7563568", "IKEY:7935620", "IKEY:7935622", "IKEY:7935624", "IKEY:7955099", "IKEY:7946183", "IKEY:8446152", "IKEY:8446180", "IKEY:8642370", "IKEY:8798204", "IKEY:9089637", "IKEY:9089531", "IKEY:9089573", "IKEY:9185410", "10.1145/2786784.2795135", "10.1145/2914796", "10.1002/9781119341031.ch3", "10.1002/cav.1729", "10.1016/j.tbs.2017.10.001", "10.1111/cgf.12993", "10.3389/frobt.2018.00082", "10.1007/s10055-018-0365-0", "10.3389/fpsyg.2018.02354", "10.1007/s10055-020-00428-8", "10.1016/j.gaitpost.2020.05.028", "10.1002/cav.1928", "10.1016/j.ssci.2020.104836", "10.1016/j.gmod.2020.101081", "10.3390/bs10090130", "10.1016/j.buildenv.2020.107329", "10.1002/cav.1963", "10.1007/978-3-030-64556-4_48"], "referencing": ["IKEY:5339124", "IKEY:6479208", "IKEY:6788944", "IKEY:5963666", "IKEY:4640665", "IKEY:6788002", "IKEY:1510565", "IKEY:5339124", "IKEY:6479208", "IKEY:6788944", "IKEY:5963666", "IKEY:4640665", "IKEY:6788002", "IKEY:1510565", "IKEY:5339124", "IKEY:6479208", "IKEY:6788944", "IKEY:5963666", "IKEY:4640665", "IKEY:6788002", "IKEY:1510565", "10.1145/1227134.1227136", "10.1145/2019406.2019414", "10.1145/1980462.1980495", "10.1145/1576246.1531361", "10.1145/1140491.1140493", "10.1145/37402.37406", "10.1145/1227134.1227136", "10.1145/2019406.2019414", "10.1145/1980462.1980495", "10.1145/1576246.1531361", "10.1145/1140491.1140493", "10.1145/37402.37406", "10.1145/1227134.1227136", "10.1145/2019406.2019414", "10.1145/1980462.1980495", "10.1145/1576246.1531361", "10.1145/1140491.1140493", "10.1145/37402.37406", "10.2307/3033551", "10.1111/j.1559-1816.2004.tb02571.x", "10.1007/s10919-009-0077-y", "10.1002/cav.1453", "10.1037/0033-2909.94.2.293", "10.1038/35035023", "10.1111/j.1467-8659.2012.03028.x", "10.1007/3-540-69342-4_21", "10.1371/journal.pone.0010047", "10.1007/978-3-7091-6874-5_3", "10.1016/j.gaitpost.2013.03.017", "10.1089/109493101300117884", "10.1007/978-3-642-04504-2_11", "10.1007/978-3-540-47641-2_26", "10.1111/cgf.12328", "10.2307/3033551", "10.1111/j.1559-1816.2004.tb02571.x", "10.1007/s10919-009-0077-y", "10.1002/cav.1453", "10.1037/0033-2909.94.2.293", "10.1038/35035023", "10.1111/j.1467-8659.2012.03028.x", "10.1007/3-540-69342-4_21", "10.1371/journal.pone.0010047", "10.1007/978-3-7091-6874-5_3", "10.1016/j.gaitpost.2013.03.017", "10.1089/109493101300117884", "10.1007/978-3-642-04504-2_11", "10.1007/978-3-540-47641-2_26", "10.1111/cgf.12328", "10.2307/3033551", "10.1111/j.1559-1816.2004.tb02571.x", "10.1007/s10919-009-0077-y", "10.1002/cav.1453", "10.1037/0033-2909.94.2.293", "10.1038/35035023", "10.1111/j.1467-8659.2012.03028.x", "10.1007/3-540-69342-4_21", "10.1371/journal.pone.0010047", "10.1007/978-3-7091-6874-5_3", "10.1016/j.gaitpost.2013.03.017", "10.1089/109493101300117884", "10.1007/978-3-642-04504-2_11", "10.1007/978-3-540-47641-2_26", "10.1111/cgf.12328"]}, "10.1109/TVCG.2015.2391853": {"doi": "10.1109/TVCG.2015.2391853", "author": ["L. Chittaro", "F. Buttussi"], "title": "Assessing Knowledge Retention of an Immersive Serious Game vs. a Traditional Education Method in Aviation Safety", "year": "2015", "abstract": "Thanks to the increasing availability of consumer head-mounted displays, educational applications of immersive VR could now reach to the general public, especially if they include gaming elements (immersive serious games). Safety education of citizens could be a particularly promising domain for immersive serious games, because people tend not to pay attention to and benefit from current safety materials. In this paper, we propose an HMD-based immersive game for educating passengers about aviation safety that allows players to experience a serious aircraft emergency with the goal of surviving it. We compare the proposed approach to a traditional aviation safety education method (the safety card) used by airlines. Unlike most studies of VR for safety knowledge acquisition, we do not focus only on assessing learning immediately after the experience but we extend our attention to knowledge retention over a longer time span. This is a fundamental requirement, because people need to retain safety procedures in order to apply them when faced with danger. A knowledge test administered before, immediately after and one week after the experimental condition showed that the immersive serious game was superior to the safety card. Moreover, subjective as well as physiological measurements employed in the study showed that the immersive serious game was more engaging and fear-arousing than the safety card, a factor that can contribute to explain the obtained superior retention, as we discuss in the paper.", "keywords": ["avionics", "computer aided instruction", "computer games", "helmet mounted displays", "virtual reality", "knowledge retention", "consumer head-mounted displays", "educational applications", "immersive VR", "gaming elements", "immersive serious games", "safety materials", "HMD-based immersive game", "aircraft emergency", "aviation safety education method", "airlines", "safety knowledge acquisition", "safety procedures", "knowledge test", "safety card", "physiological measurements", "superior retention", "Games", "Safety", "Aircraft", "Education", "Materials", "Avatars", "Engines", "Immersive VR", "serious games", "user evaluation", "knowledge retention", "physiological measurements", "aviation safety", "Immersive VR", "serious games", "user evaluation", "knowledge retention", "physiological measurements", "aviation safety", "Accidents, Aviation", "Aviation", "Computer Graphics", "Humans", "User-Computer Interface", "Video Games"], "referenced_by": ["10.1145/3064644", "10.1002/fam.2448", "10.1007/978-3-319-41769-1_4", "10.1007/978-3-319-48496-9_65", "10.1007/978-3-319-51645-5_13", "10.1007/978-3-319-57987-0_17", "10.1007/978-981-10-6144-8_6", "10.1007/s10055-016-0298-4", "10.1007/s11042-017-5459-2", "10.1016/j.chb.2015.01.040", "10.1016/j.chb.2016.02.031", "10.1016/j.ijhcs.2015.11.004", "10.1016/j.ijhcs.2017.01.002", "10.1016/j.ssci.2017.10.012", "10.1016/j.ssci.2018.02.016", "10.1016/j.trc.2017.10.007", "10.1080/10447318.2017.1286768", "10.1089/g4h.2016.0068", "10.1177/1046878117739929", "10.4018/978-1-5225-2426-7.ch010", "10.5057/jjske.TJSKE-D-16-00101", "10.1016/j.ssci.2018.07.021", "10.1016/j.ijhcs.2018.07.006", "10.1016/j.promfg.2018.07.126", "10.1108/DPM-11-2017-0283", "10.7837/kosomes.2018.24.2.232", "10.1016/j.compedu.2018.09.002", "10.1016/j.aei.2018.08.018", "10.12688/amrcopenres.13362.1", "10.12688/f1000research.16453.1"], "referencing": ["IKEY:4272085", "IKEY:4272086", "IKEY:6787893", "IKEY:4272085", "IKEY:4272086", "IKEY:6787893", "IKEY:4272085", "IKEY:4272086", "IKEY:6787893", "10.1145/375735.376390", "10.1145/2503713.2503725", "10.1145/159161.155359", "10.1145/1129006.1129021", "10.1145/375735.376390", "10.1145/2503713.2503725", "10.1145/159161.155359", "10.1145/1129006.1129021", "10.1145/375735.376390", "10.1145/2503713.2503725", "10.1145/159161.155359", "10.1145/1129006.1129021", "10.1067/msy.2002.125723", "10.1136/gut.2009.191825", "10.1016/j.firesaf.2012.01.004", "10.1111/j.1365-2729.2012.00489.x", "10.1016/j.aap.2008.03.005", "10.1111/j.1467-8535.2011.01282.x", "10.1038/nn1353", "10.1038/nrn1825", "10.1126/science.287.5451.248", "10.1016/j.nlm.2012.04.002", "10.1177/1754073908100432", "10.1177/0956797611407932", "10.1016/j.jml.2005.05.005", "10.1016/j.compedu.2013.07.033", "10.1016/j.ridd.2006.07.001", "10.1038/371702a0", "10.1007/978-1-4612-1414-4_12", "10.1016/j.tmaid.2008.06.001", "10.1016/j.cpr.2009.05.003", "10.1111/j.1468-2958.2009.01344.x", "10.1111/j.1469-8986.2009.00972.x", "10.1093/iwc/iwt049", "10.1007/s00702-011-0757-8", "10.1002/da.20734", "10.1016/j.jbtep.2007.07.007", "10.1067/msy.2002.125723", "10.1136/gut.2009.191825", "10.1016/j.firesaf.2012.01.004", "10.1111/j.1365-2729.2012.00489.x", "10.1016/j.aap.2008.03.005", "10.1111/j.1467-8535.2011.01282.x", "10.1038/nn1353", "10.1038/nrn1825", "10.1126/science.287.5451.248", "10.1016/j.nlm.2012.04.002", "10.1177/1754073908100432", "10.1177/0956797611407932", "10.1016/j.jml.2005.05.005", "10.1016/j.compedu.2013.07.033", "10.1016/j.ridd.2006.07.001", "10.1038/371702a0", "10.1007/978-1-4612-1414-4_12", "10.1016/j.tmaid.2008.06.001", "10.1016/j.cpr.2009.05.003", "10.1111/j.1468-2958.2009.01344.x", "10.1111/j.1469-8986.2009.00972.x", "10.1093/iwc/iwt049", "10.1007/s00702-011-0757-8", "10.1002/da.20734", "10.1016/j.jbtep.2007.07.007", "10.1067/msy.2002.125723", "10.1136/gut.2009.191825", "10.1016/j.firesaf.2012.01.004", "10.1111/j.1365-2729.2012.00489.x", "10.1016/j.aap.2008.03.005", "10.1111/j.1467-8535.2011.01282.x", "10.1038/nn1353", "10.1038/nrn1825", "10.1126/science.287.5451.248", "10.1016/j.nlm.2012.04.002", "10.1177/1754073908100432", "10.1177/0956797611407932", "10.1016/j.jml.2005.05.005", "10.1016/j.compedu.2013.07.033", "10.1016/j.ridd.2006.07.001", "10.1038/371702a0", "10.1007/978-1-4612-1414-4_12", "10.1016/j.tmaid.2008.06.001", "10.1016/j.cpr.2009.05.003", "10.1111/j.1468-2958.2009.01344.x", "10.1111/j.1469-8986.2009.00972.x", "10.1093/iwc/iwt049", "10.1007/s00702-011-0757-8", "10.1002/da.20734", "10.1016/j.jbtep.2007.07.007"]}, "10.1109/TVCG.2015.2391864": {"doi": "10.1109/TVCG.2015.2391864", "author": ["G. Bruder", "P. Lubos", "F. Steinicke"], "title": "Cognitive Resource Demands of Redirected Walking", "year": "2015", "abstract": "Redirected walking allows users to walk through a large-scale immersive virtual environment (IVE) while physically remaining in a reasonably small workspace. Therefore, manipulations are applied to virtual camera motions so that the user's self-motion in the virtual world differs from movements in the real world. Previous work found that the human perceptual system tolerates a certain amount of inconsistency between proprioceptive, vestibular and visual sensation in IVEs, and even compensates for slight discrepancies with recalibrated motor commands. Experiments showed that users are not able to detect an inconsistency if their physical path is bent with a radius of at least 22 meters during virtual straightforward movements. If redirected walking is applied in a smaller workspace, manipulations become noticeable, but users are still able to move through a potentially infinitely large virtual world by walking. For this semi-natural form of locomotion, the question arises if such manipulations impose cognitive demands on the user, which may compete with other tasks in IVEs for finite cognitive resources. In this article we present an experiment in which we analyze the mutual influence between redirected walking and verbal as well as spatial working memory tasks using a dual-tasking method. The results show an influence of redirected walking on verbal as well as spatial working memory tasks, and we also found an effect of cognitive tasks on walking behavior. We discuss the implications and provide guidelines for using redirected walking in virtual reality laboratories.", "keywords": ["cognitive systems", "virtual reality", "cognitive resource demands", "redirected walking", "large-scale immersive virtual environment", "large-scale IVE", "virtual camera motions", "human perceptual system", "proprioceptive sensation", "vestibular sensation", "visual sensation", "virtual straightforward movements", "finite cognitive resources", "verbal working memory tasks", "spatial working memory tasks", "dual-tasking method", "virtual reality laboratories", "Legged locomotion", "Laboratories", "Standards", "Visualization", "Virtual environments", "Cameras", "Wireless sensor networks", "Redirected walking", "cognitive demands", "locomotion", "virtual environments", "Redirected walking", "cognitive demands", "locomotion", "virtual environments", "Adult", "Computer Graphics", "Female", "Humans", "Male", "Middle Aged", "Spatial Memory", "Task Performance and Analysis", "User-Computer Interface", "Walking", "Young Adult"], "referenced_by": ["IKEY:7460028", "IKEY:7893323", "IKEY:7901607", "IKEY:7383328", "IKEY:7547900", "IKEY:7833190", "IKEY:8314105", "IKEY:7892227", "IKEY:7968669", "IKEY:8255772", "IKEY:7384536", "IKEY:8446574", "IKEY:8446216", "IKEY:8613757", "IKEY:8798286", "IKEY:8797818", "IKEY:8798029", "IKEY:8797977", "IKEY:8998141", "IKEY:8554159", "IKEY:8580399", "IKEY:9089634", "IKEY:9089480", "IKEY:9089441", "IKEY:9284804", "IKEY:9284750", "IKEY:9284673", "10.1145/2808435.2808459", "10.1145/2811258", "10.1145/3267782.3267787", "10.1145/2897824.2925883", "10.1007/978-3-319-08234-9_253-1", "10.1155/2016/1205469", "10.3390/mti1040024", "10.1007/978-3-030-23560-4_44", "10.1007/978-3-030-21607-8_22", "10.1007/978-3-030-29390-1_19", "10.1007/978-3-030-31908-3_14", "10.1007/978-3-030-58465-8_11"], "referencing": ["IKEY:996544", "IKEY:4352055", "IKEY:1381227", "IKEY:6818657", "IKEY:5759454", "IKEY:6790523", "IKEY:4480761", "IKEY:5072212", "IKEY:6180877", "IKEY:6787863", "IKEY:6797503", "IKEY:1512020", "IKEY:996544", "IKEY:4352055", "IKEY:1381227", "IKEY:6818657", "IKEY:5759454", "IKEY:6790523", "IKEY:4480761", "IKEY:5072212", "IKEY:6180877", "IKEY:6787863", "IKEY:6797503", "IKEY:1512020", "IKEY:996544", "IKEY:4352055", "IKEY:1381227", "IKEY:6818657", "IKEY:5759454", "IKEY:6790523", "IKEY:4480761", "IKEY:5072212", "IKEY:6180877", "IKEY:6787863", "IKEY:6797503", "IKEY:1512020", "10.1145/1179133.1179162", "10.1145/1152399.1152451", "10.1145/1502800.1502805", "10.1145/2043603.2043607", "10.1145/1179133.1179162", "10.1145/1152399.1152451", "10.1145/1502800.1502805", "10.1145/2043603.2043607", "10.1145/1179133.1179162", "10.1145/1152399.1152451", "10.1145/1502800.1502805", "10.1145/2043603.2043607", "10.1146/annurev-psych-120710-100422", "10.1016/S0079-7421(08)60452-1", "10.1007/978-3-540-73331-7_27", "10.1016/S0042-6989(00)00134-6", "10.1007/978-3-642-46354-9_25", "10.1016/0013-4694(93)90119-G", "10.1007/11590323_5", "10.1207/s15327108ijap0303_3", "10.1016/S1364-6613(99)01364-9", "10.1016/S0966-6362(00)00076-X", "10.1177/1545968305275612", "10.1007/978-3-540-73107-8_102", "10.1016/S0966-6362(01)00156-4", "10.1146/annurev-psych-120710-100422", "10.1016/S0079-7421(08)60452-1", "10.1007/978-3-540-73331-7_27", "10.1016/S0042-6989(00)00134-6", "10.1007/978-3-642-46354-9_25", "10.1016/0013-4694(93)90119-G", "10.1007/11590323_5", "10.1207/s15327108ijap0303_3", "10.1016/S1364-6613(99)01364-9", "10.1016/S0966-6362(00)00076-X", "10.1177/1545968305275612", "10.1007/978-3-540-73107-8_102", "10.1016/S0966-6362(01)00156-4", "10.1146/annurev-psych-120710-100422", "10.1016/S0079-7421(08)60452-1", "10.1007/978-3-540-73331-7_27", "10.1016/S0042-6989(00)00134-6", "10.1007/978-3-642-46354-9_25", "10.1016/0013-4694(93)90119-G", "10.1007/11590323_5", "10.1207/s15327108ijap0303_3", "10.1016/S1364-6613(99)01364-9", "10.1016/S0966-6362(00)00076-X", "10.1177/1545968305275612", "10.1007/978-3-540-73107-8_102", "10.1016/S0966-6362(01)00156-4"]}, "10.1109/TVCG.2015.2391851": {"doi": "10.1109/TVCG.2015.2391851", "author": ["B. Bolte", "M. Lappe"], "title": "Subliminal Reorientation and Repositioning in Immersive Virtual Environments using Saccadic Suppression", "year": "2015", "abstract": "Virtual reality strives to provide a user with an experience of a simulated world that feels as natural as the real world. Yet, to induce this feeling, sometimes it becomes necessary for technical reasons to deviate from a one-to-one correspondence between the real and the virtual world, and to reorient or reposition the user's viewpoint. Ideally, users should not notice the change of the viewpoint to avoid breaks in perceptual continuity. Saccades, the fast eye movements that we make in order to switch gaze from one object to another, produce a visual discontinuity on the retina, but this is not perceived because the visual system suppresses perception during saccades. As a consequence, our perception fails to detect rotations of the visual scene during saccades. We investigated whether saccadic suppression of image displacement (SSID) can be used in an immersive virtual environment (VE) to unconsciously rotate and translate the observer's viewpoint. To do this, the scene changes have to be precisely time-locked to the saccade onset. We used electrooculography (EOG) for eye movement tracking and assessed the performance of two modified eye movement classification algorithms for the challenging task of online saccade detection that is fast enough for SSID. We investigated the sensitivity of participants to translations (forward/backward) and rotations (in the transverse plane) during trans-saccadic scene changes. We found that participants were unable to detect approximately \u00b10.5m translations along the line of gaze and \u00b15\u00b0 rotations in the transverse plane during saccades with an amplitude of 15\u00b0. If the user stands still, our approach exploiting SSID thus provides the means to unconsciously change the user's virtual position and/or orientation. For future research and applications, exploiting SSID has the potential to improve existing redirected walking and change blindness techniques for unlimited navigation through arbitrarily-sized VEs by real walking.", "keywords": ["electro-oculography", "gaze tracking", "image classification", "object tracking", "virtual reality", "subliminal reorientation", "subliminal repositioning", "immersive virtual environments", "virtual reality", "perceptual continuity", "eye movements", "visual discontinuity", "retina", "perception suppression", "saccadic suppression of image displacement", "SSID", "VE", "electrooculography", "EOG", "eye movement tracking", "eye movement classification algorithms", "online saccade detection", "trans-saccadic scene changes", "redirected walking technique", "change blindness technique", "Electrooculography", "Heuristic algorithms", "Acceleration", "Tracking", "Visualization", "Sensitivity", "Legged locomotion", "Reorientation", "repositioning", "saccadic suppression", "detection thresholds", "eye tracking", "electrooculography", "Reorientation", "repositioning", "saccadic suppression", "detection thresholds", "eye tracking", "electrooculography", "Adult", "Algorithms", "Electrooculography", "Female", "Humans", "Image Processing, Computer-Assisted", "Male", "Saccades", "User-Computer Interface", "Young Adult"], "referenced_by": ["IKEY:7547900", "IKEY:8260943", "IKEY:7892248", "IKEY:8255772", "IKEY:7384536", "IKEY:8446144", "IKEY:8645699", "IKEY:9003250", "IKEY:8998133", "IKEY:8998141", "IKEY:9089441", "IKEY:9089532", "IKEY:9284673", "10.1145/3197517.3201294", "10.1145/3197517.3201335", "10.1145/3414685.3417773", "10.1007/978-3-319-95270-3_13", "10.1007/978-3-030-21607-8_29", "10.1007/s11042-019-08305-6", "10.1038/s41598-020-69135-3", "10.1007/978-3-030-62655-6_2"], "referencing": ["IKEY:4121599", "IKEY:6081857", "IKEY:4663065", "IKEY:4145210", "IKEY:5072212", "IKEY:6180877", "IKEY:5759455", "IKEY:6787863", "IKEY:4297685", "IKEY:4121599", "IKEY:6081857", "IKEY:4663065", "IKEY:4145210", "IKEY:5072212", "IKEY:6180877", "IKEY:5759455", "IKEY:6787863", "IKEY:4297685", "IKEY:4121599", "IKEY:6081857", "IKEY:4663065", "IKEY:4145210", "IKEY:5072212", "IKEY:6180877", "IKEY:5759455", "IKEY:6787863", "IKEY:4297685", "10.1145/1242073.1242098", "10.1145/1179133.1179162", "10.1145/355017.355028", "10.1145/507089.507092", "10.1145/1140491.1140495", "10.1145/1140491.1140525", "10.1145/1242073.1242098", "10.1145/1179133.1179162", "10.1145/355017.355028", "10.1145/507089.507092", "10.1145/1140491.1140495", "10.1145/1140491.1140525", "10.1145/1242073.1242098", "10.1145/1179133.1179162", "10.1145/355017.355028", "10.1145/507089.507092", "10.1145/1140491.1140495", "10.1145/1140491.1140525", "10.3758/BRM.42.3.701", "10.1016/0042-6989(75)90290-4", "10.1016/j.displa.2012.10.007", "10.1113/jphysiol.1988.sp017284", "10.1016/S0042-6989(98)00048-0", "10.1016/0042-6989(95)00203-0", "10.1207/s15327108ijap0303_3", "10.3758/BF03211589", "10.1038/nature01439", "10.1016/j.cmpb.2009.04.011", "10.3758/BRM.42.1.188", "10.3758/BRM.42.3.701", "10.1016/0042-6989(75)90290-4", "10.1016/j.displa.2012.10.007", "10.1113/jphysiol.1988.sp017284", "10.1016/S0042-6989(98)00048-0", "10.1016/0042-6989(95)00203-0", "10.1207/s15327108ijap0303_3", "10.3758/BF03211589", "10.1038/nature01439", "10.1016/j.cmpb.2009.04.011", "10.3758/BRM.42.1.188", "10.3758/BRM.42.3.701", "10.1016/0042-6989(75)90290-4", "10.1016/j.displa.2012.10.007", "10.1113/jphysiol.1988.sp017284", "10.1016/S0042-6989(98)00048-0", "10.1016/0042-6989(95)00203-0", "10.1207/s15327108ijap0303_3", "10.3758/BF03211589", "10.1038/nature01439", "10.1016/j.cmpb.2009.04.011", "10.3758/BRM.42.1.188"]}, "10.1109/TVCG.2015.2415451": {"doi": "10.1109/TVCG.2015.2415451", "author": [""], "title": "Conference Author Index", "year": "2015", "abstract": "Presents the author index for the 2015 Virtual Realty Conference.", "keywords": [""], "referenced_by": [], "referencing": []}}