{"10.1109/TVCG.2015.2403352": {"doi": "10.1109/TVCG.2015.2403352", "author": ["S. DiVerdi"], "title": "A Modular Framework for Digital Painting", "year": "2015", "abstract": "While there has been tremendous research in the simulation of natural media painting, little academic work has been written to understand how all these contributions interrelate and to use this knowledge to direct future work. In this paper, we survey the set of interesting artistic tools to categorize their effects and motivate a modular framework for digital painting that can reproduce those effects in a loosely coupled way. We use this framework as a lens through which we survey the literature and classify the achievements of previous efforts. We examine our own contributions in the field in more detail, discussing how the framework motivated those results and how it impacted our accomplishments. Finally, we discuss the open challenges that remain for the research community, and how the framework can help to make contributions towards those challenges.", "keywords": ["art", "computer graphics", "interesting artistic tools", "natural media painting simulation", "digital painting", "modular framework", "Pigments", "Media", "Painting", "Shape", "Paints", "Brushes", "Computational modeling", "natural media", "digital painting", "Natural media", "digital painting"], "referenced_by": ["IKEY:8765801"], "referencing": ["IKEY:929908", "IKEY:1382898", "IKEY:1333630", "IKEY:6314479", "IKEY:803369", "IKEY:929908", "IKEY:1382898", "IKEY:1333630", "IKEY:6314479", "IKEY:803369", "IKEY:929908", "IKEY:1382898", "IKEY:1333630", "IKEY:6314479", "IKEY:803369", "10.1145/2185520.2185542", "10.1145/1866029.1866045", "10.1145/1731903.1731914", "10.1145/2461912.2461998", "10.1145/2630397.2630401", "10.1145/311625.312110", "10.1145/1321261.1321281", "10.1145/987657.987665", "10.1145/1730804.1730826", "10.1145/1809939.1809943", "10.1145/1889863.1889889", "10.1145/258734.258896", "10.1145/2159616.2159627", "10.1145/1572614.1572625", "10.1145/2185520.2185542", "10.1145/1866029.1866045", "10.1145/1731903.1731914", "10.1145/2461912.2461998", "10.1145/2630397.2630401", "10.1145/311625.312110", "10.1145/1321261.1321281", "10.1145/987657.987665", "10.1145/1730804.1730826", "10.1145/1809939.1809943", "10.1145/1889863.1889889", "10.1145/258734.258896", "10.1145/2159616.2159627", "10.1145/1572614.1572625", "10.1145/2185520.2185542", "10.1145/1866029.1866045", "10.1145/1731903.1731914", "10.1145/2461912.2461998", "10.1145/2630397.2630401", "10.1145/311625.312110", "10.1145/1321261.1321281", "10.1145/987657.987665", "10.1145/1730804.1730826", "10.1145/1809939.1809943", "10.1145/1889863.1889889", "10.1145/258734.258896", "10.1145/2159616.2159627", "10.1145/1572614.1572625", "10.1007/978-1-4471-4519-6_2", "10.1111/j.1467-8659.2010.01802.x", "10.1111/1467-8659.1330205", "10.1111/1467-8659.00589", "10.1111/1467-8659.t01-2-00701", "10.1016/j.gmod.2004.05.006", "10.1007/BF02944909", "10.1007/978-3-540-73814-5_25", "10.1002/cav.47", "10.1002/cav.95", "10.1007/s00371-007-0158-z", "10.1111/j.1467-8659.2007.01084.x", "10.1007/978-3-540-89639-5_95", "10.1007/s00371-008-0257-5", "10.1111/1467-8659.00340", "10.1111/j.1467-8659.2005.00826.x", "10.1007/s00371-007-0144-5", "10.1364/JOSA.38.000448", "10.1364/JOSA.44.000330", "10.1007/978-1-4471-4519-6_2", "10.1111/j.1467-8659.2010.01802.x", "10.1111/1467-8659.1330205", "10.1111/1467-8659.00589", "10.1111/1467-8659.t01-2-00701", "10.1016/j.gmod.2004.05.006", "10.1007/BF02944909", "10.1007/978-3-540-73814-5_25", "10.1002/cav.47", "10.1002/cav.95", "10.1007/s00371-007-0158-z", "10.1111/j.1467-8659.2007.01084.x", "10.1007/978-3-540-89639-5_95", "10.1007/s00371-008-0257-5", "10.1111/1467-8659.00340", "10.1111/j.1467-8659.2005.00826.x", "10.1007/s00371-007-0144-5", "10.1364/JOSA.38.000448", "10.1364/JOSA.44.000330", "10.1007/978-1-4471-4519-6_2", "10.1111/j.1467-8659.2010.01802.x", "10.1111/1467-8659.1330205", "10.1111/1467-8659.00589", "10.1111/1467-8659.t01-2-00701", "10.1016/j.gmod.2004.05.006", "10.1007/BF02944909", "10.1007/978-3-540-73814-5_25", "10.1002/cav.47", "10.1002/cav.95", "10.1007/s00371-007-0158-z", "10.1111/j.1467-8659.2007.01084.x", "10.1007/978-3-540-89639-5_95", "10.1007/s00371-008-0257-5", "10.1111/1467-8659.00340", "10.1111/j.1467-8659.2005.00826.x", "10.1007/s00371-007-0144-5", "10.1364/JOSA.38.000448", "10.1364/JOSA.44.000330"]}, "10.1109/TVCG.2015.2403312": {"doi": "10.1109/TVCG.2015.2403312", "author": ["E. D. Ragan", "D. A. Bowman", "R. Kopper", "C. Stinson", "S. Scerbo", "R. P. McMahan"], "title": "Effects of Field of View and Visual Complexity on Virtual Reality Training Effectiveness for a Visual Scanning Task", "year": "2015", "abstract": "Virtual reality training systems are commonly used in a variety of domains, and it is important to understand how the realism of a training simulation influences training effectiveness. We conducted a controlled experiment to test the effects of display and scenario properties on training effectiveness for a visual scanning task in a simulated urban environment. The experiment varied the levels of field of view and visual complexity during a training phase and then evaluated scanning performance with the simulator's highest levels of fidelity and scene complexity. To assess scanning performance, we measured target detection and adherence to a prescribed strategy. The results show that both field of view and visual complexity significantly affected target detection during training; higher field of view led to better performance and higher visual complexity worsened performance. Additionally, adherence to the prescribed visual scanning strategy during assessment was best when the level of visual complexity during training matched that of the assessment conditions, providing evidence that similar visual complexity was important for learning the technique. The results also demonstrate that task performance during training was not always a sufficient measure of mastery of an instructed technique. That is, if learning a prescribed strategy or skill is the goal of a training exercise, performance in a simulation may not be an appropriate indicator of effectiveness outside of training-evaluation in a more realistic setting may be necessary.", "keywords": ["computer based training", "graphical user interfaces", "optical scanners", "virtual reality", "field-of-view", "virtual reality training effectiveness", "training simulation", "controlled experiment", "visual scanning task", "simulated urban environment", "visual complexity", "scanning performance evaluation", "fidelity level", "scene complexity level", "scanning performance assessment", "target detection measurement", "target adherence measurement", "visual scanning strategy", "task performance", "instructed technique", "training exercise", "Training", "Visualization", "Complexity theory", "Virtual reality", "Object detection", "Solid modeling", "Head", "Artificial", "augmented and virtual realities", "Graphical user interfaces", "Artificial", "augmented", "and virtual realities", " Graphical user interfaces"], "referenced_by": ["IKEY:7932376", "IKEY:7547900", "IKEY:7817889", "IKEY:8302409", "IKEY:7504692", "IKEY:7892259", "IKEY:7892303", "IKEY:8446508", "IKEY:8446139", "IKEY:8576892", "IKEY:8613642", "IKEY:8746262", "IKEY:8797840", "IKEY:8943763", "IKEY:8955071", "IKEY:9090410", "IKEY:9089645", "IKEY:9090539", "IKEY:9089482", "IKEY:9130859", "IKEY:9201902", "IKEY:9212039", "IKEY:9284660", "IKEY:9288454", "10.1145/3267340", "10.1002/cae.21890", "10.1002/hfm.20702", "10.1007/978-3-319-41950-3_12", "10.1007/s10639-017-9676-0", "10.1016/j.ijhcs.2016.07.005", "10.1080/00140139.2017.1353138", "10.1080/0144929X.2016.1212929", "10.1177/0037549717726144", "10.1177/1541931213601863", "10.3389/fict.2016.00024", "10.3389/fict.2016.00029", "10.3389/fict.2017.00021", "10.1007/978-3-319-91581-4_8", "10.1007/978-3-319-08234-9_251-1", "10.1007/978-3-319-95678-7_49", "10.1016/j.cja.2018.08.011", "10.1080/10447318.2018.1498654", "10.3390/sym11010101", "10.1016/j.displa.2019.03.003", "10.1111/cura.12308", "10.1007/978-3-030-18715-6_32", "10.1016/j.autcon.2019.04.015", "10.1016/j.rcim.2019.05.004", "10.1016/j.cag.2019.06.009", "10.1111/jcal.12375", "10.1007/978-3-030-25965-5_18", "10.1088/1757-899X/571/1/012117", "10.1016/j.procir.2019.04.268", "10.1007/978-3-030-29926-2_8"], "referencing": ["IKEY:1510565", "IKEY:4287241", "IKEY:5473199", "IKEY:6261311", "IKEY:6165144", "IKEY:6479181", "IKEY:756938", "IKEY:1608026", "IKEY:6479179", "IKEY:1510565", "IKEY:4287241", "IKEY:5473199", "IKEY:6261311", "IKEY:6165144", "IKEY:6479181", "IKEY:756938", "IKEY:1608026", "IKEY:6479179", "IKEY:1510565", "IKEY:4287241", "IKEY:5473199", "IKEY:6261311", "IKEY:6165144", "IKEY:6479181", "IKEY:756938", "IKEY:1608026", "IKEY:6479179", "10.1145/2330667.2330687", "10.1145/258734.258744", "10.1145/2330667.2330687", "10.1145/258734.258744", "10.1145/2330667.2330687", "10.1145/258734.258744", "10.1007/s00268-007-9307-9", "10.1007/978-1-4612-3564-4_3", "10.1007/978-1-4612-3564-4_5", "10.1207/s15327876mp0402_1", "10.1518/107118192786749450", "10.1007/s00464-006-9072-0", "10.1111/j.1747-4949.2009.00404.x", "10.1089/109493102760147150", "10.1002/jts.20574", "10.1162/105474698565631", "10.1007/978-1-4419-8432-6_14", "10.1162/105474603765879549", "10.1162/105474605774918778", "10.1162/1054746042545292", "10.1177/154193129604002201", "10.2466/pms.105.4.1245-1256", "10.1016/j.displa.2012.08.003", "10.4135/9781412995627.d5", "10.1177/1094428102239427", "10.1037/0033-2909.86.2.420", "10.1016/j.ijnurstu.2011.01.016", "10.1007/s00268-007-9307-9", "10.1007/978-1-4612-3564-4_3", "10.1007/978-1-4612-3564-4_5", "10.1207/s15327876mp0402_1", "10.1518/107118192786749450", "10.1007/s00464-006-9072-0", "10.1111/j.1747-4949.2009.00404.x", "10.1089/109493102760147150", "10.1002/jts.20574", "10.1162/105474698565631", "10.1007/978-1-4419-8432-6_14", "10.1162/105474603765879549", "10.1162/105474605774918778", "10.1162/1054746042545292", "10.1177/154193129604002201", "10.2466/pms.105.4.1245-1256", "10.1016/j.displa.2012.08.003", "10.4135/9781412995627.d5", "10.1177/1094428102239427", "10.1037/0033-2909.86.2.420", "10.1016/j.ijnurstu.2011.01.016", "10.1007/s00268-007-9307-9", "10.1007/978-1-4612-3564-4_3", "10.1007/978-1-4612-3564-4_5", "10.1207/s15327876mp0402_1", "10.1518/107118192786749450", "10.1007/s00464-006-9072-0", "10.1111/j.1747-4949.2009.00404.x", "10.1089/109493102760147150", "10.1002/jts.20574", "10.1162/105474698565631", "10.1007/978-1-4419-8432-6_14", "10.1162/105474603765879549", "10.1162/105474605774918778", "10.1162/1054746042545292", "10.1177/154193129604002201", "10.2466/pms.105.4.1245-1256", "10.1016/j.displa.2012.08.003", "10.4135/9781412995627.d5", "10.1177/1094428102239427", "10.1037/0033-2909.86.2.420", "10.1016/j.ijnurstu.2011.01.016"]}, "10.1109/TVCG.2015.2403323": {"doi": "10.1109/TVCG.2015.2403323", "author": ["M. H. Everts", "E. Begue", "H. Bekker", "J. B. T. M. Roerdink", "T. Isenberg"], "title": "Exploration of the Brain\u2019s White Matter Structure through Visual Abstraction and Multi-Scale Local Fiber Tract Contraction", "year": "2015", "abstract": "We present a visualization technique for brain fiber tracts from DTI data that provides insight into the structure of white matter through visual abstraction. We achieve this abstraction by analyzing the local similarity of tract segment directions at different scales using a stepwise increase of the search range. Next, locally similar tract segments are moved toward each other in an iterative process, resulting in a local contraction of tracts perpendicular to the local tract direction at a given scale. This not only leads to the abstraction of the global structure of the white matter as represented by the tracts, but also creates volumetric voids. This increase of empty space decreases the mutual occlusion of tracts and, consequently, results in a better understanding of the brain's three-dimensional fiber tract structure. Our implementation supports an interactive and continuous transition between the original and the abstracted representations via various scale levels of similarity. We also support the selection of groups of tracts, which are highlighted and rendered with the abstracted visualization as context.", "keywords": ["brain", "data visualisation", "medical image processing", "3D fiber tract structure", "tract segment directions", "DTI data", "brain fiber tract visualization technique", "multiscale local fiber tract contraction", "visual abstraction", "brain white matter structure", "Diffusion tensor imaging", "Visualization", "Data visualization", "Tensile stress", "Vectors", "Nerve fibers", "Abstracts", "Diffusion Tensor Imaging (DTI)", "fiber tracts", "visual abstraction", "multi-scale representation", "illustrative visualization", "Diffusion tensor imaging (DTI)", "fiber tracts", "visual abstraction", "multi-scale representation", "illustrative visualization", "Adult", "Computer Graphics", "Female", "Humans", "Image Processing, Computer-Assisted", "Magnetic Resonance Imaging", "Male", "Neural Pathways", "White Matter"], "referenced_by": ["IKEY:7534826", "IKEY:8017623", "IKEY:8025425", "IKEY:8467383", "IKEY:8440808", "IKEY:8805465", "10.1002/hbm.23803", "10.3390/e20090625", "10.1007/978-3-319-15090-1_12", "10.1101/061267", "10.1007/s12650-020-00642-1", "10.3390/a13120316"], "referencing": ["IKEY:6579594", "IKEY:5290758", "IKEY:5290742", "IKEY:4015425", "IKEY:5290760", "IKEY:5753898", "IKEY:4015499", "IKEY:1532779", "IKEY:4359056", "IKEY:4376178", "IKEY:4376179", "IKEY:5223581", "IKEY:4479455", "IKEY:1260740", "IKEY:6579594", "IKEY:5290758", "IKEY:5290742", "IKEY:4015425", "IKEY:5290760", "IKEY:5753898", "IKEY:4015499", "IKEY:1532779", "IKEY:4359056", "IKEY:4376178", "IKEY:4376179", "IKEY:5223581", "IKEY:4479455", "IKEY:1260740", "IKEY:6579594", "IKEY:5290758", "IKEY:5290742", "IKEY:4015425", "IKEY:5290760", "IKEY:5753898", "IKEY:4015499", "IKEY:1532779", "IKEY:4359056", "IKEY:4376178", "IKEY:4376179", "IKEY:5223581", "IKEY:4479455", "IKEY:1260740", "10.1145/1179622.1179816", "10.1145/1179622.1179816", "10.1145/1179622.1179816", "10.1006/jmrb.1994.1037", "10.1006/jmrb.1996.0086", "10.1002/mrm.10415", "10.1371/journal.pbio.0060159", "10.1007/s11548-009-0302-5", "10.1111/j.1467-8659.2009.01450.x", "10.1007/978-3-319-15090-1_12", "10.1016/j.neuroimage.2011.09.015", "10.1002/1097-0193(200009)11:1&lt;12::AID-HBM20&gt;3.0.CO;2-K", "10.1016/j.media.2007.07.005", "10.1016/j.media.2007.10.003", "10.1007/978-3-642-23629-7_24", "10.1002/nbm.781", "10.1002/(SICI)1522-2594(199909)42:3&lt;526::AID-MRM15&gt;3.3.CO;2-A", "10.1111/j.1467-8659.2008.01243.x", "10.1016/j.neuroimage.2006.02.024", "10.1111/j.1467-8659.2009.01692.x", "10.1148/radiol.2301021640", "10.1126/science.1215280", "10.1006/jmrb.1994.1037", "10.1006/jmrb.1996.0086", "10.1002/mrm.10415", "10.1371/journal.pbio.0060159", "10.1007/s11548-009-0302-5", "10.1111/j.1467-8659.2009.01450.x", "10.1007/978-3-319-15090-1_12", "10.1016/j.neuroimage.2011.09.015", "10.1002/1097-0193(200009)11:1&lt;12::AID-HBM20&gt;3.0.CO;2-K", "10.1016/j.media.2007.07.005", "10.1016/j.media.2007.10.003", "10.1007/978-3-642-23629-7_24", "10.1002/nbm.781", "10.1002/(SICI)1522-2594(199909)42:3&lt;526::AID-MRM15&gt;3.3.CO;2-A", "10.1111/j.1467-8659.2008.01243.x", "10.1016/j.neuroimage.2006.02.024", "10.1111/j.1467-8659.2009.01692.x", "10.1148/radiol.2301021640", "10.1126/science.1215280", "10.1006/jmrb.1994.1037", "10.1006/jmrb.1996.0086", "10.1002/mrm.10415", "10.1371/journal.pbio.0060159", "10.1007/s11548-009-0302-5", "10.1111/j.1467-8659.2009.01450.x", "10.1007/978-3-319-15090-1_12", "10.1016/j.neuroimage.2011.09.015", "10.1002/1097-0193(200009)11:1&lt;12::AID-HBM20&gt;3.0.CO;2-K", "10.1016/j.media.2007.07.005", "10.1016/j.media.2007.10.003", "10.1007/978-3-642-23629-7_24", "10.1002/nbm.781", "10.1002/(SICI)1522-2594(199909)42:3&lt;526::AID-MRM15&gt;3.3.CO;2-A", "10.1111/j.1467-8659.2008.01243.x", "10.1016/j.neuroimage.2006.02.024", "10.1111/j.1467-8659.2009.01692.x", "10.1148/radiol.2301021640", "10.1126/science.1215280"]}, "10.1109/TVCG.2015.2407404": {"doi": "10.1109/TVCG.2015.2407404", "author": ["C. Xu", "T. Y. Wang", "Y. Liu", "L. Liu", "Y. He"], "title": "Fast Wavefront Propagation (FWP) for Computing Exact Geodesic Distances on Meshes", "year": "2015", "abstract": "Computing geodesic distances on triangle meshes is a fundamental problem in computational geometry and computer graphics. To date, two notable classes of algorithms, the Mitchell-Mount-Papadimitriou (MMP) algorithm and the Chen-Han (CH) algorithm, have been proposed. Although these algorithms can compute exact geodesic distances if numerical computation is exact, they are computationally expensive, which diminishes their usefulness for large-scale models and/or time-critical applications. In this paper, we propose the fast wavefront propagation (FWP) framework for improving the performance of both the MMP and CH algorithms. Unlike the original algorithms that propagate only a single window (a data structure locally encodes geodesic information) at each iteration, our method organizes windows with a bucket data structure so that it can process a large number of windows simultaneously without compromising wavefront quality. Thanks to its macro nature, the FWP method is less sensitive to mesh triangulation than the MMP and CH algorithms. We evaluate our FWP-based MMP and CH algorithms on a wide range of large-scale real-world models. Computational results show that our method can improve the speed by a factor of 3-10.", "keywords": ["computational geometry", "computer graphics", "differential geometry", "exact geodesic distance computation", "triangle meshes", "computational geometry", "computer graphics", "Mitchell-Mount-Papadimitriou algorithm", "Chen-Han algorithm", "large-scale models", "time-critical applications", "fast wavefront propagation framework", "geodesic information", "bucket data structure", "macro nature", "mesh triangulation", "large-scale real-world models", "Data structures", "Time complexity", "Educational institutions", "Approximation algorithms", "Computational geometry", "Computational modeling", "Discrete geodesic", "fast wavefront propagation", "algorithm complexities", "Discrete geodesic", "fast wavefront propagation", "algorithm complexities"], "referenced_by": ["IKEY:7102776", "IKEY:8643385", "IKEY:9213831", "10.1145/2939366", "10.1145/2980179.2982424", "10.1145/2999532", "10.1145/3197517.3201342", "10.1145/3243593", "10.1145/3144567", "10.1145/2897824.2925930", "10.1007/s10489-017-1114-x", "10.1007/s11390-018-1814-7", "10.1007/s41095-015-0022-4", "10.1007/s41095-016-0050-8", "10.1007/s41095-016-0057-1", "10.1007/s41095-017-0097-1", "10.1016/j.cad.2015.07.012", "10.1016/j.cad.2017.05.022", "10.1016/j.cagd.2017.03.010", "10.1016/j.gmod.2017.02.004", "10.1016/j.ipl.2017.04.005", "10.1111/cgf.13248", "10.1007/978-3-319-95588-9_220", "10.1016/j.cma.2018.10.026", "10.1016/j.cad.2019.05.023", "10.1177/0278364919855422", "10.1016/j.cad.2020.102851", "10.1007/s11081-020-09552-5", "10.1016/j.cad.2020.102943"], "referencing": ["10.1145/98524.98601", "10.1145/1073204.1073228", "10.1145/2534161", "10.1145/2508363.2508379", "10.1145/2159616.2159622", "10.1145/2407746.2407769", "10.1145/2516971.2516977", "10.1145/77635.77639", "10.1145/73393.73407", "10.1145/2461912.2461946", "10.1145/98524.98601", "10.1145/1073204.1073228", "10.1145/2534161", "10.1145/2508363.2508379", "10.1145/2159616.2159622", "10.1145/2407746.2407769", "10.1145/2516971.2516977", "10.1145/77635.77639", "10.1145/73393.73407", "10.1145/2461912.2461946", "10.1145/98524.98601", "10.1145/1073204.1073228", "10.1145/2534161", "10.1145/2508363.2508379", "10.1145/2159616.2159622", "10.1145/2407746.2407769", "10.1145/2516971.2516977", "10.1145/77635.77639", "10.1145/73393.73407", "10.1145/2461912.2461946", "10.1016/j.comgeo.2011.05.006", "10.1137/0216045", "10.1016/j.cad.2012.11.005", "10.1016/j.cad.2011.08.027", "10.1073/pnas.93.4.1591", "10.1073/pnas.95.15.8431", "10.1007/s10711-006-9109-5", "10.1007/s00371-007-0136-5", "10.1016/j.jcp.2005.08.005", "10.1016/j.comgeo.2011.05.006", "10.1137/0216045", "10.1016/j.cad.2012.11.005", "10.1016/j.cad.2011.08.027", "10.1073/pnas.93.4.1591", "10.1073/pnas.95.15.8431", "10.1007/s10711-006-9109-5", "10.1007/s00371-007-0136-5", "10.1016/j.jcp.2005.08.005", "10.1016/j.comgeo.2011.05.006", "10.1137/0216045", "10.1016/j.cad.2012.11.005", "10.1016/j.cad.2011.08.027", "10.1073/pnas.93.4.1591", "10.1073/pnas.95.15.8431", "10.1007/s10711-006-9109-5", "10.1007/s00371-007-0136-5", "10.1016/j.jcp.2005.08.005"]}, "10.1109/TVCG.2015.2398440": {"doi": "10.1109/TVCG.2015.2398440", "author": ["J. Lee", "Y. Kim", "S. Lee", "B. Kim", "J. Noh"], "title": "High-Quality Depth Estimation Using an Exemplar 3D Model for Stereo Conversion", "year": "2015", "abstract": "High-quality depth painting for each object in a scene is a challenging task in 2D to 3D stereo conversion. One way to accurately estimate the varying depth within the object in an image is to utilize existing 3D models. Automatic pose estimation approaches based on 2D-3D feature correspondences have been proposed to obtain depth from a given 3D model. However, when the 3D model is not identical to the target object, previous methods often produce erroneous depth in the vicinity of the silhouette of the object. This paper introduces a novel 3D model-based depth estimation method that effectively produces high-quality depth information for rigid objects in a stereo conversion workflow. Given an exemplar 3D model and user correspondences, our method generates detailed depth of an object by optimizing the initial depth obtained by the application of structural fitting and silhouette matching in the image domain. The final depth is accurate up to the given 3D model, while consistent with the image. Our method was applied to various image sequences containing objects with different appearances and varying poses. The experiments show that our method can generate plausible depth information that can be utilized for high-quality 2D to 3D stereo conversion.", "keywords": ["image matching", "pose estimation", "stereo image processing", "high-quality depth estimation", "exemplar 3D model", "2D to 3D stereo conversion", "automatic pose estimation approaches", "2D-3D feature correspondences", "3D model-based depth estimation method", "high-quality depth information", "rigid objects", "structural fitting", "silhouette matching", "image domain", "Three-dimensional displays", "Solid modeling", "Deformable models", "Mathematical model", "Computational modeling", "Equations", "Estimation", "depth estimation", "2D-to-3D conversion", "stereoscopic 3D", "model deformation", "pose estimation", "Depth estimation", "2D-to-3D conversion", "stereoscopic 3D", "model deformation", "pose estimation"], "referenced_by": ["IKEY:7785102", "IKEY:7813368", "IKEY:8307258", "IKEY:8961392", "10.1080/03772063.2019.1628667", "10.1007/978-3-030-34110-7_21"], "referencing": ["IKEY:5590261", "IKEY:1433077", "IKEY:5701641", "IKEY:5590261", "IKEY:1433077", "IKEY:5701641", "IKEY:5590261", "IKEY:1433077", "IKEY:5701641", "10.1145/2021164.2021173", "10.1145/383259.383310", "10.1145/311535.311556", "10.1145/1015706.1015780", "10.1145/2024156.2024196", "10.1145/1057432.1057456", "10.1145/1572741.1572749", "10.1145/1964921.1964975", "10.1145/2601097.2601209", "10.1145/1778765.1778812", "10.1145/2021164.2021173", "10.1145/383259.383310", "10.1145/311535.311556", "10.1145/1015706.1015780", "10.1145/2024156.2024196", "10.1145/1057432.1057456", "10.1145/1572741.1572749", "10.1145/1964921.1964975", "10.1145/2601097.2601209", "10.1145/1778765.1778812", "10.1145/2021164.2021173", "10.1145/383259.383310", "10.1145/311535.311556", "10.1145/1015706.1015780", "10.1145/2024156.2024196", "10.1145/1057432.1057456", "10.1145/1572741.1572749", "10.1145/1964921.1964975", "10.1145/2601097.2601209", "10.1145/1778765.1778812", "10.1111/j.1467-8659.2012.03214.x", "10.1002/cav.415", "10.5626/JCSE.2008.2.1.098", "10.1007/s11263-007-0043-2", "10.1111/j.1467-8659.2008.01187.x", "10.1007/s00371-013-0868-3", "10.1007/s11263-006-9965-3", "10.1111/j.1467-8659.2012.03214.x", "10.1002/cav.415", "10.5626/JCSE.2008.2.1.098", "10.1007/s11263-007-0043-2", "10.1111/j.1467-8659.2008.01187.x", "10.1007/s00371-013-0868-3", "10.1007/s11263-006-9965-3", "10.1111/j.1467-8659.2012.03214.x", "10.1002/cav.415", "10.5626/JCSE.2008.2.1.098", "10.1007/s11263-007-0043-2", "10.1111/j.1467-8659.2008.01187.x", "10.1007/s00371-013-0868-3", "10.1007/s11263-006-9965-3"]}, "10.1109/TVCG.2015.2403328": {"doi": "10.1109/TVCG.2015.2403328", "author": ["J. Hou", "L. Chau", "N. Magnenat-Thalmann", "Y. He"], "title": "Human Motion Capture Data Tailored Transform Coding", "year": "2015", "abstract": "Human motion capture (mocap) is a widely used technique for digitalizing human movements. With growing usage, compressing mocap data has received increasing attention, since compact data size enables efficient storage and transmission. Our analysis shows that mocap data have some unique characteristics that distinguish themselves from images and videos. Therefore, directly borrowing image or video compression techniques, such as discrete cosine transform, does not work well. In this paper, we propose a novel mocap-tailored transform coding algorithm that takes advantage of these features. Our algorithm segments the input mocap sequences into clips, which are represented in 2D matrices. Then it computes a set of data-dependent orthogonal bases to transform the matrices to frequency domain, in which the transform coefficients have significantly less dependency. Finally, the compression is obtained by entropy coding of the quantized coefficients and the bases. Our method has low computational cost and can be easily extended to compress mocap databases. It also requires neither training nor complicated parameter setting. Experimental results demonstrate that the proposed scheme significantly outperforms state-of-the-art algorithms in terms of compression performance and speed.", "keywords": ["data compression", "discrete cosine transforms", "image coding", "image motion analysis", "image sequences", "video coding", "discrete cosine transform", "mocap-tailored transform coding algorithm", "2D matrices", "mocap sequences", "data-dependent orthogonal bases", "transform coefficients", "compression performance", "video compression techniques", "compact data size", "human movements digitalization", "human motion capture data", "Discrete cosine transforms", "Transform coding", "Trajectory", "Correlation", "Videos", "Silicon", "Motion capture", "transform coding", "data compression", "optimization", "Motion capture", "transform coding", "data compression", "optimization", "Algorithms", "Computer Graphics", "Data Compression", "Humans", "Image Processing, Computer-Assisted", "Locomotion", "Signal Processing, Computer-Assisted", "Video Recording"], "referenced_by": ["IKEY:7820905", "IKEY:7446149", "IKEY:7868540", "IKEY:7823627", "IKEY:8088120", "IKEY:7368899", "IKEY:7763809", "IKEY:7822921", "IKEY:8661027", "IKEY:8949735", "IKEY:9075997", "IKEY:8945224", "10.1007/s00371-016-1308-y", "10.1007/s11042-016-3944-7", "10.1007/s11390-017-1742-y", "10.1016/j.autcon.2017.01.020", "10.1016/j.cagd.2016.02.002", "10.1111/cgf.13089", "10.1017/ATSIP.2018.15", "10.1016/j.image.2019.115659", "10.1007/s00371-020-01840-6", "10.1002/9781119527886.refs"], "referencing": ["IKEY:4015393", "IKEY:5593220", "IKEY:6517176", "IKEY:5447070", "IKEY:566806", "IKEY:5733417", "IKEY:6708414", "IKEY:6226420", "IKEY:4015393", "IKEY:5593220", "IKEY:6517176", "IKEY:5447070", "IKEY:566806", "IKEY:5733417", "IKEY:6708414", "IKEY:6226420", "IKEY:4015393", "IKEY:5593220", "IKEY:6517176", "IKEY:5447070", "IKEY:566806", "IKEY:5733417", "IKEY:6708414", "IKEY:6226420", "10.1145/1268517.1268568", "10.1145/1141911.1141971", "10.1145/1229390.1229425", "10.1145/1073204.1073247", "10.1145/2448196.2448199", "10.1145/1268517.1268568", "10.1145/1141911.1141971", "10.1145/1229390.1229425", "10.1145/1073204.1073247", "10.1145/2448196.2448199", "10.1145/1268517.1268568", "10.1145/1141911.1141971", "10.1145/1229390.1229425", "10.1145/1073204.1073247", "10.1145/2448196.2448199", "10.1111/j.1467-8659.2009.01375.x", "10.1111/j.1467-8659.2008.01309.x", "10.1002/nla.743", "10.1111/j.1467-8659.2009.01375.x", "10.1111/j.1467-8659.2008.01309.x", "10.1002/nla.743", "10.1111/j.1467-8659.2009.01375.x", "10.1111/j.1467-8659.2008.01309.x", "10.1002/nla.743"]}, "10.1109/TVCG.2015.2396063": {"doi": "10.1109/TVCG.2015.2396063", "author": ["I. Lin", "Y. Lan", "P. Cheng"], "title": "SI-Cut: Structural Inconsistency Analysis for Image Foreground Extraction", "year": "2015", "abstract": "This paper presents a novel approach for extracting foreground objects from an image. Existing methods involve separating the foreground and background mainly according to their color distributions and neighbor similarities. This paper proposes using a more discriminative strategy, structural inconsistency analysis, in which the localities of color and texture are considered. Given an indicated rectangle, the proposed system iteratively maximizes the consensus regions between the original image and predicted structures from the known background. The object contour can then be extracted according to inconsistency in the predicted background and foreground structures. The proposed method includes an efficient image completion technique for structural prediction. The results of experiments showed that the extraction accuracy of the proposed method is higher than that of related methods for structural scenes, and is also comparable to that of related methods for less structural situations.", "keywords": ["feature extraction", "image colour analysis", "image processing", "image texture", "object detection", "SI-Cut", "structural inconsistency analysis", "image foreground extraction", "foreground object extraction", "color distributions", "neighbor similarities", "discriminative strategy", "color localities", "texture localities", "indicated rectangle", "consensus regions", "object contour", "foreground structures", "predicted background", "image completion technique", "structural prediction", "Image color analysis", "Vectors", "Image segmentation", "Silicon", "Data mining", "Visualization", "Optimization", "segmentation", "picture/image generation", "scene analysis", "Segmentation", "picture/image generation", "scene analysis"], "referenced_by": ["10.1111/cgf.13261", "10.1007/978-3-030-26756-8_2"], "referencing": ["IKEY:1640859", "IKEY:6275444", "IKEY:6064952", "IKEY:6112774", "IKEY:5995344", "IKEY:1262177", "IKEY:1316848", "IKEY:1640859", "IKEY:6275444", "IKEY:6064952", "IKEY:6112774", "IKEY:5995344", "IKEY:1262177", "IKEY:1316848", "IKEY:1640859", "IKEY:6275444", "IKEY:6064952", "IKEY:6112774", "IKEY:5995344", "IKEY:1262177", "IKEY:1316848", "10.1145/1015706.1015720", "10.1145/1015706.1015719", "10.1145/344779.344972", "10.1145/2185520.2185578", "10.1145/1015706.1015720", "10.1145/1015706.1015719", "10.1145/344779.344972", "10.1145/2185520.2185578", "10.1145/1015706.1015720", "10.1145/1015706.1015719", "10.1145/344779.344972", "10.1145/2185520.2185578", "10.1016/j.patcog.2012.12.005", "10.1007/s11263-007-0090-8", "10.1016/j.patcog.2012.12.005", "10.1007/s11263-007-0090-8", "10.1016/j.patcog.2012.12.005", "10.1007/s11263-007-0090-8"]}, "10.1109/TVCG.2015.2398432": {"doi": "10.1109/TVCG.2015.2398432", "author": ["H. Zhang", "C. Wu", "J. Zhang", "J. Deng"], "title": "Variational Mesh Denoising Using Total Variation and Piecewise Constant Function Space", "year": "2015", "abstract": "Mesh surface denoising is a fundamental problem in geometry processing. The main challenge is to remove noise while preserving sharp features (such as edges and corners) and preventing generating false edges. We propose in this paper to combine total variation (TV) and piecewise constant function space for variational mesh denoising. We first give definitions of piecewise constant function spaces and associated operators. A variational mesh denoising method will then be presented by combining TV and piecewise constant function space. It is proved that, the solution of the variational problem (the key part of the method) is in some sense continuously dependent on its parameter, indicating that the solution is robust to small perturbations of this parameter. To solve the variational problem, we propose an efficient iterative algorithm (with an additional algorithmic parameter) based on variable splitting and augmented Lagrangian method, each step of which has closed form solution. Our denoising method is discussed and compared to several typical existing methods in various aspects. Experimental results show that our method outperforms all the compared methods for both CAD and non-CAD meshes at reasonable costs. It can preserve different levels of features well, and prevent generating false edges in most cases, even with the parameters evaluated by our estimation formulae.", "keywords": ["computational geometry", "edge detection", "feature extraction", "image denoising", "iterative methods", "mesh generation", "triangulated surfaces", "computer graphics", "augmented Lagrangian method", "variable splitting method", "algorithmic parameter", "iterative algorithm", "false edge generation prevention", "sharp feature preservation", "noise removal", "geometry processing", "piecewise constant function space", "total variation", "variational mesh denoising method", "Noise reduction", "Face", "TV", "Image edge detection", "Noise", "Noise measurement", "Iterative methods", "Mesh denoising", "piecewise constant function space", "total variation", "sharp feature", "Mesh denoising", "piecewise constant function space", "total variation", "sharp feature"], "referenced_by": ["IKEY:7335468", "IKEY:7425812", "IKEY:7387551", "IKEY:7467494", "IKEY:7328329", "IKEY:8249109", "IKEY:7956272", "IKEY:8012522", "IKEY:8553335", "IKEY:8283576", "IKEY:8327892", "IKEY:8434353", "IKEY:8824104", "IKEY:8972221", "IKEY:9037248", "IKEY:9063501", "IKEY:9200581", "IKEY:9187871", "IKEY:9110709", "10.1145/2816795.2818068", "10.1002/cav.1750", "10.1007/978-3-319-66272-5_17", "10.1007/s00371-017-1418-1", "10.1007/s00371-017-1434-1", "10.1007/s10915-016-0260-3", "10.1016/j.cagd.2017.02.005", "10.1016/j.cagd.2017.02.011", "10.1016/j.gmod.2015.06.012", "10.1016/j.optlaseng.2016.09.003", "10.1111/cgf.12743", "10.1111/cgf.13013", "10.3934/ipi.2017037", "10.1007/978-3-319-91143-4_2", "10.1299/jamdsm.2018jamdsm0084", "10.1111/cgf.13556", "10.1111/cgf.13549", "10.1016/j.gmod.2018.12.002", "10.1137/17M115743X", "10.3390/s19051001", "10.1016/j.cagd.2019.04.013", "10.1016/j.cad.2019.05.036", "10.1111/cgf.13863", "10.1002/pamm.201900189", "10.1007/s11263-019-01268-z", "10.1016/j.cad.2020.102858", "10.1016/j.cad.2020.102861", "10.1088/1361-6420/ab6d5c", "10.1016/j.gmod.2020.101065", "10.1016/j.cad.2020.102857"], "referencing": ["IKEY:541429", "IKEY:661180", "IKEY:1631193", "IKEY:1331446", "IKEY:4276075", "IKEY:1272725", "IKEY:5674028", "IKEY:1027503", "IKEY:541429", "IKEY:661180", "IKEY:1631193", "IKEY:1331446", "IKEY:4276075", "IKEY:1272725", "IKEY:5674028", "IKEY:1027503", "IKEY:541429", "IKEY:661180", "IKEY:1631193", "IKEY:1331446", "IKEY:4276075", "IKEY:1272725", "IKEY:5674028", "IKEY:1027503", "10.1145/2461912.2461965", "10.1145/311535.311576", "10.1145/588272.588276", "10.1145/2167076.2167079", "10.1145/218380.218473", "10.1145/882262.882368", "10.1145/882262.882367", "10.1145/1073204.1073226", "10.1145/1122501.1122504", "10.1145/2557449", "10.1145/2461912.2461965", "10.1145/311535.311576", "10.1145/588272.588276", "10.1145/2167076.2167079", "10.1145/218380.218473", "10.1145/882262.882368", "10.1145/882262.882367", "10.1145/1073204.1073226", "10.1145/1122501.1122504", "10.1145/2557449", "10.1145/2461912.2461965", "10.1145/311535.311576", "10.1145/588272.588276", "10.1145/2167076.2167079", "10.1145/218380.218473", "10.1145/882262.882368", "10.1145/882262.882367", "10.1145/1073204.1073226", "10.1145/1122501.1122504", "10.1145/2557449", "10.1016/0167-2789(92)90242-F", "10.1007/s002110050258", "10.1007/BF02684327", "10.1137/S1064827598344169", "10.1137/090769521", "10.1137/080736612", "10.1007/s10915-011-9477-3", "10.1137/S1064827596299767", "10.1137/080724265", "10.1137/080725891", "10.1137/080716542", "10.1137/090767558", "10.1137/080722758", "10.1002/cnm.1630040603", "10.1111/j.1467-8659.2004.00770.x", "10.1016/S0010-4485(01)00095-1", "10.1137/1.9781611970838", "10.1016/0167-2789(92)90242-F", "10.1007/s002110050258", "10.1007/BF02684327", "10.1137/S1064827598344169", "10.1137/090769521", "10.1137/080736612", "10.1007/s10915-011-9477-3", "10.1137/S1064827596299767", "10.1137/080724265", "10.1137/080725891", "10.1137/080716542", "10.1137/090767558", "10.1137/080722758", "10.1002/cnm.1630040603", "10.1111/j.1467-8659.2004.00770.x", "10.1016/S0010-4485(01)00095-1", "10.1137/1.9781611970838", "10.1016/0167-2789(92)90242-F", "10.1007/s002110050258", "10.1007/BF02684327", "10.1137/S1064827598344169", "10.1137/090769521", "10.1137/080736612", "10.1007/s10915-011-9477-3", "10.1137/S1064827596299767", "10.1137/080724265", "10.1137/080725891", "10.1137/080716542", "10.1137/090767558", "10.1137/080722758", "10.1002/cnm.1630040603", "10.1111/j.1467-8659.2004.00770.x", "10.1016/S0010-4485(01)00095-1", "10.1137/1.9781611970838"]}}