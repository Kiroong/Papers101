{"10.1109/TVCG.2017.2677445": {"doi": "10.1109/TVCG.2017.2677445", "author": ["A. Morgand", "M. Tamaazousti", "A. Bartoli"], "title": "A Geometric Model for Specularity Prediction on Planar Surfaces with Multiple Light Sources", "year": "2018", "abstract": "Specularities are often problematic in computer vision since they impact the dynamic range of the image intensity. A natural approach would be to predict and discard them using computer graphics models. However, these models depend on parameters which are difficult to estimate (light sources, objects' material properties and camera). We present a geometric model called JOLIMAS: JOint LIght-MAterial Specularity, which predicts the shape of specularities. JOLIMAS is reconstructed from images of specularities observed on a planar surface. It implicitly includes light and material properties, which are intrinsic to specularities. This model was motivated by the observation that specularities have a conic shape on planar surfaces. The conic shape is obtained by projecting a fixed quadric on the planar surface. JOLIMAS thus predicts the specularity using a simple geometric approach with static parameters (object material and light source shape). It is adapted to indoor light sources such as light bulbs and fluorescent lamps. The prediction has been tested on synthetic and real sequences. It works in a multi-light context by reconstructing a quadric for each light source with special cases such as lights being switched on or off. We also used specularity prediction for dynamic retexturing and obtained convincing rendering results. Further results are presented as supplementary video material, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TVCG.2017.2677445.", "keywords": ["Gaussian processes", "image colour analysis", "image enhancement", "image representation", "image resolution", "image texture", "nonlinear filters", "nonlinear functions", "rendering (computer graphics)", "light source", "specularity prediction", "geometric model", "planar surface", "multiple light sources", "computer graphics models", "JOLIMAS", "JOint LIght-MAterial Specularity", "conic shape", "object material", "indoor light sources", "light bulbs", "multilight context", "planar surfaces", "Light sources", "Image reconstruction", "Shape", "Computational modeling", "Surface reconstruction", "Predictive models", "Cameras", "JOLIMAS", "specular reflection", "multiple light sources", "phong", "blinn-phong", "specularity", "prediction", "retexturing", "quadric", "dual space", "conic", "real time"], "referenced_by": ["IKEY:8007318", "IKEY:8457312"], "referencing": ["IKEY:764865", "IKEY:6212513", "IKEY:6212513", "IKEY:5979857", "IKEY:6948406", "IKEY:6802044", "IKEY:6948406", "IKEY:1698961", "IKEY:5995358", "IKEY:7180400", "IKEY:6714519", "IKEY:590016", "IKEY:764865", "IKEY:6212513", "IKEY:6212513", "IKEY:5979857", "IKEY:6948406", "IKEY:6802044", "IKEY:6948406", "IKEY:1698961", "IKEY:5995358", "IKEY:7180400", "IKEY:6714519", "IKEY:590016", "IKEY:764865", "IKEY:6212513", "IKEY:6212513", "IKEY:5979857", "IKEY:6948406", "IKEY:6802044", "IKEY:6948406", "IKEY:1698961", "IKEY:5995358", "IKEY:7180400", "IKEY:6714519", "IKEY:590016", "10.1145/1012551.1012571", "10.1145/1409060.1409083", "10.1145/1401132.1401137", "10.1145/360825.360839", "10.1145/965141.563893", "10.1145/192161.192286", "10.1145/357290.357293", "10.1145/2897824.2925895", "10.1145/1012551.1012571", "10.1145/1409060.1409083", "10.1145/1401132.1401137", "10.1145/360825.360839", "10.1145/965141.563893", "10.1145/192161.192286", "10.1145/357290.357293", "10.1145/2897824.2925895", "10.1145/1012551.1012571", "10.1145/1409060.1409083", "10.1145/1401132.1401137", "10.1145/360825.360839", "10.1145/965141.563893", "10.1145/192161.192286", "10.1145/357290.357293", "10.1145/2897824.2925895", "10.1167/4.9.10", "10.5244/C.25.45", "10.1038/343165a0", "10.1017/CBO9780511811685", "10.1007/978-3-319-14249-4_55", "10.1007/978-3-540-88682-2_48", "10.5244/C.29.43", "10.5244/C.27.105", "10.1007/s00791-013-0214-3", "10.1007/978-3-540-76390-1_77", "10.1016/j.imavis.2005.03.008", "10.1016/0734-189X(85)90016-7", "10.2307/3315017", "10.1167/4.9.10", "10.5244/C.25.45", "10.1038/343165a0", "10.1017/CBO9780511811685", "10.1007/978-3-319-14249-4_55", "10.1007/978-3-540-88682-2_48", "10.5244/C.29.43", "10.5244/C.27.105", "10.1007/s00791-013-0214-3", "10.1007/978-3-540-76390-1_77", "10.1016/j.imavis.2005.03.008", "10.1016/0734-189X(85)90016-7", "10.2307/3315017", "10.1167/4.9.10", "10.5244/C.25.45", "10.1038/343165a0", "10.1017/CBO9780511811685", "10.1007/978-3-319-14249-4_55", "10.1007/978-3-540-88682-2_48", "10.5244/C.29.43", "10.5244/C.27.105", "10.1007/s00791-013-0214-3", "10.1007/978-3-540-76390-1_77", "10.1016/j.imavis.2005.03.008", "10.1016/0734-189X(85)90016-7", "10.2307/3315017"]}, "10.1109/TVCG.2017.2695182": {"doi": "10.1109/TVCG.2017.2695182", "author": ["K. C. Kwan", "X. Xu", "L. Wan", "T. Wong", "W. Pang"], "title": "Packing Vertex Data into Hardware-Decompressible Textures", "year": "2018", "abstract": "Most graphics hardware features memory to store textures and vertex data for rendering. However, because of the irreversible trend of increasing complexity of scenes, rendering a scene can easily reach the limit of memory resources. Thus, vertex data are preferably compressed, with a requirement that they can be decompressed during rendering. In this paper, we present a novel method to exploit existing hardware texture compression circuits to facilitate the decompression of vertex data in graphics processing unit (GPUs). This built-in hardware allows real-time, random-order decoding of data. However, vertex data must be packed into textures, and careless packing arrangements can easily disrupt data coherence. Hence, we propose an optimization approach for the best vertex data permutation that minimizes compression error. All of these result in fast and high-quality vertex data decompression for real-time rendering. To further improve the visual quality, we introduce vertex clustering to reduce the dynamic range of data during quantization. Our experiments demonstrate the effectiveness of our method for various vertex data of 3D models during rendering with the advantages of a minimized memory footprint and high frame rate.", "keywords": ["data compression", "graphics processing units", "image coding", "image texture", "optimisation", "pattern clustering", "rendering (computer graphics)", "solid modelling", "high-quality vertex data decompression", "hardware-decompressible textures", "vertex data permutation", "vertex data packing", "graphics hardware", "hardware texture compression circuits", "graphics processing unit", "real-time rendering", "optimization approach", "visual quality", "vertex clustering", "3D models", "Graphics processing units", "Hardware", "Rendering (computer graphics)", "Three-dimensional displays", "Real-time systems", "Decoding", "Games", "Vertex data compression", "real-time rendering", "hardware texture compression", "permutation", "GPU acceleration"], "referenced_by": [], "referencing": ["IKEY:841122", "IKEY:663902", "IKEY:6464265", "IKEY:6515117", "IKEY:5383356", "IKEY:745312", "IKEY:809869", "IKEY:841122", "IKEY:663902", "IKEY:6464265", "IKEY:6515117", "IKEY:5383356", "IKEY:745312", "IKEY:809869", "IKEY:841122", "IKEY:663902", "IKEY:6464265", "IKEY:6515117", "IKEY:5383356", "IKEY:745312", "IKEY:809869", "10.1145/1071866.1071876", "10.1145/344779.344922", "10.1145/383259.383281", "10.1145/218380.218391", "10.1145/364338.364384", "10.1145/566570.566589", "10.1145/1201775.882274", "10.1145/2466533.2466541", "10.1145/344779.344924", "10.1145/2338714.2338716", "10.1145/2693443", "10.1145/1073204.1073278", "10.1145/300523.300533", "10.1145/1230100.1230102", "10.1145/353981.353995", "10.1145/1071866.1071876", "10.1145/344779.344922", "10.1145/383259.383281", "10.1145/218380.218391", "10.1145/364338.364384", "10.1145/566570.566589", "10.1145/1201775.882274", "10.1145/2466533.2466541", "10.1145/344779.344924", "10.1145/2338714.2338716", "10.1145/2693443", "10.1145/1073204.1073278", "10.1145/300523.300533", "10.1145/1230100.1230102", "10.1145/353981.353995", "10.1145/1071866.1071876", "10.1145/344779.344922", "10.1145/383259.383281", "10.1145/218380.218391", "10.1145/364338.364384", "10.1145/566570.566589", "10.1145/1201775.882274", "10.1145/2466533.2466541", "10.1145/344779.344924", "10.1145/2338714.2338716", "10.1145/2693443", "10.1145/1073204.1073278", "10.1145/300523.300533", "10.1145/1230100.1230102", "10.1145/353981.353995", "10.1111/j.1467-8659.2010.01737.x", "10.1002/cav.319", "10.5626/JCSE.2010.4.3.207", "10.1126/science.220.4598.671", "10.1111/cgf.12001", "10.1111/j.1467-8659.2010.01737.x", "10.1002/cav.319", "10.5626/JCSE.2010.4.3.207", "10.1126/science.220.4598.671", "10.1111/cgf.12001", "10.1111/j.1467-8659.2010.01737.x", "10.1002/cav.319", "10.5626/JCSE.2010.4.3.207", "10.1126/science.220.4598.671", "10.1111/cgf.12001"]}, "10.1109/TVCG.2017.2661308": {"doi": "10.1109/TVCG.2017.2661308", "author": ["E. Quigley", "Y. Yu", "J. Huang", "W. Lin", "R. Fedkiw"], "title": "Real-Time Interactive Tree Animation", "year": "2018", "abstract": "We present a novel method for posing and animating botanical tree models interactively in real time. Unlike other state of the art methods which tend to produce trees that are overly flexible, bending and deforming as if they were underwater plants, our approach allows for arbitrarily high stiffness while still maintaining real-time frame rates without spurious artifacts, even on quite large trees with over ten thousand branches. This is accomplished by using an articulated rigid body model with as-stiff-as-desired rotational springs in conjunction with our newly proposed simulation technique, which is motivated both by position based dynamics and the typical O(N) algorithms for articulated rigid bodies. The efficiency of our algorithm allows us to pose and animate trees with millions of branches or alternatively simulate a small forest comprised of many highly detailed trees. Even using only a single CPU core, we can simulate ten thousand branches in real time while still maintaining quite crisp user interactivity. This has allowed us to incorporate our framework into a commodity game engine to run interactively even on a low-budget tablet. We show that our method is amenable to the incorporation of a large variety of desirable effects such as wind, leaves, fictitious forces, collisions, fracture, etc.", "keywords": ["biology computing", "botany", "computational complexity", "computer animation", "digital simulation", "interactive systems", "solid modelling", "vegetation", "position based dynamics", "typical O(N) algorithms", "articulated rigid bodies", "botanical tree models", "underwater plants", "arbitrarily high stiffness", "real-time frame rates", "articulated rigid body model", "as-stiff-as-desired rotational springs", "real-time interactive tree animation", "trees animation", "Vegetation", "Heuristic algorithms", "Real-time systems", "Springs", "Mathematical model", "Computational modeling", "Deformable models", "Computer graphics", "physically-based modeling", "botanical tree"], "referenced_by": [], "referencing": ["IKEY:1608023", "IKEY:5557867", "IKEY:7368927", "IKEY:1608023", "IKEY:5557867", "IKEY:7368927", "IKEY:1608023", "IKEY:5557867", "IKEY:7368927", "10.1145/1141911.1142012", "10.1145/1576246.1531368", "10.1145/1073204.1073300", "10.1145/1964921.1964986", "10.1145/237170.237226", "10.1145/2508462", "10.1145/218380.218427", "10.1145/2185520.2185546", "10.1145/1882261.1866177", "10.1145/2024156.2024161", "10.1145/1276377.1276487", "10.1145/1457515.1409061", "10.1145/2461912.2461952", "10.1145/1457515.1409062", "10.1145/2661229.2661252", "10.1145/2461912.2461961", "10.1145/323663.323685", "10.1145/1964921.1964987", "10.1145/882262.882358", "10.1145/127719.122719", "10.1145/2766919", "10.1145/37402.37427", "10.1145/280814.280821", "10.1145/311535.311548", "10.1145/344779.344801", "10.1145/566654.566645", "10.1145/2601097.2601152", "10.1145/1073204.1073294", "10.1145/1276377.1276486", "10.1145/1141911.1142012", "10.1145/1576246.1531368", "10.1145/1073204.1073300", "10.1145/1964921.1964986", "10.1145/237170.237226", "10.1145/2508462", "10.1145/218380.218427", "10.1145/2185520.2185546", "10.1145/1882261.1866177", "10.1145/2024156.2024161", "10.1145/1276377.1276487", "10.1145/1457515.1409061", "10.1145/2461912.2461952", "10.1145/1457515.1409062", "10.1145/2661229.2661252", "10.1145/2461912.2461961", "10.1145/323663.323685", "10.1145/1964921.1964987", "10.1145/882262.882358", "10.1145/127719.122719", "10.1145/2766919", "10.1145/37402.37427", "10.1145/280814.280821", "10.1145/311535.311548", "10.1145/344779.344801", "10.1145/566654.566645", "10.1145/2601097.2601152", "10.1145/1073204.1073294", "10.1145/1276377.1276486", "10.1145/1141911.1142012", "10.1145/1576246.1531368", "10.1145/1073204.1073300", "10.1145/1964921.1964986", "10.1145/237170.237226", "10.1145/2508462", "10.1145/218380.218427", "10.1145/2185520.2185546", "10.1145/1882261.1866177", "10.1145/2024156.2024161", "10.1145/1276377.1276487", "10.1145/1457515.1409061", "10.1145/2461912.2461952", "10.1145/1457515.1409062", "10.1145/2661229.2661252", "10.1145/2461912.2461961", "10.1145/323663.323685", "10.1145/1964921.1964987", "10.1145/882262.882358", "10.1145/127719.122719", "10.1145/2766919", "10.1145/37402.37427", "10.1145/280814.280821", "10.1145/311535.311548", "10.1145/344779.344801", "10.1145/566654.566645", "10.1145/2601097.2601152", "10.1145/1073204.1073294", "10.1145/1276377.1276486", "10.1016/j.jvcir.2007.01.005", "10.1007/978-0-387-74315-8", "10.1111/1467-8659.00594", "10.1111/j.1467-8659.2009.01381.x", "10.1006/jcph.1998.6008", "10.1007/978-3-642-59126-6_9", "10.1016/j.cag.2006.03.017", "10.1631/jzus.A0720035", "10.1111/1467-8659.1130119", "10.1111/j.1467-8659.2009.01391.x", "10.1111/j.1467-8659.2009.01393.x", "10.1007/978-3-642-22639-7_4", "10.1111/1467-8659.00152", "10.1007/978-4-431-55483-7_5", "10.1002/cav.1451", "10.1111/cgf.12009", "10.3390/s110908536", "10.1063/1.3541844", "10.1017/jfm.2012.602", "10.1103/PhysRevLett.73.1372", "10.1103/PhysRevLett.75.1420", "10.1103/PhysRevLett.75.1421", "10.1103/PhysRevLett.81.345", "10.1017/S002211200500594X", "10.1007/s41095-015-0025-1", "10.1016/j.jvcir.2007.01.005", "10.1007/978-0-387-74315-8", "10.1111/1467-8659.00594", "10.1111/j.1467-8659.2009.01381.x", "10.1006/jcph.1998.6008", "10.1007/978-3-642-59126-6_9", "10.1016/j.cag.2006.03.017", "10.1631/jzus.A0720035", "10.1111/1467-8659.1130119", "10.1111/j.1467-8659.2009.01391.x", "10.1111/j.1467-8659.2009.01393.x", "10.1007/978-3-642-22639-7_4", "10.1111/1467-8659.00152", "10.1007/978-4-431-55483-7_5", "10.1002/cav.1451", "10.1111/cgf.12009", "10.3390/s110908536", "10.1063/1.3541844", "10.1017/jfm.2012.602", "10.1103/PhysRevLett.73.1372", "10.1103/PhysRevLett.75.1420", "10.1103/PhysRevLett.75.1421", "10.1103/PhysRevLett.81.345", "10.1017/S002211200500594X", "10.1007/s41095-015-0025-1", "10.1016/j.jvcir.2007.01.005", "10.1007/978-0-387-74315-8", "10.1111/1467-8659.00594", "10.1111/j.1467-8659.2009.01381.x", "10.1006/jcph.1998.6008", "10.1007/978-3-642-59126-6_9", "10.1016/j.cag.2006.03.017", "10.1631/jzus.A0720035", "10.1111/1467-8659.1130119", "10.1111/j.1467-8659.2009.01391.x", "10.1111/j.1467-8659.2009.01393.x", "10.1007/978-3-642-22639-7_4", "10.1111/1467-8659.00152", "10.1007/978-4-431-55483-7_5", "10.1002/cav.1451", "10.1111/cgf.12009", "10.3390/s110908536", "10.1063/1.3541844", "10.1017/jfm.2012.602", "10.1103/PhysRevLett.73.1372", "10.1103/PhysRevLett.75.1420", "10.1103/PhysRevLett.75.1421", "10.1103/PhysRevLett.81.345", "10.1017/S002211200500594X", "10.1007/s41095-015-0025-1"]}, "10.1109/TVCG.2017.2682865": {"doi": "10.1109/TVCG.2017.2682865", "author": ["D. G. Harrison", "N. D. Efford", "Q. J. Fisher", "R. A. Ruddle"], "title": "PETMiner\u2014A Visual Analysis Tool for Petrophysical Properties of Core Sample Data", "year": "2018", "abstract": "The aim of the PETMiner software is to reduce the time and monetary cost of analysing petrophysical data that is obtained from reservoir sample cores. Analysis of these data requires tacit knowledge to fill `gaps' so that predictions can be made for incomplete data. Through discussions with 30 industry and academic specialists, we identified three analysis use cases that exemplified the limitations of current petrophysics analysis tools. We used those use cases to develop nine core requirements for PETMiner, which is innovative because of its ability to display detailed images of the samples as data points, directly plot multiple sample properties and derived measures for comparison, and substantially reduce interaction cost. An 11-month evaluation demonstrated benefits across all three use cases by allowing a consultant to: (1) generate more accurate reservoir flow models, (2) discover a previously unknown relationship between one easy-to-measure property and another that is costly, and (3) make a 100-fold reduction in the time required to produce plots for a report.", "keywords": ["data analysis", "data visualisation", "geophysical prospecting", "geophysics computing", "petrology", "academic specialists", "current petrophysics analysis tools", "core requirements", "detailed images", "data points", "interaction cost", "11-month evaluation", "accurate reservoir flow models", "easy-to-measure property", "visual analysis tool", "petrophysical properties", "core sample data", "PETMiner software", "monetary cost", "petrophysical data", "reservoir sample cores", "tacit knowledge", "incomplete data", "100-fold reduction", "Mathematical model", "Reservoirs", "Data visualization", "Rocks", "Data analysis", "Permeability", "Visualization", "Visualization systems and software", "information visualization", "design study"], "referenced_by": ["IKEY:8823763"], "referencing": ["IKEY:6327248", "IKEY:6634168", "IKEY:4658124", "IKEY:981851", "IKEY:5290704", "IKEY:7192728", "IKEY:4376133", "IKEY:6634108", "IKEY:6420960", "IKEY:6664351", "IKEY:6875958", "IKEY:5613488", "IKEY:5190809", "IKEY:6064952", "IKEY:5613487", "IKEY:7552504", "IKEY:6327248", "IKEY:6634168", "IKEY:4658124", "IKEY:981851", "IKEY:5290704", "IKEY:7192728", "IKEY:4376133", "IKEY:6634108", "IKEY:6420960", "IKEY:6664351", "IKEY:6875958", "IKEY:5613488", "IKEY:5190809", "IKEY:6064952", "IKEY:5613487", "IKEY:7552504", "IKEY:6327248", "IKEY:6634168", "IKEY:4658124", "IKEY:981851", "IKEY:5290704", "IKEY:7192728", "IKEY:4376133", "IKEY:6634108", "IKEY:6420960", "IKEY:6664351", "IKEY:6875958", "IKEY:5613488", "IKEY:5190809", "IKEY:6064952", "IKEY:5613487", "IKEY:7552504", "10.1145/2858036.2858194", "10.1145/1240624.1240639", "10.1145/365024.365073", "10.1145/258734.258887", "10.1145/2858036.2858194", "10.1145/1240624.1240639", "10.1145/365024.365073", "10.1145/258734.258887", "10.1145/2858036.2858194", "10.1145/1240624.1240639", "10.1145/365024.365073", "10.1145/258734.258887", "10.1137/0906011", "10.1177/1473871612460526", "10.1080/00140137808931762", "10.1186/1471-2105-16-S11-S9", "10.1016/j.scitotenv.2011.06.022", "10.1177/1473871613500978", "10.1111/j.1600-0587.2012.07815.x", "10.2118/15643-PA", "10.2118/942054-G", "10.1137/0906011", "10.1177/1473871612460526", "10.1080/00140137808931762", "10.1186/1471-2105-16-S11-S9", "10.1016/j.scitotenv.2011.06.022", "10.1177/1473871613500978", "10.1111/j.1600-0587.2012.07815.x", "10.2118/15643-PA", "10.2118/942054-G", "10.1137/0906011", "10.1177/1473871612460526", "10.1080/00140137808931762", "10.1186/1471-2105-16-S11-S9", "10.1016/j.scitotenv.2011.06.022", "10.1177/1473871613500978", "10.1111/j.1600-0587.2012.07815.x", "10.2118/15643-PA", "10.2118/942054-G"]}, "10.1109/TVCG.2017.2690433": {"doi": "10.1109/TVCG.2017.2690433", "author": ["F. Lamberti", "G. Paravati", "V. Gatteschi", "A. Cannav\u00f2", "P. Montuschi"], "title": "Virtual Character Animation Based on Affordable Motion Capture and Reconfigurable Tangible Interfaces", "year": "2018", "abstract": "Software for computer animation is generally characterized by a steep learning curve, due to the entanglement of both sophisticated techniques and interaction methods required to control 3D geometries. This paper proposes a tool designed to support computer animation production processes by leveraging the affordances offered by articulated tangible user interfaces and motion capture retargeting solutions. To this aim, orientations of an instrumented prop are recorded together with animator's motion in the 3D space and used to quickly pose characters in the virtual environment. High-level functionalities of the animation software are made accessible via a speech interface, thus letting the user control the animation pipeline via voice commands while focusing on his or her hands and body motion. The proposed solution exploits both off-the-shelf hardware components (like the Lego Mindstorms EV3 bricks and the Microsoft Kinect, used for building the tangible device and tracking animator's skeleton) and free open-source software (like the Blender animation tool), thus representing an interesting solution also for beginners approaching the world of digital animation for the first time. Experimental results in different usage scenarios show the benefits offered by the designed interaction strategy with respect to a mouse & keyboard-based interface both for expert and non-expert users.", "keywords": ["computer animation", "human computer interaction", "public domain software", "user interfaces", "animation pipeline", "body motion", "tangible device", "open-source software", "digital animation", "virtual character animation", "steep learning curve", "interaction methods", "computer animation production processes", "articulated tangible user interfaces", "motion capture retargeting solutions", "virtual environment", "high-level functionalities", "animation software", "speech interface", "hands motion", "interaction strategy", "Animation", "Tracking", "Three-dimensional displays", "Instruments", "Production", "User interfaces", "Mice", "Tangible user interfaces", "natural user interfaces", "motion capture", "human-machine interaction", "computer animation"], "referenced_by": ["IKEY:8623765", "IKEY:8824088", "IKEY:8862448", "IKEY:9063224"], "referencing": ["IKEY:7325194", "IKEY:637269", "IKEY:1512021", "IKEY:5728806", "IKEY:7325194", "IKEY:637269", "IKEY:1512021", "IKEY:5728806", "IKEY:7325194", "IKEY:637269", "IKEY:1512021", "IKEY:5728806", "10.1145/2380116.2380171", "10.1145/882262.882285", "10.1145/1978942.1979034", "10.1145/2166966.2167049", "10.1145/2601097.2601112", "10.1145/2897824.2925909", "10.1145/502122.502123", "10.1145/344779.344876", "10.1145/258549.258715", "10.1145/2380116.2380170", "10.1145/1179622.1179638", "10.1145/2534329.2534360", "10.1145/1531326.1531367", "10.1145/2071423.2071505", "10.1145/2948910.2948939", "10.1145/1276377.1276467", "10.1145/2485895.2485903", "10.1145/1409060.1409077", "10.1145/1073368.1073383", "10.1145/1070838.1070840", "10.1145/2047196.2047241", "10.1145/199404.199424", "10.1145/2019406.2019427", "10.1145/1146816.1146830", "10.1145/223904.223943", "10.1145/985692.985774", "10.1145/2380116.2380171", "10.1145/882262.882285", "10.1145/1978942.1979034", "10.1145/2166966.2167049", "10.1145/2601097.2601112", "10.1145/2897824.2925909", "10.1145/502122.502123", "10.1145/344779.344876", "10.1145/258549.258715", "10.1145/2380116.2380170", "10.1145/1179622.1179638", "10.1145/2534329.2534360", "10.1145/1531326.1531367", "10.1145/2071423.2071505", "10.1145/2948910.2948939", "10.1145/1276377.1276467", "10.1145/2485895.2485903", "10.1145/1409060.1409077", "10.1145/1073368.1073383", "10.1145/1070838.1070840", "10.1145/2047196.2047241", "10.1145/199404.199424", "10.1145/2019406.2019427", "10.1145/1146816.1146830", "10.1145/223904.223943", "10.1145/985692.985774", "10.1145/2380116.2380171", "10.1145/882262.882285", "10.1145/1978942.1979034", "10.1145/2166966.2167049", "10.1145/2601097.2601112", "10.1145/2897824.2925909", "10.1145/502122.502123", "10.1145/344779.344876", "10.1145/258549.258715", "10.1145/2380116.2380170", "10.1145/1179622.1179638", "10.1145/2534329.2534360", "10.1145/1531326.1531367", "10.1145/2071423.2071505", "10.1145/2948910.2948939", "10.1145/1276377.1276467", "10.1145/2485895.2485903", "10.1145/1409060.1409077", "10.1145/1073368.1073383", "10.1145/1070838.1070840", "10.1145/2047196.2047241", "10.1145/199404.199424", "10.1145/2019406.2019427", "10.1145/1146816.1146830", "10.1145/223904.223943", "10.1145/985692.985774", "10.1007/978-3-319-03731-8_23", "10.1111/cgf.12325", "10.4108/icst.intetain.2015.259265", "10.1007/978-3-319-03892-6_10", "10.5176/978-981-08-8227-3_cgat08-12", "10.1016/j.aml.2007.01.006", "10.1002/nav.3800020109", "10.1007/978-3-319-03731-8_23", "10.1111/cgf.12325", "10.4108/icst.intetain.2015.259265", "10.1007/978-3-319-03892-6_10", "10.5176/978-981-08-8227-3_cgat08-12", "10.1016/j.aml.2007.01.006", "10.1002/nav.3800020109", "10.1007/978-3-319-03731-8_23", "10.1111/cgf.12325", "10.4108/icst.intetain.2015.259265", "10.1007/978-3-319-03892-6_10", "10.5176/978-981-08-8227-3_cgat08-12", "10.1016/j.aml.2007.01.006", "10.1002/nav.3800020109"]}, "10.1109/TVCG.2017.2689022": {"doi": "10.1109/TVCG.2017.2689022", "author": ["G. Cordonnier", "M. Cani", "B. Benes", "J. Braun", "E. Galin"], "title": "Sculpting Mountains: Interactive Terrain Modeling Based on Subsurface Geology", "year": "2018", "abstract": "Most mountain ranges are formed by the compression and folding of colliding tectonic plates. Subduction of one plate causes large-scale asymmetry while their layered composition (or stratigraphy) explains the multi-scale folded strata observed on real terrains. We introduce a novel interactive modeling technique to generate visually plausible, large scale terrains that capture these phenomena. Our method draws on both geological knowledge for consistency and on sculpting systems for user interaction. The user is provided hands-on control on the shape and motion of tectonic plates, represented using a new geologically-inspired model for the Earth crust. The model captures their volume preserving and complex folding behaviors under collision, causing mountains to grow. It generates a volumetric uplift map representing the growth rate of subsurface layers. Erosion and uplift movement are jointly simulated to generate the terrain. The stratigraphy allows us to render folded strata on eroded cliffs. We validated the usability of our sculpting interface through a user study, and compare the visual consistency of the earth crust model with geological simulation results and real terrains.", "keywords": ["data visualisation", "Earth crust", "erosion", "faulting", "geology", "geophysical image processing", "geophysics computing", "rendering (computer graphics)", "solid modelling", "stratigraphy", "virtual reality", "large-scale asymmetry", "layered composition", "scale terrains", "geological knowledge", "user interaction", "hands-on control", "complex folding behaviors", "volumetric uplift map", "subsurface layers", "uplift movement", "sculpting interface", "user study", "visual consistency", "geological simulation results", "sculpting mountains", "interactive terrain", "subsurface geology", "mountain ranges", "plate subduction", "stratigraphy", "colliding tectonic plate compression", "colliding tectonic plate folding", "multiscale folded strata", "tectonic plate motion", "tectonic plate shape", "geologically-inspired model", "Earth crust model", "Geology", "Computational modeling", "Earth", "Solid modeling", "Shape", "Surface treatment", "Three-dimensional displays", "Terrains", "mountains", "interactive design", "geology"], "referenced_by": ["IKEY:8114413", "IKEY:9067677"], "referencing": ["IKEY:4293025", "IKEY:4293025", "IKEY:4293025", "10.1145/378456.378519", "10.1145/74334.74337", "10.1145/122718.122747", "10.1145/2643188.2643201", "10.1145/2461912.2462018", "10.1145/2366145.2366171", "10.1145/1882261.1866183", "10.1145/378456.378519", "10.1145/74334.74337", "10.1145/122718.122747", "10.1145/2643188.2643201", "10.1145/2461912.2462018", "10.1145/2366145.2366171", "10.1145/1882261.1866183", "10.1145/378456.378519", "10.1145/74334.74337", "10.1145/122718.122747", "10.1145/2643188.2643201", "10.1145/2461912.2462018", "10.1145/2366145.2366171", "10.1145/1882261.1866183", "10.1130/0091-7613(1993)021&lt;0371:MMFTTO&gt;2.3.CO;2", "10.1016/j.geomorph.2012.10.008", "10.1016/j.tecto.2009.08.032", "10.1130/0091-7613(1996)024&lt;0699:FDCCRI&gt;2.3.CO;2", "10.1111/cgf.12276", "10.1111/j.1467-8659.2010.01806.x", "10.1111/cgf.12530", "10.1111/cgf.12821", "10.1111/cgf.12545", "10.1002/cav.77", "10.1111/cgf.12820", "10.1016/j.gmod.2004.06.008", "10.1016/j.cag.2013.05.010", "10.1111/cgf.12022", "10.1111/j.1467-8659.2009.01385.x", "10.1016/j.cageo.2016.02.009", "10.1038/ngeo1582", "10.1130/G32136.1", "10.1016/S0012-821X(00)00116-3", "10.1130/0016-7606(1961)72[1595:TOFOSV]2.0.CO;2", "10.3189/172756499781821797", "10.1002/esp.3290070403", "10.1016/0012-821X(94)00093-X", "10.1016/j.tecto.2014.06.013", "10.1029/2006GL026341", "10.1130/0091-7613(1993)021&lt;0371:MMFTTO&gt;2.3.CO;2", "10.1016/j.geomorph.2012.10.008", "10.1016/j.tecto.2009.08.032", "10.1130/0091-7613(1996)024&lt;0699:FDCCRI&gt;2.3.CO;2", "10.1111/cgf.12276", "10.1111/j.1467-8659.2010.01806.x", "10.1111/cgf.12530", "10.1111/cgf.12821", "10.1111/cgf.12545", "10.1002/cav.77", "10.1111/cgf.12820", "10.1016/j.gmod.2004.06.008", "10.1016/j.cag.2013.05.010", "10.1111/cgf.12022", "10.1111/j.1467-8659.2009.01385.x", "10.1016/j.cageo.2016.02.009", "10.1038/ngeo1582", "10.1130/G32136.1", "10.1016/S0012-821X(00)00116-3", "10.1130/0016-7606(1961)72[1595:TOFOSV]2.0.CO;2", "10.3189/172756499781821797", "10.1002/esp.3290070403", "10.1016/0012-821X(94)00093-X", "10.1016/j.tecto.2014.06.013", "10.1029/2006GL026341", "10.1130/0091-7613(1993)021&lt;0371:MMFTTO&gt;2.3.CO;2", "10.1016/j.geomorph.2012.10.008", "10.1016/j.tecto.2009.08.032", "10.1130/0091-7613(1996)024&lt;0699:FDCCRI&gt;2.3.CO;2", "10.1111/cgf.12276", "10.1111/j.1467-8659.2010.01806.x", "10.1111/cgf.12530", "10.1111/cgf.12821", "10.1111/cgf.12545", "10.1002/cav.77", "10.1111/cgf.12820", "10.1016/j.gmod.2004.06.008", "10.1016/j.cag.2013.05.010", "10.1111/cgf.12022", "10.1111/j.1467-8659.2009.01385.x", "10.1016/j.cageo.2016.02.009", "10.1038/ngeo1582", "10.1130/G32136.1", "10.1016/S0012-821X(00)00116-3", "10.1130/0016-7606(1961)72[1595:TOFOSV]2.0.CO;2", "10.3189/172756499781821797", "10.1002/esp.3290070403", "10.1016/0012-821X(94)00093-X", "10.1016/j.tecto.2014.06.013", "10.1029/2006GL026341"]}, "10.1109/TVCG.2017.2688331": {"doi": "10.1109/TVCG.2017.2688331", "author": ["K. Guo", "F. Xu", "Y. Wang", "Y. Liu", "Q. Dai"], "title": "Robust Non-Rigid Motion Tracking and Surface Reconstruction Using $L_0$ Regularization", "year": "2018", "abstract": "We present a new motion tracking technique to robustly reconstruct non-rigid geometries and motions from a single view depth input recorded by a consumer depth sensor. The idea is based on the observation that most non-rigid motions (especially human-related motions) are intrinsically involved in articulate motion subspace. To take this advantage, we propose a novel L0 based motion regularizer with an iterative solver that implicitly constrains local deformations with articulate structures, leading to reduced solution space and physical plausible deformations. The L0 strategy is integrated into the available non-rigid motion tracking pipeline, and gradually extracts articulate joints information online with the tracking, which corrects the tracking errors in the results. The information of the articulate joints is used in the following tracking procedure to further improve the tracking accuracy and prevent tracking failures. Extensive experiments over complex human body motions with occlusions, facial and hand motions demonstrate that our approach substantially improves the robustness and accuracy in motion tracking.", "keywords": ["deformation", "image motion analysis", "image reconstruction", "image sequences", "iterative methods", "motion estimation", "object tracking", "articulate joints information", "nonrigid motion tracking pipeline", "articulate structures", "articulate motion subspace", "human-related motions", "nonrigid motions", "consumer depth sensor", "single view depth input", "motion tracking technique", "surface reconstruction", "robust nonrigid motion tracking", "Tracking", "Skeleton", "Optimization", "Robustness", "Deformable models", "Surface reconstruction", "Geometry", "Performance capture, non-rigid, single-view, L0"], "referenced_by": ["IKEY:8365924", "IKEY:8730349", "IKEY:8730533", "IKEY:9212831", "IKEY:9238703"], "referencing": ["IKEY:5719617", "IKEY:4178157", "IKEY:7265099", "IKEY:7410622", "IKEY:6361384", "IKEY:5719617", "IKEY:4178157", "IKEY:7265099", "IKEY:7410622", "IKEY:6361384", "IKEY:5719617", "IKEY:4178157", "IKEY:7265099", "IKEY:7410622", "IKEY:6361384", "10.1145/1276377.1276467", "10.1145/1964921.1964973", "10.1145/1276377.1276478", "10.1145/2366145.2366207", "10.1145/1360612.1360698", "10.1145/1360612.1360697", "10.1145/1360612.1360696", "10.1145/2897824.2925969", "10.1145/2508363.2508418", "10.1145/1516522.1516526", "10.1145/2508363.2508407", "10.1145/2185520.2185549", "10.1145/1618452.1618521", "10.1145/2601097.2601165", "10.1145/2070781.2024208", "10.1145/1276377.1276467", "10.1145/1964921.1964973", "10.1145/1276377.1276478", "10.1145/2366145.2366207", "10.1145/1360612.1360698", "10.1145/1360612.1360697", "10.1145/1360612.1360696", "10.1145/2897824.2925969", "10.1145/2508363.2508418", "10.1145/1516522.1516526", "10.1145/2508363.2508407", "10.1145/2185520.2185549", "10.1145/1618452.1618521", "10.1145/2601097.2601165", "10.1145/2070781.2024208", "10.1145/1276377.1276467", "10.1145/1964921.1964973", "10.1145/1276377.1276478", "10.1145/2366145.2366207", "10.1145/1360612.1360698", "10.1145/1360612.1360697", "10.1145/1360612.1360696", "10.1145/2897824.2925969", "10.1145/2508363.2508418", "10.1145/1516522.1516526", "10.1145/2508363.2508407", "10.1145/2185520.2185549", "10.1145/1618452.1618521", "10.1145/2601097.2601165", "10.1145/2070781.2024208", "10.1007/BF00055001", "10.1016/j.cviu.2006.08.002", "10.1006/cviu.2000.0897", "10.1007/s00371-005-0346-7", "10.1007/s11263-012-0553-4", "10.1007/978-3-642-15561-1_24", "10.1016/j.cviu.2007.10.001", "10.1007/978-3-642-33709-3_59", "10.1007/978-1-4471-4640-7_5", "10.1111/j.1467-8659.2008.01286.x", "10.1111/j.1467-8659.2009.01384.x", "10.1111/j.1467-8659.2008.01137.x", "10.1111/j.1467-8659.2008.01282.x", "10.1111/j.1467-8659.2010.01772.x", "10.1007/s10851-007-0007-8", "10.1287/ijoc.1.2.70", "10.1007/BF00055001", "10.1016/j.cviu.2006.08.002", "10.1006/cviu.2000.0897", "10.1007/s00371-005-0346-7", "10.1007/s11263-012-0553-4", "10.1007/978-3-642-15561-1_24", "10.1016/j.cviu.2007.10.001", "10.1007/978-3-642-33709-3_59", "10.1007/978-1-4471-4640-7_5", "10.1111/j.1467-8659.2008.01286.x", "10.1111/j.1467-8659.2009.01384.x", "10.1111/j.1467-8659.2008.01137.x", "10.1111/j.1467-8659.2008.01282.x", "10.1111/j.1467-8659.2010.01772.x", "10.1007/s10851-007-0007-8", "10.1287/ijoc.1.2.70", "10.1007/BF00055001", "10.1016/j.cviu.2006.08.002", "10.1006/cviu.2000.0897", "10.1007/s00371-005-0346-7", "10.1007/s11263-012-0553-4", "10.1007/978-3-642-15561-1_24", "10.1016/j.cviu.2007.10.001", "10.1007/978-3-642-33709-3_59", "10.1007/978-1-4471-4640-7_5", "10.1111/j.1467-8659.2008.01286.x", "10.1111/j.1467-8659.2009.01384.x", "10.1111/j.1467-8659.2008.01137.x", "10.1111/j.1467-8659.2008.01282.x", "10.1111/j.1467-8659.2010.01772.x", "10.1007/s10851-007-0007-8", "10.1287/ijoc.1.2.70"]}, "10.1109/TVCG.2017.2690294": {"doi": "10.1109/TVCG.2017.2690294", "author": ["M. Birsak", "P. Musialski", "P. Wonka", "M. Wimmer"], "title": "Dynamic Path Exploration on Mobile Devices", "year": "2018", "abstract": "We present a novel framework for visualizing routes on mobile devices. Our framework is suitable for helping users explore their environment. First, given a starting point and a maximum route length, the system retrieves nearby points of interest (POIs). Second, we automatically compute an attractive walking path through the environment trying to pass by as many highly ranked POIs as possible. Third, we automatically compute a route visualization that shows the current user position, POI locations via pins, and detail lenses for more information about the POIs. The visualization is an animation of an orthographic map view that follows the current user position. We propose an optimization based on a binary integer program (BIP) that models multiple requirements for an effective placement of detail lenses. We show that our path computation method outperforms recently proposed methods and we evaluate the overall impact of our framework in two user studies.", "keywords": ["data visualisation", "integer programming", "interactive systems", "mobile computing", "query processing", "travel industry", "dynamic path exploration", "mobile devices", "maximum route length", "POIs", "attractive walking path", "route visualization", "POI locations", "orthographic map view", "path computation method", "points of interest", "user position", "system retrieval", "binary integer program", "BIP", "tourist guide", "Lenses", "Visualization", "Mobile handsets", "Optimization", "Labeling", "Legged locomotion", "Navigation", "Tourist guide", "OpenStreetMap", "exploration", "binary integer program"], "referenced_by": [], "referencing": ["IKEY:5072215", "IKEY:4015429", "IKEY:1607948", "IKEY:5072215", "IKEY:4015429", "IKEY:1607948", "IKEY:5072215", "IKEY:4015429", "IKEY:1607948", "10.1145/1873951.1873972", "10.1145/1871437.1871513", "10.1145/1360612.1360699", "10.1145/212332.212334", "10.1145/383259.383286", "10.1145/1882261.1866184", "10.1145/2422956.2422959", "10.1145/302979.303148", "10.1145/2557500.2557514", "10.1145/1873951.1873972", "10.1145/1871437.1871513", "10.1145/1360612.1360699", "10.1145/212332.212334", "10.1145/383259.383286", "10.1145/1882261.1866184", "10.1145/2422956.2422959", "10.1145/302979.303148", "10.1145/2557500.2557514", "10.1145/1873951.1873972", "10.1145/1871437.1871513", "10.1145/1360612.1360699", "10.1145/212332.212334", "10.1145/383259.383286", "10.1145/1882261.1866184", "10.1145/2422956.2422959", "10.1145/302979.303148", "10.1145/2557500.2557514", "10.7208/chicago/9780226010786.001.0001", "10.1007/s10115-012-0580-z", "10.1080/13658810600607766", "10.1559/152304075784313304", "10.1559/152304082783948367", "10.3138/U3N2-6363-130N-H870", "10.3138/9258-63QL-3988-110H", "10.1287/opre.38.5.752", "10.1111/cgf.12333", "10.1007/11795018_3", "10.1007/s10707-014-0214-6", "10.1007/3-540-36626-1_5", "10.1016/j.comgeo.2006.05.003", "10.7208/chicago/9780226010786.001.0001", "10.1007/s10115-012-0580-z", "10.1080/13658810600607766", "10.1559/152304075784313304", "10.1559/152304082783948367", "10.3138/U3N2-6363-130N-H870", "10.3138/9258-63QL-3988-110H", "10.1287/opre.38.5.752", "10.1111/cgf.12333", "10.1007/11795018_3", "10.1007/s10707-014-0214-6", "10.1007/3-540-36626-1_5", "10.1016/j.comgeo.2006.05.003", "10.7208/chicago/9780226010786.001.0001", "10.1007/s10115-012-0580-z", "10.1080/13658810600607766", "10.1559/152304075784313304", "10.1559/152304082783948367", "10.3138/U3N2-6363-130N-H870", "10.3138/9258-63QL-3988-110H", "10.1287/opre.38.5.752", "10.1111/cgf.12333", "10.1007/11795018_3", "10.1007/s10707-014-0214-6", "10.1007/3-540-36626-1_5", "10.1016/j.comgeo.2006.05.003"]}, "10.1109/TVCG.2017.2691322": {"doi": "10.1109/TVCG.2017.2691322", "author": ["K. Mendhurwar", "Q. Gu", "S. Mudur", "T. Popa"], "title": "The Discriminative Power of Shape an Empirical Study in Time Series Matching", "year": "2018", "abstract": "Shape provides significant discriminating power in time series matching of visual or geometric data as required in many important applications in graphics and vision. The well established dynamic time warping (DTW) algorithm and its variants do this matching by determining a non-linear time mapping to minimise euclidean distances between corresponding time-warped points. However the shape of curves is not considered. In this paper, we present a new shape-aware algorithm which uses time and shape correspondence (TSC) at increasing levels of detail to define a similarity measure with an L0 norm to aggregate the results, making it robust to noise and missing data. The L0 norm is implicitly regularised using a shape-based error. Through extensive experiments we empirically show that our algorithm outperforms existing state of the art algorithms, works more effectively with high dimensional data, and handles noise and missing data better. We demonstrate its versatile applicability and comparative performance using a large in-house created gait data base, an action data base from Microsoft, exercise action data from a local company, a large public time series data base from University of California, Riverside and hand movement in quaternion stream data format.", "keywords": ["computer graphics", "gait analysis", "image matching", "image recognition", "minimisation", "shape recognition", "time series", "dynamic time warping algorithm", "nonlinear time mapping", "shape-aware algorithm", "in-house created gait data base", "action data base", "public time series data base", "quaternion stream data format", "time series matching", "time-warped points", "shape correspondence", "time correspondence", "activity recognition", "Shape", "Time series analysis", "Databases", "Visualization", "Authentication", "Heuristic algorithms", "Shape measurement", "Action recognition", "gait authentication", "shape awareness", "time and shape correspondence", "time series matching"], "referenced_by": ["10.1145/3102163.3102239"], "referencing": ["IKEY:1104847", "IKEY:4221727", "IKEY:6205761", "IKEY:121791", "IKEY:6094234", "IKEY:1104847", "IKEY:4221727", "IKEY:6205761", "IKEY:121791", "IKEY:6094234", "IKEY:1104847", "IKEY:4221727", "IKEY:6205761", "IKEY:121791", "IKEY:6094234", "10.1145/956750.956777", "10.1145/253262.253332", "10.1145/2207676.2208303", "10.1145/1922649.1922653", "10.1145/218380.218421", "10.1145/956750.956777", "10.1145/253262.253332", "10.1145/2207676.2208303", "10.1145/1922649.1922653", "10.1145/218380.218421", "10.1145/956750.956777", "10.1145/253262.253332", "10.1145/2207676.2208303", "10.1145/1922649.1922653", "10.1145/218380.218421", "10.14778/1454159.1454226", "10.1007/978-3-642-11282-9_13", "10.1137/1.9781611972818.60", "10.1137/1.9781611974010.33", "10.1016/j.ins.2015.04.007", "10.1016/B978-012088469-8.50069-3", "10.2307/1401322", "10.3138/FM57-6770-U75U-7727", "10.1179/000870406X93490", "10.1007/s10851-009-0161-2", "10.1006/cviu.1998.0716", "10.1016/j.cviu.2006.08.002", "10.1016/j.imavis.2009.11.014", "10.1007/s00371-012-0752-6", "10.1016/j.patrec.2013.02.006", "10.1007/BF02291478", "10.1016/j.gaitpost.2006.07.003", "10.1111/cgf.12285", "10.1016/j.jalgebra.2010.09.019", "10.1559/152304099782424901", "10.14778/1454159.1454226", "10.1007/978-3-642-11282-9_13", "10.1137/1.9781611972818.60", "10.1137/1.9781611974010.33", "10.1016/j.ins.2015.04.007", "10.1016/B978-012088469-8.50069-3", "10.2307/1401322", "10.3138/FM57-6770-U75U-7727", "10.1179/000870406X93490", "10.1007/s10851-009-0161-2", "10.1006/cviu.1998.0716", "10.1016/j.cviu.2006.08.002", "10.1016/j.imavis.2009.11.014", "10.1007/s00371-012-0752-6", "10.1016/j.patrec.2013.02.006", "10.1007/BF02291478", "10.1016/j.gaitpost.2006.07.003", "10.1111/cgf.12285", "10.1016/j.jalgebra.2010.09.019", "10.1559/152304099782424901", "10.14778/1454159.1454226", "10.1007/978-3-642-11282-9_13", "10.1137/1.9781611972818.60", "10.1137/1.9781611974010.33", "10.1016/j.ins.2015.04.007", "10.1016/B978-012088469-8.50069-3", "10.2307/1401322", "10.3138/FM57-6770-U75U-7727", "10.1179/000870406X93490", "10.1007/s10851-009-0161-2", "10.1006/cviu.1998.0716", "10.1016/j.cviu.2006.08.002", "10.1016/j.imavis.2009.11.014", "10.1007/s00371-012-0752-6", "10.1016/j.patrec.2013.02.006", "10.1007/BF02291478", "10.1016/j.gaitpost.2006.07.003", "10.1111/cgf.12285", "10.1016/j.jalgebra.2010.09.019", "10.1559/152304099782424901"]}, "10.1109/TVCG.2017.2689016": {"doi": "10.1109/TVCG.2017.2689016", "author": ["H. Meyerhenke", "M. N\u00f6llenburg", "C. Schulz"], "title": "Drawing Large Graphs by Multilevel Maxent-Stress Optimization", "year": "2018", "abstract": "Drawing large graphs appropriately is an important step for the visual analysis of data from real-world networks. Here we present a novel multilevel algorithm to compute a graph layout with respect to the maxent-stress metric proposed by Gansner et al. (2013) that combines layout stress and entropy. As opposed to previous work, we do not solve the resulting linear systems of the maxent-stress metric with a typical numerical solver. Instead we use a simple local iterative scheme within a multilevel approach. To accelerate local optimization, we approximate long-range forces and use shared-memory parallelism. Our experiments validate the high potential of our approach, which is particularly appealing for dynamic graphs. In comparison to the previously best maxent-stress optimizer, which is sequential, our parallel implementation is on average 30 times faster already for static graphs (and still faster if executed on a single thread) while producing a comparable solution quality.", "keywords": ["approximation theory", "data analysis", "data visualisation", "entropy", "graph theory", "iterative methods", "optimisation", "parallel processing", "shared memory systems", "multilevel maxent-stress optimization", "real-world networks", "graph layout", "layout stress", "entropy", "multilevel approach", "local optimization", "shared-memory parallelism", "dynamic graphs", "multilevel algorithm", "local iterative scheme", "long-range forces approximation", "graphs drawing", "visual analysis", "Layout", "Stress", "Computational modeling", "Approximation algorithms", "Linear systems", "Force", "Optimization", "Graph layout", "algorithm engineering", "multilevel algorithm"], "referenced_by": ["IKEY:8462766", "IKEY:9086287"], "referencing": ["IKEY:4015416", "IKEY:545307", "IKEY:6329372", "IKEY:4376155", "IKEY:4553710", "IKEY:4015416", "IKEY:545307", "IKEY:6329372", "IKEY:4376155", "IKEY:4553710", "IKEY:4015416", "IKEY:545307", "IKEY:6329372", "IKEY:4376155", "IKEY:4553710", "10.1145/2503210.2503280", "10.1145/2503210.2503280", "10.1145/2503210.2503280", "10.1007/978-3-319-27261-0_3", "10.1007/978-3-319-20086-6_16", "10.1016/j.cviu.2011.05.013", "10.1137/110843563", "10.1137/1.9781611974690.ch1", "10.1007/978-3-540-70904-6_6", "10.1002/wics.1343", "10.1002/spe.4380211102", "10.1038/324446a0", "10.1007/BF02289565", "10.1016/0020-0190(89)90102-6", "10.1007/978-3-319-50106-2_2", "10.1007/978-3-319-03841-4_24", "10.7155/jgaa.00070", "10.1007/3-540-44541-2_19", "10.1007/978-3-540-31843-9_29", "10.7155/jgaa.00052", "10.7155/jgaa.00150", "10.1007/978-3-642-18469-7_8", "10.1007/978-3-642-00219-9_10", "10.1016/j.ins.2016.11.012", "10.1007/978-3-319-50106-2_1", "10.1007/978-3-319-07959-2_30", "10.1103/PhysRevE.76.036106", "10.1023/B:JOGO.0000042115.44455.f3", "10.1007/978-3-319-27261-0_3", "10.1007/978-3-319-20086-6_16", "10.1016/j.cviu.2011.05.013", "10.1137/110843563", "10.1137/1.9781611974690.ch1", "10.1007/978-3-540-70904-6_6", "10.1002/wics.1343", "10.1002/spe.4380211102", "10.1038/324446a0", "10.1007/BF02289565", "10.1016/0020-0190(89)90102-6", "10.1007/978-3-319-50106-2_2", "10.1007/978-3-319-03841-4_24", "10.7155/jgaa.00070", "10.1007/3-540-44541-2_19", "10.1007/978-3-540-31843-9_29", "10.7155/jgaa.00052", "10.7155/jgaa.00150", "10.1007/978-3-642-18469-7_8", "10.1007/978-3-642-00219-9_10", "10.1016/j.ins.2016.11.012", "10.1007/978-3-319-50106-2_1", "10.1007/978-3-319-07959-2_30", "10.1103/PhysRevE.76.036106", "10.1023/B:JOGO.0000042115.44455.f3", "10.1007/978-3-319-27261-0_3", "10.1007/978-3-319-20086-6_16", "10.1016/j.cviu.2011.05.013", "10.1137/110843563", "10.1137/1.9781611974690.ch1", "10.1007/978-3-540-70904-6_6", "10.1002/wics.1343", "10.1002/spe.4380211102", "10.1038/324446a0", "10.1007/BF02289565", "10.1016/0020-0190(89)90102-6", "10.1007/978-3-319-50106-2_2", "10.1007/978-3-319-03841-4_24", "10.7155/jgaa.00070", "10.1007/3-540-44541-2_19", "10.1007/978-3-540-31843-9_29", "10.7155/jgaa.00052", "10.7155/jgaa.00150", "10.1007/978-3-642-18469-7_8", "10.1007/978-3-642-00219-9_10", "10.1016/j.ins.2016.11.012", "10.1007/978-3-319-50106-2_1", "10.1007/978-3-319-07959-2_30", "10.1103/PhysRevE.76.036106", "10.1023/B:JOGO.0000042115.44455.f3"]}, "10.1109/TVCG.2017.2701829": {"doi": "10.1109/TVCG.2017.2701829", "author": ["Y. Wang", "K. Feng", "X. Chu", "J. Zhang", "C. Fu", "M. Sedlmair", "X. Yu", "B. Chen"], "title": "A Perception-Driven Approach to Supervised Dimensionality Reduction for Visualization", "year": "2018", "abstract": "Dimensionality reduction (DR) is a common strategy for visual analysis of labeled high-dimensional data. Low-dimensional representations of the data help, for instance, to explore the class separability and the spatial distribution of the data. Widely-used unsupervised DR methods like PCA do not aim to maximize the class separation, while supervised DR methods like LDA often assume certain spatial distributions and do not take perceptual capabilities of humans into account. These issues make them ineffective for complicated class structures. Towards filling this gap, we present a perception-driven linear dimensionality reduction approach that maximizes the perceived class separation in projections. Our approach builds on recent developments in perception-based separation measures that have achieved good results in imitating human perception. We extend these measures to be density-aware and incorporate them into a customized simulated annealing algorithm, which can rapidly generate a near optimal DR projection. We demonstrate the effectiveness of our approach by comparing it to state-of-the-art DR methods on 93 datasets, using both quantitative measure and human judgments. We also provide case studies with class-imbalanced and unlabeled data.", "keywords": ["data reduction", "data visualisation", "class separability", "spatial distribution", "supervised DR methods", "complicated class structures", "perceived class separation", "perception-based separation measures", "human perception", "optimal DR projection", "human judgments", "supervised dimensionality reduction", "visual analysis", "labeled high-dimensional data", "low-dimensional representations", "unsupervised DR methods", "visualization", "perception-driven linear dimensionality reduction approach", "Visualization", "Principal component analysis", "Data visualization", "Density measurement", "Simulated annealing", "Computational modeling", "Dimensionality reduction", "supervised", "visual class separation", "high-dimensional data"], "referenced_by": ["IKEY:8019851", "IKEY:8440853", "IKEY:8383983", "IKEY:8986923", "IKEY:9101275", "IKEY:9101275", "IKEY:9146191"], "referencing": ["IKEY:6634128", "IKEY:4016549", "IKEY:7465244", "IKEY:1672644", "IKEY:6064985", "IKEY:5332628", "IKEY:4553710", "IKEY:6832613", "IKEY:4378370", "IKEY:7536217", "IKEY:6327294", "IKEY:6634128", "IKEY:4016549", "IKEY:7465244", "IKEY:1672644", "IKEY:6064985", "IKEY:5332628", "IKEY:4553710", "IKEY:6832613", "IKEY:4378370", "IKEY:7536217", "IKEY:6327294", "IKEY:6634128", "IKEY:4016549", "IKEY:7465244", "IKEY:1672644", "IKEY:6064985", "IKEY:5332628", "IKEY:4553710", "IKEY:6832613", "IKEY:4378370", "IKEY:7536217", "IKEY:6327294", "10.1145/2669557.2669559", "10.1145/1007730.1007733", "10.1145/2669557.2669559", "10.1145/1007730.1007733", "10.1145/2669557.2669559", "10.1145/1007730.1007733", "10.1002/0470013192.bsa501", "10.4135/9781412985130", "10.1162/089976600300014980", "10.1111/cgf.12632", "10.1111/j.1467-8659.2009.01467.x", "10.1016/j.patcog.2012.07.021", "10.1111/j.1467-8659.2012.03125.x", "10.1080/01969727408546059", "10.1016/0377-0427(87)90125-7", "10.1126/science.290.5500.2319", "10.1126/science.290.5500.2323", "10.1007/978-1-4757-3069-2", "10.1063/1.1699114", "10.1080/01431161.2011.629637", "10.1002/0470013192.bsa501", "10.4135/9781412985130", "10.1162/089976600300014980", "10.1111/cgf.12632", "10.1111/j.1467-8659.2009.01467.x", "10.1016/j.patcog.2012.07.021", "10.1111/j.1467-8659.2012.03125.x", "10.1080/01969727408546059", "10.1016/0377-0427(87)90125-7", "10.1126/science.290.5500.2319", "10.1126/science.290.5500.2323", "10.1007/978-1-4757-3069-2", "10.1063/1.1699114", "10.1080/01431161.2011.629637", "10.1002/0470013192.bsa501", "10.4135/9781412985130", "10.1162/089976600300014980", "10.1111/cgf.12632", "10.1111/j.1467-8659.2009.01467.x", "10.1016/j.patcog.2012.07.021", "10.1111/j.1467-8659.2012.03125.x", "10.1080/01969727408546059", "10.1016/0377-0427(87)90125-7", "10.1126/science.290.5500.2319", "10.1126/science.290.5500.2323", "10.1007/978-1-4757-3069-2", "10.1063/1.1699114", "10.1080/01431161.2011.629637"]}, "10.1109/TVCG.2017.2692781": {"doi": "10.1109/TVCG.2017.2692781", "author": ["G. K. Karch", "F. Beck", "M. Ertl", "C. Meister", "K. Schulte", "B. Weigand", "T. Ertl", "F. Sadlo"], "title": "Visual Analysis of Inclusion Dynamics in Two-Phase Flow", "year": "2018", "abstract": "In single-phase flow visualization, research focuses on the analysis of vector field properties. In two-phase flow, in contrast, analysis of the phase components is typically of major interest. So far, visualization research of two-phase flow concentrated on proper interface reconstruction and the analysis thereof. In this paper, we present a novel visualization technique that enables the investigation of complex two-phase flow phenomena with respect to the physics of breakup and coalescence of inclusions. On the one hand, we adapt dimensionless quantities for a localized analysis of phase instability and breakup, and provide detailed inspection of breakup dynamics with emphasis on oscillation and its interplay with rotational motion. On the other hand, we present a parametric tightly linked space-time visualization approach for an effective interactive representation of the overall dynamics. We demonstrate the utility of our approach using several two-phase CFD datasets.", "keywords": ["computational fluid dynamics", "flow visualisation", "fluid oscillations", "rotational flow", "two-phase flow", "vectors", "localized analysis", "two-phase CFD datasets", "inclusion dynamics", "single-phase flow visualization", "vector field properties", "phase breakup", "fluid oscillation", "rotational motion", "space-time visualization approach", "phase instability analysis", "Visualization", "Data visualization", "Dynamics", "Liquids", "Oscillators", "Interpolation", "Computational modeling", "Flow visualization", "two-phase flow", "feature deformation", "space-time analysis", "feature tracking"], "referenced_by": [], "referencing": ["IKEY:5383354", "IKEY:5669296", "IKEY:5128904", "IKEY:1386650", "IKEY:4376195", "IKEY:6064965", "IKEY:35197", "IKEY:5370741", "IKEY:6596136", "IKEY:4015464", "IKEY:6613495", "IKEY:6183595", "IKEY:7465250", "IKEY:6875975", "IKEY:6664349", "IKEY:4308636", "IKEY:7348066", "IKEY:5383354", "IKEY:5669296", "IKEY:5128904", "IKEY:1386650", "IKEY:4376195", "IKEY:6064965", "IKEY:35197", "IKEY:5370741", "IKEY:6596136", "IKEY:4015464", "IKEY:6613495", "IKEY:6183595", "IKEY:7465250", "IKEY:6875975", "IKEY:6664349", "IKEY:4308636", "IKEY:7348066", "IKEY:5383354", "IKEY:5669296", "IKEY:5128904", "IKEY:1386650", "IKEY:4376195", "IKEY:6064965", "IKEY:35197", "IKEY:5370741", "IKEY:6596136", "IKEY:4015464", "IKEY:6613495", "IKEY:6183595", "IKEY:7465250", "IKEY:6875975", "IKEY:6664349", "IKEY:4308636", "IKEY:7348066", "10.1145/2070781.2024192", "10.1145/37402.37422", "10.1145/1629255.1629300", "10.1145/1966394.1966400", "10.1145/1778765.1778787", "10.1145/2070781.2024192", "10.1145/37402.37422", "10.1145/1629255.1629300", "10.1145/1966394.1966400", "10.1145/1778765.1778787", "10.1145/2070781.2024192", "10.1145/37402.37422", "10.1145/1629255.1629300", "10.1145/1966394.1966400", "10.1145/1778765.1778787", "10.1007/978-0-85729-079-3", "10.1016/j.amc.2015.05.095", "10.1063/1.4737582", "10.1016/j.ijmultiphaseflow.2009.02.014", "10.1016/0021-9991(81)90145-5", "10.1111/j.1467-8659.2004.00753.x", "10.2514/6.2010-210", "10.1111/j.1467-8659.2012.03184.x", "10.1111/j.1467-8659.2010.01650.x", "10.1111/j.1467-8659.2009.01671.x", "10.1016/j.compfluid.2008.11.007", "10.1111/j.1467-8659.2011.01901.x", "10.1016/j.jcp.2009.04.042", "10.1111/j.1467-8659.2003.00723.x", "10.1007/PL00013399", "10.1007/0-387-25465-X_15", "10.1007/s00348-005-0045-1", "10.1007/978-0-85729-079-3", "10.1016/j.amc.2015.05.095", "10.1063/1.4737582", "10.1016/j.ijmultiphaseflow.2009.02.014", "10.1016/0021-9991(81)90145-5", "10.1111/j.1467-8659.2004.00753.x", "10.2514/6.2010-210", "10.1111/j.1467-8659.2012.03184.x", "10.1111/j.1467-8659.2010.01650.x", "10.1111/j.1467-8659.2009.01671.x", "10.1016/j.compfluid.2008.11.007", "10.1111/j.1467-8659.2011.01901.x", "10.1016/j.jcp.2009.04.042", "10.1111/j.1467-8659.2003.00723.x", "10.1007/PL00013399", "10.1007/0-387-25465-X_15", "10.1007/s00348-005-0045-1", "10.1007/978-0-85729-079-3", "10.1016/j.amc.2015.05.095", "10.1063/1.4737582", "10.1016/j.ijmultiphaseflow.2009.02.014", "10.1016/0021-9991(81)90145-5", "10.1111/j.1467-8659.2004.00753.x", "10.2514/6.2010-210", "10.1111/j.1467-8659.2012.03184.x", "10.1111/j.1467-8659.2010.01650.x", "10.1111/j.1467-8659.2009.01671.x", "10.1016/j.compfluid.2008.11.007", "10.1111/j.1467-8659.2011.01901.x", "10.1016/j.jcp.2009.04.042", "10.1111/j.1467-8659.2003.00723.x", "10.1007/PL00013399", "10.1007/0-387-25465-X_15", "10.1007/s00348-005-0045-1"]}, "10.1109/TVCG.2017.2693151": {"doi": "10.1109/TVCG.2017.2693151", "author": ["Y. Wang", "Y. Liu", "X. Tong", "Q. Dai", "P. Tan"], "title": "Outdoor Markerless Motion Capture with Sparse Handheld Video Cameras", "year": "2018", "abstract": "We present a method for outdoor markerless motion capture with sparse handheld video cameras. In the simplest setting, it only involves two mobile phone cameras following the character. This setup can maximize the flexibilities of data capture and broaden the applications of motion capture. To solve the character pose under such challenge settings, we exploit the generative motion capture methods and propose a novel model-view consistency that considers both foreground and background in the tracking stage. The background is modeled as a deformable 2D grid, which allows us to compute the background-view consistency for sparse moving cameras. The 3D character pose is tracked with a global-local optimization through minimizing our consistency cost. A novel L1 motion regularizer is also proposed in the optimization to constrain the solution pose space. The whole process of the proposed method is simple as frame by frame video segmentation is not required. Our method outperforms several alternative methods on various examples demonstrated in the paper.", "keywords": ["image motion analysis", "minimisation", "mobile computing", "video cameras", "video signal processing", "generative motion capture methods", "novel model-view consistency", "background-view consistency", "sparse moving cameras", "outdoor markerless motion capture", "sparse handheld video cameras", "mobile phone cameras", "data capture", "tracking stage", "global-local optimization", "consistency cost minimization", "deformable 2D grid", "Cameras", "Skeleton", "Computational modeling", "Optimization", "Image color analysis", "Deformable models", "Three-dimensional displays", "Markerless motion capture", "handheld video cameras", "model-view consistency"], "referenced_by": ["IKEY:8620257", "IKEY:8529221", "IKEY:9010381", "IKEY:8673891", "IKEY:9113400"], "referencing": ["10.1145/1360612.1360697", "10.1145/1360612.1360696", "10.1145/2508363.2508418", "10.1145/2366145.2366207", "10.1145/1276377.1276421", "10.1145/2010324.1964926", "10.1145/882262.882309", "10.1145/2699643", "10.1145/1778765.1778779", "10.1145/2816795.2818013", "10.1145/1276377.1276467", "10.1145/2461912.2461995", "10.1145/1360612.1360697", "10.1145/1360612.1360696", "10.1145/2508363.2508418", "10.1145/2366145.2366207", "10.1145/1276377.1276421", "10.1145/2010324.1964926", "10.1145/882262.882309", "10.1145/2699643", "10.1145/1778765.1778779", "10.1145/2816795.2818013", "10.1145/1276377.1276467", "10.1145/2461912.2461995", "10.1145/1360612.1360697", "10.1145/1360612.1360696", "10.1145/2508363.2508418", "10.1145/2366145.2366207", "10.1145/1276377.1276421", "10.1145/2010324.1964926", "10.1145/882262.882309", "10.1145/2699643", "10.1145/1778765.1778779", "10.1145/2816795.2818013", "10.1145/1276377.1276467", "10.1145/2461912.2461995", "10.1007/978-3-642-33783-3_53", "10.1007/s11263-015-0818-9", "10.1007/11744047_49", "10.1007/978-3-319-10584-0_11", "10.1007/978-3-642-19318-7_48", "10.1023/B:VISI.0000011203.00237.9b", "10.1007/s11263-008-0173-1", "10.1016/j.cviu.2006.08.002", "10.1016/j.cviu.2006.10.016", "10.1111/cgf.12519", "10.1007/978-3-319-46454-1_34", "10.1007/978-0-85729-997-0_9", "10.2307/1390712", "10.1007/s11263-009-0273-6", "10.1007/978-3-642-33783-3_53", "10.1007/s11263-015-0818-9", "10.1007/11744047_49", "10.1007/978-3-319-10584-0_11", "10.1007/978-3-642-19318-7_48", "10.1023/B:VISI.0000011203.00237.9b", "10.1007/s11263-008-0173-1", "10.1016/j.cviu.2006.08.002", "10.1016/j.cviu.2006.10.016", "10.1111/cgf.12519", "10.1007/978-3-319-46454-1_34", "10.1007/978-0-85729-997-0_9", "10.2307/1390712", "10.1007/s11263-009-0273-6", "10.1007/978-3-642-33783-3_53", "10.1007/s11263-015-0818-9", "10.1007/11744047_49", "10.1007/978-3-319-10584-0_11", "10.1007/978-3-642-19318-7_48", "10.1023/B:VISI.0000011203.00237.9b", "10.1007/s11263-008-0173-1", "10.1016/j.cviu.2006.08.002", "10.1016/j.cviu.2006.10.016", "10.1111/cgf.12519", "10.1007/978-3-319-46454-1_34", "10.1007/978-0-85729-997-0_9", "10.2307/1390712", "10.1007/s11263-009-0273-6"]}, "10.1109/TVCG.2017.2700273": {"doi": "10.1109/TVCG.2017.2700273", "author": ["N. W. John", "S. R. Pop", "T. W. Day", "P. D. Ritsos", "C. J. Headleand"], "title": "The Implementation and Validation of a Virtual Environment for Training Powered Wheelchair Manoeuvres", "year": "2018", "abstract": "Navigating a powered wheelchair and avoiding collisions is often a daunting task for new wheelchair users. It takes time and practice to gain the coordination needed to become a competent driver and this can be even more of a challenge for someone with a disability. We present a cost-effective virtual reality (VR) application that takes advantage of consumer level VR hardware. The system can be easily deployed in an assessment centre or for home use, and does not depend on a specialized high-end virtual environment such as a Powerwall or CAVE. This paper reviews previous work that has used virtual environments technology for training tasks, particularly wheelchair simulation. We then describe the implementation of our own system and the first validation study carried out using thirty three able bodied volunteers. The study results indicate that at a significance level of 5 percent then there is an improvement in driving skills from the use of our VR system. We thus have the potential to develop the competency of a wheelchair user whilst avoiding the risks inherent to training in the real world. However, the occurrence of cybersickness is a particular problem in this application that will need to be addressed.", "keywords": ["handicapped aids", "virtual reality", "wheelchairs", "virtual environment", "wheelchair user", "cost-effective virtual reality application", "consumer level VR hardware", "virtual environments technology", "VR system", "powered wheelchair manoeuvres training", "able bodied volunteers", "cybersickness", "Wheelchairs", "Training", "Virtual environments", "Monitoring", "Navigation", "Tools", "Visualization", "Virtual reality", "virtual environment", "simulation", "wheelchair navigation", "Adult", "Computer Graphics", "Female", "Humans", "Male", "Middle Aged", "Patient Education as Topic", "Virtual Reality", "Wheelchairs", "Young Adult"], "referenced_by": ["IKEY:8120313", "IKEY:8120314", "IKEY:8478242", "IKEY:8659016", "IKEY:8632936", "IKEY:8797726", "IKEY:8797725", "IKEY:8810006", "IKEY:8864534", "IKEY:8968290", "IKEY:8971764", "IKEY:8994550", "IKEY:9240532"], "referencing": ["IKEY:7155405", "IKEY:403825", "IKEY:7460053", "IKEY:7155405", "IKEY:403825", "IKEY:7460053", "IKEY:7155405", "IKEY:403825", "IKEY:7460053", "10.1145/1044588.1044632", "10.1145/1503454.1503465", "10.1145/257874.257886", "10.1145/2915926.2915954", "10.1145/1044588.1044632", "10.1145/1503454.1503465", "10.1145/257874.257886", "10.1145/2915926.2915954", "10.1145/1044588.1044632", "10.1145/1503454.1503465", "10.1145/257874.257886", "10.1145/2915926.2915954", "10.1007/978-3-319-05951-8_52", "10.1162/pres.1995.4.3.297", "10.1080/10508400701793141", "10.1016/j.jmatprotec.2004.04.401", "10.1016/S0166-3615(03)00103-9", "10.1111/j.1553-2712.2010.00728.x", "10.1162/pres.1997.6.1.73", "10.3389/frobt.2016.00074", "10.1080/00140139308967941", "10.1518/001872097778667988", "10.1097/00000658-200210000-00008", "10.1186/1743-0003-7-15", "10.1007/s00391-010-0124-7", "10.1186/1743-0003-11-156", "10.1038/nrn3122", "10.1162/PRES_a_00224", "10.1007/s11548-013-0929-0", "10.1016/j.cmpb.2013.05.014", "10.1037/a0034088", "10.1080/09638280110111360", "10.1177/016264341102600303", "10.1162/1054746042545265", "10.1080/10400430903520223", "10.1016/S1350-4533(02)00111-X", "10.1179/2045772313Y.0000000130", "10.1207/s15327108ijap0303_3", "10.1097/00004356-200023040-00009", "10.1007/978-3-319-05951-8_52", "10.1162/pres.1995.4.3.297", "10.1080/10508400701793141", "10.1016/j.jmatprotec.2004.04.401", "10.1016/S0166-3615(03)00103-9", "10.1111/j.1553-2712.2010.00728.x", "10.1162/pres.1997.6.1.73", "10.3389/frobt.2016.00074", "10.1080/00140139308967941", "10.1518/001872097778667988", "10.1097/00000658-200210000-00008", "10.1186/1743-0003-7-15", "10.1007/s00391-010-0124-7", "10.1186/1743-0003-11-156", "10.1038/nrn3122", "10.1162/PRES_a_00224", "10.1007/s11548-013-0929-0", "10.1016/j.cmpb.2013.05.014", "10.1037/a0034088", "10.1080/09638280110111360", "10.1177/016264341102600303", "10.1162/1054746042545265", "10.1080/10400430903520223", "10.1016/S1350-4533(02)00111-X", "10.1179/2045772313Y.0000000130", "10.1207/s15327108ijap0303_3", "10.1097/00004356-200023040-00009", "10.1007/978-3-319-05951-8_52", "10.1162/pres.1995.4.3.297", "10.1080/10508400701793141", "10.1016/j.jmatprotec.2004.04.401", "10.1016/S0166-3615(03)00103-9", "10.1111/j.1553-2712.2010.00728.x", "10.1162/pres.1997.6.1.73", "10.3389/frobt.2016.00074", "10.1080/00140139308967941", "10.1518/001872097778667988", "10.1097/00000658-200210000-00008", "10.1186/1743-0003-7-15", "10.1007/s00391-010-0124-7", "10.1186/1743-0003-11-156", "10.1038/nrn3122", "10.1162/PRES_a_00224", "10.1007/s11548-013-0929-0", "10.1016/j.cmpb.2013.05.014", "10.1037/a0034088", "10.1080/09638280110111360", "10.1177/016264341102600303", "10.1162/1054746042545265", "10.1080/10400430903520223", "10.1016/S1350-4533(02)00111-X", "10.1179/2045772313Y.0000000130", "10.1207/s15327108ijap0303_3", "10.1097/00004356-200023040-00009"]}}