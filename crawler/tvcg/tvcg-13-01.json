{"10.1109/TVCG.2012.111": {"doi": "10.1109/TVCG.2012.111", "author": ["T. Hou", "H. Qin"], "title": "Admissible Diffusion Wavelets and Their Applications in Space-Frequency Processing", "year": "2013", "abstract": "As signal processing tools, diffusion wavelets and biorthogonal diffusion wavelets have been propelled by recent research in mathematics. They employ diffusion as a smoothing and scaling process to empower multiscale analysis. However, their applications in graphics and visualization are overshadowed by nonadmissible wavelets and their expensive computation. In this paper, our motivation is to broaden the application scope to space-frequency processing of shape geometry and scalar fields. We propose the admissible diffusion wavelets (ADW) on meshed surfaces and point clouds. The ADW are constructed in a bottom-up manner that starts from a local operator in a high frequency, and dilates by its dyadic powers to low frequencies. By relieving the orthogonality and enforcing normalization, the wavelets are locally supported and admissible, hence facilitating data analysis and geometry processing. We define the novel rapid reconstruction, which recovers the signal from multiple bands of high frequencies and a low-frequency base in full resolution. It enables operations localized in both space and frequency by manipulating wavelet coefficients through space-frequency filters. This paper aims to build a common theoretic foundation for a host of applications, including saliency visualization, multiscale feature extraction, spectral geometry processing, etc.", "keywords": ["feature extraction", "geometry", "signal reconstruction", "signal resolution", "smoothing methods", "spectral analysis", "wavelet transforms", "admissible diffusion wavelet", "space-frequency processing", "signal processing tool", "biorthogonal diffusion wavelet", "mathematics", "smoothing process", "scaling process", "multiscale analysis", "shape geometry", "scalar field", "ADW", "meshed surface", "point cloud", "dyadic power", "data analysis", "signal reconstruction", "signal resolution", "wavelet coefficient", "space-frequency filter", "saliency visualization", "multiscale feature extraction", "spectral geometry processing", "Wavelet transforms", "Manifolds", "Multiresolution analysis", "Geometry", "Surface waves", "Feature extraction", "wavelet transforms", "feature extraction", "geometry", "signal reconstruction", "signal resolution", "smoothing methods", "spectral analysis", "spectral geometry processing", "admissible diffusion wavelet", "space-frequency processing", "signal processing tool", "biorthogonal diffusion wavelet", "mathematics", "smoothing process", "scaling process", "multiscale analysis", "shape geometry", "scalar field", "ADW", "meshed surface", "point cloud", "dyadic power", "data analysis", "signal reconstruction", "signal resolution", "wavelet coefficient", "space-frequency filter", "saliency visualization", "multiscale feature extraction", "Wavelet transforms", "Manifolds", "Multiresolution analysis", "Geometry", "Surface waves", "Feature extraction", "space-frequency processing", "Diffusion wavelets", "wavelet analysis", "feature extraction"], "referenced_by": ["IKEY:6619122", "IKEY:7419452", "IKEY:7410440", "IKEY:6472239", "IKEY:7321833", "IKEY:8567954", "IKEY:8765747", "10.1145/2943778", "10.1007/978-3-319-48890-5_36", "10.1007/s00371-015-1100-4", "10.1007/s00371-016-1334-9", "10.1016/j.cagd.2016.02.011", "10.1016/j.gmod.2014.03.006", "10.1201/b17585-16", "10.1016/j.cad.2019.05.006"], "referencing": ["IKEY:1314505", "IKEY:4015448", "IKEY:5521454", "IKEY:1631196", "IKEY:4276074", "IKEY:1207446", "IKEY:1467300", "IKEY:1388226", "IKEY:1634328", "IKEY:1272731", "IKEY:809898", "IKEY:663871", "IKEY:1260763", "IKEY:1314505", "IKEY:4015448", "IKEY:5521454", "IKEY:1631196", "IKEY:4276074", "IKEY:1207446", "IKEY:1467300", "IKEY:1388226", "IKEY:1634328", "IKEY:1272731", "IKEY:809898", "IKEY:663871", "IKEY:1260763", "IKEY:1314505", "IKEY:4015448", "IKEY:5521454", "IKEY:1631196", "IKEY:4276074", "IKEY:1207446", "IKEY:1467300", "IKEY:1388226", "IKEY:1634328", "IKEY:1272731", "IKEY:809898", "IKEY:663871", "IKEY:1260763", "10.1145/1186562.1015774", "10.1145/1073204.1073244", "10.1145/1670671.1670676", "10.1145/383259.383301", "10.1145/344779.344924", "10.1145/1057432.1057434", "10.1145/1037957.1037961", "10.1145/1377676.1377725", "10.1145/1618452.1618486", "10.1145/311535.311577", "10.1145/1330511.1330515", "10.1145/237748.237750", "10.1145/1186562.1015774", "10.1145/1073204.1073244", "10.1145/1670671.1670676", "10.1145/383259.383301", "10.1145/344779.344924", "10.1145/1057432.1057434", "10.1145/1037957.1037961", "10.1145/1377676.1377725", "10.1145/1618452.1618486", "10.1145/311535.311577", "10.1145/1330511.1330515", "10.1145/237748.237750", "10.1145/1186562.1015774", "10.1145/1073204.1073244", "10.1145/1670671.1670676", "10.1145/383259.383301", "10.1145/344779.344924", "10.1145/1057432.1057434", "10.1145/1037957.1037961", "10.1145/1377676.1377725", "10.1145/1618452.1618486", "10.1145/311535.311577", "10.1145/1330511.1330515", "10.1145/237748.237750", "10.1023/B:VISI.0000029664.99615.94", "10.1111/j.1467-8659.2008.01162.x", "10.1007/978-3-642-15558-1_28", "10.1007/s00371-011-0582-y", "10.1111/j.1467-8659.2009.01515.x", "10.1016/j.acha.2006.04.004", "10.1117/12.616909", "10.1007/s00371-008-0260-x", "10.1098/rsta.1999.0439", "10.1016/j.cam.2009.09.038", "10.1007/978-3-642-03596-8_18", "10.1016/j.acha.2010.04.005", "10.1137/1.9781611973068.112", "10.1006/acha.1999.0272", "10.1111/j.1467-8659.1995.cgf143_0431.x", "10.1111/1467-8659.00421", "10.1016/j.cag.2007.01.033", "10.1016/j.cag.2006.09.009", "10.1111/j.1467-8659.2008.01122.x", "10.1023/B:VISI.0000029664.99615.94", "10.1111/j.1467-8659.2008.01162.x", "10.1007/978-3-642-15558-1_28", "10.1007/s00371-011-0582-y", "10.1111/j.1467-8659.2009.01515.x", "10.1016/j.acha.2006.04.004", "10.1117/12.616909", "10.1007/s00371-008-0260-x", "10.1098/rsta.1999.0439", "10.1016/j.cam.2009.09.038", "10.1007/978-3-642-03596-8_18", "10.1016/j.acha.2010.04.005", "10.1137/1.9781611973068.112", "10.1006/acha.1999.0272", "10.1111/j.1467-8659.1995.cgf143_0431.x", "10.1111/1467-8659.00421", "10.1016/j.cag.2007.01.033", "10.1016/j.cag.2006.09.009", "10.1111/j.1467-8659.2008.01122.x", "10.1023/B:VISI.0000029664.99615.94", "10.1111/j.1467-8659.2008.01162.x", "10.1007/978-3-642-15558-1_28", "10.1007/s00371-011-0582-y", "10.1111/j.1467-8659.2009.01515.x", "10.1016/j.acha.2006.04.004", "10.1117/12.616909", "10.1007/s00371-008-0260-x", "10.1098/rsta.1999.0439", "10.1016/j.cam.2009.09.038", "10.1007/978-3-642-03596-8_18", "10.1016/j.acha.2010.04.005", "10.1137/1.9781611973068.112", "10.1006/acha.1999.0272", "10.1111/j.1467-8659.1995.cgf143_0431.x", "10.1111/1467-8659.00421", "10.1016/j.cag.2007.01.033", "10.1016/j.cag.2006.09.009", "10.1111/j.1467-8659.2008.01122.x"]}, "10.1109/TVCG.2012.104": {"doi": "10.1109/TVCG.2012.104", "author": ["C. C. L. Wang", "D. Manocha"], "title": "Efficient Boundary Extraction of BSP Solids Based on Clipping Operations", "year": "2013", "abstract": "We present an efficient algorithm to extract the manifold surface that approximates the boundary of a solid represented by a Binary Space Partition (BSP) tree. Our polygonization algorithm repeatedly performs clipping operations on volumetric cells that correspond to a spatial convex partition and computes the boundary by traversing the connected cells. We use point-based representations along with finite-precision arithmetic to improve the efficiency and generate the B-rep approximation of a BSP solid. The core of our polygonization method is a novel clipping algorithm that uses a set of logical operations to make it resistant to degeneracies resulting from limited precision of floating-point arithmetic. The overall BSP to B-rep conversion algorithm can accurately generate boundaries with sharp and small features, and is faster than prior methods. At the end of this paper, we use this algorithm for a few geometric processing applications including Boolean operations, model repair, and mesh reconstruction.", "keywords": ["Boolean algebra", "mesh generation", "solid modelling", "trees (mathematics)", "efficient boundary extraction", "BSP solids", "clipping operations", "manifold surface", "binary space partition tree", "polygonization algorithm", "volumetric cells", "spatial convex partition", "point based representations", "finite precision arithmetic", "B-rep approximation", "polygonization method", "clipping algorithm", "logical operations", "floating point arithmetic", "geometric processing", "Boolean operations", "model repair", "mesh reconstruction", "Face", "Solids", "Computational modeling", "Topology", "Octrees", "Robustness", "Solid modeling", "trees (mathematics)", "Boolean algebra", "mesh generation", "solid modelling", "mesh reconstruction", "efficient boundary extraction", "BSP solids", "clipping operations", "manifold surface", "binary space partition tree", "polygonization algorithm", "volumetric cells", "spatial convex partition", "point based representations", "finite precision arithmetic", "B-rep approximation", "polygonization method", "clipping algorithm", "logical operations", "floating point arithmetic", "geometric processing", "Boolean operations", "model repair", "Face", "Solids", "Computational modeling", "Topology", "Octrees", "Robustness", "Solid modeling", "solid modeling", "BSP to B-rep conversion", "efficient", "clipping", "approximation"], "referenced_by": ["IKEY:8290765", "10.1016/j.advengsoft.2015.03.003", "10.1016/j.cad.2015.03.001", "10.1016/j.cag.2017.07.028", "10.1016/j.gmod.2018.03.001", "10.1111/cgf.13147", "10.1108/RPJ-11-2016-0185", "10.2200/S00847ED1V01Y201804VCP031", "10.1002/ese3.335", "10.1016/j.cagx.2019.100007"], "referencing": ["IKEY:1457376", "IKEY:4276080", "IKEY:641606", "IKEY:5539758", "IKEY:1457376", "IKEY:4276080", "IKEY:641606", "IKEY:5539758", "IKEY:1457376", "IKEY:4276080", "IKEY:641606", "IKEY:5539758", "10.1145/237218.237246", "10.1145/78956.78959", "10.1145/1778765.1778787", "10.1145/800250.807481", "10.1145/97880.97892", "10.1145/37402.37421", "10.1145/253284.253326", "10.1145/1839778.1839805", "10.1145/258734.258865", "10.1145/1186822.1073306", "10.1145/129902.129906", "10.1145/274363.274364", "10.1145/1095878.1095883", "10.1145/566570.566586", "10.1145/1230100.1230128", "10.1145/304012.304016", "10.1145/781606.781627", "10.1145/1015706.1015815", "10.1145/237218.237246", "10.1145/78956.78959", "10.1145/1778765.1778787", "10.1145/800250.807481", "10.1145/97880.97892", "10.1145/37402.37421", "10.1145/253284.253326", "10.1145/1839778.1839805", "10.1145/258734.258865", "10.1145/1186822.1073306", "10.1145/129902.129906", "10.1145/274363.274364", "10.1145/1095878.1095883", "10.1145/566570.566586", "10.1145/1230100.1230128", "10.1145/304012.304016", "10.1145/781606.781627", "10.1145/1015706.1015815", "10.1145/237218.237246", "10.1145/78956.78959", "10.1145/1778765.1778787", "10.1145/800250.807481", "10.1145/97880.97892", "10.1145/37402.37421", "10.1145/253284.253326", "10.1145/1839778.1839805", "10.1145/258734.258865", "10.1145/1186822.1073306", "10.1145/129902.129906", "10.1145/274363.274364", "10.1145/1095878.1095883", "10.1145/566570.566586", "10.1145/1230100.1230128", "10.1145/304012.304016", "10.1145/781606.781627", "10.1145/1015706.1015815", "10.1115/1.1375815", "10.1111/j.1467-8659.2009.01504.x", "10.1016/j.cad.2008.11.002", "10.1111/1467-8659.1540205", "10.1111/j.1467-8659.2009.01609.x", "10.1111/j.1467-8659.2009.01545.x", "10.1080/16864360.2006.10738411", "10.1007/PL00009321", "10.1111/1467-8659.00236", "10.1111/j.1467-8659.2008.01211.x", "10.1111/j.1467-8659.2010.01781.x", "10.1115/1.1375815", "10.1111/j.1467-8659.2009.01504.x", "10.1016/j.cad.2008.11.002", "10.1111/1467-8659.1540205", "10.1111/j.1467-8659.2009.01609.x", "10.1111/j.1467-8659.2009.01545.x", "10.1080/16864360.2006.10738411", "10.1007/PL00009321", "10.1111/1467-8659.00236", "10.1111/j.1467-8659.2008.01211.x", "10.1111/j.1467-8659.2010.01781.x", "10.1115/1.1375815", "10.1111/j.1467-8659.2009.01504.x", "10.1016/j.cad.2008.11.002", "10.1111/1467-8659.1540205", "10.1111/j.1467-8659.2009.01609.x", "10.1111/j.1467-8659.2009.01545.x", "10.1080/16864360.2006.10738411", "10.1007/PL00009321", "10.1111/1467-8659.00236", "10.1111/j.1467-8659.2008.01211.x", "10.1111/j.1467-8659.2010.01781.x"]}, "10.1109/TVCG.2012.69": {"doi": "10.1109/TVCG.2012.69", "author": ["A. C. Jalba", "W. J. v. d. Laan", "J. B. T. M. Roerdink"], "title": "Fast Sparse Level Sets on Graphics Hardware", "year": "2013", "abstract": "The level-set method is one of the most popular techniques for capturing and tracking deformable interfaces. Although level sets have demonstrated great potential in visualization and computer graphics applications, such as surface editing and physically based modeling, their use for interactive simulations has been limited due to the high computational demands involved. In this paper, we address this computational challenge by leveraging the increased computing power of graphics processors, to achieve fast simulations based on level sets. Our efficient, sparse GPU level-set method is substantially faster than other state-of-the-art, parallel approaches on both CPU and GPU hardware. We further investigate its performance through a method for surface reconstruction, based on GPU level sets. Our novel multiresolution method for surface reconstruction from unorganized point clouds compares favorably with recent, existing techniques and other parallel implementations. Finally, we point out that both level-set computations and rendering of level-set surfaces can be performed at interactive rates, even on large volumetric grids. Therefore, many applications based on level sets can benefit from our sparse level-set method.", "keywords": ["data visualisation", "digital simulation", "graphics processing units", "rendering (computer graphics)", "fast sparse level sets", "graphics hardware", "deformable interfaces", "computer graphics applications", "visualization applications", "surface editing", "physically based modeling", "interactive simulations", "graphics processors", "sparse GPU level-set method", "parallel approaches", "surface reconstruction", "level-set surface rendering", "volumetric grids", "Graphics processing unit", "Level set", "Instruction sets", "Arrays", "Kernel", "Computational modeling", "rendering (computer graphics)", "data visualisation", "digital simulation", "graphics processing units", "volumetric grids", "fast sparse level sets", "graphics hardware", "deformable interfaces", "computer graphics applications", "visualization applications", "surface editing", "physically based modeling", "interactive simulations", "graphics processors", "sparse GPU level-set method", "parallel approaches", "surface reconstruction", "level-set surface rendering", "Tiles", "Graphics processing unit", "Level set", "Instruction sets", "Arrays", "Kernel", "Computational modeling", "octree", "Level-set method", "sparse representation", "sorted tile list", "surface reconstruction"], "referenced_by": ["IKEY:7882694", "IKEY:6960855", "IKEY:9157854", "10.1049/iet-ipr.2015.0489", "10.1016/j.compmedimag.2013.10.002", "10.1098/rstb.2015.0512", "10.1177/0142331214522287", "10.1016/B978-0-08-101291-8.00005-5"], "referencing": ["IKEY:4376181", "IKEY:1298799", "IKEY:4523358", "IKEY:4741302", "IKEY:958320", "IKEY:5161005", "IKEY:938900", "IKEY:4376181", "IKEY:1298799", "IKEY:4523358", "IKEY:4741302", "IKEY:958320", "IKEY:5161005", "IKEY:938900", "IKEY:4376181", "IKEY:1298799", "IKEY:4523358", "IKEY:4741302", "IKEY:958320", "IKEY:5161005", "IKEY:938900", "10.1145/1122501.1122508", "10.1145/1057432.1057434", "10.1145/800186.810616", "10.1145/1186562.1015745", "10.1145/1201775.882293", "10.1145/1836845.1836903", "10.1145/1409060.1409079", "10.1145/1122501.1122508", "10.1145/1057432.1057434", "10.1145/800186.810616", "10.1145/1186562.1015745", "10.1145/1201775.882293", "10.1145/1836845.1836903", "10.1145/1409060.1409079", "10.1145/1122501.1122508", "10.1145/1057432.1057434", "10.1145/800186.810616", "10.1145/1186562.1015745", "10.1145/1201775.882293", "10.1145/1836845.1836903", "10.1145/1409060.1409079", "10.1006/jcph.1995.1098", "10.1038/324446a0", "10.1111/j.1467-8659.2008.01200.x", "10.1006/jcph.2002.7166", "10.1111/j.1467-8659.2009.01377.x", "10.1006/jcph.1999.6205", "10.1006/jcph.1994.1187", "10.1016/j.jcp.2004.04.019", "10.1007/s10915-005-9062-8", "10.1016/0021-9991(88)90002-2", "10.1006/jcph.1999.6345", "10.1111/j.1467-8659.2007.01064.x", "10.1007/s10915-010-9399-5", "10.1023/A:1008036829907", "10.1006/jcph.1995.1098", "10.1038/324446a0", "10.1111/j.1467-8659.2008.01200.x", "10.1006/jcph.2002.7166", "10.1111/j.1467-8659.2009.01377.x", "10.1006/jcph.1999.6205", "10.1006/jcph.1994.1187", "10.1016/j.jcp.2004.04.019", "10.1007/s10915-005-9062-8", "10.1016/0021-9991(88)90002-2", "10.1006/jcph.1999.6345", "10.1111/j.1467-8659.2007.01064.x", "10.1007/s10915-010-9399-5", "10.1023/A:1008036829907", "10.1006/jcph.1995.1098", "10.1038/324446a0", "10.1111/j.1467-8659.2008.01200.x", "10.1006/jcph.2002.7166", "10.1111/j.1467-8659.2009.01377.x", "10.1006/jcph.1999.6205", "10.1006/jcph.1994.1187", "10.1016/j.jcp.2004.04.019", "10.1007/s10915-005-9062-8", "10.1016/0021-9991(88)90002-2", "10.1006/jcph.1999.6345", "10.1111/j.1467-8659.2007.01064.x", "10.1007/s10915-010-9399-5", "10.1023/A:1008036829907"]}, "10.1109/TVCG.2012.106": {"doi": "10.1109/TVCG.2012.106", "author": ["Y. Yang", "N. Peyerimhoff", "I. Ivrissimtzis"], "title": "Linear Correlations between Spatial and Normal Noise in Triangle Meshes", "year": "2013", "abstract": "We study the relationship between the noise in the vertex coordinates of a triangle mesh and normal noise. First, we compute in closed form the expectation for the angle \u03b8 between the new and the old normal when uniform noise is added to a single vertex of a triangle. Next, we propose and experimentally validate an approximation and lower and upper bounds for \u03b8 when uniform noise is added to all three vertices of the triangle. In all cases, for small amounts of spatial noise that do not severely distort the mesh, there is a linear correlation between \u03b8 and simple functions of the heights of the triangles and thus, \u03b8 can be computed efficiently. The addition of uniform spatial noise to a mesh can be seen as a dithered quantization of its vertices. We use the obtained linear correlations between spatial and normal noise to compute the level of dithered quantization of the mesh vertices when a tolerance for the average normal distortion is given.", "keywords": ["approximation theory", "computational geometry", "mesh generation", "linear correlations", "spatial noise", "normal noise", "triangle meshes", "uniform noise", "dithered vertex quantization", "mesh vertices", "average normal distortion", "Noise", "Quantization", "Degradation", "Upper bound", "Linear approximation", "Rendering (computer graphics)", "mesh generation", "approximation theory", "computational geometry", "average normal distortion", "linear correlations", "spatial noise", "normal noise", "triangle meshes", "uniform noise", "dithered vertex quantization", "mesh vertices", "Noise", "Quantization", "Degradation", "Upper bound", "Linear approximation", "Rendering (computer graphics)", "vertex quantization", "Triangle mesh", "normal noise"], "referenced_by": ["IKEY:8089350", "IKEY:7025969", "IKEY:7352354", "IKEY:7399411", "IKEY:7307637", "IKEY:8540087", "IKEY:8935245", "IKEY:8764385", "10.1145/2535555", "10.1049/iet-ipr.2017.0162", "10.1007/s11042-016-4163-y", "10.1016/j.image.2014.12.008", "10.1007/978-3-319-26561-2_76"], "referencing": ["IKEY:1088973", "IKEY:256489", "IKEY:597270", "IKEY:4564452", "IKEY:1188740", "IKEY:1471696", "IKEY:4668365", "IKEY:1088973", "IKEY:256489", "IKEY:597270", "IKEY:4564452", "IKEY:1188740", "IKEY:1471696", "IKEY:4668365", "IKEY:1088973", "IKEY:256489", "IKEY:597270", "IKEY:4564452", "IKEY:1188740", "IKEY:1471696", "IKEY:4668365", "10.1145/311535.311577", "10.1145/258734.258843", "10.1145/504502.504510", "10.1145/1507149.1507177", "10.1145/1061347.1061356", "10.1145/383259.383281", "10.1145/1576246.1531398", "10.1145/311535.311577", "10.1145/258734.258843", "10.1145/504502.504510", "10.1145/1507149.1507177", "10.1145/1061347.1061356", "10.1145/383259.383281", "10.1145/1576246.1531398", "10.1145/311535.311577", "10.1145/258734.258843", "10.1145/504502.504510", "10.1145/1507149.1507177", "10.1145/1061347.1061356", "10.1145/383259.383281", "10.1145/1576246.1531398", "10.1111/j.1467-8659.2005.00884.x", "10.1007/s00371-007-0147-2", "10.1111/j.1467-8659.2008.01161.x", "10.1007/s00371-009-0398-1", "10.1111/j.1467-8659.2010.01767.x", "10.1007/s00371-004-0271-1", "10.1111/j.1467-8659.2010.01737.x", "10.1016/j.cag.2009.03.019", "10.1016/j.gmod.2008.12.002", "10.1111/j.1467-8659.2005.00884.x", "10.1007/s00371-007-0147-2", "10.1111/j.1467-8659.2008.01161.x", "10.1007/s00371-009-0398-1", "10.1111/j.1467-8659.2010.01767.x", "10.1007/s00371-004-0271-1", "10.1111/j.1467-8659.2010.01737.x", "10.1016/j.cag.2009.03.019", "10.1016/j.gmod.2008.12.002", "10.1111/j.1467-8659.2005.00884.x", "10.1007/s00371-007-0147-2", "10.1111/j.1467-8659.2008.01161.x", "10.1007/s00371-009-0398-1", "10.1111/j.1467-8659.2010.01767.x", "10.1007/s00371-004-0271-1", "10.1111/j.1467-8659.2010.01737.x", "10.1016/j.cag.2009.03.019", "10.1016/j.gmod.2008.12.002"]}, "10.1109/TVCG.2012.95": {"doi": "10.1109/TVCG.2012.95", "author": ["A. Colburn", "A. Agarwala", "A. Hertzmann", "B. Curless", "M. F. Cohen"], "title": "Image-Based Remodeling", "year": "2013", "abstract": "Imagining what a proposed home remodel might look like without actually performing it is challenging. We present an image-based remodeling methodology that allows real-time photorealistic visualization during both the modeling and remodeling process of a home interior. Large-scale edits, like removing a wall or enlarging a window, are performed easily and in real time, with realistic results. Our interface supports the creation of concise, parameterized, and constrained geometry, as well as remodeling directly from within the photographs. Real-time texturing of modified geometry is made possible by precomputing view-dependent textures for all faces that are potentially visible to each original camera viewpoint, blending multiple viewpoints and hole-filling when necessary. The resulting textures are stored and accessed efficiently enabling intuitive real-time realistic visualization, modeling, and editing of the building interior.", "keywords": ["computational geometry", "data visualisation", "image texture", "solid modelling", "image-based remodeling methodology", "photorealistic visualization", "large-scale edits", "constrained geometry", "photographs", "real-time texturing", "modified geometry", "camera viewpoint", "hole-filling", "intuitive real-time realistic visualization", "building interior", "Solid modeling", "Geometry", "Three dimensional displays", "Rendering (computer graphics)", "Real time systems", "Visualization", "Buildings", "solid modelling", "computational geometry", "data visualisation", "image texture", "building interior", "image-based remodeling methodology", "photorealistic visualization", "large-scale edits", "constrained geometry", "photographs", "real-time texturing", "modified geometry", "camera viewpoint", "hole-filling", "intuitive real-time realistic visualization", "Solid modeling", "Geometry", "Three dimensional displays", "Rendering (computer graphics)", "Real time systems", "Visualization", "Buildings", "visualization systems and software", "Image-based rendering", "modeling packages"], "referenced_by": ["IKEY:7560395", "IKEY:6720211", "10.1145/2980179.2982432", "10.1145/3034185", "10.1145/2661229.2661256", "10.1049/iet-ipr.2012.0241", "10.1007/s11263-014-0734-4", "10.3390/ijgi4020989", "10.1007/978-3-030-39445-5_27"], "referencing": ["IKEY:5206867", "IKEY:4408933", "IKEY:5459411", "IKEY:797697", "IKEY:5459145", "IKEY:5206867", "IKEY:4408933", "IKEY:5459411", "IKEY:797697", "IKEY:5459145", "IKEY:5206867", "IKEY:4408933", "IKEY:5459411", "IKEY:797697", "IKEY:5459145", "10.1145/800125.804034", "10.1145/383259.383309", "10.1145/882262.882269", "10.1145/1731047.1731053", "10.1145/1399504.1360614", "10.1145/311535.311559", "10.1145/383259.383271", "10.1145/2024156.2024191", "10.1145/1179352.1141964", "10.1145/1179849.1180008", "10.1145/1275808.1276484", "10.1145/237170.237191", "10.1145/383259.383310", "10.1145/1457515.1409112", "10.1145/1833349.1778830", "10.1145/1230100.1230121", "10.1145/1053427.1053450", "10.1145/1833349.1778864", "10.1145/800125.804034", "10.1145/383259.383309", "10.1145/882262.882269", "10.1145/1731047.1731053", "10.1145/1399504.1360614", "10.1145/311535.311559", "10.1145/383259.383271", "10.1145/2024156.2024191", "10.1145/1179352.1141964", "10.1145/1179849.1180008", "10.1145/1275808.1276484", "10.1145/237170.237191", "10.1145/383259.383310", "10.1145/1457515.1409112", "10.1145/1833349.1778830", "10.1145/1230100.1230121", "10.1145/1053427.1053450", "10.1145/1833349.1778864", "10.1145/800125.804034", "10.1145/383259.383309", "10.1145/882262.882269", "10.1145/1731047.1731053", "10.1145/1399504.1360614", "10.1145/311535.311559", "10.1145/383259.383271", "10.1145/2024156.2024191", "10.1145/1179352.1141964", "10.1145/1179849.1180008", "10.1145/1275808.1276484", "10.1145/237170.237191", "10.1145/383259.383310", "10.1145/1457515.1409112", "10.1145/1833349.1778830", "10.1145/1230100.1230121", "10.1145/1053427.1053450", "10.1145/1833349.1778864", "10.1016/0306-4379(82)90023-0", "10.1007/978-3-642-15549-9_4", "10.1111/j.1467-8659.2008.01268.x", "10.1023/B:VISI.0000025798.50602.3a", "10.1007/s11263-007-0081-9", "10.1023/B:VISI.0000029665.07652.61", "10.1023/A:1026598000963", "10.1023/A:1016046923611", "10.1016/0306-4379(82)90023-0", "10.1007/978-3-642-15549-9_4", "10.1111/j.1467-8659.2008.01268.x", "10.1023/B:VISI.0000025798.50602.3a", "10.1007/s11263-007-0081-9", "10.1023/B:VISI.0000029665.07652.61", "10.1023/A:1026598000963", "10.1023/A:1016046923611", "10.1016/0306-4379(82)90023-0", "10.1007/978-3-642-15549-9_4", "10.1111/j.1467-8659.2008.01268.x", "10.1023/B:VISI.0000025798.50602.3a", "10.1007/s11263-007-0081-9", "10.1023/B:VISI.0000029665.07652.61", "10.1023/A:1026598000963", "10.1023/A:1016046923611"]}, "10.1109/TVCG.2012.91": {"doi": "10.1109/TVCG.2012.91", "author": ["L. Wang", "A. E. Kaufman"], "title": "Lighting System for Visual Perception Enhancement in Volume Rendering", "year": "2013", "abstract": "We introduce a lighting system that enhances the visual cues in a rendered image for the perception of 3D volumetric objects. We divide the lighting effects into global and local effects, and deploy three types of directional lights: the key light and accessory lights (fill and detail lights). The key light provides both lighting effects and carries the visual cues for the perception of local and global shapes and depth. The cues for local shapes are conveyed by gradient; those for global shapes are carried by shadows; and those for depth are provided by shadows and translucent objects. Fill lights produce global effects to increase the perceptibility. Detail lights generate local effects to improve the cues for local shapes. Our method quantifies the perception and uses an exhaustive search to set the lights. It configures accessory lights with the consideration of preserving the global impression conveyed by the key light. It ensures the feeling of smooth light movements in animations. With simplification, it achieves interactive frame rates and produces results that are visually indistinguishable from results using the nonsimplified algorithm. The major contributions of this paper are our lighting system, perception measurement and lighting design algorithm with our indistinguishable simplification.", "keywords": ["lighting", "rendering (computer graphics)", "lighting system", "visual perception enhancement", "volume rendering", "rendered image", "3D volumetric objects", "key light", "accessory lights", "translucent objects", "fill lights", "interactive frame rates", "Lighting", "Shape", "Visualization", "Rendering (computer graphics)", "Three dimensional displays", "Casting", "Visual systems", "rendering (computer graphics)", "lighting", "interactive frame rates", "lighting system", "visual perception enhancement", "volume rendering", "rendered image", "3D volumetric objects", "key light", "accessory lights", "translucent objects", "fill lights", "Lighting", "Shape", "Visualization", "Rendering (computer graphics)", "Three dimensional displays", "Casting", "Visual systems", "spherical coordinate system", "Lighting design", "volume rendering", "light placement", "Algorithms", "Computer Graphics", "Humans", "Image Enhancement", "Imaging, Three-Dimensional", "Lighting", "User-Computer Interface", "Visual Perception", "Whole Body Imaging"], "referenced_by": ["IKEY:7064413", "IKEY:7156382", "IKEY:6634193", "IKEY:6671604", "IKEY:7320556", "IKEY:8440109", "10.1007/978-3-319-53838-9_13", "10.1111/cgf.12128", "10.1186/s12859-016-1177-4", "10.1371/journal.pone.0193636", "10.1007/978-3-319-16940-8_5"], "referencing": ["IKEY:1183785", "IKEY:1250395", "IKEY:1580454", "IKEY:511", "IKEY:5429594", "IKEY:1309213", "IKEY:1388231", "IKEY:5290740", "IKEY:1183785", "IKEY:1250395", "IKEY:1580454", "IKEY:511", "IKEY:5429594", "IKEY:1309213", "IKEY:1388231", "IKEY:5290740", "IKEY:1183785", "IKEY:1250395", "IKEY:1580454", "IKEY:511", "IKEY:5429594", "IKEY:1309213", "IKEY:1388231", "IKEY:5290740", "10.1145/280814.280950", "10.1145/258734.258887", "10.1145/566654.566617", "10.1145/1141911.1142015", "10.1145/1531326.1531331", "10.1145/1730804.1730827", "10.1145/280814.280950", "10.1145/258734.258887", "10.1145/566654.566617", "10.1145/1141911.1142015", "10.1145/1531326.1531331", "10.1145/1730804.1730827", "10.1145/280814.280950", "10.1145/258734.258887", "10.1145/566654.566617", "10.1145/1141911.1142015", "10.1145/1531326.1531331", "10.1145/1730804.1730827", "10.1016/B978-012240530-3/50005-5", "10.1037/0096-1523.16.1.3", "10.1068/p230169", "10.3758/BF03206757", "10.1364/JOSAA.14.003216", "10.1016/S1364-6613(98)01204-2", "10.1068/p5418", "10.1038/331163a0", "10.2307/2685263", "10.1111/1467-8659.00514", "10.1111/j.1467-8659.2009.01695.x", "10.1167/10.9.7", "10.1002/col.20230", "10.1017/CBO9780511984037.014", "10.1111/j.1467-8659.2011.01975.x", "10.1068/p120411", "10.1016/S0042-6989(01)00141-9", "10.1016/B978-012240530-3/50005-5", "10.1037/0096-1523.16.1.3", "10.1068/p230169", "10.3758/BF03206757", "10.1364/JOSAA.14.003216", "10.1016/S1364-6613(98)01204-2", "10.1068/p5418", "10.1038/331163a0", "10.2307/2685263", "10.1111/1467-8659.00514", "10.1111/j.1467-8659.2009.01695.x", "10.1167/10.9.7", "10.1002/col.20230", "10.1017/CBO9780511984037.014", "10.1111/j.1467-8659.2011.01975.x", "10.1068/p120411", "10.1016/S0042-6989(01)00141-9", "10.1016/B978-012240530-3/50005-5", "10.1037/0096-1523.16.1.3", "10.1068/p230169", "10.3758/BF03206757", "10.1364/JOSAA.14.003216", "10.1016/S1364-6613(98)01204-2", "10.1068/p5418", "10.1038/331163a0", "10.2307/2685263", "10.1111/1467-8659.00514", "10.1111/j.1467-8659.2009.01695.x", "10.1167/10.9.7", "10.1002/col.20230", "10.1017/CBO9780511984037.014", "10.1111/j.1467-8659.2011.01975.x", "10.1068/p120411", "10.1016/S0042-6989(01)00141-9"]}, "10.1109/TVCG.2012.25": {"doi": "10.1109/TVCG.2012.25", "author": ["J. Won", "Y. Jeon", "J. K. Rosenberg", "S. Yoon", "G. D. Rubin", "S. Napel"], "title": "Uncluttered Single-Image Visualization of Vascular Structures Using GPU and Integer Programming", "year": "2013", "abstract": "Direct projection of 3D branching structures, such as networks of cables, blood vessels, or neurons onto a 2D image creates the illusion of intersecting structural parts and creates challenges for understanding and communication. We present a method for visualizing such structures, and demonstrate its utility in visualizing the abdominal aorta and its branches, whose tomographic images might be obtained by computed tomography or magnetic resonance angiography, in a single 2D stylistic image, without overlaps among branches. The visualization method, termed uncluttered single-image visualization (USIV), involves optimization of geometry. This paper proposes a novel optimization technique that utilizes an interesting connection of the optimization problem regarding USIV to the protein structure prediction problem. Adopting the integer linear programming-based formulation for the protein structure prediction problem, we tested the proposed technique using 30 visualizations produced from five patient scans with representative anatomical variants in the abdominal aortic vessel tree. The novel technique can exploit commodity-level parallelism, enabling use of general-purpose graphics processing unit (GPGPU) technology that yields a significant speedup. Comparison of the results with the other optimization technique previously reported elsewhere suggests that, in most aspects, the quality of the visualization is comparable to that of the previous one, with a significant gain in the computation time of the algorithm.", "keywords": ["biomedical MRI", "computerised tomography", "data visualisation", "geometry", "graphics processing units", "integer programming", "linear programming", "medical image processing", "parallel processing", "proteins", "uncluttered single-image visualization", "vascular structures", "GPGPU technology", "general-purpose graphics processing unit technology", "commodity-level parallelism", "abdominal aortic vessel tree", "anatomical variants", "protein structure prediction problem", "geometry optimization technique", "USIV", "2D stylistic image", "magnetic resonance angiography", "computed tomography", "tomographic images", "abdominal aorta visualization", "structure visualization", "3D branching structures direct projection", "integer linear programming-based formulation", "GPU", "Visualization", "Three dimensional displays", "Biomedical imaging", "Optimization", "Context", "Solid modeling", "Graphics processing unit", "proteins", "biomedical MRI", "computerised tomography", "data visualisation", "geometry", "graphics processing units", "integer programming", "linear programming", "medical image processing", "parallel processing", "GPU", "uncluttered single-image visualization", "vascular structures", "GPGPU technology", "general-purpose graphics processing unit technology", "commodity-level parallelism", "abdominal aortic vessel tree", "anatomical variants", "protein structure prediction problem", "geometry optimization technique", "USIV", "2D stylistic image", "magnetic resonance angiography", "computed tomography", "tomographic images", "abdominal aorta visualization", "structure visualization", "3D branching structures direct projection", "integer linear programming-based formulation", "Visualization", "Three dimensional displays", "Biomedical imaging", "Optimization", "Context", "Solid modeling", "Graphics processing unit", "parallelization", "Single-image visualization", "abdominal aorta", "side-chain placement", "integer linear programming", "GPGPU", "CUDA", "Algorithms", "Angiography", "Aorta, Abdominal", "Computer Graphics", "Humans", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Numerical Analysis, Computer-Assisted", "Pattern Recognition, Automated", "Reproducibility of Results", "Sensitivity and Specificity", "Signal Processing, Computer-Assisted", "User-Computer Interface"], "referenced_by": ["10.1016/j.cag.2016.05.024", "10.1080/02522667.2014.932092"], "referencing": ["IKEY:4359318", "IKEY:1541995", "IKEY:1250353", "IKEY:1541292", "IKEY:1541338", "IKEY:5613471", "IKEY:1388568", "IKEY:4376196", "IKEY:5290768", "IKEY:1413501", "IKEY:964538", "IKEY:5473229", "IKEY:4359318", "IKEY:1541995", "IKEY:1250353", "IKEY:1541292", "IKEY:1541338", "IKEY:5613471", "IKEY:1388568", "IKEY:4376196", "IKEY:5290768", "IKEY:1413501", "IKEY:964538", "IKEY:5473229", "IKEY:4359318", "IKEY:1541995", "IKEY:1250353", "IKEY:1541292", "IKEY:1541338", "IKEY:5613471", "IKEY:1388568", "IKEY:4376196", "IKEY:5290768", "IKEY:1413501", "IKEY:964538", "IKEY:5473229", "10.1145/212332.212334", "10.1145/1399504.1360700", "10.1145/882262.882352", "10.1145/1279640.1279642", "10.1145/1080402.1080411", "10.1145/1377980.1377986", "10.1145/212332.212334", "10.1145/1399504.1360700", "10.1145/882262.882352", "10.1145/1279640.1279642", "10.1145/1080402.1080411", "10.1145/1377980.1377986", "10.1145/212332.212334", "10.1145/1399504.1360700", "10.1145/882262.882352", "10.1145/1279640.1279642", "10.1145/1080402.1080411", "10.1145/1377980.1377986", "10.1093/nar/28.1.235", "10.1093/bioinformatics/bti144", "10.1118/1.3243866", "10.1148/radiol.2231010441", "10.1038/253694a0", "10.1016/S0959-440X(99)80072-4", "10.1038/nsb0594-334", "10.1287/opre.1060.0360", "10.2307/3001968", "10.1201/EBK1439808184", "10.1007/978-3-540-31843-9_7", "10.1007/11851561_21", "10.1007/s11590-011-0308-0", "10.1093/nar/28.1.235", "10.1093/bioinformatics/bti144", "10.1118/1.3243866", "10.1148/radiol.2231010441", "10.1038/253694a0", "10.1016/S0959-440X(99)80072-4", "10.1038/nsb0594-334", "10.1287/opre.1060.0360", "10.2307/3001968", "10.1201/EBK1439808184", "10.1007/978-3-540-31843-9_7", "10.1007/11851561_21", "10.1007/s11590-011-0308-0", "10.1093/nar/28.1.235", "10.1093/bioinformatics/bti144", "10.1118/1.3243866", "10.1148/radiol.2231010441", "10.1038/253694a0", "10.1016/S0959-440X(99)80072-4", "10.1038/nsb0594-334", "10.1287/opre.1060.0360", "10.2307/3001968", "10.1201/EBK1439808184", "10.1007/978-3-540-31843-9_7", "10.1007/11851561_21", "10.1007/s11590-011-0308-0"]}, "10.1109/TVCG.2012.105": {"doi": "10.1109/TVCG.2012.105", "author": ["R. Maciejewski", "Y. Jang", "I. Woo", "H. J\u00e4nicke", "K. P. Gaither", "D. S. Ebert"], "title": "Abstracting Attribute Space for Transfer Function Exploration and Design", "year": "2013", "abstract": "Currently, user centered transfer function design begins with the user interacting with a one or two-dimensional histogram of the volumetric attribute space. The attribute space is visualized as a function of the number of voxels, allowing the user to explore the data in terms of the attribute size/magnitude. However, such visualizations provide the user with no information on the relationship between various attribute spaces (e.g., density, temperature, pressure, x, y, z) within the multivariate data. In this work, we propose a modification to the attribute space visualization in which the user is no longer presented with the magnitude of the attribute; instead, the user is presented with an information metric detailing the relationship between attributes of the multivariate volumetric data. In this way, the user can guide their exploration based on the relationship between the attribute magnitude and user selected attribute information as opposed to being constrained by only visualizing the magnitude of the attribute. We refer to this modification to the traditional histogram widget as an abstract attribute space representation. Our system utilizes common one and two-dimensional histogram widgets where the bins of the abstract attribute space now correspond to an attribute relationship in terms of the mean, standard deviation, entropy, or skewness. In this manner, we exploit the relationships and correlations present in the underlying data with respect to the dimension(s) under examination. These relationships are often times key to insight and allow us to guide attribute discovery as opposed to automatic extraction schemes which try to calculate and extract distinct attributes a priori. In this way, our system aids in the knowledge discovery of the interaction of properties within volumetric data.", "keywords": ["data mining", "data visualisation", "transfer functions", "user centred design", "volumetric attribute space abstraction", "transfer function exploration", "user centered transfer function design", "one-dimensional histogram", "two-dimensional histogram", "attribute space visualization", "information metric", "multivariate volumetric data", "attribute magnitude", "attribute information", "histogram widget", "abstract attribute space representation", "mean", "standard deviation", "entropy", "skewness", "attribute discovery", "automatic extraction schemes", "knowledge discovery", "Histograms", "Transfer functions", "Rendering (computer graphics)", "Measurement", "Data visualization", "Entropy", "Image color analysis", "user centred design", "data mining", "data visualisation", "transfer functions", "knowledge discovery", "volumetric attribute space abstraction", "transfer function exploration", "user centered transfer function design", "one-dimensional histogram", "two-dimensional histogram", "attribute space visualization", "information metric", "multivariate volumetric data", "attribute magnitude", "attribute information", "histogram widget", "abstract attribute space representation", "mean", "standard deviation", "entropy", "skewness", "attribute discovery", "automatic extraction schemes", "Histograms", "Transfer functions", "Rendering (computer graphics)", "Measurement", "Data visualization", "Entropy", "Image color analysis", "information theory", "Transfer function design", "volume rendering"], "referenced_by": ["IKEY:7013202", "IKEY:6875956", "IKEY:7423790", "IKEY:8019819", "IKEY:7296045", "IKEY:8119816", "IKEY:8265023", "IKEY:9006003", "10.1145/3152875", "10.1007/s40846-015-0027-6", "10.1016/B978-0-12-415873-3.00035-3", "10.1016/j.bspc.2014.12.002", "10.1111/cgf.12623", "10.1111/cgf.12755", "10.1111/cgf.12934", "10.1111/cgf.13183", "10.4258/hir.2019.25.4.297"], "referencing": ["IKEY:4658174", "IKEY:5429615", "IKEY:4658159", "IKEY:4015490", "IKEY:4658188", "IKEY:4906857", "IKEY:597796", "IKEY:1250402", "IKEY:1532858", "IKEY:964519", "IKEY:346327", "IKEY:558049", "IKEY:729588", "IKEY:511", "IKEY:663875", "IKEY:1250414", "IKEY:1250413", "IKEY:1703376", "IKEY:4658153", "IKEY:4906854", "IKEY:5290763", "IKEY:1250371", "IKEY:745289", "IKEY:4015446", "IKEY:4100933", "IKEY:4906833", "IKEY:981851", "IKEY:346302", "IKEY:4658123", "IKEY:4658174", "IKEY:5429615", "IKEY:4658159", "IKEY:4015490", "IKEY:4658188", "IKEY:4906857", "IKEY:597796", "IKEY:1250402", "IKEY:1532858", "IKEY:964519", "IKEY:346327", "IKEY:558049", "IKEY:729588", "IKEY:511", "IKEY:663875", "IKEY:1250414", "IKEY:1250413", "IKEY:1703376", "IKEY:4658153", "IKEY:4906854", "IKEY:5290763", "IKEY:1250371", "IKEY:745289", "IKEY:4015446", "IKEY:4100933", "IKEY:4906833", "IKEY:981851", "IKEY:346302", "IKEY:4658123", "IKEY:4658174", "IKEY:5429615", "IKEY:4658159", "IKEY:4015490", "IKEY:4658188", "IKEY:4906857", "IKEY:597796", "IKEY:1250402", "IKEY:1532858", "IKEY:964519", "IKEY:346327", "IKEY:558049", "IKEY:729588", "IKEY:511", "IKEY:663875", "IKEY:1250414", "IKEY:1250413", "IKEY:1703376", "IKEY:4658153", "IKEY:4906854", "IKEY:5290763", "IKEY:1250371", "IKEY:745289", "IKEY:4015446", "IKEY:4100933", "IKEY:4906833", "IKEY:981851", "IKEY:346302", "IKEY:4658123", "10.1145/258734.258887", "10.1145/1268517.1268563", "10.1145/258734.258887", "10.1145/1268517.1268563", "10.1145/258734.258887", "10.1145/1268517.1268563", "10.1111/j.1467-8659.2009.01697.x", "10.1111/j.1467-8659.2009.01478.x", "10.1111/j.1467-8659.2009.01689.x", "10.1016/S0167-9473(02)00286-4", "10.1111/j.1467-8659.2009.01697.x", "10.1111/j.1467-8659.2009.01478.x", "10.1111/j.1467-8659.2009.01689.x", "10.1016/S0167-9473(02)00286-4", "10.1111/j.1467-8659.2009.01697.x", "10.1111/j.1467-8659.2009.01478.x", "10.1111/j.1467-8659.2009.01689.x", "10.1016/S0167-9473(02)00286-4"]}, "10.1109/TVCG.2012.92": {"doi": "10.1109/TVCG.2012.92", "author": ["C. R. Butson", "G. Tamm", "S. Jain", "T. Fogal", "J. Kr\u00fcger"], "title": "Evaluation of Interactive Visualization on Mobile Computing Platforms for Selection of Deep Brain Stimulation Parameters", "year": "2013", "abstract": "In recent years, there has been significant growth in the use of patient-specific models to predict the effects of neuromodulation therapies such as deep brain stimulation (DBS). However, translating these models from a research environment to the everyday clinical workflow has been a challenge, primarily due to the complexity of the models and the expertise required in specialized visualization software. In this paper, we deploy the interactive visualization system ImageVis3D Mobile, which has been designed for mobile computing devices such as the iPhone or iPad, in an evaluation environment to visualize models of Parkinson's disease patients who received DBS therapy. Selection of DBS settings is a significant clinical challenge that requires repeated revisions to achieve optimal therapeutic response, and is often performed without any visual representation of the stimulation system in the patient. We used ImageVis3D Mobile to provide models to movement disorders clinicians and asked them to use the software to determine: 1) which of the four DBS electrode contacts they would select for therapy; and 2) what stimulation settings they would choose. We compared the stimulation protocol chosen from the software versus the stimulation protocol that was chosen via clinical practice (independent of the study). Lastly, we compared the amount of time required to reach these settings using the software versus the time required through standard practice. We found that the stimulation settings chosen using ImageVis3D Mobile were similar to those used in standard of care, but were selected in drastically less time. We show how our visualization system, available directly at the point of care on a device familiar to the clinician, can be used to guide clinical decision making for selection of DBS settings. In our view, the positive impact of the system could also translate to areas other than DBS.", "keywords": ["computational complexity", "data visualisation", "decision making", "diseases", "interactive systems", "mobile computing", "neurophysiology", "mobile computing platforms", "deep brain stimulation parameters", "patient-specific models", "neuromodulation therapies", "clinical workflow", "model complexity", "visualization software", "interactive visualization system", "ImageVis3D mobile", "iPhone", "iPad", "Parkinsons disease patients", "DBS therapy", "movement disorders clinicians", "DBS electrode contacts", "stimulation protocol", "clinical decision making", "Satellite broadcasting", "Mobile communication", "Mobile handsets", "Rendering (computer graphics)", "Electrodes", "Computational modeling", "Data visualization", "neurophysiology", "computational complexity", "data visualisation", "decision making", "diseases", "interactive systems", "mobile computing", "clinical decision making", "mobile computing platforms", "deep brain stimulation parameters", "patient-specific models", "neuromodulation therapies", "clinical workflow", "model complexity", "visualization software", "interactive visualization system", "ImageVis3D mobile", "iPhone", "iPad", "Parkinsons disease patients", "DBS therapy", "movement disorders clinicians", "DBS electrode contacts", "stimulation protocol", "Satellite broadcasting", "Mobile communication", "Mobile handsets", "Rendering (computer graphics)", "Electrodes", "Computational modeling", "Data visualization", "Parkinson's disease", "Biomedical and medical visualization", "mobile and ubiquitous visualization", "computational model", "clinical decision making", "Computer Graphics", "Computer Simulation", "Computers, Handheld", "Decision Support Systems, Clinical", "Deep Brain Stimulation", "Humans", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Models, Neurological", "Parkinson Disease", "Reproducibility of Results", "Sensitivity and Specificity", "Smartphone", "Therapy, Computer-Assisted", "Treatment Outcome", "User-Computer Interface"], "referenced_by": ["IKEY:7852825", "IKEY:7397213", "IKEY:6727579", "IKEY:7127751", "IKEY:7192682", "IKEY:7111373", "IKEY:8458201", "IKEY:8589390", "IKEY:9183509", "IKEY:9226510", "10.1145/2801040.2801057", "10.1007/s10916-014-0044-y", "10.1016/B978-0-12-415873-3.00035-3", "10.1016/j.brs.2015.06.005", "10.1016/j.clinph.2018.01.015", "10.1016/j.cobme.2017.09.001", "10.1016/j.compedu.2013.07.007", "10.1016/j.lfs.2017.06.001", "10.1016/j.nrl.2017.03.006", "10.1080/21681163.2016.1253505", "10.1111/ner.12372", "10.1155/2017/4074137", "10.1155/2017/8054939", "10.1155/2017/8492619", "10.1117/12.2043358", "10.1016/j.nrleng.2018.12.002", "10.1088/1741-2552/aae590", "10.1080/21681163.2018.1484817", "10.1002/ana.25567", "10.1080/14737175.2020.1700795", "10.1016/j.neurol.2020.02.009", "10.1007/978-3-030-43395-6_6"], "referencing": ["IKEY:1607948", "IKEY:650882", "IKEY:4069234", "IKEY:1607948", "IKEY:650882", "IKEY:4069234", "IKEY:1607948", "IKEY:650882", "IKEY:4069234", "10.1145/1050491.1050499", "10.1145/566570.566639", "10.1145/1178477.1178520", "10.1145/602330.602341", "10.1145/1050491.1050499", "10.1145/566570.566639", "10.1145/1178477.1178520", "10.1145/602330.602341", "10.1145/1050491.1050499", "10.1145/566570.566639", "10.1145/1178477.1178520", "10.1145/602330.602341", "10.1088/1741-2560/3/1/001", "10.1016/j.neuroimage.2006.09.034", "10.1016/j.neuroimage.2010.10.059", "10.1016/j.clinph.2005.10.007", "10.1016/j.clinph.2007.05.061", "10.1016/j.brs.2007.08.004", "10.1056/NEJMoa060281", "10.1093/brain/awp315", "10.1097/01376517-200508000-00006", "10.1136/jnnp.2007.126219", "10.1016/j.clinph.2003.10.033", "10.1371/journal.pone.0007974", "10.1007/978-3-211-33081-4_65", "10.1002/ana.21596", "10.1016/j.cmpb.2007.11.012", "10.1016/j.nurt.2007.11.003", "10.1001/jama.2008.929", "10.1088/1741-2560/3/1/001", "10.1016/j.neuroimage.2006.09.034", "10.1016/j.neuroimage.2010.10.059", "10.1016/j.clinph.2005.10.007", "10.1016/j.clinph.2007.05.061", "10.1016/j.brs.2007.08.004", "10.1056/NEJMoa060281", "10.1093/brain/awp315", "10.1097/01376517-200508000-00006", "10.1136/jnnp.2007.126219", "10.1016/j.clinph.2003.10.033", "10.1371/journal.pone.0007974", "10.1007/978-3-211-33081-4_65", "10.1002/ana.21596", "10.1016/j.cmpb.2007.11.012", "10.1016/j.nurt.2007.11.003", "10.1001/jama.2008.929", "10.1088/1741-2560/3/1/001", "10.1016/j.neuroimage.2006.09.034", "10.1016/j.neuroimage.2010.10.059", "10.1016/j.clinph.2005.10.007", "10.1016/j.clinph.2007.05.061", "10.1016/j.brs.2007.08.004", "10.1056/NEJMoa060281", "10.1093/brain/awp315", "10.1097/01376517-200508000-00006", "10.1136/jnnp.2007.126219", "10.1016/j.clinph.2003.10.033", "10.1371/journal.pone.0007974", "10.1007/978-3-211-33081-4_65", "10.1002/ana.21596", "10.1016/j.cmpb.2007.11.012", "10.1016/j.nurt.2007.11.003", "10.1001/jama.2008.929"]}, "10.1109/TVCG.2012.93": {"doi": "10.1109/TVCG.2012.93", "author": ["B. Sajadi", "A. Majumder", "M. M. Oliveira", "R. G. Schneider", "R. Raskar"], "title": "Using Patterns to Encode Color Information for Dichromats", "year": "2013", "abstract": "Color is one of the most common ways to convey information in visualization applications. Color vision deficiency (CVD) affects approximately 200 million individuals worldwide and considerably degrades their performance in understanding such contents by creating red-green or blue-yellow ambiguities. While several content-specific methods have been proposed to resolve these ambiguities, they cannot achieve this effectively in many situations for contents with a large variety of colors. More importantly, they cannot facilitate color identification. We propose a technique for using patterns to encode color information for individuals with CVD, in particular for dichromats. We present the first content-independent method to overlay patterns on colored visualization contents that not only minimizes ambiguities but also allows color identification. Further, since overlaying patterns does not compromise the underlying original colors, it does not hamper the perception of normal trichromats. We validated our method with two user studies: one including 11 subjects with CVD and 19 normal trichromats, and focused on images that use colors to represent multiple categories; and another one including 16 subjects with CVD and 22 normal trichromats, which considered a broader set of images. Our results show that overlaying patterns significantly improves the performance of dichromats in several color-based visualization tasks, making their performance almost similar to normal trichromats'. More interestingly, the patterns augment color information in a positive manner, allowing normal trichromats to perform with greater accuracy.", "keywords": ["colour vision", "data visualisation", "image coding", "image colour analysis", "color information encoding", "dichromats", "visualization applications", "color vision deficiency", "CVD", "red-green ambiguity", "blue-yellow ambiguity", "content-specific methods", "color identification", "content-independent method", "colored visualization contents", "normal trichromats", "color-based visualization tasks", "Image color analysis", "Visualization", "Three dimensional displays", "Color", "Computed tomography", "Data visualization", "image colour analysis", "colour vision", "data visualisation", "image coding", "color-based visualization tasks", "color information encoding", "dichromats", "visualization applications", "color vision deficiency", "CVD", "red-green ambiguity", "blue-yellow ambiguity", "content-specific methods", "color identification", "content-independent method", "colored visualization contents", "normal trichromats", "Image color analysis", "Visualization", "Three dimensional displays", "Color", "Computed tomography", "Data visualization", "color visualization", "Color vision deficiency", "visual aids", "patterns in visualization", "Algorithms", "Color", "Color Perception", "Color Vision Defects", "Colorimetry", "Computer Graphics", "Humans", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Information Storage and Retrieval"], "referenced_by": ["IKEY:8275998", "IKEY:6673983", "IKEY:7305807", "IKEY:8553352", "IKEY:8676282", "IKEY:8919209", "IKEY:8951983", "10.1145/2687923", "10.1145/2702123.2702578", "10.1145/2858036.2858220", "10.1145/3355089.3356534", "10.1145/2897824.2925878", "10.1145/3329118", "10.1007/978-3-319-54407-6_15", "10.1016/j.cag.2016.06.004", "10.1117/12.2075162", "10.1142/S0219467819500165", "10.3390/app10072381", "10.1364/BOE.405026", "10.1049/ipr2.12079"], "referencing": ["IKEY:1260745", "IKEY:773807", "IKEY:1398269", "IKEY:597794", "IKEY:689664", "IKEY:1298804", "IKEY:4658199", "IKEY:5290741", "IKEY:1438255", "IKEY:7759", "IKEY:1260745", "IKEY:773807", "IKEY:1398269", "IKEY:597794", "IKEY:689664", "IKEY:1298804", "IKEY:4658199", "IKEY:5290741", "IKEY:1438255", "IKEY:7759", "IKEY:1260745", "IKEY:773807", "IKEY:1398269", "IKEY:597794", "IKEY:689664", "IKEY:1298804", "IKEY:4658199", "IKEY:5290741", "IKEY:1438255", "IKEY:7759", "10.1145/1077399.1077408", "10.1145/566570.566649", "10.1145/966131.966135", "10.1145/508530.508546", "10.1145/1135777.1135944", "10.1145/1168987.1168996", "10.1145/566570.566648", "10.1145/237170.237288", "10.1145/311535.311605", "10.1145/383259.383328", "10.1145/237170.237286", "10.1145/192161.192185", "10.1145/258734.258890", "10.1145/508535.508537", "10.1145/237170.237285", "10.1145/1090785.1090815", "10.1145/192161.192184", "10.1145/237170.237287", "10.1145/1077399.1077408", "10.1145/566570.566649", "10.1145/966131.966135", "10.1145/508530.508546", "10.1145/1135777.1135944", "10.1145/1168987.1168996", "10.1145/566570.566648", "10.1145/237170.237288", "10.1145/311535.311605", "10.1145/383259.383328", "10.1145/237170.237286", "10.1145/192161.192185", "10.1145/258734.258890", "10.1145/508535.508537", "10.1145/237170.237285", "10.1145/1090785.1090815", "10.1145/192161.192184", "10.1145/237170.237287", "10.1145/1077399.1077408", "10.1145/566570.566649", "10.1145/966131.966135", "10.1145/508530.508546", "10.1145/1135777.1135944", "10.1145/1168987.1168996", "10.1145/566570.566648", "10.1145/237170.237288", "10.1145/311535.311605", "10.1145/383259.383328", "10.1145/237170.237286", "10.1145/192161.192185", "10.1145/258734.258890", "10.1145/508535.508537", "10.1145/237170.237285", "10.1145/1090785.1090815", "10.1145/192161.192184", "10.1145/237170.237287", "10.1364/JOSAA.14.002647", "10.1111/j.1467-8659.2009.01701.x", "10.1111/j.1467-8659.2005.00867.x", "10.1155/2008/487618", "10.1364/JOSAA.14.002647", "10.1111/j.1467-8659.2009.01701.x", "10.1111/j.1467-8659.2005.00867.x", "10.1155/2008/487618", "10.1364/JOSAA.14.002647", "10.1111/j.1467-8659.2009.01701.x", "10.1111/j.1467-8659.2005.00867.x", "10.1155/2008/487618"]}, "10.1109/TVCG.2012.64": {"doi": "10.1109/TVCG.2012.64", "author": ["R. Maciejewski", "A. Pattath", "S. Ko", "R. Hafen", "W. S. Cleveland", "D. S. Ebert"], "title": "Automated Box-Cox Transformations for Improved Visual Encoding", "year": "2013", "abstract": "The concept of preconditioning data (utilizing a power transformation as an initial step) for analysis and visualization is well established within the statistical community and is employed as part of statistical modeling and analysis. Such transformations condition the data to various inherent assumptions of statistical inference procedures, as well as making the data more symmetric and easier to visualize and interpret. In this paper, we explore the use of the Box-Cox family of power transformations to semiautomatically adjust visual parameters. We focus on time-series scaling, axis transformations, and color binning for choropleth maps. We illustrate the usage of this transformation through various examples, and discuss the value and some issues in semiautomatically using these transformations for more effective data visualization.", "keywords": ["data visualisation", "inference mechanisms", "statistical analysis", "time series", "automated box-cox transformations", "improved visual encoding", "data preconditioning", "statistical community", "statistical modeling", "statistical analysis", "statistical inference procedures", "time-series scaling", "axis transformations", "color binning", "choropleth maps", "data visualization", "Data visualization", "Visualization", "Histograms", "Gaussian distribution", "Transforms", "Image color analysis", "Hospitals", "time series", "data visualisation", "inference mechanisms", "statistical analysis", "data visualization", "automated box-cox transformations", "improved visual encoding", "data preconditioning", "statistical community", "statistical modeling", "statistical analysis", "statistical inference procedures", "time-series scaling", "axis transformations", "color binning", "choropleth maps", "Data visualization", "Visualization", "Histograms", "Gaussian distribution", "Transforms", "Image color analysis", "Hospitals", "normal distribution", "Data transformation", "color mapping", "statistical analysis", "Box-Cox"], "referenced_by": ["IKEY:7987172", "IKEY:7737925", "IKEY:8440116", "IKEY:8805443", "IKEY:8706590", "10.1145/2509108", "10.1007/s10109-013-0193-4", "10.1016/j.ijhcs.2016.03.009", "10.1080/00401706.2016.1156025", "10.1111/cgf.13210", "10.3390/w10111596", "10.2514/1.A34826"], "referencing": ["IKEY:1173157", "IKEY:4658150", "IKEY:5226628", "IKEY:1173157", "IKEY:4658150", "IKEY:5226628", "IKEY:1173157", "IKEY:4658150", "IKEY:5226628", "10.1145/1518701.1518897", "10.1145/1518701.1518897", "10.1145/1518701.1518897", "10.1179/000870403235002042", "10.2307/142412", "10.2307/213213", "10.1111/1467-8306.9303005", "10.1111/j.1467-8306.1969.tb00677.x", "10.1097/00124784-200411001-00013", "10.1111/1467-8306.00310", "10.2307/2288400", "10.1126/science.229.4716.828", "10.1002/9780470316948", "10.1016/0959-8049(96)00130-X", "10.1007/978-1-4899-3324-9", "10.1111/j.0033-0124.1986.00062.x", "10.1179/000870487787858995", "10.2307/270905", "10.1214/aoms/1177706875", "10.1007/978-1-4613-9154-8_15", "10.1179/000870403235002042", "10.2307/142412", "10.2307/213213", "10.1111/1467-8306.9303005", "10.1111/j.1467-8306.1969.tb00677.x", "10.1097/00124784-200411001-00013", "10.1111/1467-8306.00310", "10.2307/2288400", "10.1126/science.229.4716.828", "10.1002/9780470316948", "10.1016/0959-8049(96)00130-X", "10.1007/978-1-4899-3324-9", "10.1111/j.0033-0124.1986.00062.x", "10.1179/000870487787858995", "10.2307/270905", "10.1214/aoms/1177706875", "10.1007/978-1-4613-9154-8_15", "10.1179/000870403235002042", "10.2307/142412", "10.2307/213213", "10.1111/1467-8306.9303005", "10.1111/j.1467-8306.1969.tb00677.x", "10.1097/00124784-200411001-00013", "10.1111/1467-8306.00310", "10.2307/2288400", "10.1126/science.229.4716.828", "10.1002/9780470316948", "10.1016/0959-8049(96)00130-X", "10.1007/978-1-4899-3324-9", "10.1111/j.0033-0124.1986.00062.x", "10.1179/000870487787858995", "10.2307/270905", "10.1214/aoms/1177706875", "10.1007/978-1-4613-9154-8_15"]}, "10.1109/TVCG.2012.108": {"doi": "10.1109/TVCG.2012.108", "author": ["S. Tak", "A. Cockburn"], "title": "Enhanced Spatial Stability with Hilbert and Moore Treemaps", "year": "2013", "abstract": "Treemaps are a well known and powerful space-filling visualisation method for displaying hierarchical data. Many alternative treemap algorithms have been proposed, often with the aim being to optimise performance across several criteria, including spatial stability to assist users in locating and monitoring items of interest. In this paper, we demonstrate that spatial stability is not fully captured by the commonly used \"distance change\u201d (DC) metric, and we introduce a new \"location drift\u201d (LD) metric to more fully capture spatial stability. An empirical study examines the validity and usefulness of the location drift metric, showing that it explains some effects on user performance that distance change does not. Next, we introduce \"Hilbert\u201d and \"Moore\u201d treemap algorithms, which are designed to achieve high spatial stability. We assess their performance in comparison to other treemaps, showing that Hilbert and Moore treemaps perform well across all stability metrics.", "keywords": ["data visualisation", "trees (mathematics)", "enhanced spatial stability", "Hilbert treemaps", "Moore treemaps", "space-filling visualisation method", "hierarchical data", "distance change metric", "DC", "location drift metric", "LD", "Layout", "Measurement", "Stability criteria", "Algorithm design and analysis", "Gravity", "Monitoring", "trees (mathematics)", "data visualisation", "LD", "enhanced spatial stability", "Hilbert treemaps", "Moore treemaps", "space-filling visualisation method", "hierarchical data", "distance change metric", "DC", "location drift metric", "Layout", "Measurement", "Stability criteria", "Algorithm design and analysis", "Gravity", "Monitoring", "spatial stability", "Treemap", "space-filling curve"], "referenced_by": ["IKEY:7156360", "IKEY:6532285", "IKEY:6876003", "IKEY:6876012", "IKEY:8017575", "IKEY:8019841", "IKEY:8107964", "IKEY:7294397", "IKEY:8530135", "IKEY:8443124", "IKEY:8614324", "IKEY:8807213", "10.1051/matecconf/20165601007", "10.3390/info9050116", "10.1111/cgf.13446", "10.1007/978-3-030-41590-7_10", "10.1021/acs.jafc.0c01291"], "referencing": ["IKEY:1532132", "IKEY:963283", "IKEY:801860", "IKEY:5613436", "IKEY:175815", "IKEY:4376152", "IKEY:1532132", "IKEY:963283", "IKEY:801860", "IKEY:5613436", "IKEY:175815", "IKEY:4376152", "IKEY:1532132", "IKEY:963283", "IKEY:801860", "IKEY:5613436", "IKEY:175815", "IKEY:4376152", "10.1145/571647.571649", "10.1145/1056808.1056915", "10.1145/223355.223747", "10.1145/102377.115768", "10.1145/1056018.1056041", "10.1145/632716.632834", "10.1145/571647.571649", "10.1145/1056808.1056915", "10.1145/223355.223747", "10.1145/102377.115768", "10.1145/1056018.1056041", "10.1145/632716.632834", "10.1145/571647.571649", "10.1145/1056808.1056915", "10.1145/223355.223747", "10.1145/102377.115768", "10.1145/1056018.1056041", "10.1145/632716.632834", "10.1006/ijhc.2000.0420", "10.1007/978-3-7091-6783-0_4", "10.1007/BFb0036198", "10.1080/00107510500052444", "10.1006/ijhc.2000.0420", "10.1007/978-3-7091-6783-0_4", "10.1007/BFb0036198", "10.1080/00107510500052444", "10.1006/ijhc.2000.0420", "10.1007/978-3-7091-6783-0_4", "10.1007/BFb0036198", "10.1080/00107510500052444"]}, "10.1109/TVCG.2012.79": {"doi": "10.1109/TVCG.2012.79", "author": ["J. S. Zurdo", "J. P. Brito", "M. A. Otaduy"], "title": "Animating Wrinkles by Example on Non-Skinned Cloth", "year": "2013", "abstract": "The simulation of cloth with rich folds and wrinkles is a computationally expensive process. In this paper, we introduce an example-based algorithm for fast animation of plausible cloth wrinkles. Our algorithm does not depend on a character's pose, therefore it is valid for loose dresses, curtains, etc., not just cloth defined by skinning techniques. Central to our approach is a correspondence between low and high-resolution cloth deformations, both at the training and synthesis stages. Based on this correspondence, we define an algorithm for synthesizing cloth wrinkles as a function of the deformation of a low-resolution cloth and a set of example poses. We demonstrate the animation of plausible high-resolution wrinkles at high frame rates, suitable for interactive applications such as video games.", "keywords": ["clothing", "computer animation", "digital simulation", "wrinkle animation", "nonskinned cloth", "cloth simulation", "rich folds", "example-based algorithm", "plausible cloth wrinkles", "loose dresses", "curtains", "skinning techniques", "cloth deformations", "video games", "interactive applications", "Animation", "Computational modeling", "Vectors", "Training", "Strain", "Skin", "Measurement", "digital simulation", "clothing", "computer animation", "interactive applications", "wrinkle animation", "nonskinned cloth", "cloth simulation", "rich folds", "example-based algorithm", "plausible cloth wrinkles", "loose dresses", "curtains", "skinning techniques", "cloth deformations", "video games", "Animation", "Computational modeling", "Vectors", "Training", "Strain", "Skin", "Measurement", "pose-space deformation", "Cloth animation", "data-driven methods"], "referenced_by": ["IKEY:7924928", "IKEY:8103323", "IKEY:6797976", "10.1145/3072959.3073623", "10.1145/3028842.3028846", "10.1145/2766924", "10.1145/2601097.2601160", "10.1145/2601097.2601136", "10.1007/978-3-319-39601-9_26", "10.1016/j.cag.2013.07.007", "10.1111/cgf.12215", "10.1111/cgf.12346", "10.1111/cgf.12851", "10.1111/cgf.13004", "10.1201/b18154-30", "10.4271/2015-01-2578", "10.1007/978-3-319-91337-7_44", "10.1002/cav.1810", "10.1111/cgf.13643", "10.1177/1729881419848894", "10.1007/s11042-019-08532-x", "10.1007/s11042-020-09917-z", "10.1111/cgf.14109"], "referencing": ["IKEY:540491", "IKEY:809885", "IKEY:1146681", "IKEY:1167852", "IKEY:1500352", "IKEY:1309258", "IKEY:1335277", "IKEY:540491", "IKEY:809885", "IKEY:1146681", "IKEY:1167852", "IKEY:1500352", "IKEY:1309258", "IKEY:1335277", "IKEY:540491", "IKEY:809885", "IKEY:1146681", "IKEY:1167852", "IKEY:1500352", "IKEY:1309258", "IKEY:1335277", "10.1145/1401032.1401121", "10.1145/1778765.1778844", "10.1145/1409060.1409074", "10.1145/1882262.1866183", "10.1145/344779.344862", "10.1145/545282.545286", "10.1145/1028523.1028571", "10.1145/1141911.1141970", "10.1145/1276377.1276468", "10.1145/1399504.1360695", "10.1145/1778765.1778843", "10.1145/1778765.1778845", "10.1145/1964921.1964988", "10.1145/1275808.1276420", "10.1145/1360612.1360698", "10.1145/383259.383266", "10.1145/1275808.1276439", "10.1145/258734.258863", "10.1145/1401032.1401121", "10.1145/1778765.1778844", "10.1145/1409060.1409074", "10.1145/1882262.1866183", "10.1145/344779.344862", "10.1145/545282.545286", "10.1145/1028523.1028571", "10.1145/1141911.1141970", "10.1145/1276377.1276468", "10.1145/1399504.1360695", "10.1145/1778765.1778843", "10.1145/1778765.1778845", "10.1145/1964921.1964988", "10.1145/1275808.1276420", "10.1145/1360612.1360698", "10.1145/383259.383266", "10.1145/1275808.1276439", "10.1145/258734.258863", "10.1145/1401032.1401121", "10.1145/1778765.1778844", "10.1145/1409060.1409074", "10.1145/1882262.1866183", "10.1145/344779.344862", "10.1145/545282.545286", "10.1145/1028523.1028571", "10.1145/1141911.1141970", "10.1145/1276377.1276468", "10.1145/1399504.1360695", "10.1145/1778765.1778843", "10.1145/1778765.1778845", "10.1145/1964921.1964988", "10.1145/1275808.1276420", "10.1145/1360612.1360698", "10.1145/383259.383266", "10.1145/1275808.1276439", "10.1145/258734.258863", "10.1016/j.cag.2005.08.024", "10.1111/j.1467-8659.2006.00963.x", "10.1111/j.1467-8659.2007.01048.x", "10.1111/j.1467-8659.2009.01382.x", "10.1016/j.cag.2005.08.024", "10.1111/j.1467-8659.2006.00963.x", "10.1111/j.1467-8659.2007.01048.x", "10.1111/j.1467-8659.2009.01382.x", "10.1016/j.cag.2005.08.024", "10.1111/j.1467-8659.2006.00963.x", "10.1111/j.1467-8659.2007.01048.x", "10.1111/j.1467-8659.2009.01382.x"]}, "10.1109/TVCG.2012.107": {"doi": "10.1109/TVCG.2012.107", "author": ["F. Cosco", "C. Garre", "F. Bruno", "M. Muzzupappa", "M. A. Otaduy"], "title": "Visuo-Haptic Mixed Reality with Unobstructed Tool-Hand Integration", "year": "2013", "abstract": "Visuo-haptic mixed reality consists of adding to a real scene the ability to see and touch virtual objects. It requires the use of see-through display technology for visually mixing real and virtual objects, and haptic devices for adding haptic interaction with the virtual objects. Unfortunately, the use of commodity haptic devices poses obstruction and misalignment issues that complicate the correct integration of a virtual tool and the user's real hand in the mixed reality scene. In this work, we propose a novel mixed reality paradigm where it is possible to touch and see virtual objects in combination with a real scene, using commodity haptic devices, and with a visually consistent integration of the user's hand and the virtual tool. We discuss the visual obstruction and misalignment issues introduced by commodity haptic devices, and then propose a solution that relies on four simple technical steps: color-based segmentation of the hand, tracking-based segmentation of the haptic device, background repainting using image-based models, and misalignment-free compositing of the user's hand. We have developed a successful proof-of-concept implementation, where a user can touch virtual objects and interact with them in the context of a real scene, and we have evaluated the impact on user performance of obstruction and misalignment correction.", "keywords": ["haptic interfaces", "image segmentation", "visuo haptic mixed reality scene", "unobstructed tool hand integration", "touch virtual object", "see through display technology", "haptic interaction", "commodity haptic device", "virtual tool", "visual obstruction", "color based segmentation", "tracking based segmentation", "image based model", "misalignment correction", "Haptic interfaces", "Visualization", "Cameras", "Virtual reality", "Calibration", "Computational modeling", "Heuristic algorithms", "image segmentation", "haptic interfaces", "misalignment correction", "visuo haptic mixed reality scene", "unobstructed tool hand integration", "touch virtual object", "see through display technology", "haptic interaction", "commodity haptic device", "virtual tool", "visual obstruction", "color based segmentation", "tracking based segmentation", "image based model", "Haptic interfaces", "Visualization", "Cameras", "Virtual reality", "Calibration", "Computational modeling", "Heuristic algorithms", "image-based rendering", "Mixed reality", "visuo-haptic mixed reality", "occlusion handling", "haptic interfaces"], "referenced_by": ["10.1145/2702123.2702389", "10.1007/s00530-015-0488-z", "10.1007/s11042-016-3276-7", "10.1007/s11135-018-0694-9", "10.1186/s41074-017-0028-1", "10.3390/mti1030018", "10.1017/ATSIP.2018.13", "10.3390/app10020636", "10.1002/rcs.2120", "10.3390/app10155344", "10.1007/978-3-030-60703-6_27"], "referencing": ["10.1145/1255047.1255065", "10.1145/300523.300544", "10.1145/641489.641490", "10.1145/1400885.1400954", "10.1145/383259.383309", "10.1145/237170.237191", "10.1145/1255047.1255065", "10.1145/300523.300544", "10.1145/641489.641490", "10.1145/1400885.1400954", "10.1145/383259.383309", "10.1145/237170.237191", "10.1145/1255047.1255065", "10.1145/300523.300544", "10.1145/641489.641490", "10.1145/1400885.1400954", "10.1145/383259.383309", "10.1145/237170.237191", "10.1007/978-3-540-73281-5_70", "10.1111/1467-8659.t01-1-00706", "10.1037/0096-3445.121.1.95", "10.1007/978-3-540-73281-5_68", "10.1007/978-0-387-21779-6", "10.1007/s00371-010-0501-7", "10.1016/j.patcog.2006.06.010", "10.1111/1467-8659.1530011", "10.1016/S0097-8493(99)00107-7", "10.1115/1.3130144", "10.1117/12.349400", "10.1097/SIH.0b013e3181e9e783", "10.1007/978-3-540-69057-3_99", "10.1111/j.1467-8659.2009.01396.x", "10.1007/978-3-540-73281-5_70", "10.1111/1467-8659.t01-1-00706", "10.1037/0096-3445.121.1.95", "10.1007/978-3-540-73281-5_68", "10.1007/978-0-387-21779-6", "10.1007/s00371-010-0501-7", "10.1016/j.patcog.2006.06.010", "10.1111/1467-8659.1530011", "10.1016/S0097-8493(99)00107-7", "10.1115/1.3130144", "10.1117/12.349400", "10.1097/SIH.0b013e3181e9e783", "10.1007/978-3-540-69057-3_99", "10.1111/j.1467-8659.2009.01396.x", "10.1007/978-3-540-73281-5_70", "10.1111/1467-8659.t01-1-00706", "10.1037/0096-3445.121.1.95", "10.1007/978-3-540-73281-5_68", "10.1007/978-0-387-21779-6", "10.1007/s00371-010-0501-7", "10.1016/j.patcog.2006.06.010", "10.1111/1467-8659.1530011", "10.1016/S0097-8493(99)00107-7", "10.1115/1.3130144", "10.1117/12.349400", "10.1097/SIH.0b013e3181e9e783", "10.1007/978-3-540-69057-3_99", "10.1111/j.1467-8659.2009.01396.x"]}}