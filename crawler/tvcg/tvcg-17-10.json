{"10.1109/TVCG.2017.2738478": {"doi": "10.1109/TVCG.2017.2738478", "author": ["M. Otaduy"], "title": "Introduction to the Special Section on the ACM/Eurographics Symposium on Computer Animation 2016", "year": "2017", "abstract": "The papers in this special section were presented at the 15th Annual ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA 2016), which was held in Zurich, Switzerland on July 11-13, 2016. ", "keywords": ["Special issues and sections", "Meetings", "Animation", "Computational modeling", "Rendering (computer graphics)", "Computer graphics"], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2730202": {"doi": "10.1109/TVCG.2017.2730202", "author": ["D. Koschier", "C. Deul", "M. Brand", "J. Bender"], "title": "An hp-adaptive discretization algorithm for signed distance field generation", "year": "2017", "abstract": "In this paper we present an hp-adaptive algorithm to generate discrete higher-order polynomial Signed Distance Fields (SDFs) on axis-aligned hexahedral grids from manifold polygonal input meshes. Using an orthonormal polynomial basis, we efficiently fit the polynomials to the underlying signed distance function on each cell. The proposed error-driven construction algorithm is globally adaptive and iteratively refines the SDFs using either spatial subdivision (h-refinement) following an octree scheme or by cell-wise adaption of the polynomial approximation's degree (p-refinement). We further introduce a novel decision criterion based on an error-estimator in order to decide whether to apply por h-refinement. We demonstrate that our method is able to construct more accurate SDFs at significantly lower memory consumption compared to previous approaches. While the cell-wise polynomial approximation will result in highly accurate SDFs, it can not be guaranteed that the piecewise approximation is continuous over cell interfaces. Therefore, we propose an optimization-based post-processing step in order to weakly enforce continuity. Finally, we apply our generated SDFs as collision detector to the physically-based simulation of geometrically highly complex solid objects in order to demonstrate the practical relevance and applicability of our method.", "keywords": ["computer graphics", "optimisation", "polynomial approximation", "hp-adaptive discretization algorithm", "discrete higher-order polynomial signed distance fields", "SDF", "orthonormal polynomial basis", "error-driven construction algorithm", "polynomial approximation", "piecewise approximation", "optimization-based post-processing step", "Memory management", "Computational modeling", "Adaptation models", "Collision avoidance", "Animation", "Octrees", "Signed distance field", "adaptive discretization", "higher-order polynomials", "physically based simulation", "collision detection"], "referenced_by": ["10.1109/TVCG.2018.2859924", "10.1109/TVCG.2020.3004245"], "referencing": ["10.1109/TVCG.2006.56", "10.1109/VG.2005.194111", "10.1109/VISUAL.2004.37", "10.1109/TVCG.2007.20", "10.1109/TVCG.2014.2312013", "10.1109/TOH.2008.1", "10.1109/TVCG.2005.49", "10.1145/1185657.1185675", "10.1145/344779.344899", "10.1145/2448531.2448544", "10.1145/383259.383264", "10.1145/566654.566586", "10.1145/1278780.1278800", "10.1145/2185520.2185593", "10.1145/2010324.1964932", "10.1145/2629459", "10.1111/j.1467-8659.2011.02058.x", "10.1137/1036141", "10.1016/S0168-9274(99)00046-X", "10.1007/978-88-470-2089-4_58", "10.1016/j.finel.2016.07.001", "10.1016/j.cag.2014.07.004", "10.1002/cav.1614"]}, "10.1109/TVCG.2017.2730875": {"doi": "10.1109/TVCG.2017.2730875", "author": ["M. Overby", "G. E. Brown", "J. Li", "R. Narain"], "title": "ADMM $\\supseteq$ Projective Dynamics: Fast Simulation of Hyperelastic Models with Dynamic Constraints", "year": "2017", "abstract": "We apply the alternating direction method of multipliers (ADMM) optimization algorithm to implicit time integration of elastic bodies, and show that the resulting method closely relates to the recently proposed projective dynamics algorithm. However, as ADMM is a general purpose optimization algorithm applicable to a broad range of objective functions, it permits the use of nonlinear constitutive models and hard constraints while retaining the speed, parallelizability, and robustness of projective dynamics. We further extend the algorithm to improve the handling of dynamically changing constraints such as sliding and contact, while maintaining the benefits of a constant, prefactored system matrix. We demonstrate the benefits of our algorithm on several examples that include cloth, collisions, and volumetric deformable bodies with nonlinear elasticity and skin sliding effects.", "keywords": ["computer animation", "optimisation", "alternating direction method of multipliers optimization algorithm", "hyperelastic models", "dynamic constraints", "nonlinear constitutive models", "hard constraints", "prefactored system matrix", "computer graphics", "animation", "Heuristic algorithms", "Convex functions", "Optimization", "Dynamics", "Skin", "Robustness", "Convergence", "Computer graphics", "animation", "computer simulation", "optimization methods", "dynamics"], "referenced_by": ["10.1109/TIM.2019.2909247"], "referencing": ["10.1109/TVCG.2015.2459687", "10.1109/JSTSP.2011.2114324", "10.1109/TCNS.2015.2476198", "10.1145/2601097.2601116", "10.1145/2766917", "10.1145/2461912.2462018", "10.1145/2668064.2668089", "10.1145/37401.37427", "10.1145/280814.280821", "10.1145/2994258.2994282", "10.1145/2980179.2982437", "10.1145/2994258.2994272", "10.1145/2816795.2818063", "10.1145/2990496", "10.1145/2783258.2783400", "10.1145/2601097.2601147", "10.1145/1028523.1028541", "10.1145/3072959.3073705", "10.1111/j.1467-8659.2012.03031.x", "10.1111/cgf.12840", "10.1016/j.jvcir.2007.01.005", "10.1111/cgf.12346", "10.1561/2200000016", "10.1111/j.1467-8659.2012.03171.x", "10.1137/09076934X", "10.1137/13094671X", "10.1137/0329006", "10.1137/120896219", "10.1088/0266-5611/28/11/115010", "10.1137/140998135", "10.1561/2400000003", "10.1006/jcph.2002.7144", "10.1017/S0962492904000212", "10.1137/S0036142994273343", "10.1007/978-3-319-24208-8_42"]}, "10.1109/TVCG.2017.2706289": {"doi": "10.1109/TVCG.2017.2706289", "author": ["T. Yang", "R. R. Martin", "M. C. Lin", "J. Chang", "S. Hu"], "title": "Pairwise Force SPH Model for Real-Time Multi-Interaction Applications", "year": "2017", "abstract": "In this paper, we present a novel pairwise-force smoothed particle hydrodynamics (PF-SPH) model to enable simulation of various interactions at interfaces in real time. Realistic capture of interactions at interfaces is a challenging problem for SPH-based simulations, especially for scenarios involving multiple interactions at different interfaces. Our PF-SPH model can readily handle multiple types of interactions simultaneously in a single simulation; its basis is to use a larger support radius than that used in standard SPH. We adopt a novel anisotropic filtering term to further improve the performance of interaction forces. The proposed model is stable; furthermore, it avoids the particle clustering problem which commonly occurs at the free surface. We show how our model can be used to capture various interactions. We also consider the close connection between droplets and bubbles, and show how to animate bubbles rising in liquid as well as bubbles in air. Our method is versatile, physically plausible and easy-to-implement. Examples are provided to demonstrate the capabilities and effectiveness of our approach.", "keywords": ["computer graphics", "hydrodynamics", "novel pairwise-force smoothed particle hydrodynamics model", "PF-SPH model", "novel anisotropic filtering term", "computer graphics", "Liquids", "Computational modeling", "Atmospheric modeling", "Surface tension", "Force", "Solids", "Couplings", "Smoothed particle hydrodynamics (SPH)", "pairwise force", "surface tension", "bubble animation", "fluid simulation"], "referenced_by": [], "referencing": ["10.1109/TVCG.2012.87", "10.1145/2816795.2818117", "10.1145/1882261.1866197", "10.1145/2601097.2601146", "10.1145/1833349.1778785", "10.1145/2767003", "10.1145/1276377.1276500", "10.1145/2185520.2185557", "10.1145/1073368.1073402", "10.1145/2185520.2335413", "10.1145/2185520.2185559", "10.1145/1073368.1073400", "10.1103/PhysRevE.72.026301", "10.1016/j.advwatres.2013.09.014", "10.1007/s10596-015-9468-9", "10.1016/j.jcp.2015.08.037", "10.1002/1097-0363(20000615)33:3&lt;333::AID-FLD11&gt;3.0.CO;2-7", "10.1007/s00371-012-0697-9", "10.1007/s41095-015-0020-6", "10.1007/s00371-010-0531-1", "10.1002/cav.162", "10.1111/cgf.12467", "10.1006/jcph.2000.6439", "10.1016/j.jcp.2006.08.008", "10.1016/j.jcp.2005.09.001"]}, "10.1109/TVCG.2016.2620975": {"doi": "10.1109/TVCG.2016.2620975", "author": ["F. Sauer", "J. Xie", "K. Ma"], "title": "A Combined Eulerian-Lagrangian Data Representation for Large-Scale Applications", "year": "2017", "abstract": "The Eulerian and Lagrangian reference frames each provide a unique perspective when studying and visualizing results from scientific systems. As a result, many large-scale simulations produce data in both formats, and analysis tasks that simultaneously utilize information from both representations are becoming increasingly popular. However, due to their fundamentally different nature, drawing correlations between these data formats is a computationally difficult task, especially in a large-scale setting. In this work, we present a new data representation which combines both reference frames into a joint Eulerian-Lagrangian format. By reorganizing Lagrangian information according to the Eulerian simulation grid into a \u201cunit cell\u201d based approach, we can provide an efficient out-of-core means of sampling, querying, and operating with both representations simultaneously. We also extend this design to generate multi-resolution subsets of the full data to suit the viewer's needs and provide a fast flow-aware trajectory construction scheme. We demonstrate the effectiveness of our method using three large-scale real world scientific datasets and provide insight into the types of performance gains that can be achieved.", "keywords": ["data analysis", "data structures", "combined Eulerian-Lagrangian data representation", "Eulerian reference frames", "Lagrangian reference frames", "scientific systems", "Eulerian simulation grid", "unit cell based approach", "multiresolution subsets", "fast flow-aware trajectory construction scheme", "large-scale real world scientific datasets", "performance gains", "Data models", "Computational modeling", "Data visualization", "Analytical models", "Correlation", "Octrees", "Flow visualization", "particle data", "volume data", "multi-resolution", "large-scale data", "data structures"], "referenced_by": ["10.1109/TVCG.2019.2934335", "10.1109/TVCG.2019.2920130"], "referencing": ["10.1109/LDAV.2014.7013206", "10.1109/VISUAL.1997.663930", "10.1109/TVCG.2002.1021575", "10.1109/TVCG.2014.2346423", "10.1109/2945.646239", "10.1109/TVCG.2010.156", "10.1109/VISUAL.2004.55", "10.1109/TVCG.2012.274", "10.1109/TVCG.2009.142", "10.1109/MCG.2004.7", "10.1109/PACIFICVIS.2008.4475461", "10.1145/2485895.2485912", "10.1145/2487228.2487230", "10.1145/130881.130882", "10.1145/1507149.1507152", "10.1145/1362622.1362655", "10.1145/2493123.2462906", "10.1145/2600212.2600230", "10.1088/1742-6596/180/1/012036", "10.1016/j.proci.2010.06.147", "10.1080/01431160802558758", "10.1016/j.ocemod.2007.11.005", "10.1111/j.1467-8659.2009.01709.x", "10.1111/j.1467-8659.2011.01964.x"]}, "10.1109/TVCG.2016.2637904": {"doi": "10.1109/TVCG.2016.2637904", "author": ["C. Peng", "S. Sahani", "J. Rushing"], "title": "A GPU-Accelerated Approach for Feature Tracking in Time-Varying Imagery Datasets", "year": "2017", "abstract": "We propose a novel parallel connected component labeling (CCL) algorithm along with efficient out-of-core data management to detect and track feature regions of large time-varying imagery datasets. Our approach contributes to the big data field with parallel algorithms tailored for GPU architectures. We remove the data dependency between frames and achieve pixel-level parallelism. Due to the large size, the entire dataset cannot fit into cached memory. Frames have to be streamed through the memory hierarchy (disk to CPU main memory and then to GPU memory), partitioned, and processed as batches, where each batch is small enough to fit into the GPU. To reconnect the feature regions that are separated due to data partitioning, we present a novel batch merging algorithm to extract the region connection information across multiple batches in a parallel fashion. The information is organized in a memory-efficient structure and supports fast indexing on the GPU. Our experiment uses a commodity workstation equipped with a single GPU. The results show that our approach can efficiently process a weather dataset composed of terabytes of time-varying radar images. The advantages of our approach are demonstrated by comparing to the performance of an efficient CPU cluster implementation which is being used by the weather scientists.", "keywords": ["Big Data", "data analysis", "graphics processing units", "image processing", "parallel algorithms", "pattern clustering", "target tracking", "visual databases", "GPU-accelerated approach", "feature tracking", "CCL algorithm", "parallel connected component labeling", "out-of-core data management", "feature regions", "large time-varying imagery datasets", "big data field", "parallel algorithms", "GPU architectures", "pixel-level parallelism", "memory hierarchy", "data partitioning", "batch merging algorithm", "memory-efficient structure", "fast indexing", "commodity workstation", "weather dataset", "time-varying radar images", "cluster implementation", "weather scientists", "Graphics processing units", "Feature extraction", "Labeling", "Algorithm design and analysis", "Merging", "Computer architecture", "Meteorology", "Connected component labeling", "time-varying imagery feature detection", "GPGPU"], "referenced_by": ["10.1109/TIP.2018.2851445", "10.1109/TVCG.2017.2779501", "10.1109/ACCESS.2018.2879337", "10.1109/ACCESS.2019.2912647"], "referencing": ["10.1109/2.299407", "10.1109/VISUAL.1998.745288", "10.1109/VISUAL.2004.107", "10.1109/TVCG.2014.2346423", "10.1109/34.295913", "10.1109/83.951532", "10.1145/1365490.1365500", "10.1007/978-3-642-41914-0_21", "10.1016/j.patcog.2003.06.001", "10.1007/978-3-7091-6803-5_7", "10.1007/978-3-540-70823-0_4", "10.1016/j.parco.2010.07.002", "10.1016/S1077-3142(02)00030-9", "10.1007/s10044-008-0109-y", "10.1007/978-3-540-77220-0_21", "10.1175/1520-0477(1994)075&lt;0757:IGITFO&gt;2.0.CO;2"]}, "10.1109/TVCG.2016.2618797": {"doi": "10.1109/TVCG.2016.2618797", "author": ["P. Goffin", "J. Boy", "W. Willett", "P. Isenberg"], "title": "An Exploratory Study of Word-Scale Graphics in Data-Rich Text Documents", "year": "2017", "abstract": "We contribute an investigation of the design and function of word-scale graphics and visualizations embedded in text documents. Word-scale graphics include both data-driven representations such as word-scale visualizations and sparklines, and non-data-driven visual marks. Their design, function, and use has so far received little research attention. We present the results of an open ended exploratory study with nine graphic designers. The study resulted in a rich collection of different types of graphics, data provenance, and relationships between text, graphics, and data. Based on this corpus, we present a systematic overview of word-scale graphic designs, and examine how designers used them. We also discuss the designers' goals in creating their graphics, and characterize how they used word-scale graphics to visualize data, add emphasis, and create alternative narratives. Building on these examples, we discuss implications for the design of authoring tools for word-scale graphics and visualizations, and explore how new authoring environments could make it easier for designers to integrate them into documents.", "keywords": ["data visualisation", "text analysis", "word-scale graphics", "data-rich text documents", "data-driven representations", "word-scale visualizations", "sparklines", "data provenance", "Data visualization", "Visualization", "Europe", "Encyclopedias", "Electronic publishing", "Word-scale visualization", "word-scale graphic", "text visualization", "sparklines", "authoring tool", "information visualization"], "referenced_by": ["10.1109/TVCG.2017.2674958", "10.1109/TVCG.2018.2865119", "10.1109/TVCG.2018.2865142", "10.1109/MCSE.2018.2875316"], "referencing": ["10.1109/TVCG.2014.2346435", "10.1109/TVCG.2013.192", "10.1109/IV.2011.43", "10.1109/VL.1996.545307", "10.1109/TVCG.2013.210", "10.1109/TVCG.2015.2467732", "10.1145/2254556.2254636", "10.1145/2702123.2702275", "10.1145/2598510.2598566", "10.1111/cgf.12104", "10.1111/j.1540-5907.2011.00525.x", "10.1016/j.cag.2011.01.011", "10.1057/palgrave.ivs.9500025", "10.1007/978-3-540-33037-0_8", "10.1111/j.1468-2885.2010.01362.x", "10.1111/cgf.12936"]}, "10.1109/TVCG.2016.2617325": {"doi": "10.1109/TVCG.2016.2617325", "author": ["N. Kawai", "T. Sato", "Y. Nakashima", "N. Yokoya"], "title": "Augmented Reality Marker Hiding with Texture Deformation", "year": "2017", "abstract": "Augmented reality (AR) marker hiding is a technique to visually remove AR markers in a real-time video stream. A conventional approach transforms a background image with a homography matrix calculated on the basis of a camera pose and overlays the transformed image on an AR marker region in a real-time frame, assuming that the AR marker is on a planar surface. However, this approach may cause discontinuities in textures around the boundary between the marker and its surrounding area when the planar surface assumption is not satisfied. This paper proposes a method for AR marker hiding without discontinuities around texture boundaries even under nonplanar background geometry without measuring it. For doing this, our method estimates the dense motion in the marker's background by analyzing the motion of sparse feature points around it, together with a smooth motion assumption, and deforms the background image according to it. Our experiments demonstrate the effectiveness of the proposed method in various environments with different background geometries and textures.", "keywords": ["augmented reality", "image texture", "matrix algebra", "real-time systems", "video streaming", "augmented reality marker hiding", "texture deformation", "real-time video stream", "background image", "homography matrix", "camera pose", "AR marker region", "real-time frame", "sparse feature points", "background geometries", "background textures", "Geometry", "Real-time systems", "Streaming media", "Cameras", "Transforms", "Image reconstruction", "Transmission line matrix methods", "Marker hiding", "diminished reality", "texture deformation"], "referenced_by": ["10.1109/ISMAR-Adjunct.2018.00020", "10.1109/VR46266.2020.00036", "10.1109/TVCG.2020.3003768"], "referencing": ["10.1109/IWAR.1999.803809", "10.1109/ISMAR.2006.297831", "10.1109/ISMARW.2015.15", "10.1109/ISMAR.2009.5336492", "10.1109/ISMARW.2015.16", "10.1109/ISMAR.2010.5643572", "10.1109/TVCG.2014.2298016", "10.1109/TVCG.2015.2462368", "10.1109/ISMAR.2006.297805", "10.1145/1152399.1152412", "10.1145/237170.237191", "10.3169/mta.1.343", "10.2201/NiiPi.2010.7.3", "10.1007/978-3-642-15393-8_56", "10.1023/B:VISI.0000029664.99615.94", "10.1007/s11263-006-0017-9", "10.1007/978-3-642-01811-4_9", "10.1561/0600000052", "10.5244/C.2.23", "10.1016/j.cviu.2007.09.014"]}, "10.1109/TVCG.2016.2620467": {"doi": "10.1109/TVCG.2016.2620467", "author": ["Y. Li", "H. Xu", "J. Barbi\u010d"], "title": "Enriching Triangle Mesh Animations with Physically Based Simulation", "year": "2017", "abstract": "We present a system to combine arbitrary triangle mesh animations with physically based Finite Element Method (FEM) simulation, enabling control over the combination both in space and time. The input is a triangle mesh animation obtained using any method, such as keyframed animation, character rigging, 3D scanning, or geometric shape modeling. The input may be nonphysical, crude or even incomplete. The user provides weights, specified using a minimal user interface, for how much physically based simulation should be allowed to modify the animation in any region of the model, and in time. Our system then computes a physically-based animation that is constrained to the input animation to the amount prescribed by these weights. This permits smoothly turning physics on and off over space and time, making it possible for the output to strictly follow the input, to evolve purely based on physically based simulation, and anything in between. Achieving such results requires a careful combination of several system components. We propose and analyze these components, including proper automatic creation of simulation meshes (even for non-manifold and self-colliding undeformed triangle meshes), converting triangle mesh animations into animations of the simulation mesh, and resolving collisions and self-collisions while following the input.", "keywords": ["computer animation", "mesh generation", "triangle mesh animations", "physically based FEM simulation", "physically based finite element method simulation", "Animation", "Computational modeling", "Shape", "Finite element analysis", "Three-dimensional displays", "Dynamics", "Computer graphics", "animation", "physically based modeling", "animation system", "directable simulation", "FEM", "collisions"], "referenced_by": [], "referencing": ["10.1109/TVCG.2012.78", "10.1109/TVCG.2010.109", "10.1109/TVCG.2005.42", "10.1145/37402.37427", "10.1145/280814.280821", "10.1145/383259.383262", "10.1145/1028523.1028541", "10.1145/1073368.1073394", "10.1145/1073368.1073412", "10.1145/1360612.1360627", "10.1145/2185520.2185568", "10.1145/2485895.2485918", "10.1145/1276377.1276439", "10.1145/1882261.1866183", "10.1145/1576246.1531359", "10.1145/2185520.2185567", "10.1145/1073368.1073385", "10.1145/1457515.1409116", "10.1145/2185520.2185565", "10.1145/2185520.2185566", "10.1145/1477926.1477932", "10.1145/1900354.1900357", "10.1145/2816795.2818093", "10.1145/344779.344859", "10.1145/2343483.2343501", "10.1145/2461912.2461916", "10.1145/237170.237244", "10.1145/566654.566623", "10.1111/j.1467-8659.2007.01046.x", "10.1002/cav.1521", "10.1016/j.gmod.2014.10.002", "10.1111/cgf.12177", "10.1007/978-3-642-11615-5_7", "10.1016/j.cag.2014.09.006", "10.1007/978-3-642-14061-7_27", "10.1016/j.cag.2010.01.003", "10.1111/j.1467-8659.2012.03159.x", "10.1007/s007910050004", "10.1016/j.gmod.2005.01.004", "10.1002/nme.2318", "10.1002/nme.3016", "10.1111/j.1467-8659.2012.03230.x", "10.1111/cgf.12181"]}, "10.1109/TVCG.2016.2618875": {"doi": "10.1109/TVCG.2016.2618875", "author": ["X. Chen", "C. Zheng", "K. Zhou"], "title": "Example-Based Subspace Stress Analysis for Interactive Shape Design", "year": "2017", "abstract": "Stress analysis is a crucial tool for designing structurally sound shapes. However, the expensive computational cost has hampered its use in interactive shape editing tasks. We augment the existing example-based shape editing tools, and propose a fast subspace stress analysis method to enable stress-aware shape editing. In particular, we construct a reduced stress basis from a small set of shape exemplars and possible external forces. This stress basis is automatically adapted to the current user edited shape on the fly, and thereby offers reliable stress estimation. We then introduce a new finite element discretization scheme to use the reduced basis for fast stress analysis. Our method runs up to two orders of magnitude faster than the full-space finite element analysis, with average L2 estimation errors less than 2 percent and maximum L2 errors less than 6 percent. Furthermore, we build an interactive stress-aware shape editing tool to demonstrate its performance in practice.", "keywords": ["finite element analysis", "stress analysis", "text editing", "example-based subspace stress analysis", "interactive shape design", "expensive computational cost", "external forces", "finite element discretization scheme", "fast stress analysis", "full-space finite element analysis", "interactive stress-aware shape editing tool", "structurally sound shapes", "Shape", "Strain", "Tensile stress", "Indexes", "Computational modeling", "Fabrication", "Shape editing", "elastostatic stress analysis", "reduced stress basis", "finite element method", "shape deformation"], "referenced_by": [], "referencing": ["10.1109/SMI.2004.1314505", "10.1109/TVCG.2007.1054", "10.1145/2461912.2461967", "10.1145/2508363.2508382", "10.1145/2601097.2601168", "10.1145/344779.344862", "10.1145/1073204.1073218", "10.1145/1141911.1142011", "10.1145/1360612.1360628", "10.1145/2729972", "10.1145/15922.15903", "10.1145/1015706.1015772", "10.1145/258734.258863", "10.1145/280814.280831", "10.1145/1057432.1057456", "10.1145/1015706.1015774", "10.1145/2010324.1964967", "10.1145/1289603.1289608", "10.1145/2485895.2485904", "10.1145/2601097.2601181", "10.1145/1141911.1141962", "10.1145/2601097.2601217", "10.1145/2601097.2601156", "10.1145/1833349.1778806", "10.1145/2699648", "10.1145/2185520.2185582", "10.1145/2601097.2601189", "10.1145/2542355.2542361", "10.1145/2019627.2019638", "10.1145/1531326.1531357", "10.1145/1531326.1531358", "10.1145/2766889", "10.1145/1531326.1531339", "10.1145/2816795.2818089", "10.1016/j.cagd.2015.03.019", "10.1111/j.1467-8659.2007.01048.x", "10.1243/03093247V102063", "10.1007/s001580050100", "10.1016/j.cma.2008.01.025", "10.1016/0013-7944(95)00178-6"]}, "10.1109/TVCG.2016.2618878": {"doi": "10.1109/TVCG.2016.2618878", "author": ["Y. Nie", "Z. Zhang", "H. Sun", "T. Su", "G. Li"], "title": "Homography Propagation and Optimization for Wide-Baseline Street Image Interpolation", "year": "2017", "abstract": "Wide-baseline street image interpolation is useful but very challenging. Existing approaches either rely on heavyweight 3D reconstruction or computationally intensive deep networks. We present a lightweight and efficient method which uses simple homography computing and refining operators to estimate piecewise smooth homographies between input views. To achieve the goal, we show how to combine homography fitting and homography propagation together based on reliable and unreliable superpixel discrimination. Such a combination, other than using homography fitting only, dramatically increases the accuracy and robustness of the estimated homographies. Then, we integrate the concepts of homography and mesh warping, and propose a novel homography-constrained warping formulation which enforces smoothness between neighboring homographies by utilizing the first-order continuity of the warped mesh. This further eliminates small artifacts of overlapping, stretching, etc. The proposed method is lightweight and flexible, allows wide-baseline interpolation. It improves the state of the art and demonstrates that homography computation suffices for interpolation. Experiments on city and rural datasets validate the efficiency and effectiveness of our method.", "keywords": ["image reconstruction", "interpolation", "homography propagation", "wide-baseline street image interpolation", "heavyweight 3D reconstruction", "computationally intensive deep networks", "lightweight method", "homography computing", "refining operators", "homography fitting", "reliable superpixel discrimination", "unreliable superpixel discrimination", "mesh warping", "homography-constrained warping formulation", "first-order continuity", "Interpolation", "Optical imaging", "Robustness", "Three-dimensional displays", "Benchmark testing", "Adaptive optics", "Image interpolation", "street view synthesis", "homography propagation", "homography-constrained warping"], "referenced_by": ["10.1109/TIP.2017.2736603", "10.1109/ICASSP.2019.8683037", "10.1109/TIP.2019.2938086", "10.1109/ICSAI48974.2019.9010410"], "referencing": ["10.1109/TIP.2008.2010206", "10.1109/TIP.2013.2274731", "10.1109/MC.2010.170", "10.1109/TPAMI.2010.143", "10.1109/ICCV.2015.257", "10.1109/TCSVT.2014.2302379", "10.1109/TPAMI.2012.120", "10.1145/1870076.1870079", "10.1145/358669.358692", "10.1145/2461912.2461917", "10.1111/j.1467-8659.2008.01323.x", "10.1007/s11263-010-0390-2", "10.1111/j.1467-8659.2011.01981.x", "10.1016/0004-3702(81)90024-2", "10.1016/0734-189X(88)90059-X", "10.1007/s41095-016-0037-5", "10.1007/978-3-319-46493-0_18", "10.1007/s41095-015-0008-2", "10.1111/j.1467-8659.2009.01568.x"]}, "10.1109/TVCG.2016.2621763": {"doi": "10.1109/TVCG.2016.2621763", "author": ["X. Pan", "Y. Zhou", "F. Li", "C. Zhang"], "title": "Superpixels of RGB-D Images for Indoor Scenes Based on Weighted Geodesic Driven Metric", "year": "2017", "abstract": "Serving as a key step for applications of image processing, superpixel generation has been attracting increasing attention. RGB-D images are used pervasively in scenes reconstruction and representation, benefiting from their contained depth data. In this paper, we present a novel framework for generating superpixels focus on RGB-D images of indoor scenes, based on a weighted geodesic driven metric that combines both color and geometric information. In particular, taking into account the unique structures of indoor scenarios, we first denoise the given RGB-D image, and construct the corresponding triangular mesh. A new weighted geodesic driven metric is defined by introducing a weight function constrained with normal vectors and colors. Under this metric, an energy function is defined to measure our over-segmentation of the triangular mesh, by optimizing which, we can acquire an optimal oversegmentation of the triangular mesh with object boundaries respected, such that vertices in each sub-region have similar geometric structures and color intensities. Re-mapping the over-segmentation of the triangular mesh to the RGB-D image results in desired superpixels. We perform extensive experiments on a large-scale database of RGB-D images to verify the efficacy of our algorithm. The results show that our algorithm has considerable advantages over the existing state-of-the-art methods.", "keywords": ["image colour analysis", "image resolution", "image segmentation", "mesh generation", "RGB-D images", "indoor scenes", "superpixel generation", "weighted geodesic driven metric", "triangular mesh", "optimal oversegmentation", "image denoising", "Image color analysis", "Three-dimensional displays", "Two dimensional displays", "Euclidean distance", "Algorithm design and analysis", "Level measurement", "RGB-D images", "superpixels", "triangular mesh", "geodesic driven metric"], "referenced_by": ["10.1109/ICASSP.2019.8682701", "10.1145/3272127.3275097", "10.1142/S0218001418500234", "10.1111/cgf.13538", "10.1007/s00371-019-01682-x", "10.3390/rs12030473", "10.1007/s11042-020-09920-4"], "referencing": ["10.1109/ICRA.2012.6224766", "10.1109/ICCVW.2011.6130298", "10.1109/TPAMI.2012.120", "10.1109/ICCV.2005.112", "10.1109/34.1000236", "10.1109/TIP.2015.2501749", "10.1109/TIP.2014.2329776", "10.1109/ICRA.2014.6907778", "10.1109/CVPRW.2006.48", "10.1109/ICCV.2007.4408985", "10.1145/325165.325182", "10.1023/A:1011174803800", "10.1007/s11263-012-0588-6", "10.1073/pnas.95.15.8431", "10.1137/S0036144598347059", "10.1016/j.cad.2014.08.023", "10.1111/cgf.12486"]}, "10.1109/TVCG.2016.2628743": {"doi": "10.1109/TVCG.2016.2628743", "author": ["Y. Wang", "Y. Liu", "W. Heidrich", "Q. Dai"], "title": "The Light Field Attachment: Turning a DSLR into a Light Field Camera Using a Low Budget Camera Ring", "year": "2017", "abstract": "We propose a concept for a lens attachment that turns a standard DSLR camera and lens into a light field camera. The attachment consists of eight low-resolution, low-quality side cameras arranged around the central high-quality SLR lens. Unlike most existing light field camera architectures, this design provides a high-quality 2D image mode, while simultaneously enabling a new high-quality light field mode with a large camera baseline but little added weight, cost, or bulk compared with the base DSLR camera. From an algorithmic point of view, the high-quality light field mode is made possible by a new light field super-resolution method that first improves the spatial resolution and image quality of the side cameras and then interpolates additional views as needed. At the heart of this process is a super-resolution method that we call iterative PatchAnd Depth-based Synthesis (iPADS), which combines patch-based and depth-based synthesis in a novel fashion. Experimental results obtained for both real captured data and synthetic data confirm that our method achieves substantial improvements in super-resolution for side-view images as well as the high-quality and view-coherent rendering of dense and high-resolution light fields.", "keywords": ["image capture", "image resolution", "iterative methods", "photographic lenses", "rendering (computer graphics)", "light field attachment", "standard DSLR camera", "light field camera", "low budget camera ring", "low-quality side cameras", "low-resolution cameras", "central high-quality SLR lens", "high-quality 2D image mode", "algorithmic point of view", "light field super-resolution method", "spatial resolution", "image quality", "iterative patch-and depth-based synthesis", "iPADS", "real captured data", "synthetic data", "side-view images", "high-quality rendering", "view-coherent rendering", "high-resolution light fields", "Cameras", "Spatial resolution", "Lenses", "Tablet computers", "Prototypes", "Light field", "super-resolution", "computational imaging"], "referenced_by": ["10.1109/JSTSP.2017.2747126", "10.1109/ICCPHOT.2017.7951481", "10.1109/LSP.2018.2856619", "10.1109/TCI.2018.2838457", "10.1109/ICDSP.2018.8631859", "10.1109/TMM.2019.2934819", "10.1109/TPAMI.2019.2893666", "10.1109/TPAMI.2020.2987316", "10.1109/TIP.2020.3042064"], "referencing": ["10.1109/TPAMI.2013.147", "10.1109/CVPR.2011.5995372", "10.1109/TIP.2003.819861", "10.1145/344779.344929", "10.1145/2461912.2461937", "10.1145/237170.237199", "10.1145/237170.237200", "10.1145/1015706.1015806", "10.1145/1073204.1073259", "10.1145/2824840.2824845", "10.1145/1276377.1276463", "10.1145/237170.237191", "10.1145/383259.383309", "10.1145/2682631", "10.1038/nmeth.2964", "10.1117/12.524762"]}}