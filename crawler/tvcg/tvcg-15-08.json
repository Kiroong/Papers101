{"10.1109/TVCG.2015.2401025": {"doi": "10.1109/TVCG.2015.2401025", "author": ["A. van Goethem", "W. Meulemans", "B. Speckmann", "J. Wood"], "title": "Exploring Curved Schematization of Territorial Outlines", "year": "2015", "abstract": "Hand-drawn schematized maps traditionally make extensive use of curves. However, there are few automated approaches for curved schematization; most previous work focuses on straight lines. We present a new algorithm for area-preserving curved schematization of territorial outlines. Our algorithm converts a simple polygon into a schematic crossing-free representation using circular arcs. We use two basic operations to iteratively replace consecutive arcs until the desired complexity is reached. Our results are not restricted to arcs ending at input vertices. The method can be steered towards different degrees of \u201ccurviness\u201d: we can encourage or discourage the use of arcs with a large central angle via a single parameter. Our method creates visually pleasing results even for very low output complexities. To evaluate the effectiveness of our design choices, we present a geometric evaluation of the resulting schematizations. Besides the geometric qualities of our algorithm, we also investigate the potential of curved schematization as a concept. We conducted an online user study investigating the effectiveness of curved schematizations compared to straight-line schematizations. While the visual complexity of curved shapes was judged higher than that of straight-line shapes, users generally preferred curved schematizations. We observed that curves significantly improved the ability of users to match schematized shapes of moderate complexity to their unschematized equivalents.", "keywords": ["computational complexity", "computational geometry", "territorial outlines", "hand-drawn schematized maps", "area-preserving curved schematization", "polygons", "schematic crossing-free representation", "circular arcs", "input vertices", "curviness degrees", "central angle", "output complexities", "geometric evaluation", "geometric qualities", "visual complexity", "Shape", "Complexity theory", "Clocks", "Visualization", "Algorithm design and analysis", "Topology", "Accuracy", "Schematization", "circular arcs", "algorithm", "user study", "Schematization", "circular arcs", "algorithm", "user study"], "referenced_by": ["10.1080/13658816.2017.1306864"], "referencing": ["IKEY:6327283", "IKEY:6327280", "IKEY:6327281", "IKEY:6327283", "IKEY:6327280", "IKEY:6327281", "IKEY:6327283", "IKEY:6327280", "IKEY:6327281", "10.1145/2093973.2094009", "10.1145/1572614.1572617", "10.1145/2093973.2094009", "10.1145/1572614.1572617", "10.1145/2093973.2094009", "10.1145/1572614.1572617", "10.1111/j.1467-9280.2006.01759.x", "10.1559/152304098782383007", "10.1137/1.9781611971521.ch1", "10.1007/978-3-642-31125-3_21", "10.1016/j.comgeo.2007.10.009", "10.1007/978-3-642-25878-7_30", "10.1007/978-3-540-31843-9_46", "10.1179/1743277413Y.0000000066", "10.1142/S0218195908002593", "10.1007/978-3-540-70904-6_26", "10.7208/chicago/9780226029009.001.0001", "10.1007/11618058_29", "10.1016/j.patrec.2011.03.013", "10.1179/000870410X12825500202896", "10.1016/j.ijhcs.2012.09.004", "10.1016/j.comgeo.2005.01.004", "10.1167/10.2.18", "10.1179/caj.1993.30.1.46", "10.1111/j.1467-9280.2006.01759.x", "10.1559/152304098782383007", "10.1137/1.9781611971521.ch1", "10.1007/978-3-642-31125-3_21", "10.1016/j.comgeo.2007.10.009", "10.1007/978-3-642-25878-7_30", "10.1007/978-3-540-31843-9_46", "10.1179/1743277413Y.0000000066", "10.1142/S0218195908002593", "10.1007/978-3-540-70904-6_26", "10.7208/chicago/9780226029009.001.0001", "10.1007/11618058_29", "10.1016/j.patrec.2011.03.013", "10.1179/000870410X12825500202896", "10.1016/j.ijhcs.2012.09.004", "10.1016/j.comgeo.2005.01.004", "10.1167/10.2.18", "10.1179/caj.1993.30.1.46", "10.1111/j.1467-9280.2006.01759.x", "10.1559/152304098782383007", "10.1137/1.9781611971521.ch1", "10.1007/978-3-642-31125-3_21", "10.1016/j.comgeo.2007.10.009", "10.1007/978-3-642-25878-7_30", "10.1007/978-3-540-31843-9_46", "10.1179/1743277413Y.0000000066", "10.1142/S0218195908002593", "10.1007/978-3-540-70904-6_26", "10.7208/chicago/9780226029009.001.0001", "10.1007/11618058_29", "10.1016/j.patrec.2011.03.013", "10.1179/000870410X12825500202896", "10.1016/j.ijhcs.2012.09.004", "10.1016/j.comgeo.2005.01.004", "10.1167/10.2.18", "10.1179/caj.1993.30.1.46"]}, "10.1109/TVCG.2014.2371856": {"doi": "10.1109/TVCG.2014.2371856", "author": ["R. Krueger", "D. Thom", "T. Ertl"], "title": "Semantic Enrichment of Movement Behavior with Foursquare\u2013A Visual Analytics Approach", "year": "2015", "abstract": "In recent years, many approaches have been developed that efficiently and effectively visualize movement data, e.g., by providing suitable aggregation strategies to reduce visual clutter. Analysts can use them to identify distinct movement patterns, such as trajectories with similar direction, form, length, and speed. However, less effort has been spent on finding the semantics behind movements, i.e. why somebody or something is moving. This can be of great value for different applications, such as product usage and consumer analysis, to better understand urban dynamics, and to improve situational awareness. Unfortunately, semantic information often gets lost when data is recorded. Thus, we suggest to enrich trajectory data with POI information using social media services and show how semantic insights can be gained. Furthermore, we show how to handle semantic uncertainties in time and space, which result from noisy, unprecise, and missing data, by introducing a POI decision model in combination with highly interactive visualizations. Finally, we evaluate our approach with two case studies on a large electric scooter data set and test our model on data with known ground truth.", "keywords": ["data visualisation", "decision making", "geographic information systems", "mobile computing", "social networking (online)", "Foursquare", "visual analytics approach", "semantic movement behavior enrichment", "movement data visualization", "aggregation strategies", "visual clutter", "product usage", "consumer analysis", "urban dynamics", "situational awareness", "trajectory data", "POI information", "social media services", "POI decision model", "interactive visualizations", "electric scooter data", "Semantics", "Data visualization", "Trajectory", "Uncertainty", "Visualization", "Data models", "Context", "Visual Analytics", "Semantic Movement Analysis", "Social Media", "Geographic Visualization", "Foursquare", "Visual analytics", "semantic movement analysis", "social media", "geographic visualization", "foursquare"], "referenced_by": ["IKEY:7506246", "IKEY:7817741", "IKEY:7891950", "IKEY:8107989", "IKEY:8114626", "IKEY:8506366", "IKEY:8746762", "IKEY:8807274", "10.1145/3162076", "10.1007/s11042-016-4114-7", "10.1007/978-3-319-73247-3_10", "10.1080/13658816.2015.1049951", "10.4236/jsea.2017.104022", "10.1007/s12650-018-0531-1", "10.1111/cgf.13713", "10.1111/cgf.13211", "10.1007/s00779-019-01346-6", "10.1007/978-3-030-33698-1_9", "10.1080/13658816.2020.1778003", "10.3390/en13153936", "10.1126/sciadv.abb4112", "10.1080/13658816.2020.1823396", "10.1007/s41095-020-0191-7"], "referencing": ["IKEY:6787167", "IKEY:5290707", "IKEY:6634174", "IKEY:6065008", "IKEY:4658136", "IKEY:6787167", "IKEY:5290707", "IKEY:6634174", "IKEY:6065008", "IKEY:4658136", "IKEY:6787167", "IKEY:5290707", "IKEY:6634174", "IKEY:6065008", "IKEY:4658136", "10.1145/2501654.2501656", "10.1145/1341012.1341041", "10.1145/2424321.2424395", "10.1145/2108616.2108660", "10.1145/2536689.2536806", "10.1145/2505821.2505830", "10.1145/1951365.1951398", "10.1145/1526709.1526816", "10.1145/2501654.2501656", "10.1145/1341012.1341041", "10.1145/2424321.2424395", "10.1145/2108616.2108660", "10.1145/2536689.2536806", "10.1145/2505821.2505830", "10.1145/1951365.1951398", "10.1145/1526709.1526816", "10.1145/2501654.2501656", "10.1145/1341012.1341041", "10.1145/2424321.2424395", "10.1145/2108616.2108660", "10.1145/2536689.2536806", "10.1145/2505821.2505830", "10.1145/1951365.1951398", "10.1145/1526709.1526816", "10.1057/ivs.2008.29", "10.1111/cgf.12132", "10.1038/nature06958", "10.1007/s13218-012-0177-4", "10.1016/j.datak.2007.10.008", "10.1007/978-3-642-37583-5", "10.1559/1523040054738936", "10.1057/ivs.2008.29", "10.1111/cgf.12132", "10.1038/nature06958", "10.1007/s13218-012-0177-4", "10.1016/j.datak.2007.10.008", "10.1007/978-3-642-37583-5", "10.1559/1523040054738936", "10.1057/ivs.2008.29", "10.1111/cgf.12132", "10.1038/nature06958", "10.1007/s13218-012-0177-4", "10.1016/j.datak.2007.10.008", "10.1007/978-3-642-37583-5", "10.1559/1523040054738936"]}, "10.1109/TVCG.2014.2369036": {"doi": "10.1109/TVCG.2014.2369036", "author": ["R. Bujack", "I. Hotz", "G. Scheuermann", "E. Hitzer"], "title": "Moment Invariants for 2D Flow Fields via Normalization in Detail", "year": "2015", "abstract": "The analysis of 2D flow data is often guided by the search for characteristic structures with semantic meaning. One way to approach this question is to identify structures of interest by a human observer, with the goal of finding similar structures in the same or other datasets. The major challenges related to this task are to specify the notion of similarity and define respective pattern descriptors. While the descriptors should be invariant to certain transformations, such as rotation and scaling, they should provide a similarity measure with respect to other transformations, such as deformations. In this paper, we propose to use moment invariants as pattern descriptors for flow fields. Moment invariants are one of the most popular techniques for the description of objects in the field of image recognition. They have recently also been applied to identify 2D vector patterns limited to the directional properties of flow fields. Moreover, we discuss which transformations should be considered for the application to flow analysis. In contrast to previous work, we follow the intuitive approach of moment normalization, which results in a complete and independent set of translation, rotation, and scaling invariant flow field descriptors. They also allow to distinguish flow features with different velocity profiles. We apply the moment invariants in a pattern recognition algorithm to a real world dataset and show that the theoretical results can be extended to discrete functions in a robust way.", "keywords": ["flow visualisation", "image recognition", "pattern recognition algorithm", "moment normalization", "2D vector patterns", "image recognition", "pattern descriptors", "moment invariants", "2D flow fields", "Vectors", "Standards", "Pattern recognition", "Transforms", "Shape", "Electronic mail", "Convolution", "Moments", "Moment Invariants", "Pattern Recognition", "Flow Visualization", "Normalization", "Moments", "moment invariants", "pattern recognition", "flow visualization", "normalization"], "referenced_by": ["10.1007/978-3-319-61358-1_3", "10.1007/s00006-015-0620-3", "10.1186/s12880-018-0266-4", "10.1007/s12665-019-8800-4", "10.1007/978-3-030-34444-3_5"], "referencing": ["IKEY:4767594", "IKEY:5613498", "IKEY:1674832", "IKEY:1207439", "IKEY:1057692", "IKEY:6064972", "IKEY:1206702", "IKEY:1372195", "IKEY:4276078", "IKEY:4376210", "IKEY:4658165", "IKEY:3913", "IKEY:4767594", "IKEY:5613498", "IKEY:1674832", "IKEY:1207439", "IKEY:1057692", "IKEY:6064972", "IKEY:1206702", "IKEY:1372195", "IKEY:4276078", "IKEY:4376210", "IKEY:4658165", "IKEY:3913", "IKEY:4767594", "IKEY:5613498", "IKEY:1674832", "IKEY:1207439", "IKEY:1057692", "IKEY:6064972", "IKEY:1206702", "IKEY:1372195", "IKEY:4276078", "IKEY:4376210", "IKEY:4658165", "IKEY:3913", "10.1145/166117.166151", "10.1145/166117.166151", "10.1145/166117.166151", "10.1016/S0031-3203(99)00127-2", "10.1002/9780470684757", "10.1017/S0022112095000462", "10.1007/978-3-642-23175-9_14", "10.1007/978-3-642-14980-1_51", "10.1364/JOSA.70.000920", "10.1016/S0031-3203(99)00127-2", "10.1002/9780470684757", "10.1017/S0022112095000462", "10.1007/978-3-642-23175-9_14", "10.1007/978-3-642-14980-1_51", "10.1364/JOSA.70.000920", "10.1016/S0031-3203(99)00127-2", "10.1002/9780470684757", "10.1017/S0022112095000462", "10.1007/978-3-642-23175-9_14", "10.1007/978-3-642-14980-1_51", "10.1364/JOSA.70.000920"]}, "10.1109/TVCG.2015.2440250": {"doi": "10.1109/TVCG.2015.2440250", "author": ["P. Skraba", "B. Wang", "G. Chen", "P. Rosen"], "title": "Robustness-Based Simplification of 2D Steady and Unsteady Vector Fields", "year": "2015", "abstract": "Vector field simplification aims to reduce the complexity of the flow by removing features in order of their relevance and importance, to reveal prominent behavior and obtain a compact representation for interpretation. Most existing simplification techniques based on the topological skeleton successively remove pairs of critical points connected by separatrices, using distance or area-based relevance measures. These methods rely on the stable extraction of the topological skeleton, which can be difficult due to instability in numerical integration, especially when processing highly rotational flows. In this paper, we propose a novel simplification scheme derived from the recently introduced topological notion of robustness which enables the pruning of sets of critical points according to a quantitative measure of their stability, that is, the minimum amount of vector field perturbation required to remove them. This leads to a hierarchical simplification scheme that encodes flow magnitude in its perturbation metric. Our novel simplification algorithm is based on degree theory and has minimal boundary restrictions. Finally, we provide an implementation under the piecewise-linear setting and apply it to both synthetic and real-world datasets. We show local and complete hierarchical simplifications for steady as well as unsteady vector fields.", "keywords": ["computational fluid dynamics", "computational geometry", "flow visualisation", "piecewise linear techniques", "piecewise-linear setting", "flow magnitude", "hierarchical simplification scheme", "vector field perturbation", "topological notion", "rotational flows", "numerical integration", "topological skeleton", "robustness-based simplification", "2D unsteady vector field simplification", "Robustness", "Smoothing methods", "Skeleton", "Indexes", "Laplace equations", "Vegetation", "Complexity theory", "Flow visualization", "Vector field simplification,", "Robustness", "Computational topology", "Flow visualization", "vector field simplification", "robustness", "computational topology"], "referenced_by": ["IKEY:7422144", "IKEY:8630911", "IKEY:8801825", "IKEY:8805436", "10.1007/978-3-319-61358-1_1", "10.1007/s11390-016-1663-1", "10.1111/cgf.12933", "10.1016/j.advengsoft.2018.06.013", "10.1111/cgf.13693", "10.1007/978-3-030-43036-8_14"], "referencing": ["10.1145/1183287.1183290", "10.1145/882262.882290", "10.1145/1183287.1183290", "10.1145/882262.882290", "10.1145/1183287.1183290", "10.1145/882262.882290", "10.1007/978-3-540-70823-0_1", "10.1007/s00454-002-2885-2", "10.1007/978-3-662-05105-4_6", "10.1016/S0097-8493(00)00028-5", "10.1007/978-3-319-04099-8_3", "10.1007/s00454-003-2926-5", "10.1007/978-3-540-70823-0_3", "10.1017/CBO9781139106962.003", "10.1016/j.comgeo.2014.10.009", "10.1007/978-3-642-15014-2_3", "10.1016/j.aml.2012.01.046", "10.1007/s10208-011-9090-8", "10.1111/cgf.12109", "10.1016/S0925-7721(02)00093-7", "10.1007/s10652-009-9154-3", "10.1016/j.combustflame.2005.09.018", "10.1007/978-3-319-04099-8_2", "10.1111/j.1467-8659.2003.00723.x", "10.1007/978-3-540-70823-0_1", "10.1007/s00454-002-2885-2", "10.1007/978-3-662-05105-4_6", "10.1016/S0097-8493(00)00028-5", "10.1007/978-3-319-04099-8_3", "10.1007/s00454-003-2926-5", "10.1007/978-3-540-70823-0_3", "10.1017/CBO9781139106962.003", "10.1016/j.comgeo.2014.10.009", "10.1007/978-3-642-15014-2_3", "10.1016/j.aml.2012.01.046", "10.1007/s10208-011-9090-8", "10.1111/cgf.12109", "10.1016/S0925-7721(02)00093-7", "10.1007/s10652-009-9154-3", "10.1016/j.combustflame.2005.09.018", "10.1007/978-3-319-04099-8_2", "10.1111/j.1467-8659.2003.00723.x", "10.1007/978-3-540-70823-0_1", "10.1007/s00454-002-2885-2", "10.1007/978-3-662-05105-4_6", "10.1016/S0097-8493(00)00028-5", "10.1007/978-3-319-04099-8_3", "10.1007/s00454-003-2926-5", "10.1007/978-3-540-70823-0_3", "10.1017/CBO9781139106962.003", "10.1016/j.comgeo.2014.10.009", "10.1007/978-3-642-15014-2_3", "10.1016/j.aml.2012.01.046", "10.1007/s10208-011-9090-8", "10.1111/cgf.12109", "10.1016/S0925-7721(02)00093-7", "10.1007/s10652-009-9154-3", "10.1016/j.combustflame.2005.09.018", "10.1007/978-3-319-04099-8_2", "10.1111/j.1467-8659.2003.00723.x"]}, "10.1109/TVCG.2015.2407398": {"doi": "10.1109/TVCG.2015.2407398", "author": ["T. Ho", "Y. Xiao", "R. Feng", "C. Leung", "T. Wong"], "title": "All-Frequency Direct Illumination with Vectorized Visibility", "year": "2015", "abstract": "Many existing pre-computed radiance transfer (PRT) approaches for all-frequency lighting store the information of a 3D object in the pre-vertex manner. To preserve the fidelity of high frequency effects, the 3D object must be tessellated densely. Otherwise, rendering artifacts due to interpolation may appear. This paper presents an all-frequency lighting algorithm for direct illumination based on a new visibility representation which approximates a visibility function using a sequence of 3D vectors. The algorithm is able to construct the visibility function of an on-screen pixel on-the-fly. Hence even though the 3D object is not tessellated densely, the rendering artifacts can be suppressed greatly. Besides, a summed area table based rendering algorithm, which is able to handle the integration over a non-axis aligned polygon, is developed. Using our approach, we can rotate lighting environment, change view point, and adjust the shininess of the 3D object in a real-time manner. Experimental results show that our approach can render plausible all-frequency lighting effects for direct illumination in real-time, especially for specular shadows, which are difficult for other methods to obtain.", "keywords": ["interpolation", "lighting", "rendering (computer graphics)", "all-frequency direct illumination", "vectorized visibility", "precomputed radiance transfer", "PRT approach", "information store", "3D object", "fidelity preservation", "high-frequency effects", "artifact rendering", "interpolation", "all-frequency lighting algorithm", "direct illumination", "visibility representation", "visibility function", "3D vector sequence", "on-screen pixel", "summed area table based rendering algorithm", "lighting environment", "3D object shininess", "specular shadows", "Lighting", "Vectors", "Three-dimensional displays", "Rendering (computer graphics)", "Interpolation", "Educational institutions", "Approximation algorithms", "Pre-computed radiance transfer (PRT),", "Visibility functions", "all-frequency rendering", "Pre-computed radiance transfer (PRT)", "visibility functions", "all-frequency rendering"], "referenced_by": [], "referencing": ["IKEY:5708145", "IKEY:1608149", "IKEY:6244794", "IKEY:5708145", "IKEY:1608149", "IKEY:6244794", "IKEY:5708145", "IKEY:1608149", "IKEY:6244794", "10.1145/15886.15902", "10.1145/882262.882314", "10.1145/1015706.1015750", "10.1145/566654.566612", "10.1145/882262.882281", "10.1145/1141911.1141979", "10.1145/964965.808600", "10.1145/1015706.1015725", "10.1145/566654.566611", "10.1145/882262.882280", "10.1145/1138450.1138456", "10.1145/1141911.1141980", "10.1145/218380.218439", "10.1145/1141911.1141981", "10.1145/1275808.1276411", "10.1145/1409060.1409081", "10.1145/311535.311553", "10.1145/1073204.1073332", "10.1145/1360612.1360633", "10.1145/1661412.1618479", "10.1145/1073204.1073327", "10.1145/1187112.1187152", "10.1145/360825.360839", "10.1145/1409060.1409094", "10.1145/166117.166153", "10.1145/15886.15902", "10.1145/882262.882314", "10.1145/1015706.1015750", "10.1145/566654.566612", "10.1145/882262.882281", "10.1145/1141911.1141979", "10.1145/964965.808600", "10.1145/1015706.1015725", "10.1145/566654.566611", "10.1145/882262.882280", "10.1145/1138450.1138456", "10.1145/1141911.1141980", "10.1145/218380.218439", "10.1145/1141911.1141981", "10.1145/1275808.1276411", "10.1145/1409060.1409081", "10.1145/311535.311553", "10.1145/1073204.1073332", "10.1145/1360612.1360633", "10.1145/1661412.1618479", "10.1145/1073204.1073327", "10.1145/1187112.1187152", "10.1145/360825.360839", "10.1145/1409060.1409094", "10.1145/166117.166153", "10.1145/15886.15902", "10.1145/882262.882314", "10.1145/1015706.1015750", "10.1145/566654.566612", "10.1145/882262.882281", "10.1145/1141911.1141979", "10.1145/964965.808600", "10.1145/1015706.1015725", "10.1145/566654.566611", "10.1145/882262.882280", "10.1145/1138450.1138456", "10.1145/1141911.1141980", "10.1145/218380.218439", "10.1145/1141911.1141981", "10.1145/1275808.1276411", "10.1145/1409060.1409081", "10.1145/311535.311553", "10.1145/1073204.1073332", "10.1145/1360612.1360633", "10.1145/1661412.1618479", "10.1145/1073204.1073327", "10.1145/1187112.1187152", "10.1145/360825.360839", "10.1145/1409060.1409094", "10.1145/166117.166153", "10.1007/978-3-7091-6303-0_4", "10.1111/j.1467-8659.2012.03052.x", "10.1111/j.1467-8659.2006.00949.x", "10.1111/cgf.12257", "10.1111/j.1467-8659.2005.00880.x", "10.1007/978-3-7091-6303-0_4", "10.1111/j.1467-8659.2012.03052.x", "10.1111/j.1467-8659.2006.00949.x", "10.1111/cgf.12257", "10.1111/j.1467-8659.2005.00880.x", "10.1007/978-3-7091-6303-0_4", "10.1111/j.1467-8659.2012.03052.x", "10.1111/j.1467-8659.2006.00949.x", "10.1111/cgf.12257", "10.1111/j.1467-8659.2005.00880.x"]}, "10.1109/TVCG.2015.2410273": {"doi": "10.1109/TVCG.2015.2410273", "author": ["Y. Su", "Y. Chuang"], "title": "Disambiguating Stereoscopic Transparency Using a Thaumatrope Approach", "year": "2015", "abstract": "Volume rendering is a popular visualization technique for scientific computing and medical imaging. By assigning proper transparency, it allows us to see more information inside the volume. However, because volume rendering projects complex 3D structures into the 2D domain, the resultant visualization often suffers from ambiguity and its spatial relationship could be difficult to recognize correctly, especially when the scene or setting is highly transparent. Stereoscopic displays are not the rescue to the problem even though they add an additional dimension which seems helpful for resolving the ambiguity. This paper proposes a thaumatrope method to enhance 3D understanding with stereoscopic transparency for volume rendering. Our method first generates an additional cue with less spatial ambiguity by using a high opacity setting. To avoid cluttering the actual content, we only select its prominent feature for displaying. By alternating the actual content and the selected feature quickly, the viewer only perceives a whole volume while its spatial understanding has been enhanced. A user study was performed to compare the proposed method with the original stereoscopic volume rendering and the static combination of the actual content and the selected feature using a 3D display. Results show that the proposed thaumatrope approach provides better spatial understanding than compared approaches.", "keywords": ["data visualisation", "rendering (computer graphics)", "solid modelling", "stereo image processing", "three-dimensional displays", "stereoscopic transparency disambiguation", "thaumatrope approach", "volume rendering", "scientific computing", "medical imaging", "volume rendering projects complex 3D structures", "stereoscopic displays", "opacity setting", "stereoscopic volume rendering", "3D display", "Rendering (computer graphics)", "Stereo image processing", "Three-dimensional displays", "Visualization", "Transfer functions", "Data visualization", "Hardware", "Stereoscopic perception", "stereoscopic display", "volume rendering", "Stereoscopic perception", "stereoscopic display", "volume rendering"], "referenced_by": [], "referencing": ["IKEY:1372208", "IKEY:597794", "IKEY:5290740", "IKEY:6226392", "IKEY:1021579", "IKEY:4658153", "IKEY:5416704", "IKEY:4480769", "IKEY:1667676", "IKEY:1492264", "IKEY:1703376", "IKEY:109295", "IKEY:1372208", "IKEY:597794", "IKEY:5290740", "IKEY:6226392", "IKEY:1021579", "IKEY:4658153", "IKEY:5416704", "IKEY:4480769", "IKEY:1667676", "IKEY:1492264", "IKEY:1703376", "IKEY:109295", "IKEY:1372208", "IKEY:597794", "IKEY:5290740", "IKEY:6226392", "IKEY:1021579", "IKEY:4658153", "IKEY:5416704", "IKEY:4480769", "IKEY:1667676", "IKEY:1492264", "IKEY:1703376", "IKEY:109295", "10.1145/1462048.1462054", "10.1145/37401.37436", "10.1145/1077399.1077409", "10.1145/1276377.1276427", "10.1145/2010324.1964990", "10.1145/1015706.1015804", "10.1145/2159516.2159521", "10.1145/566654.566575", "10.1145/1778765.1778850", "10.1145/1462048.1462054", "10.1145/37401.37436", "10.1145/1077399.1077409", "10.1145/1276377.1276427", "10.1145/2010324.1964990", "10.1145/1015706.1015804", "10.1145/2159516.2159521", "10.1145/566654.566575", "10.1145/1778765.1778850", "10.1145/1462048.1462054", "10.1145/37401.37436", "10.1145/1077399.1077409", "10.1145/1276377.1276427", "10.1145/2010324.1964990", "10.1145/1015706.1015804", "10.1145/2159516.2159521", "10.1145/566654.566575", "10.1145/1778765.1778850", "10.1007/3DRes.01(2012)3", "10.3758/BF03210426", "10.1167/8.5.5", "10.1068/p040159", "10.1068/p240127", "10.1038/scientificamerican0474-90", "10.1111/j.1467-8659.2009.01464.x", "10.1111/j.1467-8659.2009.01695.x", "10.1364/AO.46.001244", "10.1111/j.1467-8659.2006.00979.x", "10.1006/cogp.1999.0715", "10.1016/0042-6989(94)90027-2", "10.1007/3DRes.01(2012)3", "10.3758/BF03210426", "10.1167/8.5.5", "10.1068/p040159", "10.1068/p240127", "10.1038/scientificamerican0474-90", "10.1111/j.1467-8659.2009.01464.x", "10.1111/j.1467-8659.2009.01695.x", "10.1364/AO.46.001244", "10.1111/j.1467-8659.2006.00979.x", "10.1006/cogp.1999.0715", "10.1016/0042-6989(94)90027-2", "10.1007/3DRes.01(2012)3", "10.3758/BF03210426", "10.1167/8.5.5", "10.1068/p040159", "10.1068/p240127", "10.1038/scientificamerican0474-90", "10.1111/j.1467-8659.2009.01464.x", "10.1111/j.1467-8659.2009.01695.x", "10.1364/AO.46.001244", "10.1111/j.1467-8659.2006.00979.x", "10.1006/cogp.1999.0715", "10.1016/0042-6989(94)90027-2"]}, "10.1109/TVCG.2015.2429576": {"doi": "10.1109/TVCG.2015.2429576", "author": ["W. Griffin", "M. Olano"], "title": "Evaluating Texture Compression Masking Effects Using Objective Image Quality Assessment Metrics", "year": "2015", "abstract": "Texture compression is widely used in real-time rendering to reduce storage and bandwidth requirements. Recent research in compression algorithms has explored both reduced fixed bit rate and variable bit rate algorithms. The results are evaluated at the individual texture level using mean square error, peak signal-to-noise ratio, or visual image inspection. We argue this is the wrong evaluation approach. Compression artifacts in individual textures are likely visually masked in final rendered images and this masking is not accounted for when evaluating individual textures. This masking comes from both geometric mapping of textures onto models and the effects of combining different textures on the same model such as diffuse, gloss, and bump maps. We evaluate final rendered images using rigorous perceptual error metrics. Our method samples the space of viewpoints in a scene, renders the scene from each viewpoint using variations of compressed textures, and then compares each to a ground truth using uncompressed textures from the same viewpoint. We show that masking has a significant effect on final rendered image quality, masking effects and perceptual sensitivity to masking varies by the type of texture, graphics hardware compression algorithms are too conservative, and reduced bit rates are possible while maintaining final rendered image quality.", "keywords": ["data compression", "image coding", "image texture", "rendering (computer graphics)", "texture compression masking effect evaluation", "objective image quality assessment metrics", "real-time rendering", "storage requirement reduction", "bandwidth requirement reduction", "compression algorithm", "fixed bit rate algorithm", "variable bit rate algorithms", "texture level", "mean square error", "peak signal-to-noise ratio", "visual image inspection", "compression artifacts", "visually masked textures", "geometric mapping", "diffusion maps", "gloss maps", "bump maps", "rendered images", "perceptual error metrics", "compressed texture variation", "ground truth", "uncompressed textures", "perceptual sensitivity", "graphics hardware compression algorithms", "reduced bit rates", "Measurement", "Image coding", "Image color analysis", "Image quality", "Rendering (computer graphics)", "Compression algorithms", "Graphics processing units", "MIP mapping", "bump maps", "texture compression", "image quality assessment", "MIP mapping", "bump maps", "texture compression", "image quality assessment"], "referenced_by": ["IKEY:8292880", "10.1145/2996296", "10.1145/3414685.3417787", "10.5626/JCSE.2016.10.2.68", "10.1111/cgf.13871"], "referencing": ["IKEY:1094560", "IKEY:1284395", "IKEY:1094560", "IKEY:1284395", "IKEY:1094560", "IKEY:1284395", "10.1145/1283900.1283918", "10.1145/258734.258818", "10.1145/1071866.1071877", "10.1145/353981.353995", "10.1145/641876.641879", "10.1145/237170.237276", "10.1145/1730804.1730834", "10.1145/285305.285310", "10.1145/1283900.1283918", "10.1145/258734.258818", "10.1145/1071866.1071877", "10.1145/353981.353995", "10.1145/641876.641879", "10.1145/237170.237276", "10.1145/1730804.1730834", "10.1145/285305.285310", "10.1145/1283900.1283918", "10.1145/258734.258818", "10.1145/1071866.1071877", "10.1145/353981.353995", "10.1145/641876.641879", "10.1145/237170.237276", "10.1145/1730804.1730834", "10.1145/285305.285310", "10.1111/j.1467-8659.2011.01989.x", "10.1111/j.1467-8659.2011.01989.x", "10.1111/j.1467-8659.2011.01989.x"]}, "10.1109/TVCG.2013.265": {"doi": "10.1109/TVCG.2013.265", "author": ["B. Duffy", "J. Thiyagalingam", "S. Walton", "D. J. Smith", "A. Trefethen", "J. C. Kirkman-Brown", "E. A. Gaffney", "M. Chen"], "title": "Glyph-Based Video Visualization for Semen Analysis", "year": "2015", "abstract": "The existing efforts in computer assisted semen analysis have been focused on high speed imaging and automated image analysis of sperm motility. This results in a large amount of data, and it is extremely challenging for both clinical scientists and researchers to interpret, compare and correlate the multidimensional and time-varying measurements captured from video data. In this work, we use glyphs to encode a collection of numerical measurements taken at a regular interval and to summarize spatio-temporal motion characteristics using static visual representations. The design of the glyphs addresses the needs for (a) encoding some 20 variables using separable visual channels, (b) supporting scientific observation of the interrelationships between different measurements and comparison between different sperm cells and their flagella, and (c) facilitating the learning of the encoding scheme by making use of appropriate visual abstractions and metaphors. As a case study, we focus this work on video visualization for computer-aided semen analysis, which has a broad impact on both biological sciences and medical healthcare. We demonstrate that glyph-based visualization can serve as a means of external memorization of video data as well as an overview of a large set of spatiotemporal measurements. It enables domain scientists to make scientific observation in a cost-effective manner by reducing the burden of viewing videos repeatedly, while providing them with a new visual representation for conveying semen statistics.", "keywords": ["bioinformatics", "cellular biophysics", "data visualisation", "video coding", "glyph-based video visualization", "computer-assisted semen analysis", "high-speed imaging", "automated image analysis", "sperm motility", "multidimensional time-varying measurements", "video data", "numerical measurements", "spatio-temporal motion characteristics", "static visual representations", "variable encoding", "separable visual channels", "sperm cells", "flagella", "encoding scheme learning", "visual abstractions", "metaphors", "video visualization", "external memorization", "spatiotemporal measurements", "visual representation", "semen statistics", "Data visualization", "Visualization", "Context", "Head", "Educational institutions", "Electronic mail", "Video visualization", "glyph visualization", "multivariate data", "semen analysis", "flagellum locomotion", "Algorithms", "Computer Graphics", "Humans", "Image Interpretation, Computer-Assisted", "Male", "Multivariate Analysis", "Semen Analysis", "Sperm Motility", "Sperm Tail", "Video Recording"], "referenced_by": ["IKEY:8440102", "IKEY:8781592", "IKEY:8846208", "IKEY:8585103", "10.1145/3162075", "10.1007/978-3-319-56895-9_8", "10.1007/s10586-017-0885-5", "10.1016/j.pbiomolbio.2014.07.009", "10.1177/1473871616686635", "10.1177/1473871616666395", "10.1111/cgf.12784", "10.5772/intechopen.76386", "10.1186/s13640-017-0175-4"], "referencing": ["10.1145/1357054.1357096", "10.1145/1291233.1291332", "10.1145/1141911.1141967", "10.1145/964696.964708", "10.1145/1357054.1357096", "10.1145/1291233.1291332", "10.1145/1141911.1141967", "10.1145/964696.964708", "10.1145/1357054.1357096", "10.1145/1291233.1291332", "10.1145/1141911.1141967", "10.1145/964696.964708", "10.1095/biolreprod60.1.32", "10.1002/cm.970050605", "10.3758/BF03198284", "10.1111/j.1467-8659.2012.03158.x", "10.1016/S0079-7421(08)60008-0", "10.1530/jrf.0.0750153", "10.1016/j.theriogenology.2008.05.056", "10.1111/j.1467-8659.2009.01429.x", "10.1098/rsif.2010.0136", "10.1016/0010-0285(76)90006-2", "10.3758/BF03212854", "10.1007/978-3-540-76858-6_33", "10.1111/j.1467-8659.2009.01670.x", "10.1071/RD07037", "10.1016/S0890-6238(99)00061-1", "10.1111/j.1439-0272.1973.tb00908.x", "10.1016/0169-2607(85)90002-1", "10.1016/0022-2496(75)90047-4", "10.1111/j.1467-8659.2004.00753.x", "10.1111/j.1467-8659.2012.03118.x", "10.1525/aa.1979.81.3.02a00040", "10.1093/humupd/3.5.403", "10.1016/0010-0285(75)90019-5", "10.1016/S0031-3203(96)00114-8", "10.1111/j.1467-8659.2003.00723.x", "10.1016/j.theriogenology.2011.02.003", "10.1016/j.cag.2011.01.011", "10.1016/0022-2496(64)90017-3", "10.1002/cm.20345", "10.1111/j.1439-0272.1998.tb01378.x", "10.1007/978-3-540-33037-0_8", "10.1057/palgrave.ivs.9500025", "10.1057/palgrave.ivs.9500024", "10.1095/biolreprod60.1.32", "10.1002/cm.970050605", "10.3758/BF03198284", "10.1111/j.1467-8659.2012.03158.x", "10.1016/S0079-7421(08)60008-0", "10.1530/jrf.0.0750153", "10.1016/j.theriogenology.2008.05.056", "10.1111/j.1467-8659.2009.01429.x", "10.1098/rsif.2010.0136", "10.1016/0010-0285(76)90006-2", "10.3758/BF03212854", "10.1007/978-3-540-76858-6_33", "10.1111/j.1467-8659.2009.01670.x", "10.1071/RD07037", "10.1016/S0890-6238(99)00061-1", "10.1111/j.1439-0272.1973.tb00908.x", "10.1016/0169-2607(85)90002-1", "10.1016/0022-2496(75)90047-4", "10.1111/j.1467-8659.2004.00753.x", "10.1111/j.1467-8659.2012.03118.x", "10.1525/aa.1979.81.3.02a00040", "10.1093/humupd/3.5.403", "10.1016/0010-0285(75)90019-5", "10.1016/S0031-3203(96)00114-8", "10.1111/j.1467-8659.2003.00723.x", "10.1016/j.theriogenology.2011.02.003", "10.1016/j.cag.2011.01.011", "10.1016/0022-2496(64)90017-3", "10.1002/cm.20345", "10.1111/j.1439-0272.1998.tb01378.x", "10.1007/978-3-540-33037-0_8", "10.1057/palgrave.ivs.9500025", "10.1057/palgrave.ivs.9500024", "10.1095/biolreprod60.1.32", "10.1002/cm.970050605", "10.3758/BF03198284", "10.1111/j.1467-8659.2012.03158.x", "10.1016/S0079-7421(08)60008-0", "10.1530/jrf.0.0750153", "10.1016/j.theriogenology.2008.05.056", "10.1111/j.1467-8659.2009.01429.x", "10.1098/rsif.2010.0136", "10.1016/0010-0285(76)90006-2", "10.3758/BF03212854", "10.1007/978-3-540-76858-6_33", "10.1111/j.1467-8659.2009.01670.x", "10.1071/RD07037", "10.1016/S0890-6238(99)00061-1", "10.1111/j.1439-0272.1973.tb00908.x", "10.1016/0169-2607(85)90002-1", "10.1016/0022-2496(75)90047-4", "10.1111/j.1467-8659.2004.00753.x", "10.1111/j.1467-8659.2012.03118.x", "10.1525/aa.1979.81.3.02a00040", "10.1093/humupd/3.5.403", "10.1016/0010-0285(75)90019-5", "10.1016/S0031-3203(96)00114-8", "10.1111/j.1467-8659.2003.00723.x", "10.1016/j.theriogenology.2011.02.003", "10.1016/j.cag.2011.01.011", "10.1016/0022-2496(64)90017-3", "10.1002/cm.20345", "10.1111/j.1439-0272.1998.tb01378.x", "10.1007/978-3-540-33037-0_8", "10.1057/palgrave.ivs.9500025", "10.1057/palgrave.ivs.9500024"]}}