{"10.1109/TVCG.2017.2709313": {"doi": "10.1109/TVCG.2017.2709313", "author": ["G. Capannini", "T. Larsson"], "title": "Adaptive Collision Culling for Massive Simulations by a Parallel and Context-Aware Sweep and Prune Algorithm", "year": "2018", "abstract": "We present an improved parallel Sweep and Prune algorithm that solves the dynamic box intersection problem in three dimensions. It scales up to very large datasets, which makes it suitable for broad phase collision detection in complex moving body simulations. Our algorithm gracefully handles high-density scenarios, including challenging clustering behavior, by using a double-axis sweeping approach and a cache-friendly succinct data structure. The algorithm is realized by three parallel stages for sorting, candidate generation, and object pairing. By the use of temporal coherence, our sorting stage runs with close to optimal load balancing. Furthermore, our approach is characterized by a work-division strategy that relies on adaptive partitioning, which leads to almost ideal scalability. In addition, for scenarios that involves intense clustering along several axes simultaneously, we propose an enhancement that increases the context-awareness of the algorithm. By exploiting information gathered along three orthogonal axes, an efficient choice of what range query to perform can be made per object during run-time. Experimental results show high performance for up to millions of objects on modern multi-core CPUs.", "keywords": ["computational geometry", "parallel algorithms", "pattern clustering", "query processing", "resource allocation", "tree data structures", "dynamic box intersection problem", "broad phase collision detection", "complex moving body simulations", "high-density scenarios", "cache-friendly succinct data structure", "object pairing", "optimal load balancing", "work-division strategy", "adaptive partitioning", "adaptive collision culling", "massive simulations", "parallel algorithm", "context-aware sweep and prune algorithm", "Sorting", "Data structures", "Computational modeling", "Heuristic algorithms", "Clustering algorithms", "Biological system modeling", "Testing", "Collision detection", "simulation", "parallel algorithms", "multicore processing", "multithreading", "tree data structures", "sorting"], "referenced_by": [], "referencing": ["IKEY:6225337", "IKEY:4359963", "IKEY:4414258", "IKEY:376615", "IKEY:6225337", "IKEY:4359963", "IKEY:4414258", "IKEY:376615", "IKEY:6225337", "IKEY:4359963", "IKEY:4414258", "IKEY:376615", "10.1145/199404.199437", "10.1145/231731.231732", "10.1145/1053427.1053457", "10.1145/361002.361007", "10.1145/1882261.1866180", "10.1145/2499913.2499918", "10.1145/2948628.2948640", "10.1145/1944745.1944756", "10.1145/199404.199437", "10.1145/231731.231732", "10.1145/1053427.1053457", "10.1145/361002.361007", "10.1145/1882261.1866180", "10.1145/2499913.2499918", "10.1145/2948628.2948640", "10.1145/1944745.1944756", "10.1145/199404.199437", "10.1145/231731.231732", "10.1145/1053427.1053457", "10.1145/361002.361007", "10.1145/1882261.1866180", "10.1145/2499913.2499918", "10.1145/2948628.2948640", "10.1145/1944745.1944756", "10.1006/jcph.2001.6858", "10.1016/0020-0190(92)90211-D", "10.1007/s11044-011-9246-y", "10.1016/j.comgeo.2010.04.008", "10.1016/j.matcom.2011.11.005", "10.1111/j.1467-8659.2005.00829.x", "10.1007/978-3-319-01020-5", "10.1007/978-1-4612-1098-6", "10.1016/j.cag.2006.02.011", "10.1007/978-981-287-134-3_9", "10.1111/j.1467-8659.2009.01556.x", "10.1016/j.gmod.2010.01.001", "10.1006/jcph.2001.6858", "10.1016/0020-0190(92)90211-D", "10.1007/s11044-011-9246-y", "10.1016/j.comgeo.2010.04.008", "10.1016/j.matcom.2011.11.005", "10.1111/j.1467-8659.2005.00829.x", "10.1007/978-3-319-01020-5", "10.1007/978-1-4612-1098-6", "10.1016/j.cag.2006.02.011", "10.1007/978-981-287-134-3_9", "10.1111/j.1467-8659.2009.01556.x", "10.1016/j.gmod.2010.01.001", "10.1006/jcph.2001.6858", "10.1016/0020-0190(92)90211-D", "10.1007/s11044-011-9246-y", "10.1016/j.comgeo.2010.04.008", "10.1016/j.matcom.2011.11.005", "10.1111/j.1467-8659.2005.00829.x", "10.1007/978-3-319-01020-5", "10.1007/978-1-4612-1098-6", "10.1016/j.cag.2006.02.011", "10.1007/978-981-287-134-3_9", "10.1111/j.1467-8659.2009.01556.x", "10.1016/j.gmod.2010.01.001"]}, "10.1109/TVCG.2017.2718514": {"doi": "10.1109/TVCG.2017.2718514", "author": ["S. D. Lynch", "R. Kulpa", "L. A. Meerhoff", "J. Pettr\u00e9", "A. Cr\u00e9tual", "A. Olivier"], "title": "Collision Avoidance Behavior between Walkers: Global and Local Motion Cues", "year": "2018", "abstract": "Daily activities require agents to interact with each other, such as during collision avoidance. The nature of visual information that is used for a collision free interaction requires further understanding. We aim to manipulate the nature of visual information in two forms, global and local information appearances. Sixteen healthy participants navigated towards a target in an immersive computer-assisted virtual environment (CAVE) using a joystick. A moving passive obstacle crossed the participant's trajectory perpendicularly at various pre-defined risks of collision distances. The obstacle was presented with one of five virtual appearances, associated to global motion cues (i.e., a cylinder or a sphere), or local motion cues (i.e., only the legs or the trunk). A full body virtual walker, showing both local and global motion cues, used as a reference condition. The final crossing distance was affected by the global motion appearances, however, appearance had no qualitative effect on motion adaptations. These findings contribute towards further understanding what information people use when interacting with others.", "keywords": ["collision avoidance", "interactive devices", "mobile robots", "motion control", "virtual reality", "information people", "collision avoidance behavior", "global motion cues", "local motion cues", "visual information", "collision free interaction", "global information appearances", "local information appearances", "sixteen healthy participants", "collision distances", "virtual appearances", "final crossing distance", "global motion appearances", "motion adaptations", "computer-assisted virtual environment", "joystick", "full body virtual walker", "passive obstacle moving", "Collision avoidance", "Visualization", "Legged locomotion", "Trajectory", "Apertures", "Virtual environments", "Locomotion", "interaction", "collision avoidance", "virtual reality", "motion perception"], "referenced_by": ["IKEY:8388190", "IKEY:8798204", "IKEY:8943608", "IKEY:8939374", "IKEY:9089637"], "referencing": ["IKEY:6479208", "IKEY:7014249", "IKEY:6479208", "IKEY:7014249", "IKEY:6479208", "IKEY:7014249", "10.1145/1833349.1778860", "10.1145/1227134.1227136", "10.1145/1077399.1077402", "10.1145/1833349.1778860", "10.1145/1227134.1227136", "10.1145/1077399.1077402", "10.1145/1833349.1778860", "10.1145/1227134.1227136", "10.1145/1077399.1077402", "10.1167/14.2.4", "10.1111/j.1467-8659.2012.03028.x", "10.3389/fpsyg.2015.01013", "10.1016/j.gaitpost.2006.08.012", "10.1016/j.gaitpost.2008.04.006", "10.1016/j.visres.2010.02.008", "10.1016/j.gaitpost.2012.03.021", "10.1016/j.gaitpost.2013.03.017", "10.1016/j.gaitpost.2012.08.003", "10.1371/journal.pone.0089589", "10.1037/xhp0000223", "10.1037/0033-295X.102.4.627", "10.1037/0096-1523.10.5.683", "10.1037/0096-1523.29.2.343", "10.1037/0033-295X.113.2.358", "10.1167/13.8.25", "10.1068/p050437", "10.1068/p5236", "10.1016/j.visres.2011.09.016", "10.1016/j.gaitpost.2016.09.022", "10.1016/j.gaitpost.2007.03.015", "10.1016/j.actpsy.2015.10.007", "10.1016/j.ijpsycho.2015.05.007", "10.1037/0096-1523.17.2.315", "10.1371/journal.pone.0037494", "10.1016/j.neulet.2014.08.022", "10.3758/BF03200735", "10.1201/9781410608888.pt1", "10.1068/p5144", "10.1162/105474605774785262", "10.1093/ageing/26.1.15", "10.1207/s15327108ijap0303_3", "10.1016/B978-012372560-8/50002-4", "10.1177/154193129503902006", "10.1167/14.2.4", "10.1111/j.1467-8659.2012.03028.x", "10.3389/fpsyg.2015.01013", "10.1016/j.gaitpost.2006.08.012", "10.1016/j.gaitpost.2008.04.006", "10.1016/j.visres.2010.02.008", "10.1016/j.gaitpost.2012.03.021", "10.1016/j.gaitpost.2013.03.017", "10.1016/j.gaitpost.2012.08.003", "10.1371/journal.pone.0089589", "10.1037/xhp0000223", "10.1037/0033-295X.102.4.627", "10.1037/0096-1523.10.5.683", "10.1037/0096-1523.29.2.343", "10.1037/0033-295X.113.2.358", "10.1167/13.8.25", "10.1068/p050437", "10.1068/p5236", "10.1016/j.visres.2011.09.016", "10.1016/j.gaitpost.2016.09.022", "10.1016/j.gaitpost.2007.03.015", "10.1016/j.actpsy.2015.10.007", "10.1016/j.ijpsycho.2015.05.007", "10.1037/0096-1523.17.2.315", "10.1371/journal.pone.0037494", "10.1016/j.neulet.2014.08.022", "10.3758/BF03200735", "10.1201/9781410608888.pt1", "10.1068/p5144", "10.1162/105474605774785262", "10.1093/ageing/26.1.15", "10.1207/s15327108ijap0303_3", "10.1016/B978-012372560-8/50002-4", "10.1177/154193129503902006", "10.1167/14.2.4", "10.1111/j.1467-8659.2012.03028.x", "10.3389/fpsyg.2015.01013", "10.1016/j.gaitpost.2006.08.012", "10.1016/j.gaitpost.2008.04.006", "10.1016/j.visres.2010.02.008", "10.1016/j.gaitpost.2012.03.021", "10.1016/j.gaitpost.2013.03.017", "10.1016/j.gaitpost.2012.08.003", "10.1371/journal.pone.0089589", "10.1037/xhp0000223", "10.1037/0033-295X.102.4.627", "10.1037/0096-1523.10.5.683", "10.1037/0096-1523.29.2.343", "10.1037/0033-295X.113.2.358", "10.1167/13.8.25", "10.1068/p050437", "10.1068/p5236", "10.1016/j.visres.2011.09.016", "10.1016/j.gaitpost.2016.09.022", "10.1016/j.gaitpost.2007.03.015", "10.1016/j.actpsy.2015.10.007", "10.1016/j.ijpsycho.2015.05.007", "10.1037/0096-1523.17.2.315", "10.1371/journal.pone.0037494", "10.1016/j.neulet.2014.08.022", "10.3758/BF03200735", "10.1201/9781410608888.pt1", "10.1068/p5144", "10.1162/105474605774785262", "10.1093/ageing/26.1.15", "10.1207/s15327108ijap0303_3", "10.1016/B978-012372560-8/50002-4", "10.1177/154193129503902006"]}, "10.1109/TVCG.2017.2708083": {"doi": "10.1109/TVCG.2017.2708083", "author": ["E. Molla", "H. G. Debarba", "R. Boulic"], "title": "Egocentric Mapping of Body Surface Constraints", "year": "2018", "abstract": "The relative location of human body parts often materializes the semantics of on-going actions, intentions and even emotions expressed, or performed, by a human being. However, traditional methods of performance animation fail to correctly and automatically map the semantics of performer postures involving self-body contacts onto characters with different sizes and proportions. Our method proposes an egocentric normalization of the body-part relative distances to preserve the consistency of self contacts for a large variety of human-like target characters. Egocentric coordinates are character independent and encode the whole posture space, i.e., it ensures the continuity of the motion with and without self-contacts. We can transfer classes of complex postures involving multiple interacting limb segments by preserving their spatial order without depending on temporal coherence. The mapping process exploits a low-cost constraint relaxation technique relying on analytic inverse kinematics; thus, we can achieve online performance animation. We demonstrate our approach on a variety of characters and compare it with the state of the art in online retargeting with a user study. Overall, our method performs better than the state of the art, especially when the proportions of the animated character deviate from those of the performer.", "keywords": ["biomechanics", "computer animation", "image motion analysis", "image segmentation", "pose estimation", "posture space", "complex postures", "multiple interacting limb segments", "mapping process", "low-cost constraint relaxation technique", "analytic inverse kinematics", "online performance animation", "egocentric mapping", "body surface constraints", "human body parts", "performer postures", "self-body contacts", "egocentric normalization", "body-part relative distances", "egocentric coordinates", "animated character deviation", "Avatars", "Calibration", "Surface morphology", "Animation", "Motion segmentation", "Surface treatment", "Semantics", "Motion retargeting", "online performance animation", "self-body contact", "inverse kinematics", "spatial relationship"], "referenced_by": ["IKEY:8283639"], "referencing": ["IKEY:637269", "IKEY:7029978", "IKEY:4535545", "IKEY:637269", "IKEY:7029978", "IKEY:4535545", "IKEY:637269", "IKEY:7029978", "IKEY:4535545", "10.1145/502122.502123", "10.1145/2503713.2503747", "10.1145/2503713.2503739", "10.1145/280814.280820", "10.1145/1360612.1360626", "10.1145/1778765.1778770", "10.1145/2671015.2671020", "10.1145/1201775.882285", "10.1145/2485895.2485903", "10.1145/2601097.2601181", "10.1145/2485895.2485905", "10.1145/2503177", "10.1145/2522628.2522649", "10.1145/2010324.1964972", "10.1145/502122.502123", "10.1145/2503713.2503747", "10.1145/2503713.2503739", "10.1145/280814.280820", "10.1145/1360612.1360626", "10.1145/1778765.1778770", "10.1145/2671015.2671020", "10.1145/1201775.882285", "10.1145/2485895.2485903", "10.1145/2601097.2601181", "10.1145/2485895.2485905", "10.1145/2503177", "10.1145/2522628.2522649", "10.1145/2010324.1964972", "10.1145/502122.502123", "10.1145/2503713.2503747", "10.1145/2503713.2503739", "10.1145/280814.280820", "10.1145/1360612.1360626", "10.1145/1778765.1778770", "10.1145/2671015.2671020", "10.1145/1201775.882285", "10.1145/2485895.2485903", "10.1145/2601097.2601181", "10.1145/2485895.2485905", "10.1145/2503177", "10.1145/2522628.2522649", "10.1145/2010324.1964972", "10.1037/10001-000", "10.1111/j.1467-8659.2005.00859.x", "10.1007/3-540-49384-0_3", "10.1002/1099-1778(200012)11:5&lt;223::AID-VIS236&gt;3.3.CO;2-X", "10.1111/cgf.12507", "10.1111/j.1467-8659.2009.01601.x", "10.1111/cgf.12816", "10.1111/j.1467-8659.2009.01369.x", "10.1007/978-3-642-34710-8_21", "10.1111/j.1467-8659.2012.03209.x", "10.1016/j.gmod.2008.03.002", "10.1006/gmod.2000.0528", "10.1002/cav.1560", "10.1111/cgf.12817", "10.1037/10001-000", "10.1111/j.1467-8659.2005.00859.x", "10.1007/3-540-49384-0_3", "10.1002/1099-1778(200012)11:5&lt;223::AID-VIS236&gt;3.3.CO;2-X", "10.1111/cgf.12507", "10.1111/j.1467-8659.2009.01601.x", "10.1111/cgf.12816", "10.1111/j.1467-8659.2009.01369.x", "10.1007/978-3-642-34710-8_21", "10.1111/j.1467-8659.2012.03209.x", "10.1016/j.gmod.2008.03.002", "10.1006/gmod.2000.0528", "10.1002/cav.1560", "10.1111/cgf.12817", "10.1037/10001-000", "10.1111/j.1467-8659.2005.00859.x", "10.1007/3-540-49384-0_3", "10.1002/1099-1778(200012)11:5&lt;223::AID-VIS236&gt;3.3.CO;2-X", "10.1111/cgf.12507", "10.1111/j.1467-8659.2009.01601.x", "10.1111/cgf.12816", "10.1111/j.1467-8659.2009.01369.x", "10.1007/978-3-642-34710-8_21", "10.1111/j.1467-8659.2012.03209.x", "10.1016/j.gmod.2008.03.002", "10.1006/gmod.2000.0528", "10.1002/cav.1560", "10.1111/cgf.12817"]}, "10.1109/TVCG.2017.2705182": {"doi": "10.1109/TVCG.2017.2705182", "author": ["P. K. Jayaraman", "C. Fu", "J. Zheng", "X. Liu", "T. Wong"], "title": "Globally Consistent Wrinkle-Aware Shading of Line Drawings", "year": "2018", "abstract": "Shading is a tedious process for artists involved in 2D cartoon and manga production given the volume of contents that the artists have to prepare regularly over tight schedule. While we can automate shading production with the presence of geometry, it is impractical for artists to model the geometry for every single drawing. In this work, we aim to automate shading generation by analyzing the local shapes, connections, and spatial arrangement of wrinkle strokes in a clean line drawing. By this, artists can focus more on the design rather than the tedious manual editing work, and experiment with different shading effects under different conditions. To achieve this, we have made three key technical contributions. First, we model five perceptual cues by exploring relevant psychological principles to estimate the local depth profile around strokes. Second, we formulate stroke interpretation as a global optimization model that simultaneously balances different interpretations suggested by the perceptual cues and minimizes the interpretation discrepancy. Lastly, we develop a wrinkle-aware inflation method to generate a height field for the surface to support the shading region computation. In particular, we enable the generation of two commonly-used shading styles: 3D-like soft shading and manga-style flat shading.", "keywords": ["art", "computational geometry", "computer animation", "computer graphics", "rendering (computer graphics)", "manga-style flat shading", "globally consistent wrinkle-aware shading", "line drawings", "manga production", "tight schedule", "shading production", "shading generation", "local shapes", "spatial arrangement", "wrinkle strokes", "perceptual cues", "local depth profile", "stroke interpretation", "global optimization model", "wrinkle-aware inflation method", "shading region computation", "shading styles", "soft shading", "2D cartoon", "Geometry", "Two dimensional displays", "Three-dimensional displays", "Shape", "Production", "Image reconstruction", "Optimization", "Shading", "perception", "inflation", "manga", "cartoon"], "referenced_by": [], "referencing": ["10.1145/566282.566310", "10.1145/311535.311602", "10.1145/1276377.1276429", "10.1145/1661412.1618494", "10.1145/2591011", "10.1145/508530.508538", "10.1145/2185520.2185541", "10.1145/2710026", "10.1145/1015706.1015768", "10.1145/882262.882354", "10.1145/258734.258894", "10.1145/344779.345074", "10.1145/1399504.1360687", "10.1145/2601097.2601128", "10.1145/2766948", "10.1145/1141911.1141928", "10.1145/2442080.2442083", "10.1145/2749458", "10.1145/1275808.1276432", "10.1145/1457515.1409108", "10.1145/1576246.1531334", "10.1145/2508363.2508396", "10.1145/2024156.2024219", "10.1145/2816795.2818067", "10.1145/311535.311576", "10.1145/2516971.2516977", "10.1145/566282.566310", "10.1145/311535.311602", "10.1145/1276377.1276429", "10.1145/1661412.1618494", "10.1145/2591011", "10.1145/508530.508538", "10.1145/2185520.2185541", "10.1145/2710026", "10.1145/1015706.1015768", "10.1145/882262.882354", "10.1145/258734.258894", "10.1145/344779.345074", "10.1145/1399504.1360687", "10.1145/2601097.2601128", "10.1145/2766948", "10.1145/1141911.1141928", "10.1145/2442080.2442083", "10.1145/2749458", "10.1145/1275808.1276432", "10.1145/1457515.1409108", "10.1145/1576246.1531334", "10.1145/2508363.2508396", "10.1145/2024156.2024219", "10.1145/2816795.2818067", "10.1145/311535.311576", "10.1145/2516971.2516977", "10.1145/566282.566310", "10.1145/311535.311602", "10.1145/1276377.1276429", "10.1145/1661412.1618494", "10.1145/2591011", "10.1145/508530.508538", "10.1145/2185520.2185541", "10.1145/2710026", "10.1145/1015706.1015768", "10.1145/882262.882354", "10.1145/258734.258894", "10.1145/344779.345074", "10.1145/1399504.1360687", "10.1145/2601097.2601128", "10.1145/2766948", "10.1145/1141911.1141928", "10.1145/2442080.2442083", "10.1145/2749458", "10.1145/1275808.1276432", "10.1145/1457515.1409108", "10.1145/1576246.1531334", "10.1145/2508363.2508396", "10.1145/2024156.2024219", "10.1145/2816795.2818067", "10.1145/311535.311576", "10.1145/2516971.2516977", "10.1016/0004-3702(73)90003-9", "10.1007/BF00128527", "10.1016/0010-4485(95)00081-X", "10.1111/j.1467-8659.2011.01966.x", "10.1016/j.cag.2008.09.013", "10.1111/j.1467-8659.2007.01083.x", "10.1111/cgf.12496", "10.1111/cgf.12536", "10.1111/j.1467-8659.2009.01631.x", "10.1016/j.cag.2015.05.026", "10.1007/978-3-319-24523-2_5", "10.1016/0004-3702(81)90020-5", "10.1068/p130321", "10.1364/JOSAA.9.001449", "10.1017/S0962492900002518", "10.1007/BFb0014497", "10.1007/978-3-662-05105-4_2", "10.1016/0004-3702(73)90003-9", "10.1007/BF00128527", "10.1016/0010-4485(95)00081-X", "10.1111/j.1467-8659.2011.01966.x", "10.1016/j.cag.2008.09.013", "10.1111/j.1467-8659.2007.01083.x", "10.1111/cgf.12496", "10.1111/cgf.12536", "10.1111/j.1467-8659.2009.01631.x", "10.1016/j.cag.2015.05.026", "10.1007/978-3-319-24523-2_5", "10.1016/0004-3702(81)90020-5", "10.1068/p130321", "10.1364/JOSAA.9.001449", "10.1017/S0962492900002518", "10.1007/BFb0014497", "10.1007/978-3-662-05105-4_2", "10.1016/0004-3702(73)90003-9", "10.1007/BF00128527", "10.1016/0010-4485(95)00081-X", "10.1111/j.1467-8659.2011.01966.x", "10.1016/j.cag.2008.09.013", "10.1111/j.1467-8659.2007.01083.x", "10.1111/cgf.12496", "10.1111/cgf.12536", "10.1111/j.1467-8659.2009.01631.x", "10.1016/j.cag.2015.05.026", "10.1007/978-3-319-24523-2_5", "10.1016/0004-3702(81)90020-5", "10.1068/p130321", "10.1364/JOSAA.9.001449", "10.1017/S0962492900002518", "10.1007/BFb0014497", "10.1007/978-3-662-05105-4_2"]}, "10.1109/TVCG.2017.2709746": {"doi": "10.1109/TVCG.2017.2709746", "author": ["J. Polvi", "T. Taketomi", "A. Moteki", "T. Yoshitake", "T. Fukuoka", "G. Yamamoto", "C. Sandor", "H. Kato"], "title": "Handheld Guides in Inspection Tasks: Augmented Reality versus Picture", "year": "2018", "abstract": "Inspection tasks focus on observation of the environment and are required in many industrial domains. Inspectors usually execute these tasks by using a guide such as a paper manual, and directly observing the environment. The effort required to match the information in a guide with the information in an environment and the constant gaze shifts required between the two can severely lower the work efficiency of inspector in performing his/her tasks. Augmented reality (AR) allows the information in a guide to be overlaid directly on an environment. This can decrease the amount of effort required for information matching, thus increasing work efficiency. AR guides on head-mounted displays (HMDs) have been shown to increase efficiency. Handheld AR (HAR) is not as efficient as HMD-AR in terms of manipulability, but is more practical and features better information input and sharing capabilities. In this study, we compared two handheld guides: an AR interface that shows 3D registered annotations, that is, annotations having a fixed 3D position in the AR environment, and a non-AR picture interface that displays non-registered annotations on static images. We focused on inspection tasks that involve high information density and require the user to move, as well as to perform several viewpoint alignments. The results of our comparative evaluation showed that use of the AR interface resulted in lower task completion times, fewer errors, fewer gaze shifts, and a lower subjective workload. We are the first to present findings of a comparative study of an HAR and a picture interface when used in tasks that require the user to move and execute viewpoint alignments, focusing only on direct observation. Our findings can be useful for AR practitioners and psychology researchers.", "keywords": ["augmented reality", "helmet mounted displays", "human computer interaction", "inspection", "user interfaces", "nonAR picture interface", "information sharing capabilities", "information input capabilities", "HMD-AR", "subjective workload", "task completion times", "inspection tasks", "viewpoint alignments", "high information density", "nonregistered annotations", "AR environment", "fixed 3D position", "registered annotations", "AR interface", "HAR", "handheld AR", "AR guides", "information matching", "work efficiency", "constant gaze shifts", "paper manual", "industrial domains", "augmented reality", "handheld guides", "Inspection", "Three-dimensional displays", "Handheld computers", "Solid modeling", "Augmented reality", "Navigation", "Manuals", "Handheld devices", "augmented reality", "user evaluation", "inspection task"], "referenced_by": ["IKEY:8672062", "IKEY:8717385"], "referencing": ["IKEY:6162888", "IKEY:6162874", "IKEY:5336486", "IKEY:4637328", "IKEY:4079262", "IKEY:6162892", "IKEY:4637349", "IKEY:6162888", "IKEY:6162874", "IKEY:5336486", "IKEY:4637328", "IKEY:4079262", "IKEY:6162892", "IKEY:4637349", "IKEY:6162888", "IKEY:6162874", "IKEY:5336486", "IKEY:4637328", "IKEY:4079262", "IKEY:6162892", "IKEY:4637349", "10.1145/1518701.1518724", "10.1145/642625.642626", "10.1145/1044588.1044658", "10.1145/2659766.2661212", "10.1145/2207676.2208706", "10.1145/1315184.1315190", "10.1145/1152215.1152245", "10.1145/2407336.2407343", "10.1145/2371574.2371610", "10.1145/2642918.2647372", "10.1145/1152215.1152266", "10.1145/1152399.1152430", "10.1145/1518701.1518724", "10.1145/642625.642626", "10.1145/1044588.1044658", "10.1145/2659766.2661212", "10.1145/2207676.2208706", "10.1145/1315184.1315190", "10.1145/1152215.1152245", "10.1145/2407336.2407343", "10.1145/2371574.2371610", "10.1145/2642918.2647372", "10.1145/1152215.1152266", "10.1145/1152399.1152430", "10.1145/1518701.1518724", "10.1145/642625.642626", "10.1145/1044588.1044658", "10.1145/2659766.2661212", "10.1145/2207676.2208706", "10.1145/1315184.1315190", "10.1145/1152215.1152245", "10.1145/2407336.2407343", "10.1145/2371574.2371610", "10.1145/2642918.2647372", "10.1145/1152215.1152266", "10.1145/1152399.1152430", "10.1016/0010-0285(75)90003-1", "10.1126/science.171.3972.701", "10.1111/j.1475-5661.2008.00300.x", "10.1007/BF01421808", "10.1016/j.cag.2012.10.001", "10.1007/s00779-009-0247-2", "10.1016/j.cag.2015.10.013", "10.1016/0010-0285(75)90003-1", "10.1126/science.171.3972.701", "10.1111/j.1475-5661.2008.00300.x", "10.1007/BF01421808", "10.1016/j.cag.2012.10.001", "10.1007/s00779-009-0247-2", "10.1016/j.cag.2015.10.013", "10.1016/0010-0285(75)90003-1", "10.1126/science.171.3972.701", "10.1111/j.1475-5661.2008.00300.x", "10.1007/BF01421808", "10.1016/j.cag.2012.10.001", "10.1007/s00779-009-0247-2", "10.1016/j.cag.2015.10.013"]}, "10.1109/TVCG.2017.2711614": {"doi": "10.1109/TVCG.2017.2711614", "author": ["Y. Sun", "S. Schaefer", "W. Wang"], "title": "Image Structure Retrieval via $L_0$ Minimization", "year": "2018", "abstract": "Retrieving salient structure from textured images is an important but difficult problem in computer vision because texture, which can be irregular, anisotropic, non-uniform and complex, shares many of the same properties as structure. Observing that salient structure in a textured image should be piece-wise smooth, we present a method to retrieve such structures using an L0 minimization of a modified form of the relative total variation metric. Thanks to the characteristics shared by texture and small structures, our method is effective at retrieving structure based on scale as well. Our method outperforms state-of-art methods in texture removal as well as scale-space filtering. We also demonstrate our method's ability in other applications such as edge detection, clip art compression artifact removal, and inverse half-toning.", "keywords": ["computer vision", "data compression", "edge detection", "feature extraction", "image denoising", "image filtering", "image resolution", "image texture", "textured image", "relative total variation", "texture removal", "image structure retrieval", "salient structure", "computer vision", "minimization", "scale-space filtering", "Image edge detection", "Minimization", "Smoothing methods", "Feature extraction", "Optimization", "Image texture", "Texture removal", "scale-space filtering", "image smoothing", " $L_0$ sparsity"], "referenced_by": ["IKEY:8403202", "IKEY:8540409", "10.1049/iet-rsn.2019.0193"], "referencing": ["IKEY:6665130", "IKEY:5438812", "IKEY:6888475", "IKEY:7410406", "IKEY:6705679", "IKEY:6397620", "IKEY:710815", "IKEY:6319316", "IKEY:7194824", "IKEY:6665130", "IKEY:5438812", "IKEY:6888475", "IKEY:7410406", "IKEY:6705679", "IKEY:6397620", "IKEY:710815", "IKEY:6319316", "IKEY:7194824", "IKEY:6665130", "IKEY:5438812", "IKEY:6888475", "IKEY:7410406", "IKEY:6705679", "IKEY:6397620", "IKEY:710815", "IKEY:6319316", "IKEY:7194824", "10.1145/2601097.2601188", "10.1145/2508363.2508403", "10.1145/1618452.1618493", "10.1145/2366145.2366158", "10.1145/2070781.2024208", "10.1145/1276377.1276506", "10.1145/566654.566574", "10.1145/1778765.1778837", "10.1145/1141911.1141918", "10.1145/2010324.1964964", "10.1145/1857907.1857910", "10.1145/1276377.1276497", "10.1145/1015706.1015777", "10.1145/1360612.1360666", "10.1145/2766946", "10.1145/2461912.2461965", "10.1145/1183287.1183292", "10.1145/2601097.2601188", "10.1145/2508363.2508403", "10.1145/1618452.1618493", "10.1145/2366145.2366158", "10.1145/2070781.2024208", "10.1145/1276377.1276506", "10.1145/566654.566574", "10.1145/1778765.1778837", "10.1145/1141911.1141918", "10.1145/2010324.1964964", "10.1145/1857907.1857910", "10.1145/1276377.1276497", "10.1145/1015706.1015777", "10.1145/1360612.1360666", "10.1145/2766946", "10.1145/2461912.2461965", "10.1145/1183287.1183292", "10.1145/2601097.2601188", "10.1145/2508363.2508403", "10.1145/1618452.1618493", "10.1145/2366145.2366158", "10.1145/2070781.2024208", "10.1145/1276377.1276506", "10.1145/566654.566574", "10.1145/1778765.1778837", "10.1145/1141911.1141918", "10.1145/2010324.1964964", "10.1145/1857907.1857910", "10.1145/1276377.1276497", "10.1145/1015706.1015777", "10.1145/1360612.1360666", "10.1145/2766946", "10.1145/2461912.2461965", "10.1145/1183287.1183292", "10.1016/0167-2789(92)90242-F", "10.1007/978-3-319-10578-9_53", "10.1007/s10851-015-0617-5", "10.1137/090757083", "10.1007/s11263-006-4331-z", "10.1007/11567646_7", "10.1007/11744085_44", "10.1007/978-3-642-33718-5_29", "10.1016/j.cagd.2015.03.011", "10.1007/s00371-015-1205-9", "10.1016/j.cviu.2007.07.005", "10.1016/0167-2789(92)90242-F", "10.1007/978-3-319-10578-9_53", "10.1007/s10851-015-0617-5", "10.1137/090757083", "10.1007/s11263-006-4331-z", "10.1007/11567646_7", "10.1007/11744085_44", "10.1007/978-3-642-33718-5_29", "10.1016/j.cagd.2015.03.011", "10.1007/s00371-015-1205-9", "10.1016/j.cviu.2007.07.005", "10.1016/0167-2789(92)90242-F", "10.1007/978-3-319-10578-9_53", "10.1007/s10851-015-0617-5", "10.1137/090757083", "10.1007/s11263-006-4331-z", "10.1007/11567646_7", "10.1007/11744085_44", "10.1007/978-3-642-33718-5_29", "10.1016/j.cagd.2015.03.011", "10.1007/s00371-015-1205-9", "10.1016/j.cviu.2007.07.005"]}, "10.1109/TVCG.2017.2705687": {"doi": "10.1109/TVCG.2017.2705687", "author": ["S. H. Said", "M. Tamaazousti", "A. Bartoli"], "title": "Image-Based Models for Specularity Propagation in Diminished Reality", "year": "2018", "abstract": "The aim of Diminished Reality (DR) is to remove a target object in a live video stream seamlessly. In our approach, the area of the target object is replaced with new texture that blends with the rest of the image. The result is then propagated to the next frames of the video. One of the important stages of this technique is to update the target region with respect to the illumination change. This is a complex and recurrent problem when the viewpoint changes. We show that the state-of-the-art in DR fails in solving this problem, even under simple scenarios. We then use local illumination models to address this problem. According to these models, the variation in illumination only affects the specular component of the image. In the context of DR, the problem is therefore solved by propagating the specularities in the target area. We list a set of structural properties of specularities which we incorporate in two new models for specularity propagation. Our first model includes the same property as the previous approaches, which is the smoothness of illumination variation, but has a different estimation method based on the Thin-Plate Spline. Our second model incorporates more properties of the specularity's shape on planar surfaces. Experimental results on synthetic and real data show that our strategy substantially improves the rendering quality compared to the state-of-the-art in DR.", "keywords": ["image segmentation", "image texture", "lighting", "rendering (computer graphics)", "splines (mathematics)", "video streaming", "DR", "local illumination models", "specularities", "structural properties", "specularity propagation", "illumination variation", "Diminished Reality", "live video stream", "target region", "illumination change", "complex problem", "Lighting", "Streaming media", "Noise measurement", "Simultaneous localization and mapping", "Image color analysis", "Rendering (computer graphics)", "Real-time systems", "Diminished reality", "specularity", "propagation", "rendering", "isocontours", "brightest point", "illumination variation"], "referenced_by": [], "referencing": ["IKEY:935036", "IKEY:24792", "IKEY:765658", "IKEY:6853394", "IKEY:6714519", "IKEY:6671794", "IKEY:7344757", "IKEY:5995358", "IKEY:935036", "IKEY:24792", "IKEY:765658", "IKEY:6853394", "IKEY:6714519", "IKEY:6671794", "IKEY:7344757", "IKEY:5995358", "IKEY:935036", "IKEY:24792", "IKEY:765658", "IKEY:6853394", "IKEY:6714519", "IKEY:6671794", "IKEY:7344757", "IKEY:5995358", "10.1145/1531326.1531330", "10.1145/344779.344972", "10.1145/563858.563893", "10.1145/357290.357293", "10.1145/360825.360839", "10.1145/2980179.2982432", "10.1145/1531326.1531330", "10.1145/344779.344972", "10.1145/563858.563893", "10.1145/357290.357293", "10.1145/360825.360839", "10.1145/2980179.2982432", "10.1145/1531326.1531330", "10.1145/344779.344972", "10.1145/563858.563893", "10.1145/357290.357293", "10.1145/360825.360839", "10.1145/2980179.2982432", "10.1038/343165a0", "10.1006/jvci.2001.0487", "10.1007/BFb0086566", "10.1007/978-3-642-33709-3_2", "10.2201/NiiPi.2010.7.3", "10.1007/s11263-010-0324-z", "10.1080/10867651.2004.10487596", "10.1038/343165a0", "10.1006/jvci.2001.0487", "10.1007/BFb0086566", "10.1007/978-3-642-33709-3_2", "10.2201/NiiPi.2010.7.3", "10.1007/s11263-010-0324-z", "10.1080/10867651.2004.10487596", "10.1038/343165a0", "10.1006/jvci.2001.0487", "10.1007/BFb0086566", "10.1007/978-3-642-33709-3_2", "10.2201/NiiPi.2010.7.3", "10.1007/s11263-010-0324-z", "10.1080/10867651.2004.10487596"]}, "10.1109/TVCG.2017.2721400": {"doi": "10.1109/TVCG.2017.2721400", "author": ["S. Zhao", "F. Durand", "C. Zheng"], "title": "Inverse Diffusion Curves Using Shape Optimization", "year": "2018", "abstract": "The inverse diffusion curve problem focuses on automatic creation of diffusion curve images that resemble user provided color fields. This problem is challenging since the 1D curves have a nonlinear and global impact on resulting color fields via a partial differential equation (PDE). We introduce a new approach complementary to previous methods by optimizing curve geometry. In particular, we propose a novel iterative algorithm based on the theory of shape derivatives. The resulting diffusion curves are clean and well-shaped, and the final image closely approximates the input. Our method provides a user-controlled parameter to regularize curve complexity, and generalizes to handle input color fields represented in a variety of formats.", "keywords": ["curve fitting", "geometry", "image colour analysis", "iterative methods", "optimisation", "partial differential equations", "user provided color fields", "diffusion curve images", "automatic creation", "inverse diffusion curve problem", "shape optimization", "inverse diffusion curves", "input color fields", "curve complexity", "final image", "resulting diffusion curves", "shape derivatives", "optimizing curve geometry", "partial differential equation", "global impact", "Image color analysis", "Optimization", "Shape", "Geometry", "Laplace equations", "Inverse problems", "Vector graphics", "diffusion curves", "inverse problem", "shape optimization", "Fr\u00e9chet derivative"], "referenced_by": ["IKEY:9044325"], "referencing": ["IKEY:6051406", "IKEY:4767851", "IKEY:6051406", "IKEY:4767851", "IKEY:6051406", "IKEY:4767851", "10.1145/1360612.1360691", "10.1145/1618452.1618462", "10.1145/1882262.1866202", "10.1145/2185520.2185570", "10.1145/2508363.2508426", "10.1145/2601097.2601187", "10.1145/2661229.2661275", "10.1145/2070781.2024200", "10.1145/2366145.2366192", "10.1145/2461912.2461986", "10.1145/1360612.1360691", "10.1145/1618452.1618462", "10.1145/1882262.1866202", "10.1145/2185520.2185570", "10.1145/2508363.2508426", "10.1145/2601097.2601187", "10.1145/2661229.2661275", "10.1145/2070781.2024200", "10.1145/2366145.2366192", "10.1145/2461912.2461986", "10.1145/1360612.1360691", "10.1145/1618452.1618462", "10.1145/1882262.1866202", "10.1145/2185520.2185570", "10.1145/2508363.2508426", "10.1145/2601097.2601187", "10.1145/2661229.2661275", "10.1145/2070781.2024200", "10.1145/2366145.2366192", "10.1145/2461912.2461986", "10.1007/978-3-642-58106-9", "10.1111/cgf.12510", "10.1111/j.1467-8659.2011.01877.x", "10.1007/BF00133570", "10.1002/cpa.3160420503", "10.1016/S0167-8396(01)00036-X", "10.1007/s10851-006-6898-y", "10.1137/11085863X", "10.1016/S0146-664X(72)80017-0", "10.1080/10586458.1992.10504253", "10.1007/978-1-4614-3894-6", "10.1007/978-3-0348-0145-4", "10.1137/080737617", "10.21236/AD0663504", "10.1007/978-3-642-58106-9", "10.1111/cgf.12510", "10.1111/j.1467-8659.2011.01877.x", "10.1007/BF00133570", "10.1002/cpa.3160420503", "10.1016/S0167-8396(01)00036-X", "10.1007/s10851-006-6898-y", "10.1137/11085863X", "10.1016/S0146-664X(72)80017-0", "10.1080/10586458.1992.10504253", "10.1007/978-1-4614-3894-6", "10.1007/978-3-0348-0145-4", "10.1137/080737617", "10.21236/AD0663504", "10.1007/978-3-642-58106-9", "10.1111/cgf.12510", "10.1111/j.1467-8659.2011.01877.x", "10.1007/BF00133570", "10.1002/cpa.3160420503", "10.1016/S0167-8396(01)00036-X", "10.1007/s10851-006-6898-y", "10.1137/11085863X", "10.1016/S0146-664X(72)80017-0", "10.1080/10586458.1992.10504253", "10.1007/978-1-4614-3894-6", "10.1007/978-3-0348-0145-4", "10.1137/080737617", "10.21236/AD0663504"]}, "10.1109/TVCG.2017.2708108": {"doi": "10.1109/TVCG.2017.2708108", "author": ["L. Zhao", "M. Hansard", "A. Cavallaro"], "title": "Layered Scene Models from Single Hazy Images", "year": "2018", "abstract": "This paper describes the construction of a layered scene model, based on a single hazy image that has sufficient depth variation. A depth map and radiance image are estimated by standard dehazing methods. The radiance image is then segmented into a small number of clusters, and a corresponding scene plane is estimated for each. This provides the basic structure of a layered scene model, without the need for multiple views, or image correspondences. We show that problems of gap filling and depth blending can be addressed systematically, with respect to the layered depth structure. The final models, which resemble cardboard `pop-ups', are visually convincing. An implementation is described, and subjective depth preferences are tested in a psychophysical experiment.", "keywords": ["brightness", "image restoration", "image segmentation", "natural scenes", "pattern clustering", "sufficient depth variation", "depth map", "layered scene model", "image correspondences", "gap filling", "depth blending", "layered depth structure", "single hazy image", "scene plane", "radiance image segmentation", "subjective depth preferences", "psychophysical experiment", "Three-dimensional displays", "Solid modeling", "Computational modeling", "Atmospheric modeling", "Adaptation models", "Geometry", "Image reconstruction", "Scene modelling", "single view reconstruction", "image dehazing"], "referenced_by": [], "referencing": ["IKEY:5662013", "IKEY:1201821", "IKEY:790306", "IKEY:4408828", "IKEY:6471230", "IKEY:1451379", "IKEY:334981", "IKEY:5662013", "IKEY:1201821", "IKEY:790306", "IKEY:4408828", "IKEY:6471230", "IKEY:1451379", "IKEY:334981", "IKEY:5662013", "IKEY:1201821", "IKEY:790306", "IKEY:4408828", "IKEY:6471230", "IKEY:1451379", "IKEY:334981", "10.1145/358669.358692", "10.1145/1073204.1073232", "10.1145/258734.258854", "10.1145/2602146", "10.1145/964965.808606", "10.1145/1015706.1015720", "10.1145/358669.358692", "10.1145/1073204.1073232", "10.1145/258734.258854", "10.1145/2602146", "10.1145/964965.808606", "10.1145/1015706.1015720", "10.1145/358669.358692", "10.1145/1073204.1073232", "10.1145/258734.258854", "10.1145/2602146", "10.1145/964965.808606", "10.1145/1015706.1015720", "10.1023/A:1026598000963", "10.1186/1687-5281-2013-37", "10.1111/1467-8659.00326", "10.1117/12.906773", "10.1007/s11263-007-0071-y", "10.1007/978-3-642-33715-4_54", "10.1002/vis.291", "10.1007/978-3-319-23231-7_28", "10.1023/A:1026598000963", "10.1186/1687-5281-2013-37", "10.1111/1467-8659.00326", "10.1117/12.906773", "10.1007/s11263-007-0071-y", "10.1007/978-3-642-33715-4_54", "10.1002/vis.291", "10.1007/978-3-319-23231-7_28", "10.1023/A:1026598000963", "10.1186/1687-5281-2013-37", "10.1111/1467-8659.00326", "10.1117/12.906773", "10.1007/s11263-007-0071-y", "10.1007/978-3-642-33715-4_54", "10.1002/vis.291", "10.1007/978-3-319-23231-7_28"]}, "10.1109/TVCG.2017.2718532": {"doi": "10.1109/TVCG.2017.2718532", "author": ["A. Gim\u00e9nez", "T. Gamblin", "I. Jusufi", "A. Bhatele", "M. Schulz", "P. Bremer", "B. Hamann"], "title": "MemAxes: Visualization and Analytics for Characterizing Complex Memory Performance Behaviors", "year": "2018", "abstract": "Memory performance is often a major bottleneck for high-performance computing (HPC) applications. Deepening memory hierarchies, complex memory management, and non-uniform access times have made memory performance behavior difficult to characterize, and users require novel, sophisticated tools to analyze and optimize this aspect of their codes. Existing tools target only specific factors of memory performance, such as hardware layout, allocations, or access instructions. However, today's tools do not suffice to characterize the complex relationships between these factors. Further, they require advanced expertise to be used effectively. We present MemAxes, a tool based on a novel approach for analytic-driven visualization of memory performance data. MemAxes uniquely allows users to analyze the different aspects related to memory performance by providing multiple visual contexts for a centralized dataset. We define mappings of sampled memory access data to new and existing visual metaphors, each of which enabling a user to perform different analysis tasks. We present methods to guide user interaction by scoring subsets of the data based on known performance problems. This scoring is used to provide visual cues and automatically extract clusters of interest. We designed MemAxes in collaboration with experts in HPC and demonstrate its effectiveness in case studies.", "keywords": ["data analysis", "data visualisation", "parallel processing", "storage management", "user interfaces", "complex memory performance behavior characterization", "memory access data", "visual metaphors", "centralized dataset", "HPC", "memory performance data", "analytic-driven visualization", "nonuniform access times", "complex memory management", "memory hierarchies", "high-performance computing applications", "MemAxes", "Hardware", "Data visualization", "Resource management", "Tools", "Radiation detectors", "Visualization", "Memory management", "Performance visualization", "high-performance computing", "memory visualization"], "referenced_by": ["IKEY:8891032", "IKEY:8955677"], "referencing": ["IKEY:4290697", "IKEY:146371", "IKEY:5452445", "IKEY:4290697", "IKEY:146371", "IKEY:5452445", "IKEY:4290697", "IKEY:146371", "IKEY:5452445", "10.1145/216585.216588", "10.1145/989393.989401", "10.1145/1133956.1133972", "10.1145/2503210.2503297", "10.1145/216585.216588", "10.1145/989393.989401", "10.1145/1133956.1133972", "10.1145/2503210.2503297", "10.1145/216585.216588", "10.1145/989393.989401", "10.1145/1133956.1133972", "10.1145/2503210.2503297", "10.1007/3-540-36574-5_10", "10.1111/cgf.12103", "10.1007/978-3-319-27308-2_57", "10.2307/2685881", "10.1016/j.cag.2007.01.031", "10.1007/b107408", "10.2172/1090032", "10.1007/3-540-36574-5_10", "10.1111/cgf.12103", "10.1007/978-3-319-27308-2_57", "10.2307/2685881", "10.1016/j.cag.2007.01.031", "10.1007/b107408", "10.2172/1090032", "10.1007/3-540-36574-5_10", "10.1111/cgf.12103", "10.1007/978-3-319-27308-2_57", "10.2307/2685881", "10.1016/j.cag.2007.01.031", "10.1007/b107408", "10.2172/1090032"]}, "10.1109/TVCG.2017.2716937": {"doi": "10.1109/TVCG.2017.2716937", "author": ["M. Candela", "M. Di Bartolomeo", "G. D. Battista", "C. Squarcella"], "title": "Radian: Visual Exploration of Traceroutes", "year": "2018", "abstract": "Several projects deploy probes in the Internet. Probes are systems that continuously perform traceroutes and other networking measurements (e.g., ping) towards selected targets. Measurements can be stored and analyzed to gain knowledge on several aspects of the Internet, but making sense of such data requires suitable methods and tools for exploration and visualization. We present Radian, a tool that allows to visualize traceroute paths at different levels of detail and to animate their evolution during a selected time interval. We also describe extensive tests of the tool using traceroutes performed by RIPE Atlas Internet probes.", "keywords": ["data visualisation", "Internet", "telecommunication network routing", "telecommunication network topology", "Radian", "visual exploration", "networking measurements", "selected time interval", "RIPE Atlas Internet probes", "traceroutes paths visualization", "Probes", "Tools", "Routing", "Data visualization", "Internet", "Performance evaluation", "IP networks", "Traceroute", "graph drawing", "network visualization", "network probes"], "referenced_by": ["IKEY:8718284"], "referencing": ["IKEY:1382886", "IKEY:6658746", "IKEY:5473226", "IKEY:6183578", "IKEY:5190846", "IKEY:23105", "IKEY:4135662", "IKEY:1382886", "IKEY:6658746", "IKEY:5473226", "IKEY:6183578", "IKEY:5190846", "IKEY:23105", "IKEY:4135662", "IKEY:1382886", "IKEY:6658746", "IKEY:5473226", "IKEY:6183578", "IKEY:5190846", "IKEY:23105", "IKEY:4135662", "10.1145/2018436.2018452", "10.1145/1177080.1177100", "10.1145/1385569.1385636", "10.1145/2024288.2024344", "10.1145/2018436.2018452", "10.1145/1177080.1177100", "10.1145/1385569.1385636", "10.1145/2024288.2024344", "10.1145/2018436.2018452", "10.1145/1177080.1177100", "10.1145/1385569.1385636", "10.1145/2024288.2024344", "10.1007/978-3-319-03841-4_43", "10.5220/0005266601090116", "10.1007/978-3-642-18638-7_15", "10.1006/jvlc.1995.1010", "10.1111/j.1467-8659.2012.03113.x", "10.1016/j.ijhcs.2013.08.004", "10.7155/jgaa.00057", "10.1007/978-3-540-85891-1_8", "10.1016/S0304-3975(98)00270-9", "10.7155/jgaa.00102", "10.1007/978-3-540-24618-3_18", "10.1007/3-540-45848-4_5", "10.1016/S0022-0000(76)80045-1", "10.1007/978-3-319-03841-4_43", "10.5220/0005266601090116", "10.1007/978-3-642-18638-7_15", "10.1006/jvlc.1995.1010", "10.1111/j.1467-8659.2012.03113.x", "10.1016/j.ijhcs.2013.08.004", "10.7155/jgaa.00057", "10.1007/978-3-540-85891-1_8", "10.1016/S0304-3975(98)00270-9", "10.7155/jgaa.00102", "10.1007/978-3-540-24618-3_18", "10.1007/3-540-45848-4_5", "10.1016/S0022-0000(76)80045-1", "10.1007/978-3-319-03841-4_43", "10.5220/0005266601090116", "10.1007/978-3-642-18638-7_15", "10.1006/jvlc.1995.1010", "10.1111/j.1467-8659.2012.03113.x", "10.1016/j.ijhcs.2013.08.004", "10.7155/jgaa.00057", "10.1007/978-3-540-85891-1_8", "10.1016/S0304-3975(98)00270-9", "10.7155/jgaa.00102", "10.1007/978-3-540-24618-3_18", "10.1007/3-540-45848-4_5", "10.1016/S0022-0000(76)80045-1"]}, "10.1109/TVCG.2017.2712688": {"doi": "10.1109/TVCG.2017.2712688", "author": ["L. Shen", "D. Zhu", "S. Nadeem", "Z. Wang", "A. E. Kaufman"], "title": "Radiative Transport Based Flame Volume Reconstruction from Videos", "year": "2018", "abstract": "We introduce a novel approach for flame volume reconstruction from videos using inexpensive charge-coupled device (CCD) consumer cameras. The approach includes an economical data capture technique using inexpensive CCD cameras. Leveraging the smear feature of the CCD chip, we present a technique for synchronizing CCD cameras while capturing flame videos from different views. Our reconstruction is based on the radiative transport equation which enables complex phenomena such as emission, extinction, and scattering to be used in the rendering process. Both the color intensity and temperature reconstructions are implemented using the CUDA parallel computing framework, which provides real-time performance and allows visualization of reconstruction results after every iteration. We present the results of our approach using real captured data and physically-based simulated data. Finally, we also compare our approach against the other state-of-the-art flame volume reconstruction methods and demonstrate the efficacy and efficiency of our approach in four different applications: (1) rendering of reconstructed flames in virtual environments, (2) rendering of reconstructed flames in augmented reality, (3) flame stylization, and (4) reconstruction of other semitransparent phenomena.", "keywords": ["augmented reality", "cameras", "CCD image sensors", "flames", "image colour analysis", "image reconstruction", "parallel architectures", "rendering (computer graphics)", "video signal processing", "inexpensive charge", "device consumer cameras", "economical data capture technique", "inexpensive CCD cameras", "CCD chip", "synchronizing CCD cameras", "flame videos", "radiative transport equation", "color intensity", "temperature reconstructions", "CUDA parallel computing framework", "captured data", "reconstructed flames", "flame volume reconstruction", "flame stylization", "Cameras", "Image reconstruction", "Charge coupled devices", "Synchronization", "Videos", "Rendering (computer graphics)", "Image color analysis", "Flame volume reconstruction", "flame rendering", "flame videos", "radiative transport equation", "CCD camera synchronization"], "referenced_by": ["IKEY:8346302"], "referencing": ["10.1145/2766958", "10.1145/1409060.1409085", "10.1145/2185520.2185548", "10.1145/2601097.2601147", "10.1145/1180639.1180679", "10.1145/566654.566643", "10.1145/2766958", "10.1145/1409060.1409085", "10.1145/2185520.2185548", "10.1145/2601097.2601147", "10.1145/1180639.1180679", "10.1145/566654.566643", "10.1145/2766958", "10.1145/1409060.1409085", "10.1145/2185520.2185548", "10.1145/2601097.2601147", "10.1145/1180639.1180679", "10.1145/566654.566643", "10.1007/s00371-014-0987-5", "10.1177/016173468400600107", "10.1016/S0010-2180(97)00219-8", "10.1080/00102200108952149", "10.1023/A:1017901012998", "10.1016/S0010-2180(99)00034-6", "10.1016/j.proci.2014.07.064", "10.1088/0957-0233/7/3/023", "10.1364/AO.53.006351", "10.1016/j.ijleo.2015.03.015", "10.1016/j.gmod.2006.08.001", "10.1016/j.cag.2004.11.010", "10.1007/s00371-009-0403-8", "10.1364/JOSAA.29.00A209", "10.1007/s00371-014-0987-5", "10.1177/016173468400600107", "10.1016/S0010-2180(97)00219-8", "10.1080/00102200108952149", "10.1023/A:1017901012998", "10.1016/S0010-2180(99)00034-6", "10.1016/j.proci.2014.07.064", "10.1088/0957-0233/7/3/023", "10.1364/AO.53.006351", "10.1016/j.ijleo.2015.03.015", "10.1016/j.gmod.2006.08.001", "10.1016/j.cag.2004.11.010", "10.1007/s00371-009-0403-8", "10.1364/JOSAA.29.00A209", "10.1007/s00371-014-0987-5", "10.1177/016173468400600107", "10.1016/S0010-2180(97)00219-8", "10.1080/00102200108952149", "10.1023/A:1017901012998", "10.1016/S0010-2180(99)00034-6", "10.1016/j.proci.2014.07.064", "10.1088/0957-0233/7/3/023", "10.1364/AO.53.006351", "10.1016/j.ijleo.2015.03.015", "10.1016/j.gmod.2006.08.001", "10.1016/j.cag.2004.11.010", "10.1007/s00371-009-0403-8", "10.1364/JOSAA.29.00A209"]}, "10.1109/TVCG.2017.2711030": {"doi": "10.1109/TVCG.2017.2711030", "author": ["H. Lin", "S. Gao", "D. Gotz", "F. Du", "J. He", "N. Cao"], "title": "RCLens: Interactive Rare Category Exploration and Identification", "year": "2018", "abstract": "Rare category identification is an important task in many application domains, ranging from network security, to financial fraud detection, to personalized medicine. These are all applications which require the discovery and characterization of sets of rare but structurally-similar data entities which are obscured within a larger but structurally different dataset. This paper introduces RCLens, a visual analytics system designed to support user-guided rare category exploration and identification. RCLens adopts a novel active learning-based algorithm to iteratively identify more accurate rare categories in response to user-provided feedback. The algorithm is tightly integrated with an interactive visualization-based interface which supports a novel and effective workflow for rare category identification. This paper (1) defines RCLens' underlying active-learning algorithm; (2) describes the visualization and interaction designs, including a discussion of how the designs support user-guided rare category identification; and (3) presents results from an evaluation demonstrating RCLens' ability to support the rare category identification process.", "keywords": ["data analysis", "data handling", "data visualisation", "learning (artificial intelligence)", "interactive rare category exploration", "structurally-similar data entities", "accurate rare categories", "visualization", "interaction designs", "rare category identification process", "structurally different dataset", "RCLens", "active-learning algorithm", "Algorithm design and analysis", "Data visualization", "Visualization", "Prototypes", "Detection algorithms", "Visual analytics", "information visualization", "rare category detection", "machine learning"], "referenced_by": ["IKEY:8440842", "IKEY:8715002", "IKEY:8805439", "IKEY:8805463"], "referencing": ["IKEY:6081866", "IKEY:1003062", "IKEY:1017738", "IKEY:6876013", "IKEY:7185421", "IKEY:7018915", "IKEY:6081866", "IKEY:1003062", "IKEY:1017738", "IKEY:6876013", "IKEY:7185421", "IKEY:7018915", "IKEY:6081866", "IKEY:1003062", "IKEY:1017738", "IKEY:6876013", "IKEY:7185421", "IKEY:7018915", "10.1145/1135777.1135870", "10.1145/1541880.1541882", "10.1145/1281192.1281279", "10.1145/1557019.1557112", "10.1145/335191.335388", "10.1145/1135777.1135870", "10.1145/1541880.1541882", "10.1145/1281192.1281279", "10.1145/1557019.1557112", "10.1145/335191.335388", "10.1145/1135777.1135870", "10.1145/1541880.1541882", "10.1145/1281192.1281279", "10.1145/1557019.1557112", "10.1145/335191.335388", "10.1007/978-3-642-22813-1_3", "10.1137/1.9781611972795.14", "10.1007/BF00116828", "10.1007/3-540-45583-3_3", "10.1007/BF00993277", "10.1016/B978-1-55860-377-6.50027-X", "10.1007/978-3-642-33715-4_33", "10.1007/978-1-4471-2099-5_1", "10.1016/j.specom.2004.08.002", "10.1021/ci049810a", "10.1023/B:AIRE.0000045502.10941.a9", "10.1007/978-3-642-20847-8_22", "10.1016/j.eswa.2013.12.039", "10.1016/j.eswa.2014.06.026", "10.1002/asi.5090060411", "10.1007/978-3-642-22813-1_3", "10.1137/1.9781611972795.14", "10.1007/BF00116828", "10.1007/3-540-45583-3_3", "10.1007/BF00993277", "10.1016/B978-1-55860-377-6.50027-X", "10.1007/978-3-642-33715-4_33", "10.1007/978-1-4471-2099-5_1", "10.1016/j.specom.2004.08.002", "10.1021/ci049810a", "10.1023/B:AIRE.0000045502.10941.a9", "10.1007/978-3-642-20847-8_22", "10.1016/j.eswa.2013.12.039", "10.1016/j.eswa.2014.06.026", "10.1002/asi.5090060411", "10.1007/978-3-642-22813-1_3", "10.1137/1.9781611972795.14", "10.1007/BF00116828", "10.1007/3-540-45583-3_3", "10.1007/BF00993277", "10.1016/B978-1-55860-377-6.50027-X", "10.1007/978-3-642-33715-4_33", "10.1007/978-1-4471-2099-5_1", "10.1016/j.specom.2004.08.002", "10.1021/ci049810a", "10.1023/B:AIRE.0000045502.10941.a9", "10.1007/978-3-642-20847-8_22", "10.1016/j.eswa.2013.12.039", "10.1016/j.eswa.2014.06.026", "10.1002/asi.5090060411"]}, "10.1109/TVCG.2017.2719024": {"doi": "10.1109/TVCG.2017.2719024", "author": ["J. Digne", "S. Valette", "R. Chaine"], "title": "Sparse Geometric Representation Through Local Shape Probing", "year": "2018", "abstract": "We propose a new shape analysis approach based on the non-local analysis of local shape variations. Our method relies on a novel description of shape variations, called Local Probing Field (LPF), which describes how a local probing operator transforms a pattern onto the shape. By carefully optimizing the position and orientation of each descriptor, we are able to capture shape similarities and gather them into a geometrically relevant dictionary over which the shape decomposes sparsely. This new representation permits to handle shapes with mixed intrinsic dimensionality (e.g., shapes containing both surfaces and curves) and to encode various shape features such as boundaries. Our shape representation has several potential applications; here we demonstrate its efficiency for shape resampling and point set denoising for both synthetic and real data.", "keywords": ["feature extraction", "image denoising", "image representation", "optimisation", "surface fitting", "point set denoising", "sparse geometric representation", "shape analysis approach", "nonlocal analysis", "local shape variations", "local probing operator", "shape similarities", "geometrically relevant dictionary", "shape features", "shape representation", "shape resampling", "local shape probing", "local probing field", "Shape", "Dictionaries", "Noise reduction", "Manifolds", "Surface reconstruction", "Surface treatment", "Three-dimensional displays", "Shape similarity", "local shape descriptor", "point set denoising and resampling"], "referenced_by": ["IKEY:8730533"], "referencing": ["10.1145/1399504.1360642", "10.1145/1015706.1015814", "10.1145/1778765.1778831", "10.1145/1553374.1553463", "10.1145/2661229.2661263", "10.1145/1057432.1057456", "10.1145/2835488", "10.1145/1899404.1899405", "10.1145/1618452.1618522", "10.1145/2421636.2421645", "10.1145/1276377.1276405", "10.1145/1661412.1618522", "10.1145/1186562.1015713", "10.1145/1073204.1073227", "10.1145/1276377.1276406", "10.1145/2816795.2818073", "10.1145/2557449", "10.1145/2487228.2487237", "10.1145/133994.134011", "10.1145/882262.882368", "10.1145/1399504.1360642", "10.1145/1015706.1015814", "10.1145/1778765.1778831", "10.1145/1553374.1553463", "10.1145/2661229.2661263", "10.1145/1057432.1057456", "10.1145/2835488", "10.1145/1899404.1899405", "10.1145/1618452.1618522", "10.1145/2421636.2421645", "10.1145/1276377.1276405", "10.1145/1661412.1618522", "10.1145/1186562.1015713", "10.1145/1073204.1073227", "10.1145/1276377.1276406", "10.1145/2816795.2818073", "10.1145/2557449", "10.1145/2487228.2487237", "10.1145/133994.134011", "10.1145/882262.882368", "10.1145/1399504.1360642", "10.1145/1015706.1015814", "10.1145/1778765.1778831", "10.1145/1553374.1553463", "10.1145/2661229.2661263", "10.1145/1057432.1057456", "10.1145/2835488", "10.1145/1899404.1899405", "10.1145/1618452.1618522", "10.1145/2421636.2421645", "10.1145/1276377.1276405", "10.1145/1661412.1618522", "10.1145/1186562.1015713", "10.1145/1073204.1073227", "10.1145/1276377.1276406", "10.1145/2816795.2818073", "10.1145/2557449", "10.1145/2487228.2487237", "10.1145/133994.134011", "10.1145/882262.882368", "10.1111/cgf.12010", "10.1111/cgf.12438", "10.1111/cgf.12305", "10.1016/j.gmod.2015.06.012", "10.1023/B:VISI.0000029664.99615.94", "10.1007/978-3-642-15558-1_26", "10.1111/j.1467-8659.2009.01515.x", "10.1111/cgf.12286", "10.1111/j.1467-8659.2009.01388.x", "10.1016/j.cagd.2015.03.011", "10.1214/009053604000000067", "10.1111/cgf.12010", "10.1111/cgf.12438", "10.1111/cgf.12305", "10.1016/j.gmod.2015.06.012", "10.1023/B:VISI.0000029664.99615.94", "10.1007/978-3-642-15558-1_26", "10.1111/j.1467-8659.2009.01515.x", "10.1111/cgf.12286", "10.1111/j.1467-8659.2009.01388.x", "10.1016/j.cagd.2015.03.011", "10.1214/009053604000000067", "10.1111/cgf.12010", "10.1111/cgf.12438", "10.1111/cgf.12305", "10.1016/j.gmod.2015.06.012", "10.1023/B:VISI.0000029664.99615.94", "10.1007/978-3-642-15558-1_26", "10.1111/j.1467-8659.2009.01515.x", "10.1111/cgf.12286", "10.1111/j.1467-8659.2009.01388.x", "10.1016/j.cagd.2015.03.011", "10.1214/009053604000000067"]}, "10.1109/TVCG.2017.2714665": {"doi": "10.1109/TVCG.2017.2714665", "author": ["A. Olivier", "J. Bruneau", "R. Kulpa", "J. Pettr\u00e9"], "title": "Walking with Virtual People: Evaluation of Locomotion Interfaces in Dynamic Environments", "year": "2018", "abstract": "Navigating in virtual environments requires using some locomotion interfaces, especially when the dimensions of the environment exceed the ones of the Virtual Reality system. Locomotion interfaces induce some biases both in the perception of the self-motion or in the formation of virtual locomotion trajectories. These biases have been mostly evaluated in the context of static environments, and studies need to be revisited in the new context of populated environments where users interact with virtual characters. We focus on a situation of collision avoidance between a real participant and a virtual character, and compared it to previous studies on real walkers. Our results show that, as in reality, the risk of future collision is accurately anticipated by participants, however with delay. We also show that collision avoidance trajectories formed in VR have common properties with real ones, with some quantitative differences in avoidance distances. More generally, our evaluation demonstrates that reliable results can be obtained for qualitative analysis of small scale interactions in VR. We discuss these results in the perspective of a VR platform for large scale interaction applications, such as in a crowd, for which real data are difficult to gather.", "keywords": ["collision avoidance", "navigation", "virtual reality", "populated environments", "virtual character", "collision avoidance", "virtual people", "locomotion interfaces", "dynamic environments", "virtual environments", "Virtual Reality system", "virtual locomotion trajectories", "static environments", "VR platform", "Trajectory", "Legged locomotion", "Collision avoidance", "Context", "Measurement", "Virtual environments", "Locomotion", "interaction", "evaluation", "experiment", "collision avoidance", "virtual reality"], "referenced_by": ["IKEY:8302409", "IKEY:8326335", "IKEY:7955099", "IKEY:8438936", "IKEY:8643340", "IKEY:8798043", "IKEY:8798204", "IKEY:8943608", "IKEY:9089531", "IKEY:9089637", "IKEY:9262625", "10.1145/3190834.3190845"], "referencing": ["IKEY:5339124", "IKEY:6671765", "IKEY:7014249", "IKEY:6479208", "IKEY:5204082", "IKEY:1512020", "IKEY:5339124", "IKEY:6671765", "IKEY:7014249", "IKEY:6479208", "IKEY:5204082", "IKEY:1512020", "IKEY:5339124", "IKEY:6671765", "IKEY:7014249", "IKEY:6479208", "IKEY:5204082", "IKEY:1512020", "10.1145/1227134.1227136", "10.1145/1889863.1889906", "10.1145/1140491.1140493", "10.1145/2492494.2492507", "10.1145/2073370.2073391", "10.1145/1077399.1077402", "10.1145/2543581.2543590", "10.1145/2465780.2465785", "10.1145/210079.210084", "10.1145/1889863.1889867", "10.1145/1012551.1012558", "10.1145/1227134.1227136", "10.1145/1889863.1889906", "10.1145/1140491.1140493", "10.1145/2492494.2492507", "10.1145/2073370.2073391", "10.1145/1077399.1077402", "10.1145/2543581.2543590", "10.1145/2465780.2465785", "10.1145/210079.210084", "10.1145/1889863.1889867", "10.1145/1012551.1012558", "10.1145/1227134.1227136", "10.1145/1889863.1889906", "10.1145/1140491.1140493", "10.1145/2492494.2492507", "10.1145/2073370.2073391", "10.1145/1077399.1077402", "10.1145/2543581.2543590", "10.1145/2465780.2465785", "10.1145/210079.210084", "10.1145/1889863.1889867", "10.1145/1012551.1012558", "10.1162/105474605774785262", "10.1016/j.gaitpost.2012.08.003", "10.1093/ageing/26.1.15", "10.1037/a0020560", "10.1016/j.gaitpost.2008.04.006", "10.1037/0033-295X.102.4.627", "10.1016/j.neulet.2005.06.052", "10.1037/0096-1523.29.2.343", "10.1123/mcj.9.3.242", "10.1016/j.gaitpost.2007.03.015", "10.1016/j.gaitpost.2006.09.075", "10.1371/journal.pone.0089589", "10.1177/154193129503902006", "10.1111/j.1467-8659.2012.03028.x", "10.3758/BF03200735", "10.1007/3-540-69342-4_21", "10.1162/pres.19.3.230", "10.1016/j.gaitpost.2013.03.017", "10.1016/j.gaitpost.2012.03.021", "10.1080/00222895.1996.9941731", "10.1007/978-1-4419-8432-6", "10.1007/s00221-003-1558-6", "10.1007/978-3-642-10347-6_3", "10.1167/3.9.134", "10.1007/978-1-4020-2092-6_14", "10.1162/105474605774785262", "10.1016/j.gaitpost.2012.08.003", "10.1093/ageing/26.1.15", "10.1037/a0020560", "10.1016/j.gaitpost.2008.04.006", "10.1037/0033-295X.102.4.627", "10.1016/j.neulet.2005.06.052", "10.1037/0096-1523.29.2.343", "10.1123/mcj.9.3.242", "10.1016/j.gaitpost.2007.03.015", "10.1016/j.gaitpost.2006.09.075", "10.1371/journal.pone.0089589", "10.1177/154193129503902006", "10.1111/j.1467-8659.2012.03028.x", "10.3758/BF03200735", "10.1007/3-540-69342-4_21", "10.1162/pres.19.3.230", "10.1016/j.gaitpost.2013.03.017", "10.1016/j.gaitpost.2012.03.021", "10.1080/00222895.1996.9941731", "10.1007/978-1-4419-8432-6", "10.1007/s00221-003-1558-6", "10.1007/978-3-642-10347-6_3", "10.1167/3.9.134", "10.1007/978-1-4020-2092-6_14", "10.1162/105474605774785262", "10.1016/j.gaitpost.2012.08.003", "10.1093/ageing/26.1.15", "10.1037/a0020560", "10.1016/j.gaitpost.2008.04.006", "10.1037/0033-295X.102.4.627", "10.1016/j.neulet.2005.06.052", "10.1037/0096-1523.29.2.343", "10.1123/mcj.9.3.242", "10.1016/j.gaitpost.2007.03.015", "10.1016/j.gaitpost.2006.09.075", "10.1371/journal.pone.0089589", "10.1177/154193129503902006", "10.1111/j.1467-8659.2012.03028.x", "10.3758/BF03200735", "10.1007/3-540-69342-4_21", "10.1162/pres.19.3.230", "10.1016/j.gaitpost.2013.03.017", "10.1016/j.gaitpost.2012.03.021", "10.1080/00222895.1996.9941731", "10.1007/978-1-4419-8432-6", "10.1007/s00221-003-1558-6", "10.1007/978-3-642-10347-6_3", "10.1167/3.9.134", "10.1007/978-1-4020-2092-6_14"]}, "10.1109/TVCG.2018.2823798": {"doi": "10.1109/TVCG.2018.2823798", "author": ["D. Schmalstieg"], "title": "Erratum", "year": "2018", "abstract": "The IEEE Transactions on Visualization and Computer Graphics (TVCG) November 2016 issue, contains a special section featuring papers presented at the IEEE International Symposium on Mixed and Augmented Reality 2016. Unfortunately, the welcome message contributed by the guest editors of this special section, Wolfgang Broll, Hideo Saito, and J. Edward Swan II, was accidentially omitted. The November 2017 issue of TVCG is a special issue featuring papers presented at the IEEE International Symposium on Mixed and Augmented Reality 2017. Under similar circumstances as mentioned above, the welcome message contributed by the guest editors of this special issue, Wolfgang Broll, Holger Regenbrecht, and J. Edward Swan II, was accidentially omitted. We include both messages in the following, with apologies to the guest editors and our readers. Dieter Schmalstieg Associate Editor-in-Chief, TVCG For information.", "keywords": ["Augmented reality", "Special issues and sections", "Electronic mail"], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2018.2823799": {"doi": "10.1109/TVCG.2018.2823799", "author": ["W. Broll", "H. Saito", "J. E. Swan II"], "title": "Message from the ISMAR 2016 Science and Technology Program Chairs and Guest Editors", "year": "2018", "abstract": "Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.", "keywords": ["Special issues and sections", "Meetings", "Augmented reality"], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2018.2823772": {"doi": "10.1109/TVCG.2018.2823772", "author": ["W. Broll", "H. Regenbrecht", "J. E. Swan"], "title": "Message from the ISMAR 2017 Science and Technology Program Chairs and Guest Editors", "year": "2018", "abstract": "Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.", "keywords": ["Special issues and sections", "Meetings", "Augmented reality"], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2018.2826859": {"doi": "10.1109/TVCG.2018.2826859", "author": ["K. Guo", "F. Xu", "Y. Wang", "Y. Liu", "Q. Dai"], "title": "Errata to \u201cRobust Non-Rigid Motion Tracking and Surface Reconstruction Using L0 Regularization\u201d", "year": "2018", "abstract": "Presents corrections to grant number information from the paper, \u201cRobust non-rigid motion tracking and surface reconstruction using L0 regularization,\u201d (Guo, K., et al), IEEE Trans. Vis. Comput. Graph., vol. 24, no. 5, pp. 1770\u20131783, May 2018. ", "keywords": ["Surface reconstruction", "Motion tracking"], "referenced_by": [], "referencing": ["IKEY:7888591", "IKEY:7888591", "IKEY:7888591"]}}