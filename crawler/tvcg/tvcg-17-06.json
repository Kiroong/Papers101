{"10.1109/TVCG.2017.2677091": {"doi": "10.1109/TVCG.2017.2677091", "author": ["T. Dwyer", "Y. Wu"], "title": "Guest Editors' Introduction: Special Section on IEEE PacificVis 2017", "year": "2017", "abstract": "The papers in this special section were presented at the 2017 IEEE Paci\ufb01c Visualization Symposium (IEEE Paci\ufb01cVis\u201917) which was held at the Seoul National University, Seoul, Korea from April 18 to 21, 2017. ", "keywords": ["Special issues and sections", "Meetings", "Visualization"], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2674958": {"doi": "10.1109/TVCG.2017.2674958", "author": ["F. Beck", "D. Weiskopf"], "title": "Word-Sized Graphics for Scientific Texts", "year": "2017", "abstract": "Generating visualizations at the size of a word creates dense information representations often called sparklines. The integration of word-sized graphics into text could avoid additional cognitive load caused by splitting the readers' attention between figures and text. In scientific publications, these graphics make statements easier to understand and verify because additional quantitative information is available where needed. In this work, we perform a literature review to find out how researchers have already applied such word-sized representations. Illustrating the versatility of the approach, we leverage these representations for reporting empirical and bibliographic data in three application examples. For interactive Web-based publications, we explore levels of interactivity and discuss interaction patterns to link visualization and text. We finally call the visualization community to be a pioneer in exploring new visualization-enriched and interactive publication formats.", "keywords": ["data visualisation", "electronic publishing", "interactive systems", "scientific information systems", "text analysis", "scientific texts", "sparklines", "word-sized graphics", "reader attention", "scientific publications", "quantitative information", "word-sized representations", "empirical data", "bibliographic data", "interactive Web-based publications", "interaction patterns", "Data visualization", "Visualization", "Encoding", "Bibliographies", "Scientific publishing", "Sparklines", "word-sized graphics", "literature survey", "text and visualization", "interactive documents", "scientific publishing"], "referenced_by": ["10.1109/VISSOFT.2017.11", "10.1109/TVCG.2018.2865142", "10.1109/TVCG.2018.2865022", "10.1109/MCSE.2018.2875316", "10.1109/TVCG.2019.2934669", "10.1109/TVCG.2019.2934784", "10.1016/j.visinf.2019.03.004"], "referencing": ["10.1109/TVCG.2014.2346435", "10.1109/TVCG.2015.2467757", "10.1109/IISWC.2008.4636097", "10.1109/TVCG.2011.169", "10.1109/TVCG.2014.2346265", "10.1109/TVCG.2006.163", "10.1109/TVCG.2013.192", "10.1109/ETVIS.2016.7851166", "10.1109/PACIFICVIS.2015.7156366", "10.1109/TVCG.2014.2346435", "10.1109/TVCG.2015.2467757", "10.1109/IISWC.2008.4636097", "10.1109/TVCG.2011.169", "10.1109/TVCG.2014.2346265", "10.1109/TVCG.2006.163", "10.1109/TVCG.2013.192", "10.1109/ETVIS.2016.7851166", "10.1109/PACIFICVIS.2015.7156366", "10.1109/TVCG.2014.2346435", "10.1109/TVCG.2015.2467757", "10.1109/IISWC.2008.4636097", "10.1109/TVCG.2011.169", "10.1109/TVCG.2014.2346265", "10.1109/TVCG.2006.163", "10.1109/TVCG.2013.192", "10.1109/ETVIS.2016.7851166", "10.1109/PACIFICVIS.2015.7156366", "10.1145/2702613.2732778", "10.1145/1242572.1242595", "10.1145/2568326.2568331", "10.1145/2635868.2635877", "10.1145/1979742.1979655", "10.1145/1743666.1743717", "10.1145/2702613.2732778", "10.1145/1242572.1242595", "10.1145/2568326.2568331", "10.1145/2635868.2635877", "10.1145/1979742.1979655", "10.1145/1743666.1743717", "10.1145/2702613.2732778", "10.1145/1242572.1242595", "10.1145/2568326.2568331", "10.1145/2635868.2635877", "10.1145/1979742.1979655", "10.1145/1743666.1743717", "10.1017/CBO9780511816819.009", "10.1017/CBO9780511816819.003", "10.1023/A:1022193728205", "10.1016/j.learninstruc.2006.10.001", "10.1111/cgf.12104", "10.1007/s10257-011-0171-7", "10.1186/1471-2458-9-447", "10.1016/j.ecolecon.2012.12.010", "10.1016/j.soilbio.2013.09.021", "10.1016/j.cell.2008.08.034", "10.1016/j.jcin.2015.01.039", "10.1016/j.puhe.2007.01.005", "10.1007/s13218-013-0255-2", "10.4236/ajps.2015.614232", "10.3138/chr.694", "10.1016/j.foreco.2013.05.052", "10.3765/salt.v20i0.2565", "10.1371/journal.pone.0024914", "10.1136/amiajnl-2012-001147", "10.1016/j.jtbi.2007.09.004", "10.1111/cgf.12387", "10.1111/j.1467-8659.2012.03092.x", "10.1136/jamia.2009.000505", "10.1016/j.accinf.2012.09.001", "10.2139/ssrn.1325998", "10.1002/pmic.201400356", "10.1111/cgf.12872", "10.1017/CBO9780511816819.009", "10.1017/CBO9780511816819.003", "10.1023/A:1022193728205", "10.1016/j.learninstruc.2006.10.001", "10.1111/cgf.12104", "10.1007/s10257-011-0171-7", "10.1186/1471-2458-9-447", "10.1016/j.ecolecon.2012.12.010", "10.1016/j.soilbio.2013.09.021", "10.1016/j.cell.2008.08.034", "10.1016/j.jcin.2015.01.039", "10.1016/j.puhe.2007.01.005", "10.1007/s13218-013-0255-2", "10.4236/ajps.2015.614232", "10.3138/chr.694", "10.1016/j.foreco.2013.05.052", "10.3765/salt.v20i0.2565", "10.1371/journal.pone.0024914", "10.1136/amiajnl-2012-001147", "10.1016/j.jtbi.2007.09.004", "10.1111/cgf.12387", "10.1111/j.1467-8659.2012.03092.x", "10.1136/jamia.2009.000505", "10.1016/j.accinf.2012.09.001", "10.2139/ssrn.1325998", "10.1002/pmic.201400356", "10.1111/cgf.12872", "10.1017/CBO9780511816819.009", "10.1017/CBO9780511816819.003", "10.1023/A:1022193728205", "10.1016/j.learninstruc.2006.10.001", "10.1111/cgf.12104", "10.1007/s10257-011-0171-7", "10.1186/1471-2458-9-447", "10.1016/j.ecolecon.2012.12.010", "10.1016/j.soilbio.2013.09.021", "10.1016/j.cell.2008.08.034", "10.1016/j.jcin.2015.01.039", "10.1016/j.puhe.2007.01.005", "10.1007/s13218-013-0255-2", "10.4236/ajps.2015.614232", "10.3138/chr.694", "10.1016/j.foreco.2013.05.052", "10.3765/salt.v20i0.2565", "10.1371/journal.pone.0024914", "10.1136/amiajnl-2012-001147", "10.1016/j.jtbi.2007.09.004", "10.1111/cgf.12387", "10.1111/j.1467-8659.2012.03092.x", "10.1136/jamia.2009.000505", "10.1016/j.accinf.2012.09.001", "10.2139/ssrn.1325998", "10.1002/pmic.201400356", "10.1111/cgf.12872"]}, "10.1109/TVCG.2017.2674978": {"doi": "10.1109/TVCG.2017.2674978", "author": ["L. Micallef", "G. Palmas", "A. Oulasvirta", "T. Weinkauf"], "title": "Towards Perceptual Optimization of the Visual Design of Scatterplots", "year": "2017", "abstract": "Designing a good scatterplot can be difficult for non-experts in visualization, because they need to decide on many parameters, such as marker size and opacity, aspect ratio, color, and rendering order. This paper contributes to research exploring the use of perceptual models and quality metrics to set such parameters automatically for enhanced visual quality of a scatterplot. A key consideration in this paper is the construction of a cost function to capture several relevant aspects of the human visual system, examining a scatterplot design for some data analysis task. We show how the cost function can be used in an optimizer to search for the optimal visual design for a user's dataset and task objectives (e.g., \u201creliable linear correlation estimation is more important than class separation\u201d). The approach is extensible to different analysis tasks. To test its performance in a realistic setting, we pre-calibrated it for correlation estimation, class separation, and outlier detection. The optimizer was able to produce designs that achieved a level of speed and success comparable to that of those using human-designed presets (e.g., in R or MATLAB). Case studies demonstrate that the approach can adapt a design to the data, to reveal patterns without user intervention.", "keywords": ["crowdsourcing", "data visualisation", "perceptual optimization", "visual scatterplot design", "quality metrics", "visual quality enhancement", "cost function", "human visual system", "data analysis task", "optimal visual design", "user dataset", "task objectives", "linear correlation estimation", "class separation", "outlier detection", "human-designed presets", "R", "Matlab", "Visualization", "Measurement", "Correlation", "Cost function", "Data analysis", "Data visualization", "Scatterplot", "optimization", "perception", "crowdsourcing"], "referenced_by": ["10.1109/TVCG.2017.2744138", "10.1109/MC.2017.6", "10.1109/TVCG.2017.2744318", "10.1109/PacificVis.2018.00033", "10.1109/TVCG.2018.2865141", "10.1109/TVCG.2018.2864907", "10.1109/TVCG.2019.2903956", "10.1109/TVCG.2019.2934799", "10.1109/TVCG.2019.2934541", "10.1109/JPROC.2020.2969687", "10.1111/cgf.13446", "10.1111/cgf.13444", "10.1111/cgf.13902", "10.1016/j.cag.2020.05.028", "10.3758/s13414-020-02212-x"], "referencing": ["10.1109/TVCG.2004.1260759", "10.1109/INFVIS.2005.1532142", "10.1109/TVCG.2011.229", "10.1109/TVCG.2014.2346979", "10.1109/TVCG.2015.2467671", "10.1109/TVCG.2013.153", "10.1109/TVCG.2013.183", "10.1109/PACIFICVIS.2016.7465244", "10.1109/VAST.2006.261423", "10.1109/TVCG.2014.2330617", "10.1109/TVCG.2014.2346594", "10.1109/TVCG.2013.65", "10.1109/TVCG.2009.153", "10.1109/VAST.2009.5332628", "10.1109/MC.2017.6", "10.1109/TVCG.2014.48", "10.1109/38.946633", "10.1109/TPAMI.1986.4767851", "10.1109/TIP.2003.819861", "10.1109/TVCG.2004.1260759", "10.1109/INFVIS.2005.1532142", "10.1109/TVCG.2011.229", "10.1109/TVCG.2014.2346979", "10.1109/TVCG.2015.2467671", "10.1109/TVCG.2013.153", "10.1109/TVCG.2013.183", "10.1109/PACIFICVIS.2016.7465244", "10.1109/VAST.2006.261423", "10.1109/TVCG.2014.2330617", "10.1109/TVCG.2014.2346594", "10.1109/TVCG.2013.65", "10.1109/TVCG.2009.153", "10.1109/VAST.2009.5332628", "10.1109/MC.2017.6", "10.1109/TVCG.2014.48", "10.1109/38.946633", "10.1109/TPAMI.1986.4767851", "10.1109/TIP.2003.819861", "10.1109/TVCG.2004.1260759", "10.1109/INFVIS.2005.1532142", "10.1109/TVCG.2011.229", "10.1109/TVCG.2014.2346979", "10.1109/TVCG.2015.2467671", "10.1109/TVCG.2013.153", "10.1109/TVCG.2013.183", "10.1109/PACIFICVIS.2016.7465244", "10.1109/VAST.2006.261423", "10.1109/TVCG.2014.2330617", "10.1109/TVCG.2014.2346594", "10.1109/TVCG.2013.65", "10.1109/TVCG.2009.153", "10.1109/VAST.2009.5332628", "10.1109/MC.2017.6", "10.1109/TVCG.2014.48", "10.1109/38.946633", "10.1109/TPAMI.1986.4767851", "10.1109/TIP.2003.819861", "10.1145/2702123.2702585", "10.1145/1753326.1753357", "10.1145/2501988.2502024", "10.1145/2702123.2702585", "10.1145/1753326.1753357", "10.1145/2501988.2502024", "10.1145/2702123.2702585", "10.1145/1753326.1753357", "10.1145/2501988.2502024", "10.1111/j.1467-8659.2012.03125.x", "10.1198/jcgs.2009.07098", "10.1037/1076-898X.3.1.3", "10.1126/science.216.4550.1138", "10.1057/ivs.2008.13", "10.1111/j.1467-8659.2009.01694.x", "10.7815/ijorcs.22.2012.018", "10.1023/B:AIRE.0000045502.10941.a9", "10.1111/cgf.12632", "10.1016/0010-0285(91)90009-D", "10.1007/978-3-642-11343-7", "10.1162/106454699568728", "10.7717/peerj.453", "10.1007/s00158-009-0460-7", "10.2139/ssrn.2594183", "10.1007/978-3-319-26633-6_13", "10.1111/j.1467-8659.2012.03125.x", "10.1198/jcgs.2009.07098", "10.1037/1076-898X.3.1.3", "10.1126/science.216.4550.1138", "10.1057/ivs.2008.13", "10.1111/j.1467-8659.2009.01694.x", "10.7815/ijorcs.22.2012.018", "10.1023/B:AIRE.0000045502.10941.a9", "10.1111/cgf.12632", "10.1016/0010-0285(91)90009-D", "10.1007/978-3-642-11343-7", "10.1162/106454699568728", "10.7717/peerj.453", "10.1007/s00158-009-0460-7", "10.2139/ssrn.2594183", "10.1007/978-3-319-26633-6_13", "10.1111/j.1467-8659.2012.03125.x", "10.1198/jcgs.2009.07098", "10.1037/1076-898X.3.1.3", "10.1126/science.216.4550.1138", "10.1057/ivs.2008.13", "10.1111/j.1467-8659.2009.01694.x", "10.7815/ijorcs.22.2012.018", "10.1023/B:AIRE.0000045502.10941.a9", "10.1111/cgf.12632", "10.1016/0010-0285(91)90009-D", "10.1007/978-3-642-11343-7", "10.1162/106454699568728", "10.7717/peerj.453", "10.1007/s00158-009-0460-7", "10.2139/ssrn.2594183", "10.1007/978-3-319-26633-6_13"]}, "10.1109/TVCG.2017.2674999": {"doi": "10.1109/TVCG.2017.2674999", "author": ["Q. H. Nguyen", "S. Hong", "P. Eades", "A. Meidiana"], "title": "Proxy Graph: Visual Quality Metrics of Big Graph Sampling", "year": "2017", "abstract": "Data sampling has been extensively studied for large scale graph mining. Many analyses and tasks become more efficient when performed on graph samples of much smaller size. The use of proxy objects is common in software engineering for analysis and interaction with heavy objects or systems. In this paper, we coin the term 'proxy graph' and empirically investigate how well a proxy graph visualization can represent a big graph. Our investigation focuses on proxy graphs obtained by sampling; this is one of the most common proxy approaches. Despite the plethora of data sampling studies, this is the first evaluation of sampling in the context of graph visualization. For an objective evaluation, we propose a new family of quality metrics for visual quality of proxy graphs. Our experiments cover popular sampling techniques. Our experimental results lead to guidelines for using sampling-based proxy graphs in visualization.", "keywords": ["Big Data", "graph theory", "sampling methods", "visual quality metrics", "big-graph sampling", "empirical analysis", "proxy graph visualization", "data sampling", "graph visualization", "objective evaluation", "sampling-based proxy graphs", "Visualization", "Measurement", "Sampling methods", "Data visualization", "Software engineering", "Graph visualization", "graph sampling", "proxy graph", "quality metrics"], "referenced_by": ["10.1109/TVCG.2017.2743858", "10.1109/PacificVis.2018.00011", "10.1109/ACCESS.2018.2870684", "10.1109/TVCG.2018.2790961", "10.1109/ACCESS.2019.2953086", "10.1007/978-3-319-73915-1_22", "10.1111/cgf.13446", "10.1111/cgf.13724", "10.1016/j.cag.2020.02.004"], "referencing": ["10.1109/TVCG.2012.238", "10.1109/VISUAL.2005.1532819", "10.1109/TVCG.2016.2598867", "10.1109/TVCG.2012.299", "10.1109/TVCG.2012.238", "10.1109/VISUAL.2005.1532819", "10.1109/TVCG.2016.2598867", "10.1109/TVCG.2012.299", "10.1109/TVCG.2012.238", "10.1109/VISUAL.2005.1532819", "10.1109/TVCG.2016.2598867", "10.1109/TVCG.2012.299", "10.1145/1150402.1150479", "10.1145/2049662.2049663", "10.1145/1150402.1150479", "10.1145/2049662.2049663", "10.1145/1150402.1150479", "10.1145/2049662.2049663", "10.7155/jgaa.00405", "10.1007/3-540-44541-2_17", "10.1002/spe.4380211102", "10.1007/978-3-319-50106-2_2", "10.7155/jgaa.00405", "10.1007/3-540-44541-2_17", "10.1002/spe.4380211102", "10.1007/978-3-319-50106-2_2", "10.7155/jgaa.00405", "10.1007/3-540-44541-2_17", "10.1002/spe.4380211102", "10.1007/978-3-319-50106-2_2"]}, "10.1109/TVCG.2017.2674938": {"doi": "10.1109/TVCG.2017.2674938", "author": ["H. Miao", "G. Mistelbauer", "A. Karimov", "A. Alansary", "A. Davidson", "D. F. A. Lloyd", "M. Damodaram", "L. Story", "J. Hutter", "J. V. Hajnal", "M. Rutherford", "B. Preim", "B. Kainz", "M. E. Gr\u00f6ller"], "title": "Placenta Maps: In Utero Placental Health Assessment of the Human Fetus", "year": "2017", "abstract": "The human placenta is essential for the supply of the fetus. To monitor the fetal development, imaging data is acquired using (US). Although it is currently the gold-standard in fetal imaging, it might not capture certain abnormalities of the placenta. (MRI) is a safe alternative for the in utero examination while acquiring the fetus data in higher detail. Nevertheless, there is currently no established procedure for assessing the condition of the placenta and consequently the fetal health. Due to maternal respiration and inherent movements of the fetus during examination, a quantitative assessment of the placenta requires fetal motion compensation, precise placenta segmentation and a standardized visualization, which are challenging tasks. Utilizing advanced motion compensation and automatic segmentation methods to extract the highly versatile shape of the placenta, we introduce a novel visualization technique that presents the fetal and maternal side of the placenta in a standardized way. Our approach enables physicians to explore the placenta even in utero. This establishes the basis for a comparative assessment of multiple placentas to analyze possible pathologic arrangements and to support the research and understanding of this vital organ. Additionally, we propose a three-dimensional structure-aware surface slicing technique in order to explore relevant regions inside the placenta. Finally, to survey the applicability of our approach, we consulted clinical experts in prenatal diagnostics and imaging. We received mainly positive feedback, especially the applicability of our technique for research purposes was appreciated.", "keywords": ["image segmentation", "medical image processing", "motion compensation", "obstetrics", "placenta maps", "utero-placental health assessment", "human fetus", "fetal development monitoring", "imaging data", "maternal respiration", "fetus movements", "quantitative assessment", "fetal motion compensation", "standardized visualization", "automatic placenta segmentation method", "pathologic arrangements", "three-dimensional structure-aware surface slicing technique", "prenatal diagnostics", "prenatal imaging", "Shape analysis", "Magnetic resonance imaging", "Visualization", "Distortion", "Fetus", "Biomedical imaging", "Myocardium", "Placenta", "fetal", "flattening", "structure-aware slicing", "peeling", "Female", "Fetus", "Humans", "Image Interpretation, Computer-Assisted", "Magnetic Resonance Imaging", "Placenta", "Pregnancy", "Prenatal Diagnosis"], "referenced_by": ["10.1109/TVCG.2019.2934337", "10.1109/ACCESS.2019.2958133", "10.1109/TMI.2020.2987981", "10.1111/cgf.13445", "10.1016/j.media.2018.10.003", "10.1016/S0140-6736(18)32490-5", "10.1016/j.media.2019.03.008", "10.1097/RMR.0000000000000221", "10.1097/RMR.0000000000000218", "10.1007/978-3-030-32254-0_70", "10.1007/978-3-658-29267-6_60"], "referencing": ["10.1109/TVCG.2007.70550", "10.1109/TVCG.2014.2346405", "10.1109/TVCG.2016.2598824", "10.1109/TMI.2015.2415453", "10.1109/TVCG.2007.70550", "10.1109/TVCG.2014.2346405", "10.1109/TVCG.2016.2598824", "10.1109/TMI.2015.2415453", "10.1109/TVCG.2007.70550", "10.1109/TVCG.2014.2346405", "10.1109/TVCG.2016.2598824", "10.1109/TMI.2015.2415453", "10.1086/315449", "10.1016/0002-9378(93)90499-9", "10.1136/bmj.301.6746.259", "10.1007/978-3-642-23941-0", "10.1111/cgf.12988", "10.1111/cgf.12110", "10.1016/S0167-8396(96)00031-3", "10.1007/s00330-002-1383-5", "10.1148/radiol.2322030504", "10.1002/pd.2641", "10.1016/j.placenta.2009.03.010", "10.1007/s00247-015-3408-7", "10.1148/radiol.2015151258", "10.3174/ajnr.A3128", "10.1016/j.ultrasmedbio.2015.07.021", "10.1007/978-3-319-24574-4_4", "10.1007/978-3-319-46723-8_68", "10.1016/j.placenta.2005.02.009", "10.1002/jcu.20524", "10.1016/0146-664X(80)90054-4", "10.1006/cgip.1994.1042", "10.1016/S0167-8396(03)00002-5", "10.1086/315449", "10.1016/0002-9378(93)90499-9", "10.1136/bmj.301.6746.259", "10.1007/978-3-642-23941-0", "10.1111/cgf.12988", "10.1111/cgf.12110", "10.1016/S0167-8396(96)00031-3", "10.1007/s00330-002-1383-5", "10.1148/radiol.2322030504", "10.1002/pd.2641", "10.1016/j.placenta.2009.03.010", "10.1007/s00247-015-3408-7", "10.1148/radiol.2015151258", "10.3174/ajnr.A3128", "10.1016/j.ultrasmedbio.2015.07.021", "10.1007/978-3-319-24574-4_4", "10.1007/978-3-319-46723-8_68", "10.1016/j.placenta.2005.02.009", "10.1002/jcu.20524", "10.1016/0146-664X(80)90054-4", "10.1006/cgip.1994.1042", "10.1016/S0167-8396(03)00002-5", "10.1086/315449", "10.1016/0002-9378(93)90499-9", "10.1136/bmj.301.6746.259", "10.1007/978-3-642-23941-0", "10.1111/cgf.12988", "10.1111/cgf.12110", "10.1016/S0167-8396(96)00031-3", "10.1007/s00330-002-1383-5", "10.1148/radiol.2322030504", "10.1002/pd.2641", "10.1016/j.placenta.2009.03.010", "10.1007/s00247-015-3408-7", "10.1148/radiol.2015151258", "10.3174/ajnr.A3128", "10.1016/j.ultrasmedbio.2015.07.021", "10.1007/978-3-319-24574-4_4", "10.1007/978-3-319-46723-8_68", "10.1016/j.placenta.2005.02.009", "10.1002/jcu.20524", "10.1016/0146-664X(80)90054-4", "10.1006/cgip.1994.1042", "10.1016/S0167-8396(03)00002-5"]}, "10.1109/TVCG.2017.2674918": {"doi": "10.1109/TVCG.2017.2674918", "author": ["F. Sauer", "K. Ma"], "title": "Spatio-Temporal Feature Exploration in Combined Particle/Volume Reference Frames", "year": "2017", "abstract": "The use of large-scale scientific simulations that can represent physical systems using both particle and volume data simultaneously is gaining popularity as each of these reference frames has an inherent set of advantages when studying different phenomena. Furthermore, being able to study the dynamic evolution of these time varying data types is an integral part of nearly all scientific endeavors. However, the techniques available to scientists generally limit them to studying each reference frame separately making it difficult to draw connections between the two. In this work we present a novel method of feature exploration that can be used to investigate spatio-temporal patterns in both data types simultaneously. More specifically, we focus on how spatio-temporal subsets can be identified from both reference frames, and develop new ways of visually presenting the embedded information to a user in an intuitive manner. We demonstrate the effectiveness of our method using case studies of real world scientific datasets and illustrate the new types of exploration and analyses that can be achieved through this technique.", "keywords": ["scientific information systems", "spatiotemporal phenomena", "spatio-temporal feature exploration", "combined particle/volume reference frames", "large-scale scientific simulations", "physical systems", "particle data", "volume data", "data types", "embedded information", "scientific datasets", "Data visualization", "Data models", "Trajectory", "Computational modeling", "Couplings", "Visualization", "Feature extraction", "Particle data", "volume data", "feature exploration", "spatio-temporal analysis"], "referenced_by": ["10.1109/TVCG.2018.2864817", "10.1109/CJECE.2019.2917394", "10.1109/PacificVis48177.2020.1718"], "referencing": ["10.1109/LDAV.2014.7013206", "10.1109/APVIS.2007.329287", "10.1109/TVCG.2010.32", "10.1109/TVCG.2011.113", "10.1109/VISUAL.2005.1532859", "10.1109/PACIFICVIS.2008.4475461", "10.1109/TVCG.2014.2346423", "10.1109/TVCG.2012.33", "10.1109/TVCG.2008.140", "10.1109/TVCG.2006.164", "10.1109/TVCG.2010.212", "10.1109/TVCG.2014.2346746", "10.1109/TVCG.2012.190", "10.1109/TVCG.2010.156", "10.1109/LDAV.2014.7013206", "10.1109/APVIS.2007.329287", "10.1109/TVCG.2010.32", "10.1109/TVCG.2011.113", "10.1109/VISUAL.2005.1532859", "10.1109/PACIFICVIS.2008.4475461", "10.1109/TVCG.2014.2346423", "10.1109/TVCG.2012.33", "10.1109/TVCG.2008.140", "10.1109/TVCG.2006.164", "10.1109/TVCG.2010.212", "10.1109/TVCG.2014.2346746", "10.1109/TVCG.2012.190", "10.1109/TVCG.2010.156", "10.1109/LDAV.2014.7013206", "10.1109/APVIS.2007.329287", "10.1109/TVCG.2010.32", "10.1109/TVCG.2011.113", "10.1109/VISUAL.2005.1532859", "10.1109/PACIFICVIS.2008.4475461", "10.1109/TVCG.2014.2346423", "10.1109/TVCG.2012.33", "10.1109/TVCG.2008.140", "10.1109/TVCG.2006.164", "10.1109/TVCG.2010.212", "10.1109/TVCG.2014.2346746", "10.1109/TVCG.2012.190", "10.1109/TVCG.2010.156", "10.1145/2485895.2485912", "10.1145/2485895.2485912", "10.1145/2485895.2485912", "10.1088/1742-6596/180/1/012036", "10.1016/j.proci.2010.06.147", "10.1080/01431160802558758", "10.1007/s00371-007-0204-x", "10.1016/j.cag.2015.06.003", "10.1111/cgf.12650", "10.1016/S1045-926X(03)00046-6", "10.1063/1.857730", "10.1088/1742-6596/180/1/012036", "10.1016/j.proci.2010.06.147", "10.1080/01431160802558758", "10.1007/s00371-007-0204-x", "10.1016/j.cag.2015.06.003", "10.1111/cgf.12650", "10.1016/S1045-926X(03)00046-6", "10.1063/1.857730", "10.1088/1742-6596/180/1/012036", "10.1016/j.proci.2010.06.147", "10.1080/01431160802558758", "10.1007/s00371-007-0204-x", "10.1016/j.cag.2015.06.003", "10.1111/cgf.12650", "10.1016/S1045-926X(03)00046-6", "10.1063/1.857730"]}, "10.1109/TVCG.2016.2539960": {"doi": "10.1109/TVCG.2016.2539960", "author": ["F. Du", "B. Shneiderman", "C. Plaisant", "S. Malik", "A. Perer"], "title": "Coping with Volume and Variety in Temporal Event Sequences: Strategies for Sharpening Analytic Focus", "year": "2017", "abstract": "The growing volume and variety of data presents both opportunities and challenges for visual analytics. Addressing these challenges is needed for big data to provide valuable insights and novel solutions for business, security, social media, and healthcare. In the case of temporal event sequence analytics it is the number of events in the data and variety of temporal sequence patterns that challenges users of visual analytic tools. This paper describes 15 strategies for sharpening analytic focus that analysts can use to reduce the data volume and pattern variety. Four groups of strategies are proposed: (1) extraction strategies, (2) temporal folding, (3) pattern simplification strategies, and (4) iterative strategies. For each strategy, we provide examples of the use and impact of this strategy on volume and/or variety. Examples are selected from 20 case studies gathered from either our own work, the literature, or based on email interviews with individuals who conducted the analyses and developers who observed analysts using the tools. Finally, we discuss how these strategies might be combined and report on the feedback from 10 senior event sequence analysts.", "keywords": ["Big Data", "data visualisation", "iterative methods", "visual analytics", "Big Data", "temporal event sequence analytics", "data volume reduction", "pattern variety reduction", "extraction strategies", "temporal folding", "pattern simplification strategies", "iterative strategies", "Focusing", "Visual analytics", "Data visualization", "Pattern recognition", "Sequences", "Big data", "temporal data", "temporal event sequences", "workflow", "visual analytics", "visualization", "analytic focus"], "referenced_by": ["10.1109/VAST.2016.7883512", "10.1109/TVCG.2018.2864851", "10.1109/TVCG.2018.2864886", "10.1109/TVCG.2018.2865076", "10.1109/TVCG.2018.2864885", "10.1109/VAST.2017.8585638", "10.1109/TVCG.2018.2803829", "10.1109/MC.2018.2890217", "10.1109/VIZSEC.2018.8709223", "10.1109/TVCG.2019.2934289", "10.1109/TVCG.2019.2934280", "10.1109/TVCG.2019.2934661", "10.1109/TVCG.2019.2934267", "10.1109/VISUAL.2019.8933584", "10.1109/VAHC47919.2019.8945029", "10.1109/TVCG.2018.2886901", "10.1145/2851581.2892487", "10.1145/3301402", "10.1111/cgf.13237", "10.1111/fcp.12322", "10.1016/j.artmed.2018.08.003", "10.1111/cgf.13720", "10.1111/cgf.13697", "10.1111/cgf.13208", "10.1007/s12650-019-00609-x", "10.1186/s12913-020-5030-0", "10.1007/s00371-020-01894-6", "10.1016/j.watres.2020.116550"], "referencing": ["10.1109/TVCG.2013.178", "10.1109/TVCG.2009.84", "10.1109/TVCG.2014.2346682", "10.1109/TVCG.2015.2467622", "10.1109/TVCG.2011.179", "10.1109/TVCG.2014.2346452", "10.1109/TVCG.2013.200", "10.1109/TVCG.2014.2346574", "10.1109/TVCG.2009.187", "10.1109/TVCG.2012.225", "10.1109/VAST.2014.7042487", "10.1109/TVCG.2007.70515", "10.1109/TVCG.2013.178", "10.1109/TVCG.2009.84", "10.1109/TVCG.2014.2346682", "10.1109/TVCG.2015.2467622", "10.1109/TVCG.2011.179", "10.1109/TVCG.2014.2346452", "10.1109/TVCG.2013.200", "10.1109/TVCG.2014.2346574", "10.1109/TVCG.2009.187", "10.1109/TVCG.2012.225", "10.1109/VAST.2014.7042487", "10.1109/TVCG.2007.70515", "10.1109/TVCG.2013.178", "10.1109/TVCG.2009.84", "10.1109/TVCG.2014.2346682", "10.1109/TVCG.2015.2467622", "10.1109/TVCG.2011.179", "10.1109/TVCG.2014.2346452", "10.1109/TVCG.2013.200", "10.1109/TVCG.2014.2346574", "10.1109/TVCG.2009.187", "10.1109/TVCG.2012.225", "10.1109/VAST.2014.7042487", "10.1109/TVCG.2007.70515", "10.1145/775047.775109", "10.1145/1385569.1385584", "10.1145/2598153.2598172", "10.1145/2637748.2638423", "10.1145/2851581.2892487", "10.1145/2890478", "10.1145/2851581.2892440", "10.1145/2468356.2468434", "10.1145/2557500.2557508", "10.1145/2487575.2488213", "10.1145/2408736.2408740", "10.1145/1357054.1357129", "10.1145/2702123.2702262", "10.1145/2702123.2702419", "10.1145/775047.775109", "10.1145/1385569.1385584", "10.1145/2598153.2598172", "10.1145/2637748.2638423", "10.1145/2851581.2892487", "10.1145/2890478", "10.1145/2851581.2892440", "10.1145/2468356.2468434", "10.1145/2557500.2557508", "10.1145/2487575.2488213", "10.1145/2408736.2408740", "10.1145/1357054.1357129", "10.1145/2702123.2702262", "10.1145/2702123.2702419", "10.1145/775047.775109", "10.1145/1385569.1385584", "10.1145/2598153.2598172", "10.1145/2637748.2638423", "10.1145/2851581.2892487", "10.1145/2890478", "10.1145/2851581.2892440", "10.1145/2468356.2468434", "10.1145/2557500.2557508", "10.1145/2487575.2488213", "10.1145/2408736.2408740", "10.1145/1357054.1357129", "10.1145/2702123.2702262", "10.1145/2702123.2702419", "10.1007/978-1-4612-2404-4_19", "10.1007/s40273-015-0333-4", "10.1198/106186002317375604", "10.1007/978-3-642-32498-7_5", "10.1177/1473871611415994", "10.1007/978-3-642-39146-0_37", "10.1016/j.cag.2013.10.007", "10.1023/A:1014056429969", "10.1016/j.ijrobp.2013.06.919", "10.1016/j.jbi.2015.06.020", "10.1007/3-540-48316-0", "10.1023/A:1014047731786", "10.1016/S0004-3702(96)00025-2", "10.1136/amiajnl-2013-002033", "10.1007/978-1-4612-2404-4_19", "10.1007/s40273-015-0333-4", "10.1198/106186002317375604", "10.1007/978-3-642-32498-7_5", "10.1177/1473871611415994", "10.1007/978-3-642-39146-0_37", "10.1016/j.cag.2013.10.007", "10.1023/A:1014056429969", "10.1016/j.ijrobp.2013.06.919", "10.1016/j.jbi.2015.06.020", "10.1007/3-540-48316-0", "10.1023/A:1014047731786", "10.1016/S0004-3702(96)00025-2", "10.1136/amiajnl-2013-002033", "10.1007/978-1-4612-2404-4_19", "10.1007/s40273-015-0333-4", "10.1198/106186002317375604", "10.1007/978-3-642-32498-7_5", "10.1177/1473871611415994", "10.1007/978-3-642-39146-0_37", "10.1016/j.cag.2013.10.007", "10.1023/A:1014056429969", "10.1016/j.ijrobp.2013.06.919", "10.1016/j.jbi.2015.06.020", "10.1007/3-540-48316-0", "10.1023/A:1014047731786", "10.1016/S0004-3702(96)00025-2", "10.1136/amiajnl-2013-002033"]}, "10.1109/TVCG.2016.2542067": {"doi": "10.1109/TVCG.2016.2542067", "author": ["J. Vaillant", "K. Bouyarmane", "A. Kheddar"], "title": "Multi-Character Physical and Behavioral Interactions Controller", "year": "2017", "abstract": "We extend the quadratic program (QP)-based task-space character control approach-initially intended for individual character animation-to multiple characters interacting among each other or with mobile/articulated elements of the environment. The interactions between the characters can be either physical interactions, such as contacts that can be established or broken at will between them and for which the forces are subjected to Newton's third law, or behavioral interactions, such as collision avoidance and cooperation that naturally emerge to achieve collaborative tasks from high-level specifications. We take a systematic approach integrating all the equations of motions of the characters, objects, and articulated environment parts in a single QP formulation in order to embrace and solve the most general instance of the problem, where independent individual character controllers would fail to account for the inherent coupling of their respective motions through those physical and behavioral interactions. Various types of motions/behaviors are controlled with only the one single formulation that we propose, and some examples of the original motions the framework allows are presented in the accompanying video.", "keywords": ["computer animation", "quadratic programming", "multicharacter physical interaction controller", "multicharacter behavioral interaction controller", "quadratic program-based task-space character control approach", "QP-based task-space character control approach", "character interaction", "physical interaction", "collaborative tasks", "high-level specifications", "systematic approach", "character motion equations", "object motion equations", "articulated environment parts", "character animation", "Mathematical model", "Animation", "Physics", "Real-time systems", "Computational modeling", "Collision avoidance", "Solid modeling", "I.3 Computer graphics", "I.3.7 three-dimensional graphics and realism", "I.3.7.a animation", "I.6 simulation", "modeling", "and visualization", "I.6.8 types of simulation", "I.6.8.a animation"], "referenced_by": ["10.1109/COASE.2017.8256069", "10.1109/HUMANOIDS.2016.7803405", "10.1109/HUMANOIDS.2017.8246911", "10.1109/HUMANOIDS.2017.8246914", "10.1109/SII.2017.8279234", "10.1109/TAC.2017.2752085", "10.1109/SIMPAR.2018.8376272", "10.1109/ICRA.2018.8463167", "10.1109/HUMANOIDS.2018.8624913", "10.1109/TRO.2018.2876782", "10.1007/s10846-017-0692-5", "10.1007/978-94-007-6046-2_32", "10.1007/978-94-007-7194-9_32-1"], "referencing": ["10.1109/TVCG.2009.76", "10.1109/JRA.1987.1087068", "10.1109/ICRA.2011.5980156", "10.1109/TVCG.2012.325", "10.1109/TVCG.2010.257", "10.1109/ICRA.2011.5980088", "10.1109/TRO.2013.2296332", "10.1109/ROBOT.1987.1087982", "10.1109/TVCG.2009.76", "10.1109/JRA.1987.1087068", "10.1109/ICRA.2011.5980156", "10.1109/TVCG.2012.325", "10.1109/TVCG.2010.257", "10.1109/ICRA.2011.5980088", "10.1109/TRO.2013.2296332", "10.1109/ROBOT.1987.1087982", "10.1109/TVCG.2009.76", "10.1109/JRA.1987.1087068", "10.1109/ICRA.2011.5980156", "10.1109/TVCG.2012.325", "10.1109/TVCG.2010.257", "10.1109/ICRA.2011.5980088", "10.1109/TRO.2013.2296332", "10.1109/ROBOT.1987.1087982", "10.1145/127719.122755", "10.1145/218380.218414", "10.1145/383259.383287", "10.1145/1833349.1781157", "10.1145/1477926.1477936", "10.1145/1531326.1531386", "10.1145/882262.882286", "10.1145/192161.192266", "10.1145/1015706.1015756", "10.1145/1599470.1599476", "10.1145/2366145.2366175", "10.1145/1138450.1138457", "10.1145/1805964.1805970", "10.1145/2010324.1964954", "10.1145/1531326.1531365", "10.1145/1833349.1778770", "10.1145/2766986", "10.1145/1315184.1315200", "10.1145/127719.122755", "10.1145/218380.218414", "10.1145/383259.383287", "10.1145/1833349.1781157", "10.1145/1477926.1477936", "10.1145/1531326.1531386", "10.1145/882262.882286", "10.1145/192161.192266", "10.1145/1015706.1015756", "10.1145/1599470.1599476", "10.1145/2366145.2366175", "10.1145/1138450.1138457", "10.1145/1805964.1805970", "10.1145/2010324.1964954", "10.1145/1531326.1531365", "10.1145/1833349.1778770", "10.1145/2766986", "10.1145/1315184.1315200", "10.1145/127719.122755", "10.1145/218380.218414", "10.1145/383259.383287", "10.1145/1833349.1781157", "10.1145/1477926.1477936", "10.1145/1531326.1531386", "10.1145/882262.882286", "10.1145/192161.192266", "10.1145/1015706.1015756", "10.1145/1599470.1599476", "10.1145/2366145.2366175", "10.1145/1138450.1138457", "10.1145/1805964.1805970", "10.1145/2010324.1964954", "10.1145/1531326.1531365", "10.1145/1833349.1778770", "10.1145/2766986", "10.1145/1315184.1315200", "10.1142/S0219843605000594", "10.1111/cgf.12321", "10.1080/01691864.2012.686345", "10.15607/RSS.2008.IV.020", "10.1007/s00371-004-0244-4", "10.1142/S0219843605000594", "10.1111/cgf.12321", "10.1080/01691864.2012.686345", "10.15607/RSS.2008.IV.020", "10.1007/s00371-004-0244-4", "10.1142/S0219843605000594", "10.1111/cgf.12321", "10.1080/01691864.2012.686345", "10.15607/RSS.2008.IV.020", "10.1007/s00371-004-0244-4"]}, "10.1109/TVCG.2016.2542073": {"doi": "10.1109/TVCG.2016.2542073", "author": ["S. Nadeem", "Z. Su", "W. Zeng", "A. Kaufman", "X. Gu"], "title": "Spherical Parameterization Balancing Angle and Area Distortions", "year": "2017", "abstract": "This work presents a novel framework for spherical mesh parameterization. An efficient angle-preserving spherical parameterization algorithm is introduced, which is based on dynamic Yamabe flow and the conformal welding method with solid theoretic foundation. An area-preserving spherical parameterization is also discussed, which is based on discrete optimal mass transport theory. Furthermore, a spherical parameterization algorithm, which is based on the polar decomposition method, balancing angle distortion and area distortion is presented. The algorithms are tested on 3D geometric data and the experiments demonstrate the efficiency and efficacy of the proposed methods.", "keywords": ["computational geometry", "spherical parameterization balancing angle distortion", "area distortions", "spherical mesh parameterization", "angle-preserving spherical parameterization algorithm", "dynamic Yamabe flow", "conformal welding method", "discrete optimal mass transport theory", "polar decomposition method", "3D geometric data", "Mesh generation", "Heuristic algorithms", "Three-dimensional displays", "Conformal mapping", "Harmonic distortion", "Spherical parameterization", "conformal map", "area-preserving map", "ricci flow", "optimal mass transport", "Algorithms", "Brain", "Computer Graphics", "Humans", "Imaging, Three-Dimensional", "Models, Theoretical"], "referenced_by": ["10.1109/TVCG.2016.2598791", "10.1109/TVCG.2017.2772237", "10.1109/ICCV.2019.00233", "10.1109/ICASSP40776.2020.9054085", "10.23919/Eusipco47968.2020.9287581", "10.1109/LSP.2020.3039425", "10.1007/s10915-018-0822-7", "10.1007/978-3-030-04747-4_4", "10.1016/j.cad.2019.05.024", "10.1111/cgf.13624", "10.1002/mp.13907", "10.1016/j.sigpro.2020.107867", "10.1016/j.cmpb.2020.105839"], "referencing": ["10.1109/TVCG.2009.64", "10.1109/TMI.2004.831226", "10.1109/2945.856998", "10.1109/SMI.2005.32", "10.1109/SMI.2006.9", "10.1109/TVCG.2013.135", "10.1109/TVCG.2009.64", "10.1109/TMI.2004.831226", "10.1109/2945.856998", "10.1109/SMI.2005.32", "10.1109/SMI.2006.9", "10.1109/TVCG.2013.135", "10.1109/TVCG.2009.64", "10.1109/TMI.2004.831226", "10.1109/2945.856998", "10.1109/SMI.2005.32", "10.1109/SMI.2006.9", "10.1109/TVCG.2013.135", "10.1145/2461912.2461986", "10.1145/2366145.2366190", "10.1145/882262.882276", "10.1145/1138450.1138461", "10.1145/2601097.2601175", "10.1145/1360612.1360676", "10.1145/2461912.2461986", "10.1145/2366145.2366190", "10.1145/882262.882276", "10.1145/1138450.1138461", "10.1145/2601097.2601175", "10.1145/1360612.1360676", "10.1145/2461912.2461986", "10.1145/2366145.2366190", "10.1145/882262.882276", "10.1145/1138450.1138461", "10.1145/2601097.2601175", "10.1145/1360612.1360676", "10.1111/1467-8659.00575", "10.1137/0216006", "10.2140/gt.2015.19.2155", "10.1002/cpa.3160440402", "10.1111/j.1467-8659.2011.02033.x", "10.1016/j.neuroimage.2012.01.021", "10.1007/3-540-26808-1_9", "10.1023/B:VISI.0000036836.66311.97", "10.1111/1467-8659.00333", "10.4171/151", "10.1111/j.1467-8659.2008.01290.x", "10.1137/060659119", "10.1006/aima.1997.1634", "10.1111/j.1467-8659.2011.02032.x", "10.1007/s003710050153", "10.1561/0600000011", "10.1016/j.media.2008.10.008", "10.1007/978-3-540-39903-2_35", "10.1111/1467-8659.00575", "10.1137/0216006", "10.2140/gt.2015.19.2155", "10.1002/cpa.3160440402", "10.1111/j.1467-8659.2011.02033.x", "10.1016/j.neuroimage.2012.01.021", "10.1007/3-540-26808-1_9", "10.1023/B:VISI.0000036836.66311.97", "10.1111/1467-8659.00333", "10.4171/151", "10.1111/j.1467-8659.2008.01290.x", "10.1137/060659119", "10.1006/aima.1997.1634", "10.1111/j.1467-8659.2011.02032.x", "10.1007/s003710050153", "10.1561/0600000011", "10.1016/j.media.2008.10.008", "10.1007/978-3-540-39903-2_35", "10.1111/1467-8659.00575", "10.1137/0216006", "10.2140/gt.2015.19.2155", "10.1002/cpa.3160440402", "10.1111/j.1467-8659.2011.02033.x", "10.1016/j.neuroimage.2012.01.021", "10.1007/3-540-26808-1_9", "10.1023/B:VISI.0000036836.66311.97", "10.1111/1467-8659.00333", "10.4171/151", "10.1111/j.1467-8659.2008.01290.x", "10.1137/060659119", "10.1006/aima.1997.1634", "10.1111/j.1467-8659.2011.02032.x", "10.1007/s003710050153", "10.1561/0600000011", "10.1016/j.media.2008.10.008", "10.1007/978-3-540-39903-2_35"]}, "10.1109/TVCG.2016.2542069": {"doi": "10.1109/TVCG.2016.2542069", "author": ["A. V. P. Grosset", "M. Prasad", "C. Christensen", "A. Knoll", "C. Hansen"], "title": "TOD-Tree: Task-Overlapped Direct Send Tree Image Compositing for Hybrid MPI Parallelism and GPUs", "year": "2017", "abstract": "Modern supercomputers have thousands of nodes, each with CPUs and/or GPUs capable of several teraflops. However, the network connecting these nodes is relatively slow, on the order of gigabits per second. For time-critical workloads such as interactive visualization, the bottleneck is no longer computation but communication. In this paper, we present an image compositing algorithm that works on both CPU-only and GPU-accelerated supercomputers and focuses on communication avoidance and overlapping communication with computation at the expense of evenly balancing the workload. The algorithm has three stages: a parallel direct send stage, followed by a tree compositing stage and a gather stage. We compare our algorithm with radix-k and binary-swap from the IceT library in a hybrid OpenMP/MPI setting on the Stampede and Edison supercomputers, show strong scaling results and explain how we generally achieve better performance than these two algorithms. We developed a GPU-based image compositing algorithm where we use CUDA kernels for computation and GPU Direct RDMA for inter-node GPU communication. We tested the algorithm on the Piz Daint GPU-accelerated supercomputer and show that we achieve performance on par with CPUs. Last, we introduce a workflow in which both rendering and compositing are done on the GPU.", "keywords": ["application program interfaces", "graphics processing units", "image processing", "message passing", "rendering (computer graphics)", "tree data structures", "TOD-tree", "task-overlapped direct send tree image compositing", "hybrid MPI parallelism", "interactive visualization", "CPU-only supercomputers", "GPU-accelerated supercomputers", "communication avoidance", "overlapping communication", "radix-k", "binary-swap", "IceT library", "hybrid OpenMP/MPI setting", "GPU-based image compositing algorithm", "CUDA kernels", "GPU direct RDMA", "internode GPU communication", "Piz Daint GPU-accelerated supercomputer", "rendering", "Graphics processing units", "Rendering (computer graphics)", "Supercomputers", "Parallel processing", "Data visualization", "Loading", "Message systems", "Distributed volume rendering", "image compositing", "parallel processing"], "referenced_by": ["10.1109/LDAV.2016.7874334", "10.1109/ACCESS.2019.2913280", "10.1109/LDAV48142.2019.8944265", "10.1111/cgf.13702"], "referencing": ["10.1109/TVCG.2011.24", "10.1109/PRS.1993.586080", "10.1109/38.291528", "10.1109/38.291531", "10.1109/TVCG.2007.1026", "10.1109/TVCG.2008.104", "10.1109/99.660313", "10.1109/TVCG.2011.24", "10.1109/PRS.1993.586080", "10.1109/38.291528", "10.1109/38.291531", "10.1109/TVCG.2007.1026", "10.1109/TVCG.2008.104", "10.1109/99.660313", "10.1109/TVCG.2011.24", "10.1109/PRS.1993.586080", "10.1109/38.291528", "10.1109/38.291531", "10.1109/TVCG.2007.1026", "10.1109/TVCG.2008.104", "10.1109/99.660313", "10.1145/361002.361007", "10.1145/1816038.1816021", "10.1145/361002.361007", "10.1145/1816038.1816021", "10.1145/361002.361007", "10.1145/1816038.1816021", "10.1007/978-3-642-03770-2_24", "10.1016/B978-012387582-2/50038-1", "10.2172/1005031", "10.1002/cpe.1206", "10.1007/978-3-642-03770-2_24", "10.1016/B978-012387582-2/50038-1", "10.2172/1005031", "10.1002/cpe.1206", "10.1007/978-3-642-03770-2_24", "10.1016/B978-012387582-2/50038-1", "10.2172/1005031", "10.1002/cpe.1206"]}, "10.1109/TVCG.2016.2539949": {"doi": "10.1109/TVCG.2016.2539949", "author": ["H. Zhao", "G. W. Bryant", "W. Griffin", "J. E. Terrill", "J. Chen"], "title": "Validation of SplitVectors Encoding for Quantitative Visualization of Large-Magnitude-Range Vector Fields", "year": "2017", "abstract": "We designed and evaluated SplitVectors, a new vector field display approach to help scientists perform new discrimination tasks on large-magnitude-range scientific data shown in three-dimensional (3D) visualization environments. SplitVectors uses scientific notation to display vector magnitude, thus improving legibility. We present an empirical study comparing the SplitVectors approach with three other approaches - direct linear representation, logarithmic, and text display commonly used in scientific visualizations. Twenty participants performed three domain analysis tasks: reading numerical values (a discrimination task), finding the ratio between values (a discrimination task), and finding the larger of two vectors (a pattern detection task). Participants used both mono and stereo conditions. Our results suggest the following: (1) SplitVectors improve accuracy by about 10 times compared to linear mapping and by four times to logarithmic in discrimination tasks; (2) SplitVectors have no significant differences from the textual display approach, but reduce cluttering in the scene; (3) SplitVectors and textual display are less sensitive to data scale than linear and logarithmic approaches; (4) using logarithmic can be problematic as participants' confidence was as high as directly reading from the textual display, but their accuracy was poor; and (5) Stereoscopy improved performance, especially in more challenging discrimination tasks.", "keywords": ["physics computing", "scientific information systems", "virtual reality", "SplitVectors encoding validation", "quantitative visualization", "large-magnitude-range vector fields", "vector field display approach", "large-magnitude-range scientific data", "three-dimensional visualization environments", "empirical study", "direct linear representation", "logarithmic display", "text display", "numerical value reading", "discrimination task", "pattern detection task", "monocondition", "stereo condition", "scene cluttering reduction", "Data visualization", "Encoding", "Three-dimensional displays", "Physics", "Visualization", "Quantum physics", "Stereo image processing", "Vector field", "scientific visualization in virtual environments", "quantum physics", "visual encoding", "large-range data"], "referenced_by": ["10.1109/TVCG.2019.2898438", "10.1007/978-3-030-01388-2_9", "10.1007/978-3-030-34444-3_7"], "referencing": ["10.1109/TVCG.2014.2346428", "10.1109/TVCG.2013.10", "10.1109/TVCG.2009.126", "10.1109/TVCG.2013.126", "10.1109/TVCG.2009.111", "10.1109/TVCG.2011.203", "10.1109/VR.2006.52", "10.1109/TVCG.2011.234", "10.1109/TVCG.2008.59", "10.1109/TVCG.2012.216", "10.1109/TVCG.2013.120", "10.1109/TVCG.2004.1260759", "10.1109/TVCG.2013.124", "10.1109/TVCG.2014.2346428", "10.1109/TVCG.2013.10", "10.1109/TVCG.2009.126", "10.1109/TVCG.2013.126", "10.1109/TVCG.2009.111", "10.1109/TVCG.2011.203", "10.1109/VR.2006.52", "10.1109/TVCG.2011.234", "10.1109/TVCG.2008.59", "10.1109/TVCG.2012.216", "10.1109/TVCG.2013.120", "10.1109/TVCG.2004.1260759", "10.1109/TVCG.2013.124", "10.1109/TVCG.2014.2346428", "10.1109/TVCG.2013.10", "10.1109/TVCG.2009.126", "10.1109/TVCG.2013.126", "10.1109/TVCG.2009.111", "10.1109/TVCG.2011.203", "10.1109/VR.2006.52", "10.1109/TVCG.2011.234", "10.1109/TVCG.2008.59", "10.1109/TVCG.2012.216", "10.1109/TVCG.2013.120", "10.1109/TVCG.2004.1260759", "10.1109/TVCG.2013.124", "10.1145/1008653.1008669", "10.1145/985040.985042", "10.1145/1620993.1620996", "10.1145/234972.234975", "10.1145/2207676.2208589", "10.1145/502360.502363", "10.1145/1008653.1008669", "10.1145/985040.985042", "10.1145/1620993.1620996", "10.1145/234972.234975", "10.1145/2207676.2208589", "10.1145/502360.502363", "10.1145/1008653.1008669", "10.1145/985040.985042", "10.1145/1620993.1620996", "10.1145/234972.234975", "10.1145/2207676.2208589", "10.1145/502360.502363", "10.1103/PhysRevB.87.125423", "10.1016/j.ijhcs.2010.05.007", "10.3758/BF03194718", "10.1068/p3115", "10.1006/ijhc.2000.0419", "10.1016/j.cag.2011.01.011", "10.1075/idj.10.3.07war", "10.6028/jres.113.010", "10.1016/B978-012387582-2/50038-1", "10.1179/000870403235002042", "10.1103/PhysRevB.87.125423", "10.1016/j.ijhcs.2010.05.007", "10.3758/BF03194718", "10.1068/p3115", "10.1006/ijhc.2000.0419", "10.1016/j.cag.2011.01.011", "10.1075/idj.10.3.07war", "10.6028/jres.113.010", "10.1016/B978-012387582-2/50038-1", "10.1179/000870403235002042", "10.1103/PhysRevB.87.125423", "10.1016/j.ijhcs.2010.05.007", "10.3758/BF03194718", "10.1068/p3115", "10.1006/ijhc.2000.0419", "10.1016/j.cag.2011.01.011", "10.1075/idj.10.3.07war", "10.6028/jres.113.010", "10.1016/B978-012387582-2/50038-1", "10.1179/000870403235002042"]}, "10.1109/TVCG.2016.2543720": {"doi": "10.1109/TVCG.2016.2543720", "author": ["J. Grubert", "T. Langlotz", "S. Zollmann", "H. Regenbrecht"], "title": "Towards Pervasive Augmented Reality: Context-Awareness in Augmented Reality", "year": "2017", "abstract": "Augmented Reality is a technique that enables users to interact with their physical environment through the overlay of digital information. While being researched for decades, more recently, Augmented Reality moved out of the research labs and into the field. While most of the applications are used sporadically and for one particular task only, current and future scenarios will provide a continuous and multi-purpose user experience. Therefore, in this paper, we present the concept of Pervasive Augmented Reality, aiming to provide such an experience by sensing the user's current context and adapting the AR system based on the changing requirements and constraints. We present a taxonomy for Pervasive Augmented Reality and context-aware Augmented Reality, which classifies context sources and context targets relevant for implementing such a context-aware, continuous Augmented Reality experience. We further summarize existing approaches that contribute towards Pervasive Augmented Reality. Based our taxonomy and survey, we identify challenges for future research directions in Pervasive Augmented Reality.", "keywords": ["augmented reality", "ubiquitous computing", "pervasive augmented reality", "physical environment interaction", "digital information", "AR system", "context sources", "context targets", "context-aware continuous augmented reality experience", "Augmented reality", "Context awareness", "Mobile communication", "User interfaces", "Three-dimensional displays", "Tracking", "Ontologies", "Augmented reality", "pervasive augmented reality", "context-awareness", "adaptivity", "context", "taxonomy", "survey", "mixed reality"], "referenced_by": ["10.1109/ISMAR-Adjunct.2017.37", "10.1109/IVCNZ.2016.7804440", "10.1109/TVCG.2016.2593781", "10.1109/ISSRE.2018.00018", "10.1109/ACCESS.2018.2884536", "10.1109/VR.2019.8798262", "10.1109/VR.2019.8797804", "10.1109/IV.2019.00012", "10.1109/THMS.2019.2944384", "10.1109/ISMAR.2019.00023", "10.1109/LCN44214.2019.8990850", "10.1109/ACCESS.2020.2971962", "10.1109/SANER48275.2020.9054812", "10.1109/VR46266.2020.00036", "10.1109/SECON48991.2020.9158429", "10.23919/iLRN47897.2020.9155126", "10.1109/PerComWorkshops48775.2020.9156256", "10.1109/ISMAR50242.2020.00069", "10.1109/ISMAR50242.2020.00064", "10.1109/ISMAR-Adjunct51615.2020.00076", "10.1109/ISMAR-Adjunct51615.2020.00088", "10.1145/3274411", "10.1007/978-3-319-76270-8_3", "10.1016/j.aci.2017.08.001", "10.1016/j.csi.2017.08.003", "10.1016/j.ssci.2017.11.013", "10.1080/00207543.2017.1413259", "10.23949/kjpe.2017.09.56.5.25", "10.1080/0144929X.2018.1505950", "10.1108/AA-03-2017-032", "10.4018/IJ3DIM.2018010102", "10.1007/s42486-018-0002-8", "10.13044/j.sdewes.d6.0247.edt", "10.3390/buildings9050118", "10.1007/978-3-030-17985-4_4", "10.1080/00207543.2019.1629667", "10.4018/IJCMHS.2019070107", "10.1007/978-3-030-27928-8_3", "10.1115/1.4044331", "10.1111/cgf.13887", "10.1007/s11227-019-03082-3", "10.1007/978-3-030-27844-1_10", "10.1007/978-981-15-2568-1_76", "10.3390/app10030780", "10.1007/s40436-020-00295-1", "10.1016/j.compind.2020.103229", "10.1002/ett.3954", "10.1007/978-3-030-46540-7_11", "10.1016/j.apergo.2020.103145", "10.1007/978-3-030-42156-4_19", "10.1007/978-3-030-49698-2_7"], "referencing": ["10.1109/JPROC.2013.2294255", "10.1109/ISMAR.2011.6092389", "10.1109/MCG.2005.124", "10.1109/MSPEC.2015.7131695", "10.1109/MPRV.2009.30", "10.1109/JPROC.2013.2294314", "10.1109/MCG.2002.1046626", "10.1109/IWAR.1999.803809", "10.1109/ISMAR.2008.4637338", "10.1109/ISMAR.2011.6092378", "10.1109/ISMAR.2014.6948420", "10.1109/TVCG.2015.2480087", "10.1109/ISMAR.2013.6671773", "10.1109/VR.2014.6802044", "10.1109/ISMAR.2010.5643547", "10.1109/ISMAR.2010.5643546", "10.1109/VR.2014.6802046", "10.1109/ISAR.2000.880934", "10.1109/MCG.2006.66", "10.1109/38.963459", "10.1109/ISMAR.2011.6092372", "10.1109/TLT.2012.11", "10.1109/ICPCA.2010.5704077", "10.1109/ISAR.2000.880917", "10.1109/ISMAR.2013.6671807", "10.1109/34.730558", "10.1109/ICALT.2006.1652683", "10.1109/VR.2002.996507", "10.1109/ISUVR.2009.24", "10.1109/ISAR.2000.880938", "10.1109/TVCG.2015.2391856", "10.1109/TVCG.2015.2391857", "10.1109/JPROC.2013.2294255", "10.1109/ISMAR.2011.6092389", "10.1109/MCG.2005.124", "10.1109/MSPEC.2015.7131695", "10.1109/MPRV.2009.30", "10.1109/JPROC.2013.2294314", "10.1109/MCG.2002.1046626", "10.1109/IWAR.1999.803809", "10.1109/ISMAR.2008.4637338", "10.1109/ISMAR.2011.6092378", "10.1109/ISMAR.2014.6948420", "10.1109/TVCG.2015.2480087", "10.1109/ISMAR.2013.6671773", "10.1109/VR.2014.6802044", "10.1109/ISMAR.2010.5643547", "10.1109/ISMAR.2010.5643546", "10.1109/VR.2014.6802046", "10.1109/ISAR.2000.880934", "10.1109/MCG.2006.66", "10.1109/38.963459", "10.1109/ISMAR.2011.6092372", "10.1109/TLT.2012.11", "10.1109/ICPCA.2010.5704077", "10.1109/ISAR.2000.880917", "10.1109/ISMAR.2013.6671807", "10.1109/34.730558", "10.1109/ICALT.2006.1652683", "10.1109/VR.2002.996507", "10.1109/ISUVR.2009.24", "10.1109/ISAR.2000.880938", "10.1109/TVCG.2015.2391856", "10.1109/TVCG.2015.2391857", "10.1109/JPROC.2013.2294255", "10.1109/ISMAR.2011.6092389", "10.1109/MCG.2005.124", "10.1109/MSPEC.2015.7131695", "10.1109/MPRV.2009.30", "10.1109/JPROC.2013.2294314", "10.1109/MCG.2002.1046626", "10.1109/IWAR.1999.803809", "10.1109/ISMAR.2008.4637338", "10.1109/ISMAR.2011.6092378", "10.1109/ISMAR.2014.6948420", "10.1109/TVCG.2015.2480087", "10.1109/ISMAR.2013.6671773", "10.1109/VR.2014.6802044", "10.1109/ISMAR.2010.5643547", "10.1109/ISMAR.2010.5643546", "10.1109/VR.2014.6802046", "10.1109/ISAR.2000.880934", "10.1109/MCG.2006.66", "10.1109/38.963459", "10.1109/ISMAR.2011.6092372", "10.1109/TLT.2012.11", "10.1109/ICPCA.2010.5704077", "10.1109/ISAR.2000.880917", "10.1109/ISMAR.2013.6671807", "10.1109/34.730558", "10.1109/ICALT.2006.1652683", "10.1109/VR.2002.996507", "10.1109/ISUVR.2009.24", "10.1109/ISAR.2000.880938", "10.1109/TVCG.2015.2391856", "10.1109/TVCG.2015.2391857", "10.1145/2527190", "10.1145/2786567.2794310", "10.1145/1476589.1476686", "10.1145/159544.159566", "10.1145/2493190.2493234", "10.1145/2207676.2208405", "10.1145/1520340.1520581", "10.1145/2642918.2647383", "10.1145/2702123.2702331", "10.1145/1057792.1057803", "10.1145/355324.355325", "10.1145/2037373.2037383", "10.1145/2594128", "10.1145/2470654.2481306", "10.1145/2658779.2658802", "10.1145/2254556.2254595", "10.1145/1450579.1450625", "10.1145/2399016.2399053", "10.1145/2335484.2335500", "10.1145/571985.572017", "10.1145/2371574.2371609", "10.1145/502360.502363", "10.1145/2617841.2620695", "10.1145/2808208", "10.1145/2702123.2702215", "10.1145/2556288.2557199", "10.1145/2786567.2794349", "10.1145/2527190", "10.1145/2786567.2794310", "10.1145/1476589.1476686", "10.1145/159544.159566", "10.1145/2493190.2493234", "10.1145/2207676.2208405", "10.1145/1520340.1520581", "10.1145/2642918.2647383", "10.1145/2702123.2702331", "10.1145/1057792.1057803", "10.1145/355324.355325", "10.1145/2037373.2037383", "10.1145/2594128", "10.1145/2470654.2481306", "10.1145/2658779.2658802", "10.1145/2254556.2254595", "10.1145/1450579.1450625", "10.1145/2399016.2399053", "10.1145/2335484.2335500", "10.1145/571985.572017", "10.1145/2371574.2371609", "10.1145/502360.502363", "10.1145/2617841.2620695", "10.1145/2808208", "10.1145/2702123.2702215", "10.1145/2556288.2557199", "10.1145/2786567.2794349", "10.1145/2527190", "10.1145/2786567.2794310", "10.1145/1476589.1476686", "10.1145/159544.159566", "10.1145/2493190.2493234", "10.1145/2207676.2208405", "10.1145/1520340.1520581", "10.1145/2642918.2647383", "10.1145/2702123.2702331", "10.1145/1057792.1057803", "10.1145/355324.355325", "10.1145/2037373.2037383", "10.1145/2594128", "10.1145/2470654.2481306", "10.1145/2658779.2658802", "10.1145/2254556.2254595", "10.1145/1450579.1450625", "10.1145/2399016.2399053", "10.1145/2335484.2335500", "10.1145/571985.572017", "10.1145/2371574.2371609", "10.1145/502360.502363", "10.1145/2617841.2620695", "10.1145/2808208", "10.1145/2702123.2702215", "10.1145/2556288.2557199", "10.1145/2786567.2794349", "10.1162/pres.1997.6.4.355", "10.1162/pres.1997.6.4.399", "10.1016/S0097-8493(01)00119-4", "10.1007/978-3-642-22021-0_29", "10.1007/s00170-010-2671-x", "10.1007/s10055-013-0230-0", "10.1002/cav.221", "10.1561/1100000049", "10.1007/s00779-003-0253-8", "10.1007/978-3-540-74255-5_42", "10.1504/IJAHUC.2007.014070", "10.1016/j.pmcj.2009.06.002", "10.1207/S15327051HCI16234_07", "10.1207/S15327051HCI16234_09", "10.1207/S15327051HCI16234_17", "10.1146/annurev.psych.50.1.243", "10.1007/978-0-387-85820-3_7", "10.1007/s00779-010-0363-z", "10.3389/fpsyg.2011.00358", "10.1017/CBO9780511815478", "10.1007/s00779-004-0263-1", "10.1080/08839510490462768", "10.1016/S0020-7373(84)80054-1", "10.1016/j.jss.2011.06.063", "10.1080/13614560410001725338", "10.1007/978-3-540-73107-8_106", "10.1016/j.pmcj.2014.08.005", "10.1162/pres.1997.6.4.386", "10.1162/pres.1997.6.4.355", "10.1162/pres.1997.6.4.399", "10.1016/S0097-8493(01)00119-4", "10.1007/978-3-642-22021-0_29", "10.1007/s00170-010-2671-x", "10.1007/s10055-013-0230-0", "10.1002/cav.221", "10.1561/1100000049", "10.1007/s00779-003-0253-8", "10.1007/978-3-540-74255-5_42", "10.1504/IJAHUC.2007.014070", "10.1016/j.pmcj.2009.06.002", "10.1207/S15327051HCI16234_07", "10.1207/S15327051HCI16234_09", "10.1207/S15327051HCI16234_17", "10.1146/annurev.psych.50.1.243", "10.1007/978-0-387-85820-3_7", "10.1007/s00779-010-0363-z", "10.3389/fpsyg.2011.00358", "10.1017/CBO9780511815478", "10.1007/s00779-004-0263-1", "10.1080/08839510490462768", "10.1016/S0020-7373(84)80054-1", "10.1016/j.jss.2011.06.063", "10.1080/13614560410001725338", "10.1007/978-3-540-73107-8_106", "10.1016/j.pmcj.2014.08.005", "10.1162/pres.1997.6.4.386", "10.1162/pres.1997.6.4.355", "10.1162/pres.1997.6.4.399", "10.1016/S0097-8493(01)00119-4", "10.1007/978-3-642-22021-0_29", "10.1007/s00170-010-2671-x", "10.1007/s10055-013-0230-0", "10.1002/cav.221", "10.1561/1100000049", "10.1007/s00779-003-0253-8", "10.1007/978-3-540-74255-5_42", "10.1504/IJAHUC.2007.014070", "10.1016/j.pmcj.2009.06.002", "10.1207/S15327051HCI16234_07", "10.1207/S15327051HCI16234_09", "10.1207/S15327051HCI16234_17", "10.1146/annurev.psych.50.1.243", "10.1007/978-0-387-85820-3_7", "10.1007/s00779-010-0363-z", "10.3389/fpsyg.2011.00358", "10.1017/CBO9780511815478", "10.1007/s00779-004-0263-1", "10.1080/08839510490462768", "10.1016/S0020-7373(84)80054-1", "10.1016/j.jss.2011.06.063", "10.1080/13614560410001725338", "10.1007/978-3-540-73107-8_106", "10.1016/j.pmcj.2014.08.005", "10.1162/pres.1997.6.4.386"]}}