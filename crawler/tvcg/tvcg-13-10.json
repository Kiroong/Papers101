{"10.1109/TVCG.2013.60": {"doi": "10.1109/TVCG.2013.60", "author": ["S. Wang", "T. Hou", "S. Li", "Z. Su", "H. Qin"], "title": "Anisotropic Elliptic PDEs for Feature Classification", "year": "2013", "abstract": "The extraction and classification of multitype (point, curve, patch) features on manifolds are extremely challenging, due to the lack of rigorous definition for diverse feature forms. This paper seeks a novel solution of multitype features in a mathematically rigorous way and proposes an efficient method for feature classification on manifolds. We tackle this challenge by exploring a quasi-harmonic field (QHF) generated by elliptic PDEs, which is the stable state of heat diffusion governed by anisotropic diffusion tensor. Diffusion tensor locally encodes shape geometry and controls velocity and direction of the diffusion process. The global QHF weaves points into smooth regions separated by ridges and has superior performance in combating noise/holes. Our method's originality is highlighted by the integration of locally defined diffusion tensor and globally defined elliptic PDEs in an anisotropic manner. At the computational front, the heat diffusion PDE becomes a linear system with Dirichlet condition at heat sources (called seeds). Our new algorithms afford automatic seed selection, enhanced by a fast update procedure in a high-dimensional space. By employing diffusion probability, our method can handle both manufactured parts and organic objects. Various experiments demonstrate the flexibility and high performance of our method.", "keywords": ["computational geometry", "elliptic equations", "feature extraction", "integration", "partial differential equations", "pattern classification", "probability", "thermal diffusion", "anisotropic elliptic PDE", "multitype feature classification", "multitype feature extraction", "manifolds", "quasiharmonic field", "heat diffusion", "anisotropic diffusion tensor", "shape geometry encoding", "diffusion process direction control", "diffusion process velocity control", "global QHF weaves", "integration", "locally defined diffusion tensor", "globally defined elliptic PDE", "Dirichlet condition", "heat sources", "automatic seed selection", "high-dimensional space", "diffusion probability", "manufactured parts", "organic objects", "Feature extraction", "Tensile stress", "Noise", "Heating", "Noise measurement", "Eigenvalues and eigenfunctions", "Shape", "Diffusion tensor", "elliptic PDE", "quasi-harmonic field", "feature classification"], "referenced_by": ["IKEY:6738291", "IKEY:8128347", "IKEY:8369345", "IKEY:8559156", "IKEY:8559238", "IKEY:8719145", "10.1007/978-3-319-61358-1_8", "10.1007/s41095-016-0071-3", "10.1111/cgf.12479", "10.1007/978-981-13-2330-0_23", "10.1177/1550147718811303", "10.1016/j.cagd.2019.04.020"], "referencing": ["IKEY:1634326", "IKEY:5453359", "IKEY:885721", "IKEY:6185548", "IKEY:1310279", "IKEY:1310277", "IKEY:4015396", "IKEY:1183795", "IKEY:1348360", "IKEY:1563229", "IKEY:5963664", "IKEY:1634326", "IKEY:5453359", "IKEY:885721", "IKEY:6185548", "IKEY:1310279", "IKEY:1310277", "IKEY:4015396", "IKEY:1183795", "IKEY:1348360", "IKEY:1563229", "IKEY:5963664", "IKEY:1634326", "IKEY:5453359", "IKEY:885721", "IKEY:6185548", "IKEY:1310279", "IKEY:1310277", "IKEY:4015396", "IKEY:1183795", "IKEY:1348360", "IKEY:1563229", "IKEY:5963664", "10.1145/1015706.1015730", "10.1145/1037957.1037958", "10.1145/311535.311576", "10.1145/1122501.1122507", "10.1145/1015706.1015768", "10.1145/882262.882369", "10.1145/1128888.1128891", "10.1145/1015706.1015817", "10.1145/2167076.2167079", "10.1145/1462173.1462176", "10.1145/1015706.1015730", "10.1145/1037957.1037958", "10.1145/311535.311576", "10.1145/1122501.1122507", "10.1145/1015706.1015768", "10.1145/882262.882369", "10.1145/1128888.1128891", "10.1145/1015706.1015817", "10.1145/2167076.2167079", "10.1145/1462173.1462176", "10.1145/1015706.1015730", "10.1145/1037957.1037958", "10.1145/311535.311576", "10.1145/1122501.1122507", "10.1145/1015706.1015768", "10.1145/882262.882369", "10.1145/1128888.1128891", "10.1145/1015706.1015817", "10.1145/2167076.2167079", "10.1145/1462173.1462176", "10.1007/978-3-642-15558-1_28", "10.1006/gmod.2002.0574", "10.1016/j.cad.2004.09.001", "10.1016/j.cad.2008.12.003", "10.1016/j.cagd.2008.09.007", "10.1111/j.1467-8659.2009.01515.x", "10.1016/j.gmod.2012.04.010", "10.1007/978-4-431-66956-2_18", "10.5244/C.10.26", "10.1007/s00453-003-1051-4", "10.1111/j.1467-8659.2011.01858.x", "10.1016/j.cad.2010.05.005", "10.1111/j.1467-8659.2006.00947.x", "10.1111/j.1467-8659.2009.01622.x", "10.1111/j.1467-8659.2010.01793.x", "10.1115/1.2960489", "10.1016/j.cad.2012.04.005", "10.1111/j.1467-8659.2007.01103.x", "10.1007/s00371-010-0494-2", "10.1017/CBO9780511810817", "10.1007/s00371-011-0582-y", "10.1016/j.cag.2009.03.022", "10.1016/j.cad.2006.12.005", "10.1007/978-3-642-15558-1_28", "10.1006/gmod.2002.0574", "10.1016/j.cad.2004.09.001", "10.1016/j.cad.2008.12.003", "10.1016/j.cagd.2008.09.007", "10.1111/j.1467-8659.2009.01515.x", "10.1016/j.gmod.2012.04.010", "10.1007/978-4-431-66956-2_18", "10.5244/C.10.26", "10.1007/s00453-003-1051-4", "10.1111/j.1467-8659.2011.01858.x", "10.1016/j.cad.2010.05.005", "10.1111/j.1467-8659.2006.00947.x", "10.1111/j.1467-8659.2009.01622.x", "10.1111/j.1467-8659.2010.01793.x", "10.1115/1.2960489", "10.1016/j.cad.2012.04.005", "10.1111/j.1467-8659.2007.01103.x", "10.1007/s00371-010-0494-2", "10.1017/CBO9780511810817", "10.1007/s00371-011-0582-y", "10.1016/j.cag.2009.03.022", "10.1016/j.cad.2006.12.005", "10.1007/978-3-642-15558-1_28", "10.1006/gmod.2002.0574", "10.1016/j.cad.2004.09.001", "10.1016/j.cad.2008.12.003", "10.1016/j.cagd.2008.09.007", "10.1111/j.1467-8659.2009.01515.x", "10.1016/j.gmod.2012.04.010", "10.1007/978-4-431-66956-2_18", "10.5244/C.10.26", "10.1007/s00453-003-1051-4", "10.1111/j.1467-8659.2011.01858.x", "10.1016/j.cad.2010.05.005", "10.1111/j.1467-8659.2006.00947.x", "10.1111/j.1467-8659.2009.01622.x", "10.1111/j.1467-8659.2010.01793.x", "10.1115/1.2960489", "10.1016/j.cad.2012.04.005", "10.1111/j.1467-8659.2007.01103.x", "10.1007/s00371-010-0494-2", "10.1017/CBO9780511810817", "10.1007/s00371-011-0582-y", "10.1016/j.cag.2009.03.022", "10.1016/j.cad.2006.12.005"]}, "10.1109/TVCG.2013.79": {"doi": "10.1109/TVCG.2013.79", "author": ["R. Marques", "C. Bouville", "M. Ribardi\u00e8re", "L. P. Santos", "K. Bouatouch"], "title": "A Spherical Gaussian Framework for Bayesian Monte Carlo Rendering of Glossy Surfaces", "year": "2013", "abstract": "The Monte Carlo method has proved to be very powerful to cope with global illumination problems but it remains costly in terms of sampling operations. In various applications, previous work has shown that Bayesian Monte Carlo can significantly outperform importance sampling Monte Carlo thanks to a more effective use of the prior knowledge and of the information brought by the samples set. These good results have been confirmed in the context of global illumination but strictly limited to the perfect diffuse case. Our main goal in this paper is to propose a more general Bayesian Monte Carlo solution that allows dealing with nondiffuse BRDFs thanks to a spherical Gaussian-based framework. We also propose a fast hyperparameters determination method that avoids learning the hyperparameters for each BRDF. These contributions represent two major steps toward generalizing Bayesian Monte Carlo for global illumination rendering. We show that we achieve substantial quality improvements over importance sampling at comparable computational cost.", "keywords": ["Bayes methods", "Gaussian processes", "lighting", "Monte Carlo methods", "parameter estimation", "rendering (computer graphics)", "sampling methods", "spherical Gaussian framework", "quality improvements", "global illumination rendering", "Bayesian Monte Carlo generalization", "fast hyperparameter determination method", "nondiffuse BRDF", "sampling operations", "global illumination problems", "glossy surfaces", "Bayesian Monte Carlo rendering", "Monte Carlo methods", "Bayes methods", "Vectors", "Computational modeling", "Lighting", "Noise", "Rendering (computer graphics)", "Bayesian Monte Carlo", "Gaussian process", "spherical Gaussian"], "referenced_by": ["IKEY:8700299", "10.1145/3197517.3201340", "10.1007/s11704-014-4211-6", "10.1016/S1005-8885(14)60348-4", "10.1111/risa.12836", "10.2200/S00649ED1V01Y201505CGR019", "10.1007/s11222-019-09896-8", "10.1007/s11222-019-09902-z"], "referencing": ["IKEY:4012101", "IKEY:4012101", "IKEY:4012101", "10.1145/1618452.1618479", "10.1145/1618452.1618479", "10.1145/1618452.1618479", "10.1016/0378-3758(91)90002-V", "10.1111/j.1467-8659.2009.01537.x", "10.1111/j.1467-8659.2008.01252.x", "10.1007/BF03024331", "10.1007/978-3-7091-9430-0_2", "10.1016/0378-3758(91)90002-V", "10.1111/j.1467-8659.2009.01537.x", "10.1111/j.1467-8659.2008.01252.x", "10.1007/BF03024331", "10.1007/978-3-7091-9430-0_2", "10.1016/0378-3758(91)90002-V", "10.1111/j.1467-8659.2009.01537.x", "10.1111/j.1467-8659.2008.01252.x", "10.1007/BF03024331", "10.1007/978-3-7091-9430-0_2"]}, "10.1109/TVCG.2013.12": {"doi": "10.1109/TVCG.2013.12", "author": ["Y. Yang", "W. Xu", "X. Guo", "K. Zhou", "B. Guo"], "title": "Boundary-Aware Multidomain Subspace Deformation", "year": "2013", "abstract": "In this paper, we propose a novel framework for multidomain subspace deformation using node-wise corotational elasticity. With the proper construction of subspaces based on the knowledge of the boundary deformation, we can use the Lagrange multiplier technique to impose coupling constraints at the boundary without overconstraining. In our deformation algorithm, the number of constraint equations to couple two neighboring domains is not related to the number of the nodes on the boundary but is the same as the number of the selected boundary deformation modes. The crack artifact is not present in our simulation result, and the domain decomposition with loops can be easily handled. Experimental results show that the single-core implementation of our algorithm can achieve real-time performance in simulating deformable objects with around quarter million tetrahedral elements.", "keywords": ["computer graphics", "constraint theory", "finite element analysis", "real-time systems", "boundary-aware multidomain subspace deformation algorithm", "node-wise corotational elasticity", "Lagrange multiplier technique", "coupling constraints", "constraint equations", "boundary deformation modes", "domain decomposition", "single-core implementation", "real-time performance", "deformable object simulation", "tetrahedral elements", "loops", "Couplings", "Deformable models", "Acceleration", "Harmonic analysis", "Elasticity", "Mathematical model", "Model reduction", "domain decomposition", "FEM", "deformable model"], "referenced_by": ["IKEY:8207608", "IKEY:8629927", "10.1145/2980179.2982400", "10.1145/2601097.2601181", "10.1145/3197517.3201387", "10.1145/2766904", "10.1145/2897824.2925916", "10.1145/3072959.3073685", "10.1145/2816795.2818089", "10.1145/2816795.2818065", "10.1145/3384515", "10.1145/2461912.2461961", "10.1002/cav.1594", "10.1007/978-3-319-51031-6_1", "10.1007/s00371-017-1410-9", "10.1016/j.cag.2017.07.030", "10.1016/j.cagd.2015.03.019", "10.1016/j.gmod.2015.05.002", "10.1016/j.gmod.2018.01.001", "10.1111/cgf.12808", "10.1111/cgf.13014", "10.1016/j.cagd.2016.02.014", "10.1080/1206212X.2018.1479621", "10.1016/j.cagd.2018.06.002", "10.1016/j.cag.2018.07.011", "10.1007/s11704-018-8081-1", "10.1111/cgf.13641"], "referencing": ["IKEY:20317", "IKEY:1359737", "IKEY:20317", "IKEY:1359737", "IKEY:20317", "IKEY:1359737", "10.1145/2019406.2019415", "10.1145/1964921.1964986", "10.1145/1401132.1401245", "10.1145/37401.37427", "10.1145/545265.545268", "10.1145/566654.566578", "10.1145/1141911.1142003", "10.1145/1275808.1276480", "10.1145/1576246.1531357", "10.1145/1576246.1531358", "10.1145/545261.545269", "10.1145/1731047.1731054", "10.1145/1833349.1778776", "10.1145/2185520.2185566", "10.1145/2231816.2231821", "10.1145/74333.74355", "10.1145/383259.383321", "10.1145/566570.566621", "10.1145/545282.545286", "10.1145/1186822.1073300", "10.1145/1618452.1618469", "10.1145/1186822.1073216", "10.1145/1964921.1964987", "10.1145/2019627.2019638", "10.1145/2343483.2343501", "10.1145/1457515.1409118", "10.1145/237170.237226", "10.1145/2019406.2019415", "10.1145/1964921.1964986", "10.1145/1401132.1401245", "10.1145/37401.37427", "10.1145/545265.545268", "10.1145/566654.566578", "10.1145/1141911.1142003", "10.1145/1275808.1276480", "10.1145/1576246.1531357", "10.1145/1576246.1531358", "10.1145/545261.545269", "10.1145/1731047.1731054", "10.1145/1833349.1778776", "10.1145/2185520.2185566", "10.1145/2231816.2231821", "10.1145/74333.74355", "10.1145/383259.383321", "10.1145/566570.566621", "10.1145/545282.545286", "10.1145/1186822.1073300", "10.1145/1618452.1618469", "10.1145/1186822.1073216", "10.1145/1964921.1964987", "10.1145/2019627.2019638", "10.1145/2343483.2343501", "10.1145/1457515.1409118", "10.1145/237170.237226", "10.1145/2019406.2019415", "10.1145/1964921.1964986", "10.1145/1401132.1401245", "10.1145/37401.37427", "10.1145/545265.545268", "10.1145/566654.566578", "10.1145/1141911.1142003", "10.1145/1275808.1276480", "10.1145/1576246.1531357", "10.1145/1576246.1531358", "10.1145/545261.545269", "10.1145/1731047.1731054", "10.1145/1833349.1778776", "10.1145/2185520.2185566", "10.1145/2231816.2231821", "10.1145/74333.74355", "10.1145/383259.383321", "10.1145/566570.566621", "10.1145/545282.545286", "10.1145/1186822.1073300", "10.1145/1618452.1618469", "10.1145/1186822.1073216", "10.1145/1964921.1964987", "10.1145/2019627.2019638", "10.1145/2343483.2343501", "10.1145/1457515.1409118", "10.1145/237170.237226", "10.1016/0045-7825(72)90018-7", "10.1111/j.1467-8659.2006.01000.x", "10.1007/BF01908877", "10.1111/1467-8659.00527", "10.1016/j.gmod.2009.02.002", "10.1111/j.1467-8659.2007.01057.x", "10.1002/cav.98", "10.1016/j.cag.2006.08.014", "10.1111/j.1467-8659.2008.01122.x", "10.1007/s00371-008-0260-x", "10.1016/j.gmod.2009.02.002", "10.1016/0045-7825(72)90018-7", "10.1111/j.1467-8659.2006.01000.x", "10.1007/BF01908877", "10.1111/1467-8659.00527", "10.1016/j.gmod.2009.02.002", "10.1111/j.1467-8659.2007.01057.x", "10.1002/cav.98", "10.1016/j.cag.2006.08.014", "10.1111/j.1467-8659.2008.01122.x", "10.1007/s00371-008-0260-x", "10.1016/j.gmod.2009.02.002", "10.1016/0045-7825(72)90018-7", "10.1111/j.1467-8659.2006.01000.x", "10.1007/BF01908877", "10.1111/1467-8659.00527", "10.1016/j.gmod.2009.02.002", "10.1111/j.1467-8659.2007.01057.x", "10.1002/cav.98", "10.1016/j.cag.2006.08.014", "10.1111/j.1467-8659.2008.01122.x", "10.1007/s00371-008-0260-x", "10.1016/j.gmod.2009.02.002"]}, "10.1109/TVCG.2012.324": {"doi": "10.1109/TVCG.2012.324", "author": ["C. G\u00f6rg", "Z. Liu", "J. Kihm", "J. Choo", "H. Park", "J. Stasko"], "title": "Combining Computational Analyses and Interactive Visualization for Document Exploration and Sensemaking in Jigsaw", "year": "2013", "abstract": "Investigators across many disciplines and organizations must sift through large collections of text documents to understand and piece together information. Whether they are fighting crime, curing diseases, deciding what car to buy, or researching a new field, inevitably investigators will encounter text documents. Taking a visual analytics approach, we integrate multiple text analysis algorithms with a suite of interactive visualizations to provide a flexible and powerful environment that allows analysts to explore collections of documents while sensemaking. Our particular focus is on the process of integrating automated analyses with interactive visualizations in a smooth and fluid manner. We illustrate this integration through two example scenarios: An academic researcher examining InfoVis and VAST conference papers and a consumer exploring car reviews while pondering a purchase decision. Finally, we provide lessons learned toward the design and implementation of visual analytics systems for document exploration and understanding.", "keywords": ["data visualisation", "information retrieval", "interactive systems", "text analysis", "computational analysis", "document exploration", "Jigsaw", "sensemaking", "text document collection", "visual analytics", "text analysis algorithm", "interactive visualization", "automated analysis", "academic researcher", "InfoVis conference papers", "VAST conference papers", "purchase decision", "Text analysis", "Visualization", "Measurement", "Data visualization", "Algorithm design and analysis", "Computational modeling", "Tag clouds", "Visual analytics", "information visualization", "sensemaking", "exploratory search", "information seeking", "document analysis"], "referenced_by": ["10.1145/2812115", "10.1145/3181669", "10.1145/2836034.2836036", "10.1007/978-3-319-73080-6_3", "10.1007/s12650-015-0342-6", "10.1016/j.ymeth.2016.07.019", "10.1108/EL-03-2015-0046", "10.1111/cgf.12644", "10.1111/cgf.12918", "10.1111/cgf.13217", "10.1177/1473871615575079", "10.2991/978-94-6239-186-4_2", "10.3390/informatics4020011", "10.1007/978-3-030-01159-8_30", "10.1007/978-3-030-01379-0_6", "10.1002/asi.24171", "10.1007/s12650-019-00585-2", "10.4018/IJCICG.2019010103", "10.1016/j.cag.2020.04.006", "10.1007/s12650-020-00688-1", "10.1007/s41095-020-0191-7"], "referencing": ["IKEY:5482577", "IKEY:6327293", "IKEY:4389004", "IKEY:1667957", "IKEY:4803884", "IKEY:4677359", "IKEY:5333919", "IKEY:5290726", "IKEY:5290722", "IKEY:5333248", "IKEY:1173155", "IKEY:4658133", "IKEY:5204083", "IKEY:6482142", "IKEY:5226632", "IKEY:5613456", "IKEY:5333443", "IKEY:6065008", "IKEY:6102461", "IKEY:4389034", "IKEY:885098", "IKEY:1333624", "IKEY:5482577", "IKEY:6327293", "IKEY:4389004", "IKEY:1667957", "IKEY:4803884", "IKEY:4677359", "IKEY:5333919", "IKEY:5290726", "IKEY:5290722", "IKEY:5333248", "IKEY:1173155", "IKEY:4658133", "IKEY:5204083", "IKEY:6482142", "IKEY:5226632", "IKEY:5613456", "IKEY:5333443", "IKEY:6065008", "IKEY:6102461", "IKEY:4389034", "IKEY:885098", "IKEY:1333624", "IKEY:5482577", "IKEY:6327293", "IKEY:4389004", "IKEY:1667957", "IKEY:4803884", "IKEY:4677359", "IKEY:5333919", "IKEY:5290726", "IKEY:5290722", "IKEY:5333248", "IKEY:1173155", "IKEY:4658133", "IKEY:5204083", "IKEY:6482142", "IKEY:5226632", "IKEY:5613456", "IKEY:5333443", "IKEY:6065008", "IKEY:6102461", "IKEY:4389034", "IKEY:885098", "IKEY:1333624", "10.1145/1056808.1057069", "10.1145/2089094.2089100", "10.1145/1121949.1121979", "10.1145/1879211.1879226", "10.1145/169059.169209", "10.1145/2089094.2089097", "10.1145/1124772.1124919", "10.1145/1121949.1121978", "10.1145/564396.564398", "10.1145/1518701.1518810", "10.1145/2207676.2207738", "10.1145/133160.133214", "10.1145/1321440.1321473", "10.1145/2089094.2089100", "10.1145/1056808.1057069", "10.1145/2089094.2089100", "10.1145/1121949.1121979", "10.1145/1879211.1879226", "10.1145/169059.169209", "10.1145/2089094.2089097", "10.1145/1124772.1124919", "10.1145/1121949.1121978", "10.1145/564396.564398", "10.1145/1518701.1518810", "10.1145/2207676.2207738", "10.1145/133160.133214", "10.1145/1321440.1321473", "10.1145/2089094.2089100", "10.1145/1056808.1057069", "10.1145/2089094.2089100", "10.1145/1121949.1121979", "10.1145/1879211.1879226", "10.1145/169059.169209", "10.1145/2089094.2089097", "10.1145/1124772.1124919", "10.1145/1121949.1121978", "10.1145/564396.564398", "10.1145/1518701.1518810", "10.1145/2207676.2207738", "10.1145/133160.133214", "10.1145/1321440.1321473", "10.1145/2089094.2089100", "10.1007/978-3-540-70956-5_7", "10.3115/1218955.1218990", "10.2514/1.C000271", "10.1108/eb046814", "10.3115/1596374.1596399", "10.1057/palgrave.ivs.9500180", "10.1177/1473871613495674", "10.1007/978-1-84800-046-9", "10.1162/jmlr.2003.3.4-5.993", "10.1111/j.1467-8659.2011.01921.x", "10.1111/j.1467-8659.2009.01439.x", "10.1002/(SICI)1097-4571(199009)41:6&lt;391::AID-ASI1&gt;3.0.CO;2-9", "10.1023/A:1007612920971", "10.1080/10618600.1994.10474635", "10.1007/978-3-642-15384-6_45", "10.3115/1654641.1654645", "10.1057/palgrave.ivs.9500143", "10.1007/978-3-540-70956-5_7", "10.3115/1218955.1218990", "10.2514/1.C000271", "10.1108/eb046814", "10.3115/1596374.1596399", "10.1057/palgrave.ivs.9500180", "10.1177/1473871613495674", "10.1007/978-1-84800-046-9", "10.1162/jmlr.2003.3.4-5.993", "10.1111/j.1467-8659.2011.01921.x", "10.1111/j.1467-8659.2009.01439.x", "10.1002/(SICI)1097-4571(199009)41:6&lt;391::AID-ASI1&gt;3.0.CO;2-9", "10.1023/A:1007612920971", "10.1080/10618600.1994.10474635", "10.1007/978-3-642-15384-6_45", "10.3115/1654641.1654645", "10.1057/palgrave.ivs.9500143", "10.1007/978-3-540-70956-5_7", "10.3115/1218955.1218990", "10.2514/1.C000271", "10.1108/eb046814", "10.3115/1596374.1596399", "10.1057/palgrave.ivs.9500180", "10.1177/1473871613495674", "10.1007/978-1-84800-046-9", "10.1162/jmlr.2003.3.4-5.993", "10.1111/j.1467-8659.2011.01921.x", "10.1111/j.1467-8659.2009.01439.x", "10.1002/(SICI)1097-4571(199009)41:6&lt;391::AID-ASI1&gt;3.0.CO;2-9", "10.1023/A:1007612920971", "10.1080/10618600.1994.10474635", "10.1007/978-3-642-15384-6_45", "10.3115/1654641.1654645", "10.1057/palgrave.ivs.9500143"]}, "10.1109/TVCG.2012.176": {"doi": "10.1109/TVCG.2012.176", "author": ["Y. Nie", "C. Xiao", "H. Sun", "P. Li"], "title": "Compact Video Synopsis via Global Spatiotemporal Optimization", "year": "2013", "abstract": "Video synopsis aims at providing condensed representations of video data sets that can be easily captured from digital cameras nowadays, especially for daily surveillance videos. Previous work in video synopsis usually moves active objects along the time axis, which inevitably causes collisions among the moving objects if compressed much. In this paper, we propose a novel approach for compact video synopsis using a unified spatiotemporal optimization. Our approach globally shifts moving objects in both spatial and temporal domains, which shifting objects temporally to reduce the length of the video and shifting colliding objects spatially to avoid visible collision artifacts. Furthermore, using a multilevel patch relocation (MPR) method, the moving space of the original video is expanded into a compact background based on environmental content to fit with the shifted objects. The shifted objects are finally composited with the expanded moving space to obtain the high-quality video synopsis, which is more condensed while remaining free of collision artifacts. Our experimental results have shown that the compact video synopsis we produced can be browsed quickly, preserves relative spatiotemporal relationships, and avoids motion collisions.", "keywords": ["image motion analysis", "image representation", "optimisation", "video signal processing", "video surveillance", "compact video synopsis", "global spatiotemporal optimization", "video data set representation", "digital camera", "surveillance video", "time axis", "moving object", "spatial domain", "temporal domain", "shifting object", "video length", "visible collision artifact", "MPR method", "multilevel patch relocation method", "motion collision avoidance", "Spatiotemporal phenomena", "Surveillance", "Optimization", "Visualization", "Space vehicles", "Context", "Trajectory", "Video synopsis", "surveillance", "optimization", "patch relocation"], "referenced_by": ["IKEY:7050662", "IKEY:8230312", "IKEY:8019541", "IKEY:6890537", "IKEY:7574772", "IKEY:8120666", "IKEY:7762044", "IKEY:7428932", "IKEY:7422070", "IKEY:8012546", "IKEY:6702519", "IKEY:8335343", "IKEY:7353185", "IKEY:8485321", "IKEY:8706317", "IKEY:8706320", "IKEY:8706286", "IKEY:8663437", "IKEY:8413165", "IKEY:8409991", "IKEY:8821157", "IKEY:8478284", "IKEY:8824208", "IKEY:8848836", "IKEY:8991335", "IKEY:9031885", "IKEY:8520880", "IKEY:9040424", "IKEY:8943352", "10.1145/3328997", "10.1049/iet-cvi.2015.0238", "10.1007/s00500-015-1823-1", "10.1007/s11042-017-4843-2", "10.1007/s11704-016-6084-3", "10.1016/j.image.2016.01.002", "10.1016/j.neucom.2014.12.044", "10.1016/j.neucom.2016.11.011", "10.1049/iet-cvi.2016.0128", "10.1111/cgf.13008", "10.3390/ijgi6110333", "10.4028/www.scientific.net/AMM.321-324.1041", "10.1080/10447318.2018.1543081", "10.1016/j.cviu.2019.02.004", "10.1007/s11042-019-7389-7", "10.1007/978-981-32-9453-0_23", "10.1007/s12652-020-01914-2", "10.1007/s11042-020-09493-2", "10.1007/978-981-15-6844-2_8", "10.1007/s11760-020-01794-1"], "referencing": ["IKEY:5611508", "IKEY:1315022", "IKEY:4587642", "IKEY:824819", "IKEY:1640912", "IKEY:4444355", "IKEY:4587842", "IKEY:793807", "IKEY:1640790", "IKEY:4408934", "IKEY:1658039", "IKEY:1260028", "IKEY:1544834", "IKEY:1262177", "IKEY:969114", "IKEY:5611508", "IKEY:1315022", "IKEY:4587642", "IKEY:824819", "IKEY:1640912", "IKEY:4444355", "IKEY:4587842", "IKEY:793807", "IKEY:1640790", "IKEY:4408934", "IKEY:1658039", "IKEY:1260028", "IKEY:1544834", "IKEY:1262177", "IKEY:969114", "IKEY:5611508", "IKEY:1315022", "IKEY:4587642", "IKEY:824819", "IKEY:1640912", "IKEY:4444355", "IKEY:4587842", "IKEY:793807", "IKEY:1640790", "IKEY:4408934", "IKEY:1658039", "IKEY:1260028", "IKEY:1544834", "IKEY:1262177", "IKEY:969114", "10.1145/1073204.1073263", "10.1145/344779.345009", "10.1145/1073204.1073274", "10.1145/1198302.1198305", "10.1145/354384.354512", "10.1145/1276377.1276505", "10.1145/1531326.1531330", "10.1145/882262.882269", "10.1145/1276377.1276390", "10.1145/1073204.1073263", "10.1145/344779.345009", "10.1145/1073204.1073274", "10.1145/1198302.1198305", "10.1145/354384.354512", "10.1145/1276377.1276505", "10.1145/1531326.1531330", "10.1145/882262.882269", "10.1145/1276377.1276390", "10.1145/1073204.1073263", "10.1145/344779.345009", "10.1145/1073204.1073274", "10.1145/1198302.1198305", "10.1145/354384.354512", "10.1145/1276377.1276505", "10.1145/1531326.1531330", "10.1145/882262.882269", "10.1145/1276377.1276390", "10.1007/s00371-009-0409-2", "10.1002/cav.249", "10.1111/j.1540-8191.2010.01115.x", "10.1016/j.patrec.2004.05.020", "10.1007/s00530-004-0142-7", "10.1007/s11042-005-0895-9", "10.1007/s00371-009-0409-2", "10.1002/cav.249", "10.1111/j.1540-8191.2010.01115.x", "10.1016/j.patrec.2004.05.020", "10.1007/s00530-004-0142-7", "10.1007/s11042-005-0895-9", "10.1007/s00371-009-0409-2", "10.1002/cav.249", "10.1111/j.1540-8191.2010.01115.x", "10.1016/j.patrec.2004.05.020", "10.1007/s00530-004-0142-7", "10.1007/s11042-005-0895-9"]}, "10.1109/TVCG.2013.75": {"doi": "10.1109/TVCG.2013.75", "author": ["S. Lin", "C. Lin", "I. Yeh", "S. Chang", "C. Yeh", "T. Lee"], "title": "Content-Aware Video Retargeting Using Object-Preserving Warping", "year": "2013", "abstract": "A novel content-aware warping approach is introduced for video retargeting. The key to this technique is adapting videos to fit displays with various aspect ratios and sizes while preserving both visually salient content and temporal coherence. Most previous studies solve this spatiotemporal problem by consistently resizing content in frames. This strategy significantly improves the retargeting results, but does not fully consider object preservation, sometimes causing apparent distortions on visually salient objects. We propose an object-preserving warping scheme with object-based significance estimation to reduce this unpleasant distortion. In the proposed scheme, visually salient objects in 3D space-time space are forced to undergo as-rigid-as-possible warping, while low-significance contents are warped as close as possible to linear rescaling. These strategies enable our method to consistently preserve both the spatial shapes and temporal motions of visually salient objects and avoid overdeformations on low-significance objects, yielding a pleasing motion-aware video retargeting. Qualitative and quantitative analyses, including a user study and experiments on complex videos containing diverse cameras and dynamic motions, show a clear superiority of our method over related video retargeting methods.", "keywords": ["image motion analysis", "video signal processing", "content-aware video retargeting", "object-preserving warping", "content-aware warping approach", "aspect ratio", "visually salient content", "temporal coherence", "object preservation", "object-based significance estimation", "3D space-time space", "as-rigid-as-possible warping", "linear rescaling", "motion-aware video retargeting", "qualitative analysis", "quantitative analysis", "camera", "dynamic motion", "Coherence", "Optimization", "Shape", "Weaving", "Spatiotemporal phenomena", "Three-dimensional displays", "Motion segmentation", "Video retargeting", "spatial and temporal coherence", "optimization", "warping"], "referenced_by": ["IKEY:6821526", "IKEY:7331600", "IKEY:6665052", "IKEY:7055924", "IKEY:6774478", "IKEY:7544591", "IKEY:6832478", "IKEY:7128325", "IKEY:8451794", "IKEY:8632913", "IKEY:8657873", "IKEY:9025780", "IKEY:9018110", "IKEY:9191354", "10.1145/3231598", "10.1145/2819000", "10.1007/s11042-015-2926-5", "10.1007/s11704-016-6084-3", "10.1631/jzus.C1400102", "10.1587/transinf.2016EDP7395", "10.1049/iet-ipr.2019.0236", "10.1007/s11042-020-09767-9"], "referencing": ["IKEY:6357312", "IKEY:4302588", "IKEY:5651644", "IKEY:6011944", "IKEY:5746503", "IKEY:5229299", "IKEY:5540165", "IKEY:5540162", "IKEY:5439143", "IKEY:6012025", "IKEY:4409010", "IKEY:5540169", "IKEY:6126409", "IKEY:5539929", "IKEY:5539893", "IKEY:6357312", "IKEY:4302588", "IKEY:5651644", "IKEY:6011944", "IKEY:5746503", "IKEY:5229299", "IKEY:5540165", "IKEY:5540162", "IKEY:5439143", "IKEY:6012025", "IKEY:4409010", "IKEY:5540169", "IKEY:6126409", "IKEY:5539929", "IKEY:5539893", "IKEY:6357312", "IKEY:4302588", "IKEY:5651644", "IKEY:6011944", "IKEY:5746503", "IKEY:5229299", "IKEY:5540165", "IKEY:5540162", "IKEY:5439143", "IKEY:6012025", "IKEY:4409010", "IKEY:5540169", "IKEY:6126409", "IKEY:5539929", "IKEY:5539893", "10.1145/1618452.1618473", "10.1145/1778765.1778827", "10.1145/2010324.1964983", "10.1145/1409060.1409071", "10.1145/1360612.1360615", "10.1145/1665817.1665828", "10.1145/1882261.1866186", "10.1145/1180639.1180702", "10.1145/1435417.1435437", "10.1145/1618452.1618472", "10.1145/1618452.1618473", "10.1145/1778765.1778827", "10.1145/2010324.1964983", "10.1145/1409060.1409071", "10.1145/1360612.1360615", "10.1145/1665817.1665828", "10.1145/1882261.1866186", "10.1145/1180639.1180702", "10.1145/1435417.1435437", "10.1145/1618452.1618472", "10.1145/1618452.1618473", "10.1145/1778765.1778827", "10.1145/2010324.1964983", "10.1145/1409060.1409071", "10.1145/1360612.1360615", "10.1145/1665817.1665828", "10.1145/1882261.1866186", "10.1145/1180639.1180702", "10.1145/1435417.1435437", "10.1145/1618452.1618472", "10.1111/j.1467-8659.2009.01568.x", "10.1007/s11042-010-0717-6", "10.1111/j.1467-8659.2008.01325.x", "10.1111/j.1467-8659.2009.01568.x", "10.1007/s11042-010-0717-6", "10.1111/j.1467-8659.2008.01325.x", "10.1111/j.1467-8659.2009.01568.x", "10.1007/s11042-010-0717-6", "10.1111/j.1467-8659.2008.01325.x"]}, "10.1109/TVCG.2013.16": {"doi": "10.1109/TVCG.2013.16", "author": ["I. Prilepov", "H. Obermaier", "E. Deines", "C. Garth", "K. I. Joy"], "title": "Cubic Gradient-Based Material Interfaces", "year": "2013", "abstract": "Multifluid simulations often create volume fraction data, representing fluid volumes per region or cell of a fluid data set. Accurate and visually realistic extraction of fluid boundaries is a challenging and essential task for efficient analysis of multifluid data. In this work, we present a new material interface reconstruction method for such volume fraction data. Within each cell of the data set, our method utilizes a gradient field approximation based on trilinearly blended Coons-patches to generate a volume fraction function, representing the change in volume fractions over the cells. A continuously varying isovalue field is applied to this function to produce a smooth interface that preserves the given volume fractions well. Further, the method allows user-controlled balance between volume accuracy and physical plausibility of the interface. The method works on two- and three-dimensional Cartesian grids, and handles multiple materials. Calculations are performed locally and utilize only the one-ring of cells surrounding a given cell, allowing visualizations of the material interfaces to be easily generated on a GPU or in a large-scale distributed parallel environment. Our results demonstrate the robustness, accuracy, and flexibility of the developed algorithms.", "keywords": ["data analysis", "flow simulation", "gradient methods", "graphics processing units", "mechanical engineering computing", "parallel processing", "user interfaces", "cubic gradient-based material interface", "multifluid simulation", "volume fraction data", "fluid data set", "fluid boundary", "multifluid data analysis", "material interface reconstruction method", "gradient field approximation", "trilinearly blended Coons-patch", "continuously varying isovalue field", "interface plausibility", "user-controlled balance", "Cartesian grid", "GPU", "graphics processing unit", "large-scale distributed parallel environment", "Materials", "Approximation methods", "Computational modeling", "Visualization", "Solid modeling", "Accuracy", "Approximation algorithms", "Visualization", "boundary representations", "computational geometry and object modeling"], "referenced_by": ["IKEY:6876035", "IKEY:8445644", "IKEY:8320335", "10.1007/s00158-017-1729-x", "10.2514/6.2015-3354", "10.1016/j.compfluid.2017.02.005", "10.1117/12.2076618", "10.12677/CSA.2019.911223"], "referencing": ["IKEY:1250354", "IKEY:663887", "IKEY:885717", "IKEY:1260744", "IKEY:5383354", "IKEY:1532795", "IKEY:1250354", "IKEY:663887", "IKEY:885717", "IKEY:1260744", "IKEY:5383354", "IKEY:1532795", "IKEY:1250354", "IKEY:663887", "IKEY:885717", "IKEY:1260744", "IKEY:5383354", "IKEY:1532795", "10.1145/37402.37422", "10.1145/1833349.1778803", "10.1145/37402.37422", "10.1145/1833349.1778803", "10.1145/37402.37422", "10.1145/1833349.1778803", "10.1002/nme.775", "10.1006/jcph.1998.6168", "10.1016/S0097-8493(99)00076-X", "10.1111/j.1467-8659.2009.01671.x", "10.1111/j.1467-8659.2008.01237.x", "10.1103/RevModPhys.54.235", "10.1007/978-3-642-13411-1_4", "10.1007/BF00133570", "10.1016/j.jcp.2009.07.009", "10.1016/j.jcp.2007.12.029", "10.1016/j.jcp.2008.09.023", "10.1111/j.1467-8659.2005.00855.x", "10.1002/nme.775", "10.1006/jcph.1998.6168", "10.1016/S0097-8493(99)00076-X", "10.1111/j.1467-8659.2009.01671.x", "10.1111/j.1467-8659.2008.01237.x", "10.1103/RevModPhys.54.235", "10.1007/978-3-642-13411-1_4", "10.1007/BF00133570", "10.1016/j.jcp.2009.07.009", "10.1016/j.jcp.2007.12.029", "10.1016/j.jcp.2008.09.023", "10.1111/j.1467-8659.2005.00855.x", "10.1002/nme.775", "10.1006/jcph.1998.6168", "10.1016/S0097-8493(99)00076-X", "10.1111/j.1467-8659.2009.01671.x", "10.1111/j.1467-8659.2008.01237.x", "10.1103/RevModPhys.54.235", "10.1007/978-3-642-13411-1_4", "10.1007/BF00133570", "10.1016/j.jcp.2009.07.009", "10.1016/j.jcp.2007.12.029", "10.1016/j.jcp.2008.09.023", "10.1111/j.1467-8659.2005.00855.x"]}, "10.1109/TVCG.2013.74": {"doi": "10.1109/TVCG.2013.74", "author": ["Y. Liu", "J. Zhang", "J. Hou", "J. Ren", "W. Tang"], "title": "Cylinder Detection in Large-Scale Point Cloud of Pipeline Plant", "year": "2013", "abstract": "The huge number of points scanned from pipeline plants make the plant reconstruction very difficult. Traditional cylinder detection methods cannot be applied directly due to the high computational complexity. In this paper, we explore the structural characteristics of point cloud in pipeline plants and define a structure feature. Based on the structure feature, we propose a hierarchical structure detection and decomposition method that reduces the difficult pipeline-plant reconstruction problem in R3 into a set of simple circle detection problems in R2. Experiments with industrial applications are presented, which demonstrate the efficiency of the proposed structure detection method.", "keywords": ["industrial plants", "machinery production industries", "pipelines", "production engineering computing", "shapes (structures)", "solid modelling", "cylinder detection method", "large-scale point cloud", "plant reconstruction", "computational complexity", "point cloud structural characteristics", "hierarchical structure detection", "decomposition method", "pipeline-plant reconstruction problem", "simple circle detection problem", "virtual 3D scene reconstruction", "Pipelines", "Transforms", "Histograms", "Solid modeling", "Noise", "Computational modeling", "Fuel storage", "3D reconstruction", "point cloud", "structure analysis"], "referenced_by": ["IKEY:7335467", "IKEY:7964081", "IKEY:8329794", "IKEY:8354214", "IKEY:8354318", "IKEY:8622428", "IKEY:8651348", "IKEY:8811906", "IKEY:8856239", "10.1016/j.autcon.2018.03.008", "10.1016/j.cag.2014.09.027", "10.1016/j.cam.2014.07.001", "10.1016/j.isprsjprs.2016.01.001", "10.1080/17434440.2016.1218758", "10.1016/j.autcon.2016.12.002", "10.3390/rs71115651", "10.3390/s18030819", "10.5762/KAIS.2014.15.9.5870", "10.1007/s00371-015-1157-0", "10.1007/s11704-015-4450-1", "10.1016/j.autcon.2016.08.011", "10.1088/1742-6596/1036/1/012011", "10.3390/app9050974", "10.2493/jjspe.85.217", "10.1088/1361-6501/ab0b7d", "10.1016/j.robot.2019.04.002", "10.1007/978-3-319-13168-9_23", "10.1186/s41074-017-0018-3", "10.1016/j.cag.2019.09.003", "10.1556/606.2019.14.3.18", "10.1007/978-3-030-35990-4_3", "10.1016/B978-0-12-815503-5.00003-6", "10.1016/j.patcog.2019.107161", "10.3390/s19245345", "10.1016/j.measurement.2020.107705", "10.1016/j.autcon.2020.103236", "10.1016/j.patcog.2020.107443", "10.1007/s00371-020-01872-y", "10.1088/1361-6501/ab8b21"], "referencing": ["IKEY:1260746", "IKEY:4695834", "IKEY:5661790", "IKEY:1088007", "IKEY:4359381", "IKEY:103273", "IKEY:1260746", "IKEY:4695834", "IKEY:5661790", "IKEY:1088007", "IKEY:4359381", "IKEY:103273", "IKEY:1260746", "IKEY:4695834", "IKEY:5661790", "IKEY:1088007", "IKEY:4359381", "IKEY:103273", "10.1145/1882261.1866178", "10.1145/1778765.1778830", "10.1145/1882261.1866178", "10.1145/1778765.1778830", "10.1145/1882261.1866178", "10.1145/1778765.1778830", "10.1016/0031-3203(81)90009-1", "10.5244/C.19.78", "10.1007/BFb0055697", "10.1016/j.imavis.2004.02.009", "10.1016/S0031-3203(00)00064-9", "10.1111/j.1467-8659.2007.01016.x", "10.1016/0031-3203(81)90009-1", "10.5244/C.19.78", "10.1007/BFb0055697", "10.1016/j.imavis.2004.02.009", "10.1016/S0031-3203(00)00064-9", "10.1111/j.1467-8659.2007.01016.x", "10.1016/0031-3203(81)90009-1", "10.5244/C.19.78", "10.1007/BFb0055697", "10.1016/j.imavis.2004.02.009", "10.1016/S0031-3203(00)00064-9", "10.1111/j.1467-8659.2007.01016.x"]}, "10.1109/TVCG.2013.73": {"doi": "10.1109/TVCG.2013.73", "author": ["B. Ren", "C. Li", "M. C. Lin", "T. Kim", "S. Hu"], "title": "Flow Field Modulation", "year": "2013", "abstract": "The nonlinear and nonstationary nature of Navier-Stokes equations produces fluid flows that can be noticeably different in appearance with subtle changes. In this paper, we introduce a method that can analyze the intrinsic multiscale features of flow fields from a decomposition point of view, by using the Hilbert-Huang transform method on 3D fluid simulation. We show how this method can provide insights to flow styles and help modulate the fluid simulation with its internal physical information. We provide easy-to-implement algorithms that can be integrated with standard grid-based fluid simulation methods and demonstrate how this approach can modulate the flow field and guide the simulation with different flow styles. The modulation is straightforward and relates directly to the flow's visual effect, with moderate computational overhead.", "keywords": ["computational fluid dynamics", "flow simulation", "Hilbert transforms", "Navier-Stokes equations", "turbulence", "flow field modulation", "Navier-Stokes equation", "fluid flow", "flow decomposition", "Hilbert-Huang transform method", "3D fluid simulation", "grid-based fluid simulation method", "flow visual effect", "computational fluid dynamics", "turbulent flow", "Transforms", "Fluids", "Frequency modulation", "Three-dimensional displays", "Mathematical model", "Computational modeling", "Physically based animation", "fluid simulation", "flow style", "Hilbert-Huang transform", "Fourier", "wavelet"], "referenced_by": ["IKEY:8559411", "10.1002/cav.1574", "10.1007/s00371-015-1100-4", "10.1007/s41095-017-0096-2", "10.1111/cgf.13084", "10.1016/j.cagd.2017.11.002", "10.1111/cgf.12861", "10.1016/j.cagd.2016.02.011", "10.1007/s12650-018-0534-y", "10.1111/cgf.13856"], "referencing": ["IKEY:601299", "IKEY:6197187", "IKEY:601299", "IKEY:6197187", "IKEY:601299", "IKEY:6197187", "10.1145/1201775.882337", "10.1145/1015706.1015744", "10.1145/1015706.1015743", "10.1145/1037957.1037965", "10.1145/1073368.1073401", "10.1145/1028523.1028549", "10.1145/1028523.1028565", "10.1145/1599470.1599499", "10.1145/2010324.1964978", "10.1145/2070752.2024170", "10.1145/311535.311548", "10.1145/383259.383260", "10.1145/1073204.1073282", "10.1145/1073204.1073298", "10.1145/882262.882336", "10.1145/1015706.1015745", "10.1145/166117.166163", "10.1145/566654.566644", "10.1145/882262.882335", "10.1145/1276377.1276435", "10.1145/1360612.1360649", "10.1145/1409060.1409119", "10.1145/1618452.1618467", "10.1145/1882261.1866196", "10.1145/1618452.1618493", "10.1145/1201775.882337", "10.1145/1015706.1015744", "10.1145/1015706.1015743", "10.1145/1037957.1037965", "10.1145/1073368.1073401", "10.1145/1028523.1028549", "10.1145/1028523.1028565", "10.1145/1599470.1599499", "10.1145/2010324.1964978", "10.1145/2070752.2024170", "10.1145/311535.311548", "10.1145/383259.383260", "10.1145/1073204.1073282", "10.1145/1073204.1073298", "10.1145/882262.882336", "10.1145/1015706.1015745", "10.1145/166117.166163", "10.1145/566654.566644", "10.1145/882262.882335", "10.1145/1276377.1276435", "10.1145/1360612.1360649", "10.1145/1409060.1409119", "10.1145/1618452.1618467", "10.1145/1882261.1866196", "10.1145/1618452.1618493", "10.1145/1201775.882337", "10.1145/1015706.1015744", "10.1145/1015706.1015743", "10.1145/1037957.1037965", "10.1145/1073368.1073401", "10.1145/1028523.1028549", "10.1145/1028523.1028565", "10.1145/1599470.1599499", "10.1145/2010324.1964978", "10.1145/2070752.2024170", "10.1145/311535.311548", "10.1145/383259.383260", "10.1145/1073204.1073282", "10.1145/1073204.1073298", "10.1145/882262.882336", "10.1145/1015706.1015745", "10.1145/166117.166163", "10.1145/566654.566644", "10.1145/882262.882335", "10.1145/1276377.1276435", "10.1145/1360612.1360649", "10.1145/1409060.1409119", "10.1145/1618452.1618467", "10.1145/1882261.1866196", "10.1145/1618452.1618493", "10.1002/cav.17", "10.1016/j.gmod.2008.12.007", "10.1007/s00371-010-0526-y", "10.1016/S0021-9991(03)00276-6", "10.1007/s10915-007-9166-4", "10.1007/s00371-011-0626-3", "10.1098/rspa.1998.0193", "10.1016/S0262-8856(03)00094-5", "10.1016/j.imavis.2005.05.012", "10.1016/j.cag.2008.01.001", "10.1093/acprof:oso/9780198528692.001.0001", "10.1201/b10635", "10.1002/cav.17", "10.1016/j.gmod.2008.12.007", "10.1007/s00371-010-0526-y", "10.1016/S0021-9991(03)00276-6", "10.1007/s10915-007-9166-4", "10.1007/s00371-011-0626-3", "10.1098/rspa.1998.0193", "10.1016/S0262-8856(03)00094-5", "10.1016/j.imavis.2005.05.012", "10.1016/j.cag.2008.01.001", "10.1093/acprof:oso/9780198528692.001.0001", "10.1201/b10635", "10.1002/cav.17", "10.1016/j.gmod.2008.12.007", "10.1007/s00371-010-0526-y", "10.1016/S0021-9991(03)00276-6", "10.1007/s10915-007-9166-4", "10.1007/s00371-011-0626-3", "10.1098/rspa.1998.0193", "10.1016/S0262-8856(03)00094-5", "10.1016/j.imavis.2005.05.012", "10.1016/j.cag.2008.01.001", "10.1093/acprof:oso/9780198528692.001.0001", "10.1201/b10635"]}, "10.1109/TVCG.2013.68": {"doi": "10.1109/TVCG.2013.68", "author": ["T. Fang", "Z. Wang", "H. Zhang", "L. Quan"], "title": "Image-Based Modeling of Unwrappable Fa\u00e7ades", "year": "2013", "abstract": "In this paper, we propose an unwrappable representation for image-based fa\u00e7ade modeling from multiple registered images. An unwrappable fa\u00e7ade is represented by the mutually orthogonal baseline and profile. We first reconstruct semidense 3D points from images, then the baseline and profile are extracted from the point cloud to construct the base shape and compose the textures of the building from the images. Through our unwrapping process, the reconstructed 3D points and composed textures are further mapped to an unwrapped space that is parameterized by the baseline and profile. In doing so, the unwrapped space becomes equivalent to the planar space in which planar fa\u00e7ade modeling techniques can be used to reconstruct the details of the buildings. Finally, the augmented details can be wrapped back to the original 3D space to generate the final model. This newly introduced unwrappable representation extends the state-of-the-art modeling for planar fa\u00e7ades to a more general class of fa\u00e7ades. We demonstrate the power of the unwrappable representation with a few examples in which the fa\u00e7ade is not planar.", "keywords": ["buildings (structures)", "feature extraction", "image reconstruction", "image representation", "image texture", "shape recognition", "structural engineering computing", "image-based modeling", "unwrappable facades", "image-based facade modeling", "unwrappable image representation", "mutually orthogonal baseline", "semidense 3D point reconstruction", "unwrapping process", "3D point reconstruction", "planar facade modeling techniques", "original 3D space", "state-of-the-art modeling", "Image reconstruction", "Three-dimensional displays", "Solid modeling", "Optimization", "Computational modeling", "Shape", "Buildings", "Modeling packages", "reconstruction"], "referenced_by": ["10.1145/3130800.3130823", "10.1111/cgf.12478", "10.1007/978-3-319-16631-5_43"], "referencing": ["IKEY:5206867", "IKEY:5539804", "IKEY:1640800", "IKEY:5989831", "IKEY:5539802", "IKEY:5226635", "IKEY:5457421", "IKEY:5459148", "IKEY:6247857", "IKEY:6247839", "IKEY:5995482", "IKEY:5995319", "IKEY:1262177", "IKEY:1388267", "IKEY:5206867", "IKEY:5539804", "IKEY:1640800", "IKEY:5989831", "IKEY:5539802", "IKEY:5226635", "IKEY:5457421", "IKEY:5459148", "IKEY:6247857", "IKEY:6247839", "IKEY:5995482", "IKEY:5995319", "IKEY:1262177", "IKEY:1388267", "IKEY:5206867", "IKEY:5539804", "IKEY:1640800", "IKEY:5989831", "IKEY:5539802", "IKEY:5226635", "IKEY:5457421", "IKEY:5459148", "IKEY:6247857", "IKEY:6247839", "IKEY:5995482", "IKEY:5995319", "IKEY:1262177", "IKEY:1388267", "10.1145/237170.237191", "10.1145/1276377.1276484", "10.1145/1409060.1409114", "10.1145/1409060.1409112", "10.1145/1618452.1618460", "10.1145/1618452.1618459", "10.1145/1276377.1276485", "10.1145/1399504.1360685", "10.1145/1360612.1360670", "10.1145/1944846.1944854", "10.1145/1015706.1015773", "10.1145/1073204.1073239", "10.1145/1141911.1141931", "10.1145/237170.237191", "10.1145/1276377.1276484", "10.1145/1409060.1409114", "10.1145/1409060.1409112", "10.1145/1618452.1618460", "10.1145/1618452.1618459", "10.1145/1276377.1276485", "10.1145/1399504.1360685", "10.1145/1360612.1360670", "10.1145/1944846.1944854", "10.1145/1015706.1015773", "10.1145/1073204.1073239", "10.1145/1141911.1141931", "10.1145/237170.237191", "10.1145/1276377.1276484", "10.1145/1409060.1409114", "10.1145/1409060.1409112", "10.1145/1618452.1618460", "10.1145/1618452.1618459", "10.1145/1276377.1276485", "10.1145/1399504.1360685", "10.1145/1360612.1360670", "10.1145/1944846.1944854", "10.1145/1015706.1015773", "10.1145/1073204.1073239", "10.1145/1141911.1141931", "10.1007/s11263-007-0086-4", "10.1007/978-3-642-15561-1_27", "10.1007/978-3-642-15555-0_22", "10.1007/3-540-61332-3_144", "10.1111/j.1467-8659.2007.01016.x", "10.1007/978-3-642-15552-9_11", "10.1111/j.1467-8659.2012.03045.x", "10.1017/CBO9780511811685", "10.1007/978-3-642-15552-9_1", "10.1007/s11263-007-0086-4", "10.1007/978-3-642-15561-1_27", "10.1007/978-3-642-15555-0_22", "10.1007/3-540-61332-3_144", "10.1111/j.1467-8659.2007.01016.x", "10.1007/978-3-642-15552-9_11", "10.1111/j.1467-8659.2012.03045.x", "10.1017/CBO9780511811685", "10.1007/978-3-642-15552-9_1", "10.1007/s11263-007-0086-4", "10.1007/978-3-642-15561-1_27", "10.1007/978-3-642-15555-0_22", "10.1007/3-540-61332-3_144", "10.1111/j.1467-8659.2007.01016.x", "10.1007/978-3-642-15552-9_11", "10.1111/j.1467-8659.2012.03045.x", "10.1017/CBO9780511811685", "10.1007/978-3-642-15552-9_1"]}, "10.1109/TVCG.2012.151": {"doi": "10.1109/TVCG.2012.151", "author": ["B. Liu", "G. J. Clapworthy", "F. Dong", "E. C. Prakash"], "title": "Octree Rasterization: Accelerating High-Quality Out-of-Core GPU Volume Rendering", "year": "2013", "abstract": "We present a novel approach for GPU-based high-quality volume rendering of large out-of-core volume data. By focusing on the locations and costs of ray traversal, we are able to significantly reduce the rendering time over traditional algorithms. We store a volume in an octree (of bricks); in addition, every brick is further split into regular macrocells. Our solutions move the branch-intensive accelerating structure traversal out of the GPU raycasting loop and introduce an efficient empty-space culling method by rasterizing the proxy geometry of a view-dependent cut of the octree nodes. This rasterization pass can capture all of the bricks that the ray penetrates in a per-pixel list. Since the per-pixel list is captured in a front-to-back order, our raycasting pass needs only to cast rays inside the tighter ray segments. As a result, we achieve two levels of empty space skipping: the brick level and the macrocell level. During evaluation and testing, this technique achieved 2 to 4 times faster rendering speed than a current state-of-the-art algorithm across a variety of data sets.", "keywords": ["graphics processing units", "rendering (computer graphics)", "octree rasterization", "out-of-core GPU volume rendering", "graphics processing unit", "out-of-core volume data", "ray traversal", "GPU raycasting loop", "empty-space culling method", "proxy geometry", "per-pixel list", "front-to-back list order", "brick level", "macrocell level", "empty space skipping level", "Octrees", "Graphics processing unit", "Rendering (computer graphics)", "Acceleration", "Interpolation", "Cameras", "Casting", "GPU techniques", "out-of-core volume rendering", "octree", "ray casting", "Algorithms", "Computer Graphics", "Diagnostic Imaging", "Female", "Humans", "Imaging, Three-Dimensional", "Male", "Models, Theoretical", "Visible Human Projects"], "referenced_by": ["IKEY:8228047", "IKEY:8781571", "IKEY:8637795", "10.1016/j.ins.2015.03.026", "10.1111/cgf.13756"], "referencing": ["IKEY:1374278", "IKEY:1183757", "IKEY:1500539", "IKEY:5290773", "IKEY:5290775", "IKEY:5742355", "IKEY:1250384", "IKEY:511", "IKEY:1374278", "IKEY:1183757", "IKEY:1500539", "IKEY:5290773", "IKEY:5290775", "IKEY:5742355", "IKEY:1250384", "IKEY:511", "IKEY:1374278", "IKEY:1183757", "IKEY:1500539", "IKEY:5290773", "IKEY:5290775", "IKEY:5742355", "IKEY:1250384", "IKEY:511", "10.1145/1667239.1667241", "10.1145/1661412.1618498", "10.1145/1597990.1598069", "10.1145/37402.37422", "10.1145/964965.808589", "10.1145/1507149.1507152", "10.1145/1667239.1667241", "10.1145/1661412.1618498", "10.1145/1597990.1598069", "10.1145/37402.37422", "10.1145/964965.808589", "10.1145/1507149.1507152", "10.1145/1667239.1667241", "10.1145/1661412.1618498", "10.1145/1597990.1598069", "10.1145/37402.37422", "10.1145/964965.808589", "10.1145/1507149.1507152", "10.1111/j.1467-8659.2005.00855.x", "10.1111/j.1467-8659.2009.01466.x", "10.1111/j.1467-8659.2009.01422.x", "10.1080/2151237X.2008.10129258", "10.1111/j.1467-8659.2010.01725.x", "10.1201/b10644", "10.1111/j.1467-8659.2008.01182.x", "10.1007/s00371-008-0261-9", "10.1111/j.1467-8659.2005.00855.x", "10.1111/j.1467-8659.2009.01466.x", "10.1111/j.1467-8659.2009.01422.x", "10.1080/2151237X.2008.10129258", "10.1111/j.1467-8659.2010.01725.x", "10.1201/b10644", "10.1111/j.1467-8659.2008.01182.x", "10.1007/s00371-008-0261-9", "10.1111/j.1467-8659.2005.00855.x", "10.1111/j.1467-8659.2009.01466.x", "10.1111/j.1467-8659.2009.01422.x", "10.1080/2151237X.2008.10129258", "10.1111/j.1467-8659.2010.01725.x", "10.1201/b10644", "10.1111/j.1467-8659.2008.01182.x", "10.1007/s00371-008-0261-9"]}, "10.1109/TVCG.2012.315": {"doi": "10.1109/TVCG.2012.315", "author": ["S. Lee", "M. Sips", "H. Seidel"], "title": "Perceptually Driven Visibility Optimization for Categorical Data Visualization", "year": "2013", "abstract": "Visualization techniques often use color to present categorical differences to a user. When selecting a color palette, the perceptual qualities of color need careful consideration. Large coherent groups visually suppress smaller groups and are often visually dominant in images. This paper introduces the concept of class visibility used to quantitatively measure the utility of a color palette to present coherent categorical structure to the user. We present a color optimization algorithm based on our class visibility metric to make categorical differences clearly visible to the user. We performed two user experiments on user preference and visual search to validate our visibility measure over a range of color palettes. The results indicate that visibility is a robust measure, and our color optimization can increase the effectiveness of categorical data visualizations.", "keywords": ["cartography", "colour", "data visualisation", "optimisation", "visibility", "perceptually driven visibility optimization", "categorical data visualization technique", "categorical differences", "color perceptual qualities", "color palette utility", "coherent categorical structure", "color optimization algorithm", "class visibility metric", "visual search", "user preference", "color optimization", "Image color analysis", "Visualization", "Data visualization", "Optimization", "Measurement", "Retina", "Color design", "visualization", "visibility", "user interface"], "referenced_by": ["IKEY:6875989", "IKEY:7305807", "IKEY:7539556", "IKEY:8017604", "IKEY:8440853", "IKEY:8805429", "10.1007/978-3-319-50835-1_36", "10.1016/j.cag.2018.01.010", "10.1016/j.ins.2016.12.035", "10.1080/1091367X.2015.1048342", "10.1111/cgf.12127", "10.5626/KTCP.2014.20.12.670", "10.1080/2150704X.2018.1532129", "10.1115/1.4034472", "10.1111/cgf.13611", "10.1111/cgf.12379", "10.1007/978-3-030-27928-8_51", "10.1007/s12650-020-00691-6"], "referencing": ["IKEY:4056802", "IKEY:6155162", "IKEY:4658198", "IKEY:480803", "IKEY:568118", "IKEY:730558", "IKEY:841121", "IKEY:135886", "IKEY:4056802", "IKEY:6155162", "IKEY:4658198", "IKEY:480803", "IKEY:568118", "IKEY:730558", "IKEY:841121", "IKEY:135886", "IKEY:4056802", "IKEY:6155162", "IKEY:4658198", "IKEY:480803", "IKEY:568118", "IKEY:730558", "IKEY:841121", "IKEY:135886", "10.1046/j.1365-2486.2003.00569.x", "10.1126/science.4001937", "10.1152/jn.00780.2003", "10.3758/BF03211656", "10.1016/0010-0285(80)90005-5", "10.2307/2683294", "10.1111/j.1467-8659.2008.01203.x", "10.1016/S0042-6989(00)00152-8", "10.1016/j.csda.2008.11.033", "10.1016/S0042-6989(01)00250-4", "10.1515/9783110834901", "10.1167/8.1.23", "10.3138/80ML-3K54-0204-6172", "10.1111/0033-0124.00077", "10.1016/0042-6989(91)90203-H", "10.1037/0096-1523.18.4.1030", "10.1117/12.173842", "10.1179/000870403235002042", "10.3758/BF03334699", "10.1046/j.1365-2486.2003.00569.x", "10.1126/science.4001937", "10.1152/jn.00780.2003", "10.3758/BF03211656", "10.1016/0010-0285(80)90005-5", "10.2307/2683294", "10.1111/j.1467-8659.2008.01203.x", "10.1016/S0042-6989(00)00152-8", "10.1016/j.csda.2008.11.033", "10.1016/S0042-6989(01)00250-4", "10.1515/9783110834901", "10.1167/8.1.23", "10.3138/80ML-3K54-0204-6172", "10.1111/0033-0124.00077", "10.1016/0042-6989(91)90203-H", "10.1037/0096-1523.18.4.1030", "10.1117/12.173842", "10.1179/000870403235002042", "10.3758/BF03334699", "10.1046/j.1365-2486.2003.00569.x", "10.1126/science.4001937", "10.1152/jn.00780.2003", "10.3758/BF03211656", "10.1016/0010-0285(80)90005-5", "10.2307/2683294", "10.1111/j.1467-8659.2008.01203.x", "10.1016/S0042-6989(00)00152-8", "10.1016/j.csda.2008.11.033", "10.1016/S0042-6989(01)00250-4", "10.1515/9783110834901", "10.1167/8.1.23", "10.3138/80ML-3K54-0204-6172", "10.1111/0033-0124.00077", "10.1016/0042-6989(91)90203-H", "10.1037/0096-1523.18.4.1030", "10.1117/12.173842", "10.1179/000870403235002042", "10.3758/BF03334699"]}, "10.1109/TVCG.2013.85": {"doi": "10.1109/TVCG.2013.85", "author": ["S. Hauswiesner", "M. Straka", "G. Reitmayr"], "title": "Temporal Coherence in Image-Based Visual Hull Rendering", "year": "2013", "abstract": "Image-based visual hull rendering is a method for generating depth maps of a desired viewpoint from a set of silhouette images captured by calibrated cameras. It does not compute a view-independent data representation, such as a voxel grid or a mesh, which makes it particularly efficient for dynamic scenes. When users are captured, the scene is usually dynamic, but does not change rapidly because people move smoothly within a subsecond time frame. Exploiting this temporal coherence to avoid redundant calculations is challenging because of the lack of an explicit data representation. This paper analyzes the image-based visual hull algorithm to find intermediate information that stays valid over time and is, therefore, worth to make explicit. We then derive methods that exploit this information to improve the rendering performance. Our methods reduce the execution time by up to 25 percent. When the user's motions are very slow, reductions of up to 50 percent are achieved.", "keywords": ["calibration", "cameras", "coherence", "data structures", "image motion analysis", "rendering (computer graphics)", "virtual reality", "temporal coherence", "image-based visual hull rendering method", "depth map generation", "silhouette images", "calibrated cameras", "view-independent data representation", "voxel grid", "dynamic scenes", "subsecond time frame", "data representation", "image-based visual hull algorithm", "user motions", "Cameras", "Rendering (computer graphics)", "Coherence", "Visualization", "Image reconstruction", "Surface treatment", "Sensors", "Mixed reality", "image-based visual hull rendering", "temporal coherence"], "referenced_by": [], "referencing": ["IKEY:4563098", "IKEY:4497206", "IKEY:5413661", "IKEY:4563160", "IKEY:6165146", "IKEY:6162880", "IKEY:6180879", "IKEY:5206755", "IKEY:4563098", "IKEY:4497206", "IKEY:5413661", "IKEY:4563160", "IKEY:6165146", "IKEY:6162880", "IKEY:6180879", "IKEY:5206755", "IKEY:4563098", "IKEY:4497206", "IKEY:5413661", "IKEY:4563160", "IKEY:6165146", "IKEY:6162880", "IKEY:6180879", "IKEY:5206755", "10.1145/1889863.1889895", "10.1145/344779.344951", "10.1145/1180495.1180513", "10.1145/1866029.1866073", "10.1145/2407336.2407342", "10.1145/1073368.1073375", "10.1145/1882262.1866174", "10.1145/1964921.1964927", "10.1145/1073204.1073207", "10.1145/1198555.1198763", "10.1145/1944745.1944776", "10.1145/1889863.1889895", "10.1145/344779.344951", "10.1145/1180495.1180513", "10.1145/1866029.1866073", "10.1145/2407336.2407342", "10.1145/1073368.1073375", "10.1145/1882262.1866174", "10.1145/1964921.1964927", "10.1145/1073204.1073207", "10.1145/1198555.1198763", "10.1145/1944745.1944776", "10.1145/1889863.1889895", "10.1145/344779.344951", "10.1145/1180495.1180513", "10.1145/1866029.1866073", "10.1145/2407336.2407342", "10.1145/1073368.1073375", "10.1145/1882262.1866174", "10.1145/1964921.1964927", "10.1145/1073204.1073207", "10.1145/1198555.1198763", "10.1145/1944745.1944776", "10.1093/ietisy/e90-d.8.1175", "10.1007/978-3-7091-6303-0_30", "10.5244/C.23.35", "10.1007/978-3-642-21227-7_59", "10.1093/ietisy/e90-d.8.1175", "10.1007/978-3-7091-6303-0_30", "10.5244/C.23.35", "10.1007/978-3-642-21227-7_59", "10.1093/ietisy/e90-d.8.1175", "10.1007/978-3-7091-6303-0_30", "10.5244/C.23.35", "10.1007/978-3-642-21227-7_59"]}, "10.1109/TVCG.2013.20": {"doi": "10.1109/TVCG.2013.20", "author": ["Y. Chan", "C. D. Correa", "K. Ma"], "title": "The Generalized Sensitivity Scatterplot", "year": "2013", "abstract": "Scatterplots remain a powerful tool to visualize multidimensional data. However, accurately understanding the shape of multidimensional points from 2D projections remains challenging due to overlap. Consequently, there are a lot of variations on the scatterplot as a visual metaphor for this limitation. An important aspect often overlooked in scatterplots is the issue of sensitivity or local trend, which may help in identifying the type of relationship between two variables. However, it is not well known how or what factors influence the perception of trends from 2D scatterplots. To shed light on this aspect, we conducted an experiment where we asked people to directly draw the perceived trends on a 2D scatterplot. We found that augmenting scatterplots with local sensitivity helps to fill the gaps in visual perception while retaining the simplicity and readability of a 2D scatterplot. We call this augmentation the generalized sensitivity scatterplot (GSS). In a GSS, sensitivity coefficients are visually depicted as flow lines, which give a sense of continuity and orientation of the data that provide cues about the way data points are scattered in a higher dimensional space. We introduce a series of glyphs and operations that facilitate the analysis of multidimensional data sets using GSS, and validate with a number of well-known data sets for both regression and classification tasks.", "keywords": ["data visualisation", "pattern classification", "regression analysis", "sensitivity analysis", "visual perception", "generalized sensitivity scatterplot", "multidimensional data visualization", "multidimensional points", "2D projections", "visual metaphor", "sensitivity analysis", "2D scatterplots", "local sensitivity", "visual perception", "GSS", "sensitivity coefficients", "data orientation", "data continuity", "multidimensional data sets", "regression tasks", "classification tasks", "Market research", "Data visualization", "Sensitivity analysis", "Noise", "Image color analysis", "Interpolation", "Sensitivity analysis", "data transformations", "model fitting", "multidimensional data visualization"], "referenced_by": ["IKEY:7465252", "IKEY:6875973", "IKEY:6875982", "IKEY:7445239", "IKEY:7534792", "IKEY:7784854", "IKEY:7911335", "IKEY:8440820", "IKEY:8622502", "IKEY:8848845", "IKEY:8807247", "10.1145/2590349", "10.1007/s12650-014-0207-4", "10.1155/2014/236304", "10.1177/1473871616686635", "10.5139/IJASS.2016.17.3.409", "10.1140/epjst/e2019-800158-6", "10.1007/s41095-020-0197-1", "10.1007/s12650-020-00711-5"], "referencing": ["IKEY:4100925", "IKEY:4658159", "IKEY:4677368", "IKEY:640407", "IKEY:5652460", "IKEY:5290706", "IKEY:5332611", "IKEY:4658123", "IKEY:5613435", "IKEY:856996", "IKEY:6102450", "IKEY:485139", "IKEY:4015424", "IKEY:4389000", "IKEY:4100925", "IKEY:4658159", "IKEY:4677368", "IKEY:640407", "IKEY:5652460", "IKEY:5290706", "IKEY:5332611", "IKEY:4658123", "IKEY:5613435", "IKEY:856996", "IKEY:6102450", "IKEY:485139", "IKEY:4015424", "IKEY:4389000", "IKEY:4100925", "IKEY:4658159", "IKEY:4677368", "IKEY:640407", "IKEY:5652460", "IKEY:5290706", "IKEY:5332611", "IKEY:4658123", "IKEY:5613435", "IKEY:856996", "IKEY:6102450", "IKEY:485139", "IKEY:4015424", "IKEY:4389000", "10.1145/1376916.1376944", "10.1145/1376916.1376944", "10.1145/1376916.1376944", "10.1111/j.1467-8659.2011.01940.x", "10.1007/3-540-28349-8_2", "10.1111/1467-9884.00145", "10.1201/9780203498798", "10.1007/11731139_24", "10.1002/9781118625590", "10.1287/inte.22.6.40", "10.1111/0272-4332.00039", "10.1137/1.9780898717761", "10.1111/j.1467-8659.2011.01914.x", "10.1016/j.ress.2005.11.017", "10.1111/j.1539-6924.1988.tb01155.x", "10.1016/S0010-4655(98)00154-4", "10.1111/j.1467-8659.2009.01475.x", "10.1057/ivs.2009.34", "10.1002/0470863072", "10.2307/2683468", "10.1111/j.1467-8659.2009.01677.x", "10.1016/j.csda.2007.01.011", "10.1016/S0378-4754(00)00270-6", "10.5183/jjscs1988.7.1", "10.2307/2290332", "10.1057/palgrave.ivs.9500025", "10.1007/BF02789706", "10.1111/j.1467-8659.2011.01940.x", "10.1007/3-540-28349-8_2", "10.1111/1467-9884.00145", "10.1201/9780203498798", "10.1007/11731139_24", "10.1002/9781118625590", "10.1287/inte.22.6.40", "10.1111/0272-4332.00039", "10.1137/1.9780898717761", "10.1111/j.1467-8659.2011.01914.x", "10.1016/j.ress.2005.11.017", "10.1111/j.1539-6924.1988.tb01155.x", "10.1016/S0010-4655(98)00154-4", "10.1111/j.1467-8659.2009.01475.x", "10.1057/ivs.2009.34", "10.1002/0470863072", "10.2307/2683468", "10.1111/j.1467-8659.2009.01677.x", "10.1016/j.csda.2007.01.011", "10.1016/S0378-4754(00)00270-6", "10.5183/jjscs1988.7.1", "10.2307/2290332", "10.1057/palgrave.ivs.9500025", "10.1007/BF02789706", "10.1111/j.1467-8659.2011.01940.x", "10.1007/3-540-28349-8_2", "10.1111/1467-9884.00145", "10.1201/9780203498798", "10.1007/11731139_24", "10.1002/9781118625590", "10.1287/inte.22.6.40", "10.1111/0272-4332.00039", "10.1137/1.9780898717761", "10.1111/j.1467-8659.2011.01914.x", "10.1016/j.ress.2005.11.017", "10.1111/j.1539-6924.1988.tb01155.x", "10.1016/S0010-4655(98)00154-4", "10.1111/j.1467-8659.2009.01475.x", "10.1057/ivs.2009.34", "10.1002/0470863072", "10.2307/2683468", "10.1111/j.1467-8659.2009.01677.x", "10.1016/j.csda.2007.01.011", "10.1016/S0378-4754(00)00270-6", "10.5183/jjscs1988.7.1", "10.2307/2290332", "10.1057/palgrave.ivs.9500025", "10.1007/BF02789706"]}}