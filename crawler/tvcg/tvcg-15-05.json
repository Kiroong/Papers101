{"10.1109/TVCG.2014.2355207": {"doi": "10.1109/TVCG.2014.2355207", "author": ["V. A. Prisacariu", "O. K\u00e4hler", "D. W. Murray", "I. D. Reid"], "title": "Real-Time 3D Tracking and Reconstruction on Mobile Phones", "year": "2015", "abstract": "We present a novel framework for jointly tracking a camera in 3D and reconstructing the 3D model of an observed object. Due to the region based approach, our formulation can handle untextured objects, partial occlusions, motion blur, dynamic backgrounds and imperfect lighting. Our formulation also allows for a very efficient implementation which achieves real-time performance on a mobile phone, by running the pose estimation and the shape optimisation in parallel. We use a level set based pose estimation but completely avoid the, typically required, explicit computation of a global distance. This leads to tracking rates of more than 100 Hz on a desktop PC and 30 Hz on a mobile phone. Further, we incorporate additional orientation information from the phone's inertial sensor which helps us resolve the tracking ambiguities inherent to region based formulations. The reconstruction step first probabilistically integrates 2D image statistics from selected keyframes into a 3D volume, and then imposes coherency and compactness using a total variational regularisation term. The global optimum of the overall energy function is found using a continuous max-flow algorithm and we show that, similar to tracking, the integration of per voxel posteriors instead of likelihoods improves the precision and accuracy of the reconstruction.", "keywords": ["computational geometry", "image reconstruction", "mobile handsets", "object tracking", "pose estimation", "probability", "real-time 3D tracking", "real-time 3D reconstruction", "mobile phones", "region based approach", "untextured objects", "partial occlusions", "motion blur", "dynamic backgrounds", "imperfect lighting", "real-time performance", "shape optimisation", "level set based pose estimation", "tracking rates", "desktop PC", "orientation information", "phone inertial sensor", "tracking ambiguities", "probabilistically integrated 2D image statistics", "3D volume", "coherency", "compactness", "total variational regularisation term", "global optimum", "energy function", "continuous max-flow algorithm", "voxel posteriors", "reconstruction precision improvement", "reconstruction accuracy improvement", "Three-dimensional displays", "Shape", "Image reconstruction", "Cameras", "Optimization", "Mobile handsets", "Rendering (computer graphics)", "3d tracking", "3d reconstruction", "augmented reality", "mobile phone"], "referenced_by": ["IKEY:8099540", "IKEY:7784014", "IKEY:7165673", "IKEY:8480069", "IKEY:8570143", "IKEY:8565885", "IKEY:9026194", "IKEY:9007721", "IKEY:9197528", "10.1007/978-3-319-46493-0_26", "10.1007/s11554-017-0670-y", "10.3390/s151229847", "10.3390/s16081243", "10.3390/s17040806", "10.1016/j.ijhcs.2020.102433"], "referencing": ["IKEY:5643570", "IKEY:6103284", "IKEY:4538852", "IKEY:6136520", "IKEY:6126513", "IKEY:6671768", "IKEY:5771427", "IKEY:855839", "IKEY:6751117", "IKEY:913772", "IKEY:5539903", "IKEY:5643570", "IKEY:6103284", "IKEY:4538852", "IKEY:6136520", "IKEY:6126513", "IKEY:6671768", "IKEY:5771427", "IKEY:855839", "IKEY:6751117", "IKEY:913772", "IKEY:5539903", "IKEY:5643570", "IKEY:6103284", "IKEY:4538852", "IKEY:6136520", "IKEY:6126513", "IKEY:6671768", "IKEY:5771427", "IKEY:855839", "IKEY:6751117", "IKEY:913772", "IKEY:5539903", "10.1016/j.imavis.2008.09.005", "10.1007/s11263-009-0275-4", "10.5244/C.23.112", "10.1007/s11263-011-0514-3", "10.1007/978-3-642-37331-2_45", "10.1007/s11263-006-9965-3", "10.1007/978-3-540-74936-3_18", "10.1023/A:1020874308076", "10.1023/A:1023079624234", "10.1016/j.imavis.2008.09.005", "10.1007/s11263-009-0275-4", "10.5244/C.23.112", "10.1007/s11263-011-0514-3", "10.1007/978-3-642-37331-2_45", "10.1007/s11263-006-9965-3", "10.1007/978-3-540-74936-3_18", "10.1023/A:1020874308076", "10.1023/A:1023079624234", "10.1016/j.imavis.2008.09.005", "10.1007/s11263-009-0275-4", "10.5244/C.23.112", "10.1007/s11263-011-0514-3", "10.1007/978-3-642-37331-2_45", "10.1007/s11263-006-9965-3", "10.1007/978-3-540-74936-3_18", "10.1023/A:1020874308076", "10.1023/A:1023079624234"]}, "10.1109/TVCG.2014.2360403": {"doi": "10.1109/TVCG.2014.2360403", "author": ["B. Glocker", "J. Shotton", "A. Criminisi", "S. Izadi"], "title": "Real-Time RGB-D Camera Relocalization via Randomized Ferns for Keyframe Encoding", "year": "2015", "abstract": "Recovery from tracking failure is essential in any simultaneous localization and tracking system. In this context, we explore an efficient keyframe-based relocalization method based on frame encoding using randomized ferns. The method enables automatic discovery of keyframes through online harvesting in tracking mode, and fast retrieval of pose candidates in the case when tracking is lost. Frame encoding is achieved by applying simple binary feature tests which are stored in the nodes of an ensemble of randomized ferns. The concatenation of small block codes generated by each fern yields a global compact representation of camera frames. Based on those representations we define the frame dissimilarity as the block-wise hamming distance (BlockHD). Dissimilarities between an incoming query frame and a large set of keyframes can be efficiently evaluated by simply traversing the nodes of the ferns and counting image co-occurrences in corresponding code tables. In tracking mode, those dissimilarities decide whether a frame/pose pair is considered as a novel keyframe. For tracking recovery, poses of the most similar keyframes are retrieved and used for reinitialization of the tracking algorithm. The integration of our relocalization method into a hand-held KinectFusion system allows seamless continuation of mapping even when tracking is frequently lost.", "keywords": ["cameras", "image coding", "image colour analysis", "image representation", "image retrieval", "object tracking", "pose estimation", "SLAM (robots)", "real-time RGB-D camera relocalization", "randomized ferns", "keyframe encoding", "simultaneous localization and tracking system", "keyframe-based relocalization method", "automatic keyframe discovery", "online harvesting", "tracking mode", "pose retrieval", "binary feature tests", "block code concatenation", "global compact camera frame representation", "frame dissimilarity", "block-wise hamming distance", "BlockHD", "incoming query frame", "node traversal", "image co-occurrences", "code tables", "frame-pose pair", "tracking failure recovery", "tracking algorithm reinitialization", "hand-held KinectFusion system", "Cameras", "Three-dimensional displays", "Image reconstruction", "Real-time systems", "Simultaneous localization and mapping", "Pipelines", "Encoding", "camera relocalization", "tracking recovery", "dense tracking and mapping", "marker-free augmented reality", "Camera relocalization", "tracking recovery", "dense tracking and mapping", "marker-free augmented reality"], "referenced_by": ["IKEY:8099514", "IKEY:7989598", "IKEY:8206611", "IKEY:7463070", "IKEY:7926703", "IKEY:8336740", "IKEY:8324775", "IKEY:8372000", "IKEY:8374582", "IKEY:8492363", "IKEY:8491017", "IKEY:8593505", "IKEY:8626520", "IKEY:8699246", "IKEY:8746595", "IKEY:8794462", "IKEY:8794299", "IKEY:8794595", "IKEY:8885732", "IKEY:8851216", "IKEY:8927657", "IKEY:9022353", "IKEY:8706568", "IKEY:8723521", "10.1145/3054739", "10.1145/3182157", "10.1145/3389412", "10.1007/s11042-016-3524-x", "10.1016/j.cviu.2016.05.013", "10.1016/j.patcog.2017.09.013", "10.1177/0278364916669237", "10.17485/ijst/2017/v10i36/119182", "10.3390/s18082505", "10.1007/s00170-018-2575-8", "10.1007/978-3-030-00776-8_26", "10.1117/12.2500819", "10.1117/12.2505258", "10.1016/j.media.2019.01.003", "10.1016/j.robot.2019.01.008", "10.1016/j.isprsjprs.2019.02.020", "10.1017/S0263574719000298", "10.1007/978-3-030-01264-9_46", "10.1007/s00371-019-01720-8", "10.1007/978-3-030-28603-3_6", "10.1016/j.cviu.2019.102850", "10.1016/j.vrih.2019.09.001", "10.1016/j.vrih.2019.09.003", "10.3390/s19224897", "10.1142/S0219843620500097", "10.1007/978-3-642-41610-1_109-1", "10.1088/1361-6501/ab816c", "10.1007/978-3-030-58571-6_28", "10.1007/s10489-020-01982-z", "10.1007/s11370-020-00341-8"], "referencing": ["IKEY:1238654", "IKEY:4160954", "IKEY:4538852", "IKEY:6126513", "IKEY:6671767", "IKEY:6162880", "IKEY:6162882", "IKEY:6619022", "IKEY:6599048", "IKEY:6751117", "IKEY:6671768", "IKEY:6777443", "IKEY:4079262", "IKEY:6802045", "IKEY:6130321", "IKEY:6671777", "IKEY:6909542", "IKEY:6619221", "IKEY:4079263", "IKEY:5722962", "IKEY:6671783", "IKEY:4674368", "IKEY:6094921", "IKEY:4269996", "IKEY:1641018", "IKEY:4760148", "IKEY:1661548", "IKEY:6126544", "IKEY:4359067", "IKEY:6224623", "IKEY:1238654", "IKEY:4160954", "IKEY:4538852", "IKEY:6126513", "IKEY:6671767", "IKEY:6162880", "IKEY:6162882", "IKEY:6619022", "IKEY:6599048", "IKEY:6751117", "IKEY:6671768", "IKEY:6777443", "IKEY:4079262", "IKEY:6802045", "IKEY:6130321", "IKEY:6671777", "IKEY:6909542", "IKEY:6619221", "IKEY:4079263", "IKEY:5722962", "IKEY:6671783", "IKEY:4674368", "IKEY:6094921", "IKEY:4269996", "IKEY:1641018", "IKEY:4760148", "IKEY:1661548", "IKEY:6126544", "IKEY:4359067", "IKEY:6224623", "IKEY:1238654", "IKEY:4160954", "IKEY:4538852", "IKEY:6126513", "IKEY:6671767", "IKEY:6162880", "IKEY:6162882", "IKEY:6619022", "IKEY:6599048", "IKEY:6751117", "IKEY:6671768", "IKEY:6777443", "IKEY:4079262", "IKEY:6802045", "IKEY:6130321", "IKEY:6671777", "IKEY:6909542", "IKEY:6619221", "IKEY:4079263", "IKEY:5722962", "IKEY:6671783", "IKEY:4674368", "IKEY:6094921", "IKEY:4269996", "IKEY:1641018", "IKEY:4760148", "IKEY:1661548", "IKEY:6126544", "IKEY:4359067", "IKEY:6224623", "10.1145/2366145.2366157", "10.1145/2047196.2047270", "10.1145/358669.358692", "10.1145/2366145.2366157", "10.1145/2047196.2047270", "10.1145/358669.358692", "10.1145/2366145.2366157", "10.1145/2047196.2047270", "10.1145/358669.358692", "10.5244/C.26.112", "10.1177/0278364911434148", "10.1177/0278364910385483", "10.5244/C.22.6", "10.5244/C.26.113", "10.5244/C.26.112", "10.1177/0278364911434148", "10.1177/0278364910385483", "10.5244/C.22.6", "10.5244/C.26.113", "10.5244/C.26.112", "10.1177/0278364911434148", "10.1177/0278364910385483", "10.5244/C.22.6", "10.5244/C.26.113"]}, "10.1109/TVCG.2014.2377772": {"doi": "10.1109/TVCG.2014.2377772", "author": ["N. Haouchine", "S. Cotin", "I. Peterlik", "J. Dequidt", "M. S. Lopez", "E. Kerrien", "M. Berger"], "title": "Impact of Soft Tissue Heterogeneity on Augmented Reality for Liver Surgery", "year": "2015", "abstract": "This paper presents a method for real-time augmented reality of internal liver structures during minimally invasive hepatic surgery. Vessels and tumors computed from pre-operative CT scans can be overlaid onto the laparoscopic view for surgery guidance. Compared to current methods, our method is able to locate the in-depth positions of the tumors based on partial three-dimensional liver tissue motion using a real-time biomechanical model. This model permits to properly handle the motion of internal structures even in the case of anisotropic or heterogeneous tissues, as it is the case for the liver and many anatomical structures. Experimentations conducted on phantom liver permits to measure the accuracy of the augmentation while real-time augmentation on in vivo human liver during real surgery shows the benefits of such an approach for minimally invasive surgery.", "keywords": ["augmented reality", "biological tissues", "computerised tomography", "liver", "medical image processing", "surgery", "soft tissue heterogeneity", "real-time augmented reality", "internal liver structures", "minimally invasive hepatic surgery", "liver surgery", "pre-operative CT scans", "partial three-dimensional liver tissue motion", "real-time biomechanical model", "real-time augmentation", "Surgery", "Computational modeling", "Liver", "Biological system modeling", "Three-dimensional displays", "Deformable models", "Biomechanics", "Image-guided Simulation", "Biomechanical Modeling", "Real-Time Augmented Reality", "Computer Assisted Surgery", "Image-guided simulation", "biomechanical modeling", "real-time augmented reality", "computer assisted surgery", "Computer Graphics", "Computer Simulation", "Humans", "Liver", "Liver Neoplasms", "Phantoms, Imaging", "Surgery, Computer-Assisted", "User-Computer Interface"], "referenced_by": ["IKEY:7359884", "IKEY:7328092", "IKEY:8115411", "IKEY:8119826", "IKEY:7454467", "IKEY:7150416", "IKEY:8402449", "IKEY:8593756", "IKEY:8755235", "IKEY:8836924", "IKEY:8914543", "IKEY:9066698", "IKEY:9176214", "10.1049/htl.2017.0068", "10.1002/9781119341031.ch1", "10.1002/cae.21772", "10.1007/s00464-016-5297-8", "10.1007/s10439-015-1419-z", "10.1016/B978-0-12-804009-6.00011-0", "10.1016/j.cmpb.2018.02.006", "10.1016/j.ddmod.2017.09.003", "10.1016/j.media.2017.01.007", "10.1016/j.media.2017.06.004", "10.1371/journal.pone.0161815", "10.1016/j.cma.2018.06.011", "10.1016/j.eij.2019.11.003", "10.1002/rcs.2055", "10.1007/978-3-030-43195-2_19", "10.1007/s00464-020-07807-x"], "referencing": ["IKEY:4270225", "IKEY:4668346", "IKEY:4250473", "IKEY:5350717", "IKEY:6247829", "IKEY:6619044", "IKEY:6631349", "IKEY:5648357", "IKEY:6671780", "IKEY:6820756", "IKEY:6907458", "IKEY:888718", "IKEY:4270225", "IKEY:4668346", "IKEY:4250473", "IKEY:5350717", "IKEY:6247829", "IKEY:6619044", "IKEY:6631349", "IKEY:5648357", "IKEY:6671780", "IKEY:6820756", "IKEY:6907458", "IKEY:888718", "IKEY:4270225", "IKEY:4668346", "IKEY:4250473", "IKEY:5350717", "IKEY:6247829", "IKEY:6619044", "IKEY:6631349", "IKEY:5648357", "IKEY:6671780", "IKEY:6820756", "IKEY:6907458", "IKEY:888718", "10.1016/j.suronc.2011.07.002", "10.1007/BF00131147", "10.5244/C.18.92", "10.1007/s11263-006-0017-9", "10.1016/j.cag.2010.05.015", "10.1016/j.eururo.2009.05.017", "10.1016/j.compmedimag.2009.08.002", "10.1016/j.urology.2008.11.040", "10.1007/978-3-642-31340-0_26", "10.1016/S1361-8415(03)00068-9", "10.1118/1.4896021", "10.1007/978-3-642-15705-9_10", "10.1016/j.media.2010.05.009", "10.1016/j.media.2013.04.003", "10.1016/j.cviu.2007.09.014", "10.1016/j.jbiomech.2005.07.005", "10.1016/j.cma.2004.07.035", "10.1007/978-3-642-15705-9_29", "10.1007/978-3-642-33415-3_7", "10.1080/10929080601090623", "10.1016/j.jbiomech.2011.03.029", "10.1007/s00276-010-0763-9", "10.1016/S1361-8415(03)00008-2", "10.1007/s00464-001-9176-5", "10.1016/j.suronc.2011.07.002", "10.1007/BF00131147", "10.5244/C.18.92", "10.1007/s11263-006-0017-9", "10.1016/j.cag.2010.05.015", "10.1016/j.eururo.2009.05.017", "10.1016/j.compmedimag.2009.08.002", "10.1016/j.urology.2008.11.040", "10.1007/978-3-642-31340-0_26", "10.1016/S1361-8415(03)00068-9", "10.1118/1.4896021", "10.1007/978-3-642-15705-9_10", "10.1016/j.media.2010.05.009", "10.1016/j.media.2013.04.003", "10.1016/j.cviu.2007.09.014", "10.1016/j.jbiomech.2005.07.005", "10.1016/j.cma.2004.07.035", "10.1007/978-3-642-15705-9_29", "10.1007/978-3-642-33415-3_7", "10.1080/10929080601090623", "10.1016/j.jbiomech.2011.03.029", "10.1007/s00276-010-0763-9", "10.1016/S1361-8415(03)00008-2", "10.1007/s00464-001-9176-5", "10.1016/j.suronc.2011.07.002", "10.1007/BF00131147", "10.5244/C.18.92", "10.1007/s11263-006-0017-9", "10.1016/j.cag.2010.05.015", "10.1016/j.eururo.2009.05.017", "10.1016/j.compmedimag.2009.08.002", "10.1016/j.urology.2008.11.040", "10.1007/978-3-642-31340-0_26", "10.1016/S1361-8415(03)00068-9", "10.1118/1.4896021", "10.1007/978-3-642-15705-9_10", "10.1016/j.media.2010.05.009", "10.1016/j.media.2013.04.003", "10.1016/j.cviu.2007.09.014", "10.1016/j.jbiomech.2005.07.005", "10.1016/j.cma.2004.07.035", "10.1007/978-3-642-15705-9_29", "10.1007/978-3-642-33415-3_7", "10.1080/10929080601090623", "10.1016/j.jbiomech.2011.03.029", "10.1007/s00276-010-0763-9", "10.1016/S1361-8415(03)00008-2", "10.1007/s00464-001-9176-5"]}, "10.1109/TVCG.2014.2385092": {"doi": "10.1109/TVCG.2014.2385092", "author": ["Z. Bai", "A. F. Blackwell", "G. Coulouris"], "title": "Using Augmented Reality to Elicit Pretend Play for Children with Autism", "year": "2015", "abstract": "Children with autism spectrum condition (ASC) suffer from deficits or developmental delays in symbolic thinking. In particular, they are often found lacking in pretend play during early childhood. Researchers believe that they encounter difficulty in generating and maintaining mental representation of pretense coupled with the immediate reality. We have developed an interactive system that explores the potential of Augmented Reality (AR) technology to visually conceptualize the representation of pretense within an open-ended play environment. Results from an empirical study involving children with ASC aged 4 to 7 demonstrated a significant improvement of pretend play in terms of frequency, duration and relevance using the AR system in comparison to a non computer-assisted situation. We investigated individual differences, skill transfer, system usability and limitations of the proposed AR system. We discuss design guidelines for future AR systems for children with ASC and other pervasive developmental disorders.", "keywords": ["augmented reality", "handicapped aids", "medical disorders", "augmented reality", "pervasive developmental disorders", "system limitations", "system usability", "skill transfer", "individual-differences", "relevance parameter", "duration parameter", "frequency parameter", "empirical study", "open-ended play environment", "visually conceptualized pretense representation", "AR technology", "interactive system", "pretense mental representation", "immediate reality", "pretend play", "symbolic thinking", "developmental delays", "deficits", "ASC", "autism spectrum condition", "autistic children", "Autism", "Computers", "Airplanes", "Vehicles", "Educational institutions", "Target tracking", "Materials", "H.5.1 Multimedia Information Systems", "Augmented Reality, pretend play, children, autism", "Asperger Syndrome", "Autistic Disorder", "Child", "Child, Preschool", "Computer Graphics", "Female", "Humans", "Male", "Play Therapy", "Virtual Reality Exposure Therapy"], "referenced_by": ["IKEY:8663595", "IKEY:8719140", "IKEY:8925327", "IKEY:9060971", "IKEY:9204125", "10.1007/978-3-319-41685-4_44", "10.1007/978-3-319-42108-7_35", "10.1007/s10209-017-0562-8", "10.1016/j.chc.2017.11.013", "10.2196/mhealth.8534", "10.1007/978-3-319-94334-3_26", "10.1007/s10639-018-9768-5", "10.12963/csd.18504", "10.3390/s18072368", "10.3390/s18082486", "10.1017/9781108131384.029", "10.18178/ijiet.2018.8.12.1160", "10.1007/s10209-019-00646-1", "10.1101/164376", "10.1016/j.displa.2019.03.001", "10.1007/s40474-019-00169-7", "10.1007/978-3-030-23563-5_16", "10.1007/978-3-030-21565-1_19", "10.1007/978-3-030-33695-0_48", "10.1016/j.jneumeth.2020.108616", "10.1007/978-3-030-30402-7_26", "10.1007/s11042-020-08647-6", "10.1016/j.ijhcs.2020.102485", "10.1007/978-3-030-51038-1_45", "10.1007/978-3-030-49760-6_28", "10.1007/978-3-030-40237-2_4", "10.3390/ijerph17176143", "10.1007/s10639-020-10326-w", "10.1007/978-3-030-60149-2_31", "10.5772/intechopen.94587"], "referencing": ["IKEY:6671763", "IKEY:5194207", "IKEY:4161035", "IKEY:6402561", "IKEY:4362148", "IKEY:6671763", "IKEY:5194207", "IKEY:4161035", "IKEY:6402561", "IKEY:4362148", "IKEY:6671763", "IKEY:5194207", "IKEY:4161035", "IKEY:6402561", "IKEY:4362148", "10.1145/1109540.1109545", "10.1145/2207676.2208649", "10.1145/1753846.1754021", "10.1145/1139073.1139096", "10.1145/632716.632883", "10.1145/1109540.1109545", "10.1145/2207676.2208649", "10.1145/1753846.1754021", "10.1145/1139073.1139096", "10.1145/632716.632883", "10.1145/1109540.1109545", "10.1145/2207676.2208649", "10.1145/1753846.1754021", "10.1145/1139073.1139096", "10.1145/632716.632883", "10.1016/0010-0277(85)90022-8", "10.1111/j.2044-835X.1987.tb01049.x", "10.1192/bjp.175.5.484", "10.1111/j.2044-835X.1990.tb00836.x", "10.1177/0271121408318799", "10.1023/A:1025806616149", "10.1504/IJART.2012.046270", "10.1177/1362361307086657", "10.1016/j.tics.2003.11.003", "10.1111/j.2044-835X.1996.tb00706.x", "10.1177/1362361303007004004", "10.1037/0033-295X.94.4.412", "10.1177/1362361307078135", "10.4108/ICST.INTETAIN2008.2472", "10.1007/BF01531618", "10.1007/BF01531288", "10.1016/0010-0277(85)90022-8", "10.1111/j.2044-835X.1987.tb01049.x", "10.1192/bjp.175.5.484", "10.1111/j.2044-835X.1990.tb00836.x", "10.1177/0271121408318799", "10.1023/A:1025806616149", "10.1504/IJART.2012.046270", "10.1177/1362361307086657", "10.1016/j.tics.2003.11.003", "10.1111/j.2044-835X.1996.tb00706.x", "10.1177/1362361303007004004", "10.1037/0033-295X.94.4.412", "10.1177/1362361307078135", "10.4108/ICST.INTETAIN2008.2472", "10.1007/BF01531618", "10.1007/BF01531288", "10.1016/0010-0277(85)90022-8", "10.1111/j.2044-835X.1987.tb01049.x", "10.1192/bjp.175.5.484", "10.1111/j.2044-835X.1990.tb00836.x", "10.1177/0271121408318799", "10.1023/A:1025806616149", "10.1504/IJART.2012.046270", "10.1177/1362361307086657", "10.1016/j.tics.2003.11.003", "10.1111/j.2044-835X.1996.tb00706.x", "10.1177/1362361303007004004", "10.1037/0033-295X.94.4.412", "10.1177/1362361307078135", "10.4108/ICST.INTETAIN2008.2472", "10.1007/BF01531618", "10.1007/BF01531288"]}, "10.1109/TVCG.2015.2408612": {"doi": "10.1109/TVCG.2015.2408612", "author": ["T. Oskiper", "M. Sizintsev", "V. Branzoi", "S. Samarasekera", "R. Kumar"], "title": "Augmented Reality Binoculars", "year": "2015", "abstract": "In this paper we present an augmented reality binocular system to allow long range high precision augmentation of live telescopic imagery with aerial and terrain based synthetic objects, vehicles, people and effects. The inserted objects must appear stable in the display and must not jitter and drift as the user pans around and examines the scene with the binoculars. The design of the system is based on using two different cameras with wide field of view and narrow field of view lenses enclosed in a binocular shaped shell. Using the wide field of view gives us context and enables us to recover the 3D location and orientation of the binoculars much more robustly, whereas the narrow field of view is used for the actual augmentation as well as to increase precision in tracking. We present our navigation algorithm that uses the two cameras in combination with an inertial measurement unit and global positioning system in an extended Kalman filter and provides jitter free, robust and real-time pose estimation for precise augmentation. We have demonstrated successful use of our system as part of information sharing example as well as a live simulated training system for observer training, in which fixed and rotary wing aircrafts, ground vehicles, and weapon effects are combined with real world scenes.", "keywords": ["augmented reality", "computer vision", "Global Positioning System", "Kalman filters", "extended Kalman filter", "global positioning system", "inertial measurement unit", "navigation algorithm", "binocular shaped shell", "wide field", "narrow field", "live telescopic imagery", "augmented reality binocular system", "Cameras", "Augmented reality", "Calibration", "Global Positioning System", "Visualization", "Training", "Robustness", "IMU", "monocular wide and narrow field of view camera", "GPS", "inertial navigation", "sensor fusion", "EKF", "IMU", "monocular wide and narrow field of view camera", "GPS", "inertial navigation", "sensor fusion", "EKF"], "referenced_by": ["IKEY:7504692", "IKEY:8029074", "IKEY:9049540", "10.1177/1541931213602010", "10.3390/app8112318", "10.1007/978-981-13-9190-3_10", "10.15407/emodel.42.02.069", "10.3390/s20102997"], "referencing": ["IKEY:6162870", "IKEY:756959", "IKEY:1467360", "IKEY:1467495", "IKEY:6402532", "IKEY:1310049", "IKEY:970516", "IKEY:4538852", "IKEY:6162878", "IKEY:4637877", "IKEY:4209642", "IKEY:6126513", "IKEY:6402541", "IKEY:1046627", "IKEY:6402542", "IKEY:4079263", "IKEY:1014801", "IKEY:6162875", "IKEY:5643604", "IKEY:6162870", "IKEY:756959", "IKEY:1467360", "IKEY:1467495", "IKEY:6402532", "IKEY:1310049", "IKEY:970516", "IKEY:4538852", "IKEY:6162878", "IKEY:4637877", "IKEY:4209642", "IKEY:6126513", "IKEY:6402541", "IKEY:1046627", "IKEY:6402542", "IKEY:4079263", "IKEY:1014801", "IKEY:6162875", "IKEY:5643604", "IKEY:6162870", "IKEY:756959", "IKEY:1467360", "IKEY:1467495", "IKEY:6402532", "IKEY:1310049", "IKEY:970516", "IKEY:4538852", "IKEY:6162878", "IKEY:4637877", "IKEY:4209642", "IKEY:6126513", "IKEY:6402541", "IKEY:1046627", "IKEY:6402542", "IKEY:4079263", "IKEY:1014801", "IKEY:6162875", "IKEY:5643604", "10.1023/B:VISI.0000011205.11775.fd", "10.5244/C.2.23", "10.1017/CBO9780511811685", "10.1023/B:VISI.0000011205.11775.fd", "10.5244/C.2.23", "10.1017/CBO9780511811685", "10.1023/B:VISI.0000011205.11775.fd", "10.5244/C.2.23", "10.1017/CBO9780511811685"]}, "10.1109/TVCG.2014.2383380": {"doi": "10.1109/TVCG.2014.2383380", "author": ["L. Shi", "C. Wang", "Z. Wen", "H. Qu", "C. Lin", "Q. Liao"], "title": "1.5D Egocentric Dynamic Network Visualization", "year": "2015", "abstract": "Dynamic network visualization has been a challenging research topic due to the visual and computational complexity introduced by the extra time dimension. Existing solutions are usually good for overview and presentation tasks, but not for the interactive analysis of a large dynamic network. We introduce in this paper a new approach which considers only the dynamic network central to a focus node, also known as the egocentric dynamic network. Our major contribution is a novel 1.5D visualization design which greatly reduces the visual complexity of the dynamic network without sacrificing the topological and temporal context central to the focus node. In our design, the egocentric dynamic network is presented in a single static view, supporting rich analysis through user interactions on both time and network. We propose a general framework for the 1.5D visualization approach, including the data processing pipeline, the visualization algorithm design, and customized interaction methods. Finally, we demonstrate the effectiveness of our approach on egocentric dynamic network analysis tasks, through case studies and a controlled user experiment comparing with three baseline dynamic network visualization methods.", "keywords": ["computational complexity", "data visualisation", "graph theory", "network theory (graphs)", "1.5D egocentric dynamic network visualization design", "visual complexity", "computational complexity", "focus node", "topological context", "temporal context", "static view", "user interactions", "time dimension", "network dimension", "data processing pipeline", "Market research", "Layout", "Data visualization", "Visualization", "Electronic mail", "Heuristic algorithms", "Algorithm design and analysis", "Graph Visualization", "1.5D Visualization", "Dynamic Network", "Egocentric Abstraction", "Graph visualization", "1.5D visualization", "dynamic network", "egocentric abstraction"], "referenced_by": ["IKEY:7938243", "IKEY:7570239", "IKEY:7347632", "IKEY:8440852", "IKEY:8616725", "IKEY:8802415", "IKEY:8964236", "IKEY:8986934", "10.1145/3162075", "10.1007/978-3-319-51811-4_53", "10.1007/s11390-016-1663-1", "10.1111/cgf.12791", "10.1177/1473871616667632", "10.1007/978-3-030-00764-5_9", "10.1177/1473871618812163", "10.1016/j.visinf.2018.12.006", "10.1007/978-981-13-9190-3_29", "10.1016/j.ins.2019.07.097", "10.1007/978-981-10-3874-7_17", "10.18632/aging.101751", "10.1177/1473871620972339", "10.3390/s20205895"], "referencing": ["IKEY:5643249", "IKEY:6065000", "IKEY:6102458", "IKEY:5473226", "IKEY:5742388", "IKEY:56447", "IKEY:4433990", "IKEY:1382908", "IKEY:1173160", "IKEY:1532148", "IKEY:6065001", "IKEY:4658146", "IKEY:5290699", "IKEY:4376140", "IKEY:485140", "IKEY:963273", "IKEY:5643249", "IKEY:6065000", "IKEY:6102458", "IKEY:5473226", "IKEY:5742388", "IKEY:56447", "IKEY:4433990", "IKEY:1382908", "IKEY:1173160", "IKEY:1532148", "IKEY:6065001", "IKEY:4658146", "IKEY:5290699", "IKEY:4376140", "IKEY:485140", "IKEY:963273", "IKEY:5643249", "IKEY:6065000", "IKEY:6102458", "IKEY:5473226", "IKEY:5742388", "IKEY:56447", "IKEY:4433990", "IKEY:1382908", "IKEY:1173160", "IKEY:1532148", "IKEY:6065001", "IKEY:4658146", "IKEY:5290699", "IKEY:4376140", "IKEY:485140", "IKEY:963273", "10.1145/1168149.1168168", "10.1145/1385569.1385584", "10.1145/1385569.1385636", "10.1145/1357054.1357101", "10.1145/2024288.2024344", "10.1145/1401890.1402008", "10.1145/1168149.1168168", "10.1145/1385569.1385584", "10.1145/1385569.1385636", "10.1145/1357054.1357101", "10.1145/2024288.2024344", "10.1145/1401890.1402008", "10.1145/1168149.1168168", "10.1145/1385569.1385584", "10.1145/1385569.1385636", "10.1145/1357054.1357101", "10.1145/2024288.2024344", "10.1145/1401890.1402008", "10.1086/421509", "10.1007/3-540-45848-4_19", "10.1007/978-3-540-31843-9_24", "10.1137/S0097539792235724", "10.1007/BFb0021824", "10.1006/jvlc.1995.1010", "10.1007/978-3-540-77537-9_36", "10.1007/978-3-7091-6215-6_19", "10.1080/10447318.2010.516722", "10.1111/j.1467-8659.2008.01213.x", "10.1007/3-540-44541-2_37", "10.1111/j.1467-8659.2012.03113.x", "10.1007/978-3-642-18469-7_5", "10.1016/0020-0190(89)90102-6", "10.1007/978-3-540-31843-9_25", "10.1086/421509", "10.1007/3-540-45848-4_19", "10.1007/978-3-540-31843-9_24", "10.1137/S0097539792235724", "10.1007/BFb0021824", "10.1006/jvlc.1995.1010", "10.1007/978-3-540-77537-9_36", "10.1007/978-3-7091-6215-6_19", "10.1080/10447318.2010.516722", "10.1111/j.1467-8659.2008.01213.x", "10.1007/3-540-44541-2_37", "10.1111/j.1467-8659.2012.03113.x", "10.1007/978-3-642-18469-7_5", "10.1016/0020-0190(89)90102-6", "10.1007/978-3-540-31843-9_25", "10.1086/421509", "10.1007/3-540-45848-4_19", "10.1007/978-3-540-31843-9_24", "10.1137/S0097539792235724", "10.1007/BFb0021824", "10.1006/jvlc.1995.1010", "10.1007/978-3-540-77537-9_36", "10.1007/978-3-7091-6215-6_19", "10.1080/10447318.2010.516722", "10.1111/j.1467-8659.2008.01213.x", "10.1007/3-540-44541-2_37", "10.1111/j.1467-8659.2012.03113.x", "10.1007/978-3-642-18469-7_5", "10.1016/0020-0190(89)90102-6", "10.1007/978-3-540-31843-9_25"]}, "10.1109/TVCG.2014.2385056": {"doi": "10.1109/TVCG.2014.2385056", "author": ["M. Gattullo", "A. E. Uva", "M. Fiorentino", "G. Monno"], "title": "Effect of Text Outline and Contrast Polarity on AR Text Readability in Industrial Lighting", "year": "2015", "abstract": "Text readability with augmented reality head-worn displays is critical and at present time, there are no standard guidelines to follow. The readability depends mainly on background lighting, display technology (i.e., OST: optical see-through or VST: video see-through), and text style (e.g., plain text, outline or billboard). In this work, we addressed the readability limits for industrial activities. We experimented the effects of two background illuminances levels (1,000 lx for very fine basic industrial tasks and 4,000 lx for fine machining), two commercially available head-worn display technologies, variable outline widths and contrast polarity of text. We analyzed the performance of 12 subjects by collecting about 3,400 measurements using a specific test application and followed by qualitative interviews. With high illuminances, VST performed better than OST, regardless of contrast polarity and outline width. We found that negative contrast polarity is preferable with VST, and that just a minimum outline (1 px) around black text is optimal. On the contrary, positive contrast polarity should be used with OST and outline is not effective. Therefore, we evaluated the usage limits of the OST by sampling its contrast sensitivity function.", "keywords": ["augmented reality", "text outline", "contrast polarity", "AR text readability", "industrial lighting", "augmented reality head-worn displays", "background illuminances levels", "VST", "Lighting", "Image color analysis", "Color", "Cameras", "Visualization", "Standards", "Optical sensors", "Augmented reality", "Industrial lighting", "Optical see-through", "Video see-through", "Contrast sensitivity function", "Augmented reality", "industrial lighting", "optical see-through", "video see-through", "contrast sensitivity function"], "referenced_by": ["IKEY:9288417"], "referencing": ["IKEY:5620905", "IKEY:4161003", "IKEY:5444808", "IKEY:6788092", "IKEY:5324831", "IKEY:1240696", "IKEY:4577996", "IKEY:6797341", "IKEY:4441708", "IKEY:6520861", "IKEY:6797291", "IKEY:4079250", "IKEY:5643530", "IKEY:1383059", "IKEY:6671761", "IKEY:6402574", "IKEY:1383039", "IKEY:5620905", "IKEY:4161003", "IKEY:5444808", "IKEY:6788092", "IKEY:5324831", "IKEY:1240696", "IKEY:4577996", "IKEY:6797341", "IKEY:4441708", "IKEY:6520861", "IKEY:6797291", "IKEY:4079250", "IKEY:5643530", "IKEY:1383059", "IKEY:6671761", "IKEY:6402574", "IKEY:1383039", "IKEY:5620905", "IKEY:4161003", "IKEY:5444808", "IKEY:6788092", "IKEY:5324831", "IKEY:1240696", "IKEY:4577996", "IKEY:6797341", "IKEY:4441708", "IKEY:6520861", "IKEY:6797291", "IKEY:4079250", "IKEY:5643530", "IKEY:1383059", "IKEY:6671761", "IKEY:6402574", "IKEY:1383039", "10.1145/2449396.2449443", "10.1145/1394669.1394675", "10.1145/2449396.2449443", "10.1145/1394669.1394675", "10.1145/2449396.2449443", "10.1145/1394669.1394675", "10.1016/j.cad.2008.10.015", "10.1080/00221309.1930.9918218", "10.1016/0042-6989(87)90028-9", "10.1113/jphysiol.1968.sp008574", "10.1136/bjo.69.1.51", "10.1007/978-3-642-58552-4_43", "10.1080/713754254", "10.1113/jphysiol.1973.sp010072", "10.1113/jphysiol.1985.sp015591", "10.1016/0042-6989(77)90009-8", "10.1007/978-1-4614-4205-9_3", "10.1016/j.cad.2008.10.015", "10.1080/00221309.1930.9918218", "10.1016/0042-6989(87)90028-9", "10.1113/jphysiol.1968.sp008574", "10.1136/bjo.69.1.51", "10.1007/978-3-642-58552-4_43", "10.1080/713754254", "10.1113/jphysiol.1973.sp010072", "10.1113/jphysiol.1985.sp015591", "10.1016/0042-6989(77)90009-8", "10.1007/978-1-4614-4205-9_3", "10.1016/j.cad.2008.10.015", "10.1080/00221309.1930.9918218", "10.1016/0042-6989(87)90028-9", "10.1113/jphysiol.1968.sp008574", "10.1136/bjo.69.1.51", "10.1007/978-3-642-58552-4_43", "10.1080/713754254", "10.1113/jphysiol.1973.sp010072", "10.1113/jphysiol.1985.sp015591", "10.1016/0042-6989(77)90009-8", "10.1007/978-1-4614-4205-9_3"]}, "10.1109/TVCG.2014.2388205": {"doi": "10.1109/TVCG.2014.2388205", "author": ["R. Poranne", "R. Chen", "C. Gotsman"], "title": "On Linear Spaces of Polyhedral Meshes", "year": "2015", "abstract": "Polyhedral meshes (PM)-meshes having planar faces-have enjoyed a rise in popularity in recent years due to their importance in architectural and industrial design. However, they are also notoriously difficult to generate and manipulate. Previous methods start with a smooth surface and then apply elaborate meshing schemes to create polyhedral meshes approximating the surface. In this paper, we describe a reverse approach: given the topology of a mesh, we explore the space of possible planar meshes having that topology. Our approach is based on a complete characterization of the maximal linear spaces of polyhedral meshes contained in the curved manifold of polyhedral meshes with a given topology. We show that these linear spaces can be described as nullspaces of differential operators, much like harmonic functions are nullspaces of the Laplacian operator. An analysis of this operator provides tools for global and local design of a polyhedral mesh, which fully expose the geometric possibilities and limitations of the given topology.", "keywords": ["computational geometry", "mathematical operators", "mesh generation", "topology", "polyhedral meshes", "PM", "mesh topology", "planar meshes", "maximal linear spaces", "curved manifold", "differential operators", "nullspaces", "harmonic functions", "Laplacian operator", "global design", "local design", "Topology", "Manifolds", "Vectors", "Transmission line matrix methods", "Geometry", "Shape", "Space exploration", "Polyhedral meshes", "Polyhedral meshes"], "referenced_by": ["10.1007/s11804-017-1419-5", "10.1016/j.autcon.2018.08.010", "10.1007/978-3-319-92294-2_18"], "referencing": ["IKEY:4385788", "IKEY:4385788", "IKEY:4385788", "10.1145/1576246.1531340", "10.1145/1186562.1015817", "10.1145/1268517.1268522", "10.1145/1186822.1073323", "10.1145/1964921.1964973", "10.1145/1141911.1141941", "10.1145/2024156.2024174", "10.1145/1275808.1276458", "10.1145/1057432.1057456", "10.1145/2024156.2024158", "10.1145/1576246.1531340", "10.1145/1186562.1015817", "10.1145/1268517.1268522", "10.1145/1186822.1073323", "10.1145/1964921.1964973", "10.1145/1141911.1141941", "10.1145/2024156.2024174", "10.1145/1275808.1276458", "10.1145/1057432.1057456", "10.1145/2024156.2024158", "10.1145/1576246.1531340", "10.1145/1186562.1015817", "10.1145/1268517.1268522", "10.1145/1186822.1073323", "10.1145/1964921.1964973", "10.1145/1141911.1141941", "10.1145/2024156.2024174", "10.1145/1275808.1276458", "10.1145/1057432.1057456", "10.1145/2024156.2024158", "10.1111/j.1467-8659.2009.01395.x", "10.1111/j.1467-8659.2008.01121.x", "10.1016/0024-3795(89)90494-1", "10.1111/j.1467-8659.2012.03043.x", "10.1007/978-3-642-15582-6_31", "10.1111/j.1467-8659.2008.01290.x", "10.1111/cgf.12005", "10.1111/j.1467-8659.2010.01776.x", "10.1007/978-3-7091-1251-9_25", "10.1111/j.1467-8659.2009.01395.x", "10.1111/j.1467-8659.2008.01121.x", "10.1016/0024-3795(89)90494-1", "10.1111/j.1467-8659.2012.03043.x", "10.1007/978-3-642-15582-6_31", "10.1111/j.1467-8659.2008.01290.x", "10.1111/cgf.12005", "10.1111/j.1467-8659.2010.01776.x", "10.1007/978-3-7091-1251-9_25", "10.1111/j.1467-8659.2009.01395.x", "10.1111/j.1467-8659.2008.01121.x", "10.1016/0024-3795(89)90494-1", "10.1111/j.1467-8659.2012.03043.x", "10.1007/978-3-642-15582-6_31", "10.1111/j.1467-8659.2008.01290.x", "10.1111/cgf.12005", "10.1111/j.1467-8659.2010.01776.x", "10.1007/978-3-7091-1251-9_25"]}, "10.1109/TVCG.2014.2377753": {"doi": "10.1109/TVCG.2014.2377753", "author": ["M. Stengel", "P. Bauszat", "M. Eisemann", "E. Eisemann", "M. Magnor"], "title": "Temporal Video Filtering and Exposure Control for Perceptual Motion Blur", "year": "2015", "abstract": "We propose the computation of a perceptual motion blur in videos. Our technique takes the predicted eye motion into account when watching the video. Compared to traditional motion blur recorded by a video camera our approach results in a perceptual blur that is closer to reality. This postprocess can also be used to simulate different shutter effects or for other artistic purposes. It handles real and artificial video input, is easy to compute and has a low additional cost for rendered content. We illustrate its advantages in a user study using eye tracking.", "keywords": ["gaze tracking", "image filtering", "image restoration", "motion estimation", "rendering (computer graphics)", "video signal processing", "temporal video filtering", "exposure control", "perceptual motion blur", "eye motion prediction", "shutter effects", "artistic purposes", "real video input", "artificial video input", "rendering", "eye tracking", "Cameras", "Retina", "Motion pictures", "Observers", "Image edge detection", "Target tracking", "high frame rate", "temporal filtering", "perception", "sharpening and blur", "High frame rate", "temporal filtering", "perception", "sharpening and blur"], "referenced_by": ["IKEY:7533071", "IKEY:7559993", "IKEY:7223443", "IKEY:7305789", "IKEY:8488586", "10.1007/978-3-319-71767-8_45", "10.1177/1473871615609787", "10.1111/cgf.13870"], "referencing": ["IKEY:761554", "IKEY:963286", "IKEY:4761406", "IKEY:5693092", "IKEY:6522878", "IKEY:761554", "IKEY:963286", "IKEY:4761406", "IKEY:5693092", "IKEY:6522878", "IKEY:761554", "IKEY:963286", "IKEY:4761406", "IKEY:5693092", "IKEY:6522878", "10.1145/1559755.1559757", "10.1145/1394281.1394289", "10.1145/566654.566650", "10.1145/344779.344932", "10.1145/1778765.1778850", "10.1145/2461217.2461230", "10.1145/1186562.1015764", "10.1145/964965.808590", "10.1145/1559755.1559757", "10.1145/1394281.1394289", "10.1145/566654.566650", "10.1145/344779.344932", "10.1145/1778765.1778850", "10.1145/2461217.2461230", "10.1145/1186562.1015764", "10.1145/964965.808590", "10.1145/1559755.1559757", "10.1145/1394281.1394289", "10.1145/566654.566650", "10.1145/344779.344932", "10.1145/1778765.1778850", "10.1145/2461217.2461230", "10.1145/1186562.1015764", "10.1145/964965.808590", "10.1111/j.1467-8659.2007.01082.x", "10.1016/j.cag.2010.05.017", "10.1016/S0042-6989(97)00430-6", "10.1098/rspb.1997.0061", "10.1016/S0042-6989(97)00016-3", "10.1167/10.10.28", "10.1889/JSID19.3.271", "10.1016/j.visres.2008.12.003", "10.5594/j18266", "10.1002/cne.902920402", "10.1111/cgf.12158", "10.1111/j.1467-8659.2010.01840.x", "10.1098/rspb.1981.0010", "10.1111/j.1467-8659.2007.01082.x", "10.1016/j.cag.2010.05.017", "10.1016/S0042-6989(97)00430-6", "10.1098/rspb.1997.0061", "10.1016/S0042-6989(97)00016-3", "10.1167/10.10.28", "10.1889/JSID19.3.271", "10.1016/j.visres.2008.12.003", "10.5594/j18266", "10.1002/cne.902920402", "10.1111/cgf.12158", "10.1111/j.1467-8659.2010.01840.x", "10.1098/rspb.1981.0010", "10.1111/j.1467-8659.2007.01082.x", "10.1016/j.cag.2010.05.017", "10.1016/S0042-6989(97)00430-6", "10.1098/rspb.1997.0061", "10.1016/S0042-6989(97)00016-3", "10.1167/10.10.28", "10.1889/JSID19.3.271", "10.1016/j.visres.2008.12.003", "10.5594/j18266", "10.1002/cne.902920402", "10.1111/cgf.12158", "10.1111/j.1467-8659.2010.01840.x", "10.1098/rspb.1981.0010"]}, "10.1109/TVCG.2014.2388208": {"doi": "10.1109/TVCG.2014.2388208", "author": ["S. Gad", "W. Javed", "S. Ghani", "N. Elmqvist", "T. Ewing", "K. N. Hampton", "N. Ramakrishnan"], "title": "ThemeDelta: Dynamic Segmentations over Temporal Topic Models", "year": "2015", "abstract": "We present ThemeDelta, a visual analytics system for extracting and visualizing temporal trends, clustering, and reorganization in time-indexed textual datasets. ThemeDelta is supported by a dynamic temporal segmentation algorithm that integrates with topic modeling algorithms to identify change points where significant shifts in topics occur. This algorithm detects not only the clustering and associations of keywords in a time period, but also their convergence into topics (groups of keywords) that may later diverge into new groups. The visual representation of ThemeDelta uses sinuous, variable-width lines to show this evolution on a timeline, utilizing color for categories, and line width for keyword strength. We demonstrate how interaction with ThemeDelta helps capture the rise and fall of topics by analyzing archives of historical newspapers, of U.S. presidential campaign speeches, and of social messages collected through iNeighbors, a web-based social website. ThemeDelta is evaluated using a qualitative expert user study involving three researchers from rhetoric and history using the historical newspapers corpus.", "keywords": ["data analysis", "text analysis", "Web sites", "US presidential campaign speeches", "historical newspapers", "Web-based social Website", "iNeighbors", "keyword strength", "topic modeling algorithms", "dynamic temporal segmentation algorithm", "time-indexed textual datasets", "ThemeDelta", "visual analytics system", "temporal topic models", "Market research", "Data visualization", "Tag clouds", "Layout", "Visual analytics", "Heuristic algorithms", "Language models", "time-series segmentation", "text analytics", "visual representations", "Language models", "time-series segmentation", "text analytics", "visual representations"], "referenced_by": ["IKEY:8252893", "IKEY:7374750", "IKEY:7536654", "IKEY:7883511", "IKEY:8585487", "IKEY:8305502", "IKEY:8358974", "IKEY:8356097", "10.1145/3385729", "10.1007/s11390-016-1663-1", "10.1007/s12650-015-0323-9", "10.1007/s12650-017-0462-2", "10.1017/S1351324918000025", "10.1111/cgf.13180", "10.1146/annurev-soc-060116-053505", "10.2991/978-94-6239-186-4_2", "10.1007/978-3-319-94289-6_27", "10.1016/j.cag.2018.07.009", "10.1177/0010836718808315", "10.1007/s12650-018-0531-1", "10.1155/2018/1728303", "10.1111/cgf.13706", "10.1007/s10015-020-00585-8"], "referencing": ["IKEY:981848", "IKEY:4658136", "IKEY:545307", "IKEY:4438863", "IKEY:5290722", "IKEY:528686", "IKEY:6171184", "IKEY:4389005", "IKEY:5333443", "IKEY:6102461", "IKEY:6065008", "IKEY:6137314", "IKEY:6542437", "IKEY:1249025", "IKEY:6327274", "IKEY:1510530", "IKEY:6875967", "IKEY:981848", "IKEY:4658136", "IKEY:545307", "IKEY:4438863", "IKEY:5290722", "IKEY:528686", "IKEY:6171184", "IKEY:4389005", "IKEY:5333443", "IKEY:6102461", "IKEY:6065008", "IKEY:6137314", "IKEY:6542437", "IKEY:1249025", "IKEY:6327274", "IKEY:1510530", "IKEY:6875967", "IKEY:981848", "IKEY:4658136", "IKEY:545307", "IKEY:4438863", "IKEY:5290722", "IKEY:528686", "IKEY:6171184", "IKEY:4389005", "IKEY:5333443", "IKEY:6102461", "IKEY:6065008", "IKEY:6137314", "IKEY:6542437", "IKEY:1249025", "IKEY:6327274", "IKEY:1510530", "IKEY:6875967", "10.1145/1321440.1321473", "10.1145/1124772.1124891", "10.1145/1835804.1835827", "10.1145/1842993.1843035", "10.1145/1143844.1143859", "10.1145/1150402.1150450", "10.1145/1835804.1835889", "10.1145/2487575.2487603", "10.1145/1498759.1498826", "10.1145/1281192.1281276", "10.1145/1557019.1557077", "10.1145/1321440.1321473", "10.1145/1124772.1124891", "10.1145/1835804.1835827", "10.1145/1842993.1843035", "10.1145/1143844.1143859", "10.1145/1150402.1150450", "10.1145/1835804.1835889", "10.1145/2487575.2487603", "10.1145/1498759.1498826", "10.1145/1281192.1281276", "10.1145/1557019.1557077", "10.1145/1321440.1321473", "10.1145/1124772.1124891", "10.1145/1835804.1835827", "10.1145/1842993.1843035", "10.1145/1143844.1143859", "10.1145/1150402.1150450", "10.1145/1835804.1835889", "10.1145/2487575.2487603", "10.1145/1498759.1498826", "10.1145/1281192.1281276", "10.1145/1557019.1557077", "10.1007/978-3-642-03655-2_43", "10.1111/j.1467-8659.2011.01920.x", "10.1007/s10844-014-0304-9", "10.1198/016214506000000302", "10.1007/978-3-642-03655-2_43", "10.1111/j.1467-8659.2011.01920.x", "10.1007/s10844-014-0304-9", "10.1198/016214506000000302", "10.1007/978-3-642-03655-2_43", "10.1111/j.1467-8659.2011.01920.x", "10.1007/s10844-014-0304-9", "10.1198/016214506000000302"]}}