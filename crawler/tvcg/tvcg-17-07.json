{"10.1109/TVCG.2016.2551242": {"doi": "10.1109/TVCG.2016.2551242", "author": ["M. Chai", "C. Zheng", "K. Zhou"], "title": "Adaptive Skinning for Interactive Hair-Solid Simulation", "year": "2017", "abstract": "Reduced hair models have proven successful for interactively simulating a full head of hair strands, building upon a fundamental assumption that only a small set of guide hairs are needed for explicit simulation, and the rest of the hair move coherently and thus can be interpolated using guide hairs. Unfortunately, hair-solid interactions is a pathological case for traditional reduced hair models, as the motion coherence between hair strands can be arbitrarily broken by interacting with solids. In this paper, we propose an adaptive hair skinning method for interactive hair simulation with hair-solid collisions. We precompute many eligible sets of guide hairs and the corresponding interpolation relationships that are represented using a compact strand-based hair skinning model. At runtime, we simulate only guide hairs; for interpolating every other hair, we adaptively choose its guide hairs, taking into account motion coherence and potential hair-solid collisions. Further, we introduce a two-way collision correction algorithm to allow sparsely sampled guide hairs to resolve collisions with solids that can have small geometric features. Our method enables interactive simulation of more than 150 K hair strands interacting with complex solid objects, using 400 guide hairs. We demonstrate the efficiency and robustness of the method with various hairstyles and user-controlled arbitrary hair-solid interactions.", "keywords": ["digital simulation", "interactive systems", "solid modelling", "adaptive skinning", "interactive hair-solid simulation", "reduced hair models", "hair strands", "guide hairs", "motion coherence", "hair-solid collisions", "compact strand-based hair skinning model", "two-way collision correction algorithm", "geometric features", "complex solid objects", "user-controlled arbitrary hair-solid interactions", "Hair", "Adaptation models", "Computational modeling", "Solids", "Runtime", "Interpolation", "Animation", "Hair simulation", "interactive method", "reduced model", "adaptivity", "collision correction", "Algorithms", "Computer Graphics", "Computer Simulation", "Hair", "Humans", "Image Processing, Computer-Assisted", "Movement"], "referenced_by": ["10.1109/ACCESS.2017.2720465", "10.1109/ACCESS.2018.2818795", "10.1109/TVCG.2018.2808972", "10.1016/j.gmod.2020.101077"], "referencing": ["10.1109/TVCG.2007.30", "10.1109/TIT.2005.858979", "10.1109/TVCG.2007.30", "10.1109/TIT.2005.858979", "10.1109/TVCG.2007.30", "10.1109/TIT.2005.858979", "10.1145/1401132.1401247", "10.1145/1837101.1837102", "10.1145/142920.134021", "10.1145/1360612.1360663", "10.1145/2485895.2485913", "10.1145/1141911.1142012", "10.1145/1399504.1360662", "10.1145/2461912.2461962", "10.1145/1576246.1531368", "10.1145/2070781.2024173", "10.1145/566654.566623", "10.1145/2185520.2185592", "10.1145/2661229.2661237", "10.1145/1360612.1360622", "10.1145/882262.882358", "10.1145/1198555.1198573", "10.1145/1073368.1073389", "10.1145/1401032.1401080", "10.1145/1073204.1073206", "10.1145/2010324.1964988", "10.1145/2601097.2601160", "10.1145/2775280.2792541", "10.1145/2487228.2487230", "10.1145/1401132.1401247", "10.1145/1837101.1837102", "10.1145/142920.134021", "10.1145/1360612.1360663", "10.1145/2485895.2485913", "10.1145/1141911.1142012", "10.1145/1399504.1360662", "10.1145/2461912.2461962", "10.1145/1576246.1531368", "10.1145/2070781.2024173", "10.1145/566654.566623", "10.1145/2185520.2185592", "10.1145/2661229.2661237", "10.1145/1360612.1360622", "10.1145/882262.882358", "10.1145/1198555.1198573", "10.1145/1073368.1073389", "10.1145/1401032.1401080", "10.1145/1073204.1073206", "10.1145/2010324.1964988", "10.1145/2601097.2601160", "10.1145/2775280.2792541", "10.1145/2487228.2487230", "10.1145/1401132.1401247", "10.1145/1837101.1837102", "10.1145/142920.134021", "10.1145/1360612.1360663", "10.1145/2485895.2485913", "10.1145/1141911.1142012", "10.1145/1399504.1360662", "10.1145/2461912.2461962", "10.1145/1576246.1531368", "10.1145/2070781.2024173", "10.1145/566654.566623", "10.1145/2185520.2185592", "10.1145/2661229.2661237", "10.1145/1360612.1360622", "10.1145/882262.882358", "10.1145/1198555.1198573", "10.1145/1073368.1073389", "10.1145/1401032.1401080", "10.1145/1073204.1073206", "10.1145/2010324.1964988", "10.1145/2601097.2601160", "10.1145/2775280.2792541", "10.1145/2487228.2487230", "10.1002/vis.4340020410", "10.1007/11784203_68", "10.1111/1467-8659.00594", "10.1111/1467-8659.00525", "10.1111/1467-8659.00688", "10.1007/s00371-003-0226-y", "10.1016/j.jvcir.2007.01.005", "10.1137/0215075", "10.1137/S1064827596304010", "10.1002/vis.4340020410", "10.1007/11784203_68", "10.1111/1467-8659.00594", "10.1111/1467-8659.00525", "10.1111/1467-8659.00688", "10.1007/s00371-003-0226-y", "10.1016/j.jvcir.2007.01.005", "10.1137/0215075", "10.1137/S1064827596304010", "10.1002/vis.4340020410", "10.1007/11784203_68", "10.1111/1467-8659.00594", "10.1111/1467-8659.00525", "10.1111/1467-8659.00688", "10.1007/s00371-003-0226-y", "10.1016/j.jvcir.2007.01.005", "10.1137/0215075", "10.1137/S1064827596304010"]}, "10.1109/TVCG.2016.2570755": {"doi": "10.1109/TVCG.2016.2570755", "author": ["N. Pezzotti", "B. P. F. Lelieveldt", "L. v. d. Maaten", "T. H\u00f6llt", "E. Eisemann", "A. Vilanova"], "title": "Approximated and User Steerable tSNE for Progressive Visual Analytics", "year": "2017", "abstract": "Progressive Visual Analytics aims at improving the interactivity in existing analytics techniques by means of visualization as well as interaction with intermediate results. One key method for data analysis is dimensionality reduction, for example, to produce 2D embeddings that can be visualized and analyzed efficiently. t-Distributed Stochastic Neighbor Embedding (tSNE) is a well-suited technique for the visualization of high-dimensional data. tSNE can create meaningful intermediate results but suffers from a slow initialization that constrains its application in Progressive Visual Analytics. We introduce a controllable tSNE approximation (A-tSNE), which trades off speed and accuracy, to enable interactive data exploration. We offer real-time visualization techniques, including a density-based solution and a Magic Lens to inspect the degree of approximation. With this feedback, the user can decide on local refinements and steer the approximation level during the analysis. We demonstrate our technique with several datasets, in a real-world research scenario and for the real-time analysis of high-dimensional streams to illustrate its effectiveness for interactive data analysis.", "keywords": ["data analysis", "data visualisation", "user steerable tSNE", "progressive visual analytics", "t-distributed stochastic neighbor embedding", "data analysis", "dimensionality reduction", "high-dimensional data visualization", "controllable tSNE approximation", "density-based solution", "magic lens", "visualization techniques", "approximation level", "interactive data analysis", "Data visualization", "Visual analytics", "Algorithm design and analysis", "Approximation algorithms", "Real-time systems", "Computational complexity", "High dimensional data", "dimensionality reduction", "progressive visual analytics", "approximate computation"], "referenced_by": ["10.1109/ACCESS.2018.2890390", "10.1109/SMC.2018.00318", "10.1109/ACCESS.2018.2890693", "10.1109/CAHPC.2018.8645912", "10.1109/ACCESS.2019.2910589", "10.1109/TPEL.2018.2875350", "10.1109/ACCESS.2019.2923736", "10.1109/TVCG.2018.2846735", "10.1109/TVCG.2019.2934433", "10.1109/HPEC.2019.8916505", "10.1109/TVCG.2018.2869149", "10.1109/VDS48975.2019.8973380", "10.1109/VDS48975.2019.8973384", "10.1109/IoTaIS47347.2019.8980418", "10.1109/VAST47406.2019.8986943", "10.1109/HiPC.2019.00019", "10.1109/PacificVis48177.2020.9280", "10.1109/TIM.2019.2953436", "10.1109/TVCG.2020.2986996", "10.1109/CNS48642.2020.9162280", "10.1109/TIFS.2020.3027148", "10.1109/ICSMD50554.2020.9261691", "10.1109/TVCG.2019.2931299", "10.1016/j.neucom.2017.01.105", "10.1016/j.oraloncology.2017.02.005", "10.1021/acs.jproteome.7b00725", "10.3389/fimmu.2017.01953", "10.1084/jem.20171934", "10.1093/nar/gkx046", "10.2200/S00797ED1V01Y201709VIS009", "10.1038/s41467-017-01689-9", "10.3390/informatics5030031", "10.1038/s41598-018-30047-y", "10.1371/journal.pone.0200818", "10.1016/j.jvlc.2018.08.006", "10.1051/matecconf/201820703008", "10.1016/j.neucom.2018.09.027", "10.1007/s12650-018-0531-1", "10.1016/j.apenergy.2018.12.059", "10.3390/sym11010107", "10.1038/s41590-018-0294-9", "10.1002/cyto.a.23738", "10.3390/informatics6010014", "10.1101/496869", "10.1016/j.jpdc.2019.04.008", "10.1007/s10462-018-09680-6", "10.1093/bioinformatics/btz180", "10.1101/451690", "10.1101/453449", "10.1111/cgf.13672", "10.1101/169888", "10.1101/331611", "10.1101/316034"], "referencing": ["10.1109/TVCG.2014.2346574", "10.1109/TVCG.2014.2346578", "10.1109/VAST.2014.7042510", "10.1109/MC.2013.120", "10.1109/INFVIS.2004.60", "10.1109/TVCG.2011.220", "10.1109/TVCG.2010.207", "10.1109/TVCG.2007.70443", "10.1109/TPAMI.2014.2321376", "10.1109/TVCG.2014.2346452", "10.1109/TVCG.2014.2346574", "10.1109/TVCG.2014.2346578", "10.1109/VAST.2014.7042510", "10.1109/MC.2013.120", "10.1109/INFVIS.2004.60", "10.1109/TVCG.2011.220", "10.1109/TVCG.2010.207", "10.1109/TVCG.2007.70443", "10.1109/TPAMI.2014.2321376", "10.1109/TVCG.2014.2346452", "10.1109/TVCG.2014.2346574", "10.1109/TVCG.2014.2346578", "10.1109/VAST.2014.7042510", "10.1109/MC.2013.120", "10.1109/INFVIS.2004.60", "10.1109/TVCG.2011.220", "10.1109/TVCG.2010.207", "10.1109/TVCG.2007.70443", "10.1109/TPAMI.2014.2321376", "10.1109/TVCG.2014.2346452", "10.1145/355744.355745", "10.1145/2413097.2413148", "10.1145/355744.355745", "10.1145/2413097.2413148", "10.1145/355744.355745", "10.1145/2413097.2413148", "10.1007/978-1-4684-5883-1_9", "10.1080/00949657508810123", "10.1038/nbt.2594", "10.1038/ni.3006", "10.1016/j.ymeth.2014.10.004", "10.1073/pnas.1321405111", "10.1016/j.neucom.2014.09.062", "10.1038/nature14236", "10.1016/S0167-739X(98)00047-8", "10.1016/j.neucom.2014.07.073", "10.1017/CBO9780511535246", "10.1038/324446a0", "10.1002/spe.4380211102", "10.1007/978-1-4899-3324-9", "10.1016/j.cag.2014.01.006", "10.1038/nature05453", "10.1111/cgf.12878", "10.1007/978-1-4684-5883-1_9", "10.1080/00949657508810123", "10.1038/nbt.2594", "10.1038/ni.3006", "10.1016/j.ymeth.2014.10.004", "10.1073/pnas.1321405111", "10.1016/j.neucom.2014.09.062", "10.1038/nature14236", "10.1016/S0167-739X(98)00047-8", "10.1016/j.neucom.2014.07.073", "10.1017/CBO9780511535246", "10.1038/324446a0", "10.1002/spe.4380211102", "10.1007/978-1-4899-3324-9", "10.1016/j.cag.2014.01.006", "10.1038/nature05453", "10.1111/cgf.12878", "10.1007/978-1-4684-5883-1_9", "10.1080/00949657508810123", "10.1038/nbt.2594", "10.1038/ni.3006", "10.1016/j.ymeth.2014.10.004", "10.1073/pnas.1321405111", "10.1016/j.neucom.2014.09.062", "10.1038/nature14236", "10.1016/S0167-739X(98)00047-8", "10.1016/j.neucom.2014.07.073", "10.1017/CBO9780511535246", "10.1038/324446a0", "10.1002/spe.4380211102", "10.1007/978-1-4899-3324-9", "10.1016/j.cag.2014.01.006", "10.1038/nature05453", "10.1111/cgf.12878"]}, "10.1109/TVCG.2016.2554114": {"doi": "10.1109/TVCG.2016.2554114", "author": ["T. R. Kol", "O. Klehm", "H. Seidel", "E. Eisemann"], "title": "Expressive Single Scattering for Light Shaft Stylization", "year": "2017", "abstract": "Light scattering in participating media is a natural phenomenon that is increasingly featured in movies and games, as it is visually pleasing and lends realism to a scene. In art, it may further be used to express a certain mood or emphasize objects. Here, artists often rely on stylization when creating scattering effects, not only because of the complexity of physically correct scattering, but also to increase expressiveness. Little research, however, focuses on artistically influencing the simulation of the scattering process in a virtual 3D scene. We propose novel stylization techniques, enabling artists to change the appearance of single scattering effects such as light shafts. Users can add, remove, or enhance light shafts using occluder manipulation. The colors of the light shafts can be stylized and animated using easily modifiable transfer functions. Alternatively, our system can optimize a light map given a simple user input for a number of desired views in the 3D world. Finally, we enable artists to control the heterogeneity of the underlying medium. Our stylized scattering solution is easy to use and compatible with standard rendering pipelines. It works for animated scenes and can be executed in real time to provide the artist with quick feedback.", "keywords": ["rendering (computer graphics)", "expressive single scattering", "light shaft stylization", "light scattering", "scattering effects", "virtual 3D scene", "stylization techniques", "occluder manipulation", "easily modifiable transfer functions", "light map", "rendering pipelines", "Scattering", "Shafts", "Image color analysis", "Media", "Art", "Transfer functions", "Real-time systems", "Interactive stylization", "artist control", "single scattering"], "referenced_by": ["10.1007/s11042-018-6296-7"], "referencing": ["10.1109/TVCG.2014.2346333", "10.1109/TVCG.2014.13", "10.1109/TVCG.2014.2346333", "10.1109/TVCG.2014.13", "10.1109/TVCG.2014.2346333", "10.1109/TVCG.2014.13", "10.1145/1944745.1944752", "10.1145/2556700.2556704", "10.1145/2010324.1964924", "10.1145/2448196.2448222", "10.1145/1073204.1073214", "10.1145/1276377.1276409", "10.1145/1531326.1531337", "10.1145/1274871.1274884", "10.1145/2492684", "10.1145/1409060.1409073", "10.1145/1778765.1778794", "10.1145/1618452.1618480", "10.1145/2451236.2451237", "10.1145/2018323.2018329", "10.1145/2461912.2461980", "10.1145/166117.166135", "10.1145/1882261.1866200", "10.1145/325165.325247", "10.1145/1360612.1360691", "10.1145/1809939.1809944", "10.1145/97880.97901", "10.1145/1944745.1944752", "10.1145/2556700.2556704", "10.1145/2010324.1964924", "10.1145/2448196.2448222", "10.1145/1073204.1073214", "10.1145/1276377.1276409", "10.1145/1531326.1531337", "10.1145/1274871.1274884", "10.1145/2492684", "10.1145/1409060.1409073", "10.1145/1778765.1778794", "10.1145/1618452.1618480", "10.1145/2451236.2451237", "10.1145/2018323.2018329", "10.1145/2461912.2461980", "10.1145/166117.166135", "10.1145/1882261.1866200", "10.1145/325165.325247", "10.1145/1360612.1360691", "10.1145/1809939.1809944", "10.1145/97880.97901", "10.1145/1944745.1944752", "10.1145/2556700.2556704", "10.1145/2010324.1964924", "10.1145/2448196.2448222", "10.1145/1073204.1073214", "10.1145/1276377.1276409", "10.1145/1531326.1531337", "10.1145/1274871.1274884", "10.1145/2492684", "10.1145/1409060.1409073", "10.1145/1778765.1778794", "10.1145/1618452.1618480", "10.1145/2451236.2451237", "10.1145/2018323.2018329", "10.1145/2461912.2461980", "10.1145/166117.166135", "10.1145/1882261.1866200", "10.1145/325165.325247", "10.1145/1360612.1360691", "10.1145/1809939.1809944", "10.1145/97880.97901", "10.1111/j.1467-8659.2008.01260.x", "10.1111/j.1467-8659.2010.01742.x", "10.1111/cgf.12037", "10.1111/cgf.12721", "10.1111/j.1467-8659.2009.01372.x", "10.1111/j.1467-8659.2008.01256.x", "10.1111/j.1467-8659.2008.01260.x", "10.1111/j.1467-8659.2010.01742.x", "10.1111/cgf.12037", "10.1111/cgf.12721", "10.1111/j.1467-8659.2009.01372.x", "10.1111/j.1467-8659.2008.01256.x", "10.1111/j.1467-8659.2008.01260.x", "10.1111/j.1467-8659.2010.01742.x", "10.1111/cgf.12037", "10.1111/cgf.12721", "10.1111/j.1467-8659.2009.01372.x", "10.1111/j.1467-8659.2008.01256.x"]}, "10.1109/TVCG.2016.2569080": {"doi": "10.1109/TVCG.2016.2569080", "author": ["M. Ament", "T. Zirr", "C. Dachsbacher"], "title": "Extinction-Optimized Volume Illumination", "year": "2017", "abstract": "We present a novel method to optimize the attenuation of light for the single scattering model in direct volume rendering. A common problem of single scattering is the high dynamic range between lit and shadowed regions due to the exponential attenuation of light along a ray. Moreover, light is often attenuated too strong between a sample point and the camera, hampering the visibility of important features. Our algorithm employs an importance function to selectively illuminate important structures and make them visible from the camera. With the importance function, more light can be transmitted to the features of interest, while contextual structures cast shadows which provide visual cues for perception of depth. At the same time, more scattered light is transmitted from the sample point to the camera to improve the primary visibility of important features. We formulate a minimization problem that automatically determines the extinction along a view or shadow ray to obtain a good balance between sufficient transmittance and attenuation. In contrast to previous approaches, we do not require a computationally expensive solution of a global optimization, but instead provide a closed-form solution for each sampled extinction value along a view or shadow ray and thus achieve interactive performance.", "keywords": ["lighting", "rendering (computer graphics)", "extinction-optimized volume illumination", "light attenuation", "single scattering model", "direct volume rendering", "importance function", "visual cue", "minimization problem", "shadow ray", "closed-form solution", "extinction value", "Lighting", "Scattering", "Cost function", "Rendering (computer graphics)", "Light sources", "Visualization", "Direct volume rendering", "volume illumination", "extinction optimization"], "referenced_by": ["10.1109/MCG.2019.2959568", "10.1109/TVCG.2019.2915222"], "referencing": ["10.1109/38.135913", "10.1109/TVCG.2011.161", "10.1109/2945.468400", "10.1109/TVCG.2005.9", "10.1109/TVCG.2013.129", "10.1109/PACIFICVIS.2010.5429594", "10.1109/TVCG.2011.198", "10.1109/TVCG.2010.145", "10.1109/TVCG.2009.172", "10.1109/TVCG.2010.35", "10.1109/TVCG.2006.124", "10.1109/TVCG.2010.30", "10.1109/TVCG.2005.62", "10.1109/TVCG.2009.45", "10.1109/TVCG.2011.35", "10.1109/TVCG.2011.211", "10.1109/TVCG.2014.2346333", "10.1109/VISUAL.2004.64", "10.1109/TVCG.2012.267", "10.1109/TVCG.2013.172", "10.1109/TVCG.2013.257", "10.1109/ICARCV.2014.7064413", "10.1109/TVCG.2012.232", "10.1109/SVV.1998.729588", "10.1109/TVCG.2007.1051", "10.1109/TVCG.2011.173", "10.1109/TVCG.2010.147", "10.1109/TVCG.2014.2346432", "10.1109/TVCG.2006.72", "10.1109/TVCG.2012.143", "10.1109/38.135913", "10.1109/TVCG.2011.161", "10.1109/2945.468400", "10.1109/TVCG.2005.9", "10.1109/TVCG.2013.129", "10.1109/PACIFICVIS.2010.5429594", "10.1109/TVCG.2011.198", "10.1109/TVCG.2010.145", "10.1109/TVCG.2009.172", "10.1109/TVCG.2010.35", "10.1109/TVCG.2006.124", "10.1109/TVCG.2010.30", "10.1109/TVCG.2005.62", "10.1109/TVCG.2009.45", "10.1109/TVCG.2011.35", "10.1109/TVCG.2011.211", "10.1109/TVCG.2014.2346333", "10.1109/VISUAL.2004.64", "10.1109/TVCG.2012.267", "10.1109/TVCG.2013.172", "10.1109/TVCG.2013.257", "10.1109/ICARCV.2014.7064413", "10.1109/TVCG.2012.232", "10.1109/SVV.1998.729588", "10.1109/TVCG.2007.1051", "10.1109/TVCG.2011.173", "10.1109/TVCG.2010.147", "10.1109/TVCG.2014.2346432", "10.1109/TVCG.2006.72", "10.1109/TVCG.2012.143", "10.1109/38.135913", "10.1109/TVCG.2011.161", "10.1109/2945.468400", "10.1109/TVCG.2005.9", "10.1109/TVCG.2013.129", "10.1109/PACIFICVIS.2010.5429594", "10.1109/TVCG.2011.198", "10.1109/TVCG.2010.145", "10.1109/TVCG.2009.172", "10.1109/TVCG.2010.35", "10.1109/TVCG.2006.124", "10.1109/TVCG.2010.30", "10.1109/TVCG.2005.62", "10.1109/TVCG.2009.45", "10.1109/TVCG.2011.35", "10.1109/TVCG.2011.211", "10.1109/TVCG.2014.2346333", "10.1109/VISUAL.2004.64", "10.1109/TVCG.2012.267", "10.1109/TVCG.2013.172", "10.1109/TVCG.2013.257", "10.1109/ICARCV.2014.7064413", "10.1109/TVCG.2012.232", "10.1109/SVV.1998.729588", "10.1109/TVCG.2007.1051", "10.1109/TVCG.2011.173", "10.1109/TVCG.2010.147", "10.1109/TVCG.2014.2346432", "10.1109/TVCG.2006.72", "10.1109/TVCG.2012.143", "10.1145/329693.329695", "10.1145/360825.360839", "10.1145/566654.566573", "10.1145/2448196.2448205", "10.1145/964965.808600", "10.1145/1283900.1283908", "10.1145/1198555.1198783", "10.1145/329693.329695", "10.1145/360825.360839", "10.1145/566654.566573", "10.1145/2448196.2448205", "10.1145/964965.808600", "10.1145/1283900.1283908", "10.1145/1198555.1198783", "10.1145/329693.329695", "10.1145/360825.360839", "10.1145/566654.566573", "10.1145/2448196.2448205", "10.1145/964965.808600", "10.1145/1283900.1283908", "10.1145/1198555.1198783", "10.1068/p3060", "10.1007/s00371-005-0287-1", "10.1371/journal.pone.0038586", "10.1111/cgf.12336", "10.1111/cgf.12357", "10.1016/j.cag.2010.03.005", "10.1086/144246", "10.1111/j.1467-8659.2006.00979.x", "10.1111/cgf.12625", "10.1111/j.1467-8659.2005.00880.x", "10.1117/12.872449", "10.1090/qam/10666", "10.6028/jres.049.044", "10.1068/p3060", "10.1007/s00371-005-0287-1", "10.1371/journal.pone.0038586", "10.1111/cgf.12336", "10.1111/cgf.12357", "10.1016/j.cag.2010.03.005", "10.1086/144246", "10.1111/j.1467-8659.2006.00979.x", "10.1111/cgf.12625", "10.1111/j.1467-8659.2005.00880.x", "10.1117/12.872449", "10.1090/qam/10666", "10.6028/jres.049.044", "10.1068/p3060", "10.1007/s00371-005-0287-1", "10.1371/journal.pone.0038586", "10.1111/cgf.12336", "10.1111/cgf.12357", "10.1016/j.cag.2010.03.005", "10.1086/144246", "10.1111/j.1467-8659.2006.00979.x", "10.1111/cgf.12625", "10.1111/j.1467-8659.2005.00880.x", "10.1117/12.872449", "10.1090/qam/10666", "10.6028/jres.049.044"]}, "10.1109/TVCG.2016.2570215": {"doi": "10.1109/TVCG.2016.2570215", "author": ["P. Klacansky", "J. Tierny", "H. Carr", "Z. Geng"], "title": "Fast and Exact Fiber Surfaces for Tetrahedral Meshes", "year": "2017", "abstract": "Isosurfaces are fundamental geometrical objects for the analysis and visualization of volumetric scalar fields. Recent work has generalized them to bivariate volumetric fields with fiber surfaces, the pre-image of polygons in range space. However, the existing algorithm for their computation is approximate, and is limited to closed polygons. Moreover, its runtime performance does not allow instantaneous updates of the fiber surfaces upon user edits of the polygons. Overall, these limitations prevent a reliable and interactive exploration of the space of fiber surfaces. This paper introduces the first algorithm for the exact computation of fiber surfaces in tetrahedral meshes. It assumes no restriction on the topology of the input polygon, handles degenerate cases and better captures sharp features induced by polygon bends. The algorithm also allows visualization of individual fibers on the output surface, better illustrating their relationship with data features in range space. To enable truly interactive exploration sessions, we further improve the runtime performance of this algorithm. In particular, we show that it is trivially parallelizable and that it scales nearly linearly with the number of cores. Further, we study acceleration data-structures both in geometrical domain and range space and we show how to generalize interval trees used in isosurface extraction to fiber surface extraction. Experiments demonstrate the superiority of our algorithm over previous work, both in terms of accuracy and running time, with up to two orders of magnitude speedups. This improvement enables interactive edits of range polygons with instantaneous updates of the fiber surface for exploration purpose. A VTK-based reference implementation is provided as additional material to reproduce our results.", "keywords": ["data visualisation", "mesh generation", "trees (mathematics)", "exact fiber surfaces", "tetrahedral meshes", "isosurfaces", "fundamental geometrical objects", "volumetric scalar field analysis", "volumetric scalar field visualization", "bivariate volumetric fields", "polygon preimage", "range space", "closed polygons", "input polygon topology", "polygon bends", "individual fiber visualization", "data features", "interactive exploration sessions", "acceleration data-structures", "geometrical domain", "interval trees", "isosurface extraction", "fiber surface extraction", "fiber surface instantaneous updates", "VTK-based reference implementation", "Isosurfaces", "Acceleration", "Topology", "Feature extraction", "Chemicals", "Robustness", "Bivariate data", "data segmentation", "data analysis", "isosurfaces", "continuous scatterplot"], "referenced_by": ["10.1109/TVCG.2016.2599017", "10.1109/TVCG.2016.2599040", "10.1109/TVCG.2016.2640960", "10.1109/TVCG.2018.2864846", "10.1109/PacificVis.2019.00030", "10.1109/TVCG.2018.2867488", "10.1007/978-3-030-43036-8_12"], "referencing": ["10.1109/TVCG.2009.194", "10.1109/TVCG.2011.109", "10.1109/2945.597798", "10.1109/TVCG.2003.1207437", "10.1109/TVCG.2013.269", "10.1109/VISUAL.1996.568103", "10.1109/TVCG.2006.39", "10.1109/TVCG.2008.119", "10.1109/TVCG.2010.146", "10.1109/TVCG.2012.110", "10.1109/2945.597794", "10.1109/TVCG.2006.22", "10.1109/TVCG.2004.1260765", "10.1109/TVCG.2009.194", "10.1109/TVCG.2011.109", "10.1109/2945.597798", "10.1109/TVCG.2003.1207437", "10.1109/TVCG.2013.269", "10.1109/VISUAL.1996.568103", "10.1109/TVCG.2006.39", "10.1109/TVCG.2008.119", "10.1109/TVCG.2010.146", "10.1109/TVCG.2012.110", "10.1109/2945.597794", "10.1109/TVCG.2006.22", "10.1109/TVCG.2004.1260765", "10.1109/TVCG.2009.194", "10.1109/TVCG.2011.109", "10.1109/2945.597798", "10.1109/TVCG.2003.1207437", "10.1109/TVCG.2013.269", "10.1109/VISUAL.1996.568103", "10.1109/TVCG.2006.39", "10.1109/TVCG.2008.119", "10.1109/TVCG.2010.146", "10.1109/TVCG.2012.110", "10.1109/2945.597794", "10.1109/TVCG.2006.22", "10.1109/TVCG.2004.1260765", "10.1145/37402.37422", "10.1145/130881.130882", "10.1145/262839.269238", "10.1145/99308.99322", "10.1145/15922.15916", "10.1145/37402.37422", "10.1145/130881.130882", "10.1145/262839.269238", "10.1145/99308.99322", "10.1145/15922.15916", "10.1145/37402.37422", "10.1145/130881.130882", "10.1145/262839.269238", "10.1145/99308.99322", "10.1145/15922.15916", "10.1021/ja100936w", "10.1111/cgf.12636", "10.1016/j.cag.2006.07.021", "10.1016/0167-8396(88)90013-1", "10.1016/0146-664X(82)90104-6", "10.1007/BF01900346", "10.1007/b100393", "10.1007/BF01900699", "10.1016/S0097-8493(00)00036-4", "10.1007/978-3-662-03567-2_1", "10.1080/2151237X.2007.10129237", "10.1111/j.1467-8659.2008.01261.x", "10.1021/ja100936w", "10.1111/cgf.12636", "10.1016/j.cag.2006.07.021", "10.1016/0167-8396(88)90013-1", "10.1016/0146-664X(82)90104-6", "10.1007/BF01900346", "10.1007/b100393", "10.1007/BF01900699", "10.1016/S0097-8493(00)00036-4", "10.1007/978-3-662-03567-2_1", "10.1080/2151237X.2007.10129237", "10.1111/j.1467-8659.2008.01261.x", "10.1021/ja100936w", "10.1111/cgf.12636", "10.1016/j.cag.2006.07.021", "10.1016/0167-8396(88)90013-1", "10.1016/0146-664X(82)90104-6", "10.1007/BF01900346", "10.1007/b100393", "10.1007/BF01900699", "10.1016/S0097-8493(00)00036-4", "10.1007/978-3-662-03567-2_1", "10.1080/2151237X.2007.10129237", "10.1111/j.1467-8659.2008.01261.x"]}, "10.1109/TVCG.2016.2574705": {"doi": "10.1109/TVCG.2016.2574705", "author": ["C. Yeh", "S. Huang", "P. K. Jayaraman", "C. Fu", "T. Lee"], "title": "Interactive High-Relief Reconstruction for Organic and Double-Sided Objects from a Photo", "year": "2017", "abstract": "We introduce an interactive user-driven method to reconstruct high-relief 3D geometry from a single photo. Particularly, we consider two novel but challenging reconstruction issues: i) common non-rigid objects whose shapes are organic rather than polyhedral/symmetric, and ii) double-sided structures, where front and back sides of some curvy object parts are revealed simultaneously on image. To address these issues, we develop a three-stage computational pipeline. First, we construct a 2.5D model from the input image by user-driven segmentation, automatic layering, and region completion, handling three common types of occlusion. Second, users can interactively mark-up slope and curvature cues on the image to guide our constrained optimization model to inflate and lift up the image layers. We provide real-time preview of the inflated geometry to allow interactive editing. Third, we stitch and optimize the inflated layers to produce a high-relief 3D model. Compared to previous work, we can generate high-relief geometry with large viewing angles, handle complex organic objects with multiple occluded regions and varying shape profiles, and reconstruct objects with double-sided structures. Lastly, we demonstrate the applicability of our method on a wide variety of input images with human, animals, flowers, etc.", "keywords": ["image reconstruction", "image segmentation", "solid modelling", "interactive high-relief reconstruction", "organic objects", "double-sided objects", "photo", "interactive user-driven method", "high-relief 3D geometry reconstruction", "common non-rigid objects", "double-sided structures", "three-stage computational pipeline", "user-driven segmentation", "automatic layering", "region completion", "high-relief 3D model", "viewing angles", "Three-dimensional displays", "Image reconstruction", "Geometry", "Shape", "Solid modeling", "Image segmentation", "Surface reconstruction", "Reconstruction", "high-relief", "lenticular posters", "single image", "folded", "double-sided", "object modeling", "depth cues", "completion", "inflation"], "referenced_by": ["10.1109/TVCG.2018.2818146", "10.1109/TVCG.2018.2860004", "10.1145/3005274.3005280", "10.1145/3197517.3201326", "10.1145/3414685.3417805", "10.1016/j.cag.2018.09.009", "10.1016/j.cag.2019.04.006", "10.1111/cgf.13655", "10.1111/cgf.13754", "10.1016/j.cagd.2020.101860", "10.1111/cgf.14016", "10.1016/j.cad.2020.102904"], "referencing": ["10.1109/TPAMI.2008.132", "10.1109/MCG.2007.8", "10.1109/CVPR.2006.281", "10.1109/TVCG.2011.111", "10.1109/TPAMI.2004.60", "10.1109/TIP.2004.833105", "10.1109/TPAMI.2008.132", "10.1109/MCG.2007.8", "10.1109/CVPR.2006.281", "10.1109/TVCG.2011.111", "10.1109/TPAMI.2004.60", "10.1109/TIP.2004.833105", "10.1109/TPAMI.2008.132", "10.1109/MCG.2007.8", "10.1109/CVPR.2006.281", "10.1109/TVCG.2011.111", "10.1109/TPAMI.2004.60", "10.1109/TIP.2004.833105", "10.1145/1073204.1073232", "10.1145/1276377.1276429", "10.1145/2601097.2601209", "10.1145/311535.311602", "10.1145/1141911.1141928", "10.1145/383259.383310", "10.1145/1276377.1276432", "10.1145/258734.258854", "10.1145/1778765.1778796", "10.1145/2508363.2508396", "10.1145/2542355.2542365", "10.1145/311535.311576", "10.1145/1073204.1073232", "10.1145/1276377.1276429", "10.1145/2601097.2601209", "10.1145/311535.311602", "10.1145/1141911.1141928", "10.1145/383259.383310", "10.1145/1276377.1276432", "10.1145/258734.258854", "10.1145/1778765.1778796", "10.1145/2508363.2508396", "10.1145/2542355.2542365", "10.1145/311535.311576", "10.1145/1073204.1073232", "10.1145/1276377.1276429", "10.1145/2601097.2601209", "10.1145/311535.311602", "10.1145/1141911.1141928", "10.1145/383259.383310", "10.1145/1276377.1276432", "10.1145/258734.258854", "10.1145/1778765.1778796", "10.1145/2508363.2508396", "10.1145/2542355.2542365", "10.1145/311535.311576", "10.1080/10867651.1997.10487476", "10.1111/cgf.12536", "10.1111/cgf.12332", "10.1007/s11263-006-0031-y", "10.1016/j.cviu.2007.09.003", "10.1111/j.1467-8659.2006.00981.x", "10.1002/vis.291", "10.1016/S0167-8396(01)00036-X", "10.1080/10867651.1997.10487476", "10.1111/cgf.12536", "10.1111/cgf.12332", "10.1007/s11263-006-0031-y", "10.1016/j.cviu.2007.09.003", "10.1111/j.1467-8659.2006.00981.x", "10.1002/vis.291", "10.1016/S0167-8396(01)00036-X", "10.1080/10867651.1997.10487476", "10.1111/cgf.12536", "10.1111/cgf.12332", "10.1007/s11263-006-0031-y", "10.1016/j.cviu.2007.09.003", "10.1111/j.1467-8659.2006.00981.x", "10.1002/vis.291", "10.1016/S0167-8396(01)00036-X"]}, "10.1109/TVCG.2016.2553102": {"doi": "10.1109/TVCG.2016.2553102", "author": ["D. Li", "T. Shao", "H. Wu", "K. Zhou"], "title": "Shape Completion from a Single RGBD Image", "year": "2017", "abstract": "We present a novel approach for constructing a complete 3D model for an object from a single RGBD image. Given an image of an object segmented from the background, a collection of 3D models of the same category are non-rigidly aligned with the input depth, to compute a rough initial result. A volumetric-patch-based optimization algorithm is then performed to refine the initial result to generate a 3D model that not only is globally consistent with the overall shape expected from the input image but also possesses geometric details similar to those in the input image. The optimization with a set of high-level constraints, such as visibility, surface confidence and symmetry, can achieve more robust and accurate completion over state-of-the art techniques. We demonstrate the efficiency and robustness of our approach with multiple categories of objects with various geometries and details, including busts, chairs, bikes, toys, vases and tables.", "keywords": ["computational geometry", "image colour analysis", "image segmentation", "solid modelling", "shape completion", "single RGBD image", "complete 3D model", "segmented object", "volumetric-patch-based optimization algorithm", "geometric details", "high-level constraints", "optimization", "Shape", "Three-dimensional displays", "Solid modeling", "Geometry", "Optimization", "Computational modeling", "Deformable models", "RGBD camera", "shape completion", "single RGBD image"], "referenced_by": ["10.1109/3DV.2018.00088", "10.1109/WACV.2019.00122", "10.1109/CVPR.2019.00047", "10.1109/ACCESS.2020.2973003", "10.1109/TVCG.2018.2889944", "10.1145/3272127.3275039", "10.1007/s00371-018-1586-7", "10.3390/s20072025", "10.1016/j.cagd.2020.101925", "10.1007/978-3-030-58545-7_21"], "referencing": ["10.1109/TVCG.2012.56", "10.1109/TIP.2012.2221728", "10.1109/TPAMI.2007.60", "10.1109/TVCG.2012.56", "10.1109/TIP.2012.2221728", "10.1109/TPAMI.2007.60", "10.1109/TVCG.2012.56", "10.1109/TIP.2012.2221728", "10.1109/TPAMI.2007.60", "10.1145/2047196.2047270", "10.1145/2532548", "10.1145/1095878.1095883", "10.1145/1882262.1866176", "10.1145/383259.383296", "10.1145/1531326.1531330", "10.1145/1778765.1778831", "10.1145/311535.311556", "10.1145/1073204.1073207", "10.1145/2366145.2366155", "10.1145/2601097.2601134", "10.1145/2185520.2185578", "10.1145/2601097.2601159", "10.1145/1276377.1276478", "10.1145/237170.237269", "10.1145/37401.37422", "10.1145/2047196.2047270", "10.1145/2532548", "10.1145/1095878.1095883", "10.1145/1882262.1866176", "10.1145/383259.383296", "10.1145/1531326.1531330", "10.1145/1778765.1778831", "10.1145/311535.311556", "10.1145/1073204.1073207", "10.1145/2366145.2366155", "10.1145/2601097.2601134", "10.1145/2185520.2185578", "10.1145/2601097.2601159", "10.1145/1276377.1276478", "10.1145/237170.237269", "10.1145/37401.37422", "10.1145/2047196.2047270", "10.1145/2532548", "10.1145/1095878.1095883", "10.1145/1882262.1866176", "10.1145/383259.383296", "10.1145/1531326.1531330", "10.1145/1778765.1778831", "10.1145/311535.311556", "10.1145/1073204.1073207", "10.1145/2366145.2366155", "10.1145/2601097.2601134", "10.1145/2185520.2185578", "10.1145/2601097.2601159", "10.1145/1276377.1276478", "10.1145/237170.237269", "10.1145/37401.37422", "10.1007/s11390-009-9206-7", "10.1111/cgf.12307", "10.1111/j.1467-8659.2007.01016.x", "10.1007/s11390-009-9206-7", "10.1111/cgf.12307", "10.1111/j.1467-8659.2007.01016.x", "10.1007/s11390-009-9206-7", "10.1111/cgf.12307", "10.1111/j.1467-8659.2007.01016.x"]}, "10.1109/TVCG.2016.2545670": {"doi": "10.1109/TVCG.2016.2545670", "author": ["S. A. St\u00fcvel", "N. Magnenat-Thalmann", "D. Thalmann", "A. F. v. d. Stappen", "A. Egges"], "title": "Torso Crowds", "year": "2017", "abstract": "We present a novel dense crowd simulation method. In real crowds of high density, people manoeuvring the crowd need to twist their torso to pass between others. Our proposed method does not use the traditional disc-shaped agent, but instead employs capsule-shaped agents, which enables us to plan such torso orientations. Contrary to other crowd simulation systems, which often focus on the movement of the entire crowd, our method distinguishes between active agents that try to manoeuvre through the crowd, and passive agents that have no incentive to move. We introduce the concept of a focus point to influence crowd agent orientation. Recorded data from real human crowds are used for validation, which shows that our proposed model produces equivalent paths for 85 percent of the validation set. Furthermore, we present a character animation technique that uses the results from our crowd model to generate torso-twisting and side-stepping characters.", "keywords": ["computer animation", "multi-agent systems", "torso crowds", "dense crowd simulation method", "disc-shaped agent", "capsule-shaped agents", "torso orientation", "focus point concept", "torso-twisting characters", "side-stepping characters", "character animation technique", "Torso", "Computational modeling", "Planning", "Animation", "Shape", "Data models", "Legged locomotion", "Crowd simulation", "crowd animation", "dense crowds", "agent representation", "holonomic motion", "Computer Graphics", "Computer Simulation", "Crowding", "Humans", "Image Processing, Computer-Assisted", "Movement", "Torso"], "referenced_by": ["10.1145/3072959.3073705", "10.1145/3272127.3275079", "10.1111/cgf.13333", "10.1002/cav.1875", "10.1016/j.cag.2020.04.003", "10.1016/j.gmod.2020.101081"], "referencing": ["10.1109/TVCG.2013.80", "10.1109/ICRA.2014.6907324", "10.1109/TVCG.2008.27", "10.1109/TVCG.2013.80", "10.1109/ICRA.2014.6907324", "10.1109/TVCG.2008.27", "10.1109/TVCG.2013.80", "10.1109/ICRA.2014.6907324", "10.1109/TVCG.2008.27", "10.1145/1028523.1028553", "10.1145/2485895.2485910", "10.1145/2485895.2485909", "10.1145/2822013.2822037", "10.1145/1111411.1111432", "10.1145/2822013.2822020", "10.1145/1360612.1360679", "10.1145/1531326.1531385", "10.1145/2601097.2601170", "10.1145/1028523.1028553", "10.1145/2485895.2485910", "10.1145/2485895.2485909", "10.1145/2822013.2822037", "10.1145/1111411.1111432", "10.1145/2822013.2822020", "10.1145/1360612.1360679", "10.1145/1531326.1531385", "10.1145/2601097.2601170", "10.1145/1028523.1028553", "10.1145/2485895.2485910", "10.1145/2485895.2485909", "10.1145/2822013.2822037", "10.1145/1111411.1111432", "10.1145/2822013.2822020", "10.1145/1360612.1360679", "10.1145/1531326.1531385", "10.1145/2601097.2601170", "10.1007/978-1-4471-4450-2", "10.1038/229381a0", "10.1016/j.ssci.2010.09.006", "10.1111/j.1467-8659.2012.03028.x", "10.1002/cav.1592", "10.1002/cav.403", "10.1016/j.cag.2014.12.004", "10.1111/cgf.12316", "10.1016/0379-7112(95)00019-P", "10.1007/978-3-642-87427-7_6", "10.1111/j.1467-8659.2007.01090.x", "10.1007/978-3-642-10347-6_4", "10.1016/j.physa.2011.07.022", "10.1002/cav.277", "10.1016/S0925-7721(01)00003-7", "10.1016/0141-5425(85)90055-X", "10.1111/cgf.12328", "10.1037/h0081114", "10.1007/978-1-4471-4450-2", "10.1038/229381a0", "10.1016/j.ssci.2010.09.006", "10.1111/j.1467-8659.2012.03028.x", "10.1002/cav.1592", "10.1002/cav.403", "10.1016/j.cag.2014.12.004", "10.1111/cgf.12316", "10.1016/0379-7112(95)00019-P", "10.1007/978-3-642-87427-7_6", "10.1111/j.1467-8659.2007.01090.x", "10.1007/978-3-642-10347-6_4", "10.1016/j.physa.2011.07.022", "10.1002/cav.277", "10.1016/S0925-7721(01)00003-7", "10.1016/0141-5425(85)90055-X", "10.1111/cgf.12328", "10.1037/h0081114", "10.1007/978-1-4471-4450-2", "10.1038/229381a0", "10.1016/j.ssci.2010.09.006", "10.1111/j.1467-8659.2012.03028.x", "10.1002/cav.1592", "10.1002/cav.403", "10.1016/j.cag.2014.12.004", "10.1111/cgf.12316", "10.1016/0379-7112(95)00019-P", "10.1007/978-3-642-87427-7_6", "10.1111/j.1467-8659.2007.01090.x", "10.1007/978-3-642-10347-6_4", "10.1016/j.physa.2011.07.022", "10.1002/cav.277", "10.1016/S0925-7721(01)00003-7", "10.1016/0141-5425(85)90055-X", "10.1111/cgf.12328", "10.1037/h0081114"]}, "10.1109/TVCG.2016.2559483": {"doi": "10.1109/TVCG.2016.2559483", "author": ["D. Bari\u010devi\u0107", "T. H\u00f6llerer", "P. Sen", "M. Turk"], "title": "User-Perspective AR Magic Lens from Gradient-Based IBR and Semi-Dense Stereo", "year": "2017", "abstract": "We present a new approach to rendering a geometrically-correct user-perspective view for a magic lens interface, based on leveraging the gradients in the real world scene. Our approach couples a recent gradient-domain image-based rendering method with a novel semi-dense stereo matching algorithm. Our stereo algorithm borrows ideas from PatchMatch, and adapts them to semi-dense stereo. This approach is implemented in a prototype device build from off-the-shelf hardware, with no active depth sensing. Despite the limited depth data, we achieve high-quality rendering for the user-perspective magic lens.", "keywords": ["augmented reality", "image matching", "rendering (computer graphics)", "stereo image processing", "user interfaces", "user-perspective AR magic lens", "gradient-based IBR", "semi-dense stereo", "augmented reality", "geometrically-correct user-perspective view", "magic lens interface", "gradient-domain image-based rendering method", "semi-dense stereo matching algorithm", "PatchMatch", "depth sensing", "Lenses", "Rendering (computer graphics)", "Image reconstruction", "Cameras", "Real-time systems", "Sensors", "Augmented reality", "Augmented reality", "magic lens", "user-perspective", "image based rendering", "gradient domain", "semi-dense stereo"], "referenced_by": ["10.1109/3DUI.2017.7893336", "10.1109/ISMAR-Adjunct.2018.00084", "10.1117/12.2500023", "10.1186/s41074-017-0028-1"], "referencing": ["10.1109/38.963460", "10.1109/ISMAR.2011.6092372", "10.1109/ISMAR.2011.6092395", "10.1109/3DUI.2013.6550226", "10.1109/TCSVT.2010.2077771", "10.1109/TCSVT.2011.2133150", "10.1109/TCSVT.2012.2203200", "10.1109/TPAMI.2012.156", "10.1109/38.963460", "10.1109/ISMAR.2011.6092372", "10.1109/ISMAR.2011.6092395", "10.1109/3DUI.2013.6550226", "10.1109/TCSVT.2010.2077771", "10.1109/TCSVT.2011.2133150", "10.1109/TCSVT.2012.2203200", "10.1109/TPAMI.2012.156", "10.1109/38.963460", "10.1109/ISMAR.2011.6092372", "10.1109/ISMAR.2011.6092395", "10.1109/3DUI.2013.6550226", "10.1109/TCSVT.2010.2077771", "10.1109/TCSVT.2011.2133150", "10.1109/TCSVT.2012.2203200", "10.1109/TPAMI.2012.156", "10.1145/237091.237098", "10.1145/215585.215647", "10.1145/215585.215639", "10.1145/1101616.1101662", "10.1145/237170.237199", "10.1145/280814.280882", "10.1145/237170.237191", "10.1145/237091.237098", "10.1145/215585.215647", "10.1145/215585.215639", "10.1145/1101616.1101662", "10.1145/237170.237199", "10.1145/280814.280882", "10.1145/237170.237191", "10.1145/237091.237098", "10.1145/215585.215647", "10.1145/215585.215639", "10.1145/1101616.1101662", "10.1145/237170.237199", "10.1145/280814.280882", "10.1145/237170.237191", "10.1117/12.386541", "10.1023/A:1014573219977", "10.5244/C.25.14", "10.1016/j.cviu.2013.01.007", "10.1117/12.386541", "10.1023/A:1014573219977", "10.5244/C.25.14", "10.1016/j.cviu.2013.01.007", "10.1117/12.386541", "10.1023/A:1014573219977", "10.5244/C.25.14", "10.1016/j.cviu.2013.01.007"]}, "10.1109/TVCG.2016.2554113": {"doi": "10.1109/TVCG.2016.2554113", "author": ["Y. Matsui", "T. Shiratori", "K. Aizawa"], "title": "DrawFromDrawings: 2D Drawing Assistance via Stroke Interpolation with a Sketch Database", "year": "2017", "abstract": "We present DrawFromDrawings, an interactive drawing system that provides users with visual feedback for assistance in 2D drawing using a database of sketch images. Following the traditional imitation and emulation training from art education, DrawFromDrawings enables users to retrieve and refer to a sketch image stored in a database and provides them with various novel strokes as suggestive or deformation feedback. Given regions of interest (ROIs) in the user and reference sketches, DrawFromDrawings detects as-long-as-possible (ALAP) stroke segments and the correspondences between user and reference sketches that are the key to computing seamless interpolations. The stroke-level interpolations are parametrized with the user strokes, the reference strokes, and new strokes created by warping the reference strokes based on the user and reference ROI shapes, and the user study indicated that the interpolation could produce various reasonable strokes varying in shapes and complexity. DrawFromDrawings allows users to either replace their strokes with interpolated strokes (deformation feedback) or overlays interpolated strokes onto their strokes (suggestive feedback). The other user studies on the feedback modes indicated that the suggestive feedback enabled drawers to develop and render their ideas using their own stroke style, whereas the deformation feedback enabled them to finish the sketch composition quickly.", "keywords": ["computer graphics", "DrawFromDrawings", "2D drawing assistance", "stroke interpolation", "sketch database", "interactive drawing system", "sketch image database", "regions of interest", "ALAP stroke segments", "as-long-as-possible stroke segments", "stroke-level interpolation", "deformation feedback", "suggestive feedback", "sketch composition", "Interpolation", "Shape", "Feature extraction", "Animation", "Visual databases", "Visualization", "interactive drawing", "2D shape interpolation"], "referenced_by": ["10.1109/KST.2019.8687404", "10.1109/TMM.2019.2892301", "10.1145/3386569.3392386", "10.1007/978-3-319-73062-2_3"], "referencing": ["10.1109/TVCG.2009.38", "10.1109/34.993558", "10.1109/34.24792", "10.1109/TVCG.2010.266", "10.1109/TVCG.2009.38", "10.1109/34.993558", "10.1109/34.24792", "10.1109/TVCG.2010.266", "10.1109/TVCG.2009.38", "10.1109/34.993558", "10.1109/34.24792", "10.1109/TVCG.2010.266", "10.1145/344779.344859", "10.1145/354401.354413", "10.1145/1187112.1187227", "10.1145/2556288.2557327", "10.1145/2010324.1964930", "10.1145/2185520.2185540", "10.1145/358669.358692", "10.1145/2501988.2501997", "10.1145/2185520.2185542", "10.1145/2536798", "10.1145/1141911.1141920", "10.1145/1572614.1572619", "10.1145/985692.985767", "10.1145/2642918.2647399", "10.1145/357994.358023", "10.1145/344779.344859", "10.1145/354401.354413", "10.1145/1187112.1187227", "10.1145/2556288.2557327", "10.1145/2010324.1964930", "10.1145/2185520.2185540", "10.1145/358669.358692", "10.1145/2501988.2501997", "10.1145/2185520.2185542", "10.1145/2536798", "10.1145/1141911.1141920", "10.1145/1572614.1572619", "10.1145/985692.985767", "10.1145/2642918.2647399", "10.1145/357994.358023", "10.1145/344779.344859", "10.1145/354401.354413", "10.1145/1187112.1187227", "10.1145/2556288.2557327", "10.1145/2010324.1964930", "10.1145/2185520.2185540", "10.1145/358669.358692", "10.1145/2501988.2501997", "10.1145/2185520.2185542", "10.1145/2536798", "10.1145/1141911.1141920", "10.1145/1572614.1572619", "10.1145/985692.985767", "10.1145/2642918.2647399", "10.1145/357994.358023", "10.1111/j.1467-8659.2006.00967.x", "10.1007/BF02278710", "10.1111/j.1467-8659.2005.00850.x", "10.1111/j.1467-8659.2011.01969.x", "10.1111/j.1467-8659.2009.01630.x", "10.1111/j.1467-8659.2006.00967.x", "10.1007/BF02278710", "10.1111/j.1467-8659.2005.00850.x", "10.1111/j.1467-8659.2011.01969.x", "10.1111/j.1467-8659.2009.01630.x", "10.1111/j.1467-8659.2006.00967.x", "10.1007/BF02278710", "10.1111/j.1467-8659.2005.00850.x", "10.1111/j.1467-8659.2011.01969.x", "10.1111/j.1467-8659.2009.01630.x"]}, "10.1109/TVCG.2016.2549018": {"doi": "10.1109/TVCG.2016.2549018", "author": ["J. Fuchs", "P. Isenberg", "A. Bezerianos", "D. Keim"], "title": "A Systematic Review of Experimental Studies on Data Glyphs", "year": "2017", "abstract": "We systematically reviewed 64 user-study papers on data glyphs to help researchers and practitioners gain an informed understanding of tradeoffs in the glyph design space. The glyphs we consider are individual representations of multi-dimensional data points, often meant to be shown in small-multiple settings. Over the past 60 years many different glyph designs were proposed and many of these designs have been subjected to perceptual or comparative evaluations. Yet, a systematic overview of the types of glyphs and design variations tested, the tasks under which they were analyzed, or even the study goals and results does not yet exist. In this paper we provide such an overview by systematically sampling and tabulating the literature on data glyph studies, listing their designs, questions, data, and tasks. In addition we present a concise overview of the types of glyphs and their design characteristics analyzed by researchers in the past, and a synthesis of the study results. Based on our meta analysis of all results we further contribute a set of design implications and a discussion on open research directions.", "keywords": ["data handling", "data glyphs", "glyph design space", "multidimensional data points", "perceptual evaluation", "comparative evaluation", "Visualization", "Data visualization", "Systematics", "Layout", "Encoding", "Guidelines", "Survey", "glyphs", "quantitative evaluation", "glyph design"], "referenced_by": ["10.1109/TVCG.2018.2865234", "10.1109/TVCG.2018.2865142", "10.1109/iV.2018.00015", "10.1109/iV.2018.00037", "10.1109/iV.2018.00023", "10.1109/iV.2018.00021", "10.1109/VIZSEC.2018.8709212", "10.1109/PacificVis.2019.00020", "10.1109/IV.2019.00066", "10.1109/TVCG.2019.2934260", "10.1109/VISUAL.2019.8933656", "10.1109/TVCG.2019.2907583", "10.1109/BELIV51497.2020.00013", "10.1007/978-3-319-58640-3_5", "10.1111/cgf.13446", "10.1080/17489725.2019.1630680", "10.3390/info10100302", "10.3390/info11020123", "10.1016/B978-0-12-812875-6.16001-3", "10.1101/2020.06.15.153098"], "referencing": ["10.1109/TVCG.2013.20", "10.1109/TVCG.2006.155", "10.1109/TVCG.2012.199", "10.1109/TVCG.2012.271", "10.1109/VISUAL.1991.175795", "10.1109/38.689658", "10.1109/2.299412", "10.1109/TVCG.2011.189", "10.1109/IV.2005.123", "10.1109/IV.2005.97", "10.1109/TVCG.2013.10", "10.1109/2945.773807", "10.1109/TVCG.2009.63", "10.1109/2945.537309", "10.1109/TVCG.2014.2346426", "10.1109/VISUAL.2005.1532835", "10.1109/TVCG.2011.194", "10.1109/TVCG.2015.2467435", "10.1109/TVCG.2005.53", "10.1109/TVCG.2011.217", "10.1109/TVCG.2013.20", "10.1109/TVCG.2006.155", "10.1109/TVCG.2012.199", "10.1109/TVCG.2012.271", "10.1109/VISUAL.1991.175795", "10.1109/38.689658", "10.1109/2.299412", "10.1109/TVCG.2011.189", "10.1109/IV.2005.123", "10.1109/IV.2005.97", "10.1109/TVCG.2013.10", "10.1109/2945.773807", "10.1109/TVCG.2009.63", "10.1109/2945.537309", "10.1109/TVCG.2014.2346426", "10.1109/VISUAL.2005.1532835", "10.1109/TVCG.2011.194", "10.1109/TVCG.2015.2467435", "10.1109/TVCG.2005.53", "10.1109/TVCG.2011.217", "10.1109/TVCG.2013.20", "10.1109/TVCG.2006.155", "10.1109/TVCG.2012.199", "10.1109/TVCG.2012.271", "10.1109/VISUAL.1991.175795", "10.1109/38.689658", "10.1109/2.299412", "10.1109/TVCG.2011.189", "10.1109/IV.2005.123", "10.1109/IV.2005.97", "10.1109/TVCG.2013.10", "10.1109/2945.773807", "10.1109/TVCG.2009.63", "10.1109/2945.537309", "10.1109/TVCG.2014.2346426", "10.1109/VISUAL.2005.1532835", "10.1109/TVCG.2011.194", "10.1109/TVCG.2015.2467435", "10.1109/TVCG.2005.53", "10.1109/TVCG.2011.217", "10.1145/2470654.2466443", "10.1145/1980462.1980470", "10.1145/1056808.1057048", "10.1145/2801040.2801062", "10.1145/2470654.2466444", "10.1145/1929916.1929918", "10.1145/800049.801781", "10.1145/800049.801778", "10.1145/2556288.2557200", "10.1145/2702613.2732778", "10.1145/2636879.2636880", "10.1145/2110192.2110201", "10.1145/331770.331777", "10.1145/1620993.1621006", "10.1145/365024.365097", "10.1145/2470654.2466443", "10.1145/1980462.1980470", "10.1145/1056808.1057048", "10.1145/2801040.2801062", "10.1145/2470654.2466444", "10.1145/1929916.1929918", "10.1145/800049.801781", "10.1145/800049.801778", "10.1145/2556288.2557200", "10.1145/2702613.2732778", "10.1145/2636879.2636880", "10.1145/2110192.2110201", "10.1145/331770.331777", "10.1145/1620993.1621006", "10.1145/365024.365097", "10.1145/2470654.2466443", "10.1145/1980462.1980470", "10.1145/1056808.1057048", "10.1145/2801040.2801062", "10.1145/2470654.2466444", "10.1145/1929916.1929918", "10.1145/800049.801781", "10.1145/800049.801778", "10.1145/2556288.2557200", "10.1145/2702613.2732778", "10.1145/2636879.2636880", "10.1145/2110192.2110201", "10.1145/331770.331777", "10.1145/1620993.1621006", "10.1145/365024.365097", "10.1073/pnas.43.10.923", "10.2307/2284077", "10.1057/palgrave.ivs.9500025", "10.1007/978-3-540-33037-0_8", "10.1007/978-1-4612-4950-4", "10.1007/978-3-540-78243-8_9", "10.1007/978-1-4471-6497-5_13", "10.1016/j.cag.2011.01.011", "10.3138/carto-v42-1-053", "10.1080/01621459.1981.10477718", "10.1111/cgf.12104", "10.1177/1473871613511959", "10.3138/carto.44.3.217", "10.1111/j.1467-8659.2008.01234.x", "10.1016/j.jvlc.2013.09.002", "10.1177/1541931214581248", "10.1177/154193128703100125", "10.1207/s15327043hup0301_1", "10.1207/s15327051hci0203_1", "10.1080/00140138708969741", "10.1016/B978-0-12-734750-9.50010-1", "10.1111/j.1467-8659.2011.01931.x", "10.1207/s15327906mbr2701_4", "10.1559/152304009788188808", "10.1177/001872087601800207", "10.1177/154193128703100126", "10.1057/palgrave.ivs.9500119", "10.1117/12.872576", "10.2307/2285931", "10.1177/014662168500900305", "10.1016/S0020-7373(86)80022-0", "10.1016/0898-1221(87)90127-1", "10.1016/B978-0-12-734750-9.50014-9", "10.1016/B978-0-12-589320-6.50025-3", "10.1177/001872088202400102", "10.3138/15T3-3222-X25H-35JU", "10.1167/13.9.689", "10.1177/1541931213571358", "10.2307/2490314", "10.2307/2490708", "10.1016/0167-9473(93)90219-J", "10.1080/00140138508963269", "10.1111/j.1467-8659.2009.01711.x", "10.1016/S0097-8493(00)00033-9", "10.2307/2288400", "10.1111/cgf.12365", "10.1073/pnas.43.10.923", "10.2307/2284077", "10.1057/palgrave.ivs.9500025", "10.1007/978-3-540-33037-0_8", "10.1007/978-1-4612-4950-4", "10.1007/978-3-540-78243-8_9", "10.1007/978-1-4471-6497-5_13", "10.1016/j.cag.2011.01.011", "10.3138/carto-v42-1-053", "10.1080/01621459.1981.10477718", "10.1111/cgf.12104", "10.1177/1473871613511959", "10.3138/carto.44.3.217", "10.1111/j.1467-8659.2008.01234.x", "10.1016/j.jvlc.2013.09.002", "10.1177/1541931214581248", "10.1177/154193128703100125", "10.1207/s15327043hup0301_1", "10.1207/s15327051hci0203_1", "10.1080/00140138708969741", "10.1016/B978-0-12-734750-9.50010-1", "10.1111/j.1467-8659.2011.01931.x", "10.1207/s15327906mbr2701_4", "10.1559/152304009788188808", "10.1177/001872087601800207", "10.1177/154193128703100126", "10.1057/palgrave.ivs.9500119", "10.1117/12.872576", "10.2307/2285931", "10.1177/014662168500900305", "10.1016/S0020-7373(86)80022-0", "10.1016/0898-1221(87)90127-1", "10.1016/B978-0-12-734750-9.50014-9", "10.1016/B978-0-12-589320-6.50025-3", "10.1177/001872088202400102", "10.3138/15T3-3222-X25H-35JU", "10.1167/13.9.689", "10.1177/1541931213571358", "10.2307/2490314", "10.2307/2490708", "10.1016/0167-9473(93)90219-J", "10.1080/00140138508963269", "10.1111/j.1467-8659.2009.01711.x", "10.1016/S0097-8493(00)00033-9", "10.2307/2288400", "10.1111/cgf.12365", "10.1073/pnas.43.10.923", "10.2307/2284077", "10.1057/palgrave.ivs.9500025", "10.1007/978-3-540-33037-0_8", "10.1007/978-1-4612-4950-4", "10.1007/978-3-540-78243-8_9", "10.1007/978-1-4471-6497-5_13", "10.1016/j.cag.2011.01.011", "10.3138/carto-v42-1-053", "10.1080/01621459.1981.10477718", "10.1111/cgf.12104", "10.1177/1473871613511959", "10.3138/carto.44.3.217", "10.1111/j.1467-8659.2008.01234.x", "10.1016/j.jvlc.2013.09.002", "10.1177/1541931214581248", "10.1177/154193128703100125", "10.1207/s15327043hup0301_1", "10.1207/s15327051hci0203_1", "10.1080/00140138708969741", "10.1016/B978-0-12-734750-9.50010-1", "10.1111/j.1467-8659.2011.01931.x", "10.1207/s15327906mbr2701_4", "10.1559/152304009788188808", "10.1177/001872087601800207", "10.1177/154193128703100126", "10.1057/palgrave.ivs.9500119", "10.1117/12.872576", "10.2307/2285931", "10.1177/014662168500900305", "10.1016/S0020-7373(86)80022-0", "10.1016/0898-1221(87)90127-1", "10.1016/B978-0-12-734750-9.50014-9", "10.1016/B978-0-12-589320-6.50025-3", "10.1177/001872088202400102", "10.3138/15T3-3222-X25H-35JU", "10.1167/13.9.689", "10.1177/1541931213571358", "10.2307/2490314", "10.2307/2490708", "10.1016/0167-9473(93)90219-J", "10.1080/00140138508963269", "10.1111/j.1467-8659.2009.01711.x", "10.1016/S0097-8493(00)00033-9", "10.2307/2288400", "10.1111/cgf.12365"]}}