{"10.1109/TVCG.2013.243": {"doi": "10.1109/TVCG.2013.243", "author": ["S. Gauglitz", "C. Sweeney", "J. Ventura", "M. Turk", "T. H\u00f6llerer"], "title": "Model Estimation and Selection towardsUnconstrained Real-Time Tracking and Mapping", "year": "2014", "abstract": "We present an approach and prototype implementation to initialization-free real-time tracking and mapping that supports any type of camera motion in 3D environments, that is, parallax-inducing as well as rotation-only motions. Our approach effectively behaves like a keyframe-based Simultaneous Localization and Mapping system or a panorama tracking and mapping system, depending on the camera movement. It seamlessly switches between the two modes and is thus able to track and map through arbitrary sequences of parallax-inducing and rotation-only camera movements. The system integrates both model-based and model-free tracking, automatically choosing between the two depending on the situation, and subsequently uses the \u201cGeometric Robust Information Criterion\u201d to decide whether the current camera motion can best be represented as a parallax-inducing motion or a rotation-only motion. It continues to collect and map data after tracking failure by creating separate tracks which are later merged if they are found to overlap. This is in contrast to most existing tracking and mapping systems, which suspend tracking and mapping and thus discard valuable data until relocalization with respect to the initial map is successful. We tested our prototype implementation on a variety of video sequences, successfully tracking through different camera motions and fully automatically building combinations of panoramas and 3D structure.", "keywords": ["image motion analysis", "image sequences", "object tracking", "real-time systems", "video signal processing", "model estimation", "model selection", "unconstrained real-time tracking and mapping system", "initialization-free real-time tracking and mapping system", "keyframe-based simultaneous localization and mapping system", "panorama tracking and mapping system", "camera movement", "parallax-inducing camera movements", "rotation-only camera movements", "model-based tracking", "model-free tracking", "geometric robust information criterion", "tracking failure", "video sequences", "3D structure", "Cameras", "Tracking", "Computational modeling", "Simultaneous localization and mapping", "Three-dimensional displays", "Estimation", "Data models", "Visual tracking", "simultaneous localization and mapping", "panorama mapping", "model selection", "GRIC score", "keyframe-based", "initialization-free", "augmented reality"], "referenced_by": ["IKEY:7363191", "IKEY:7328054", "IKEY:8953718", "10.1145/2926964", "10.1111/phor.12188", "10.1111/phor.12213", "10.1007/s11704-018-6600-8", "10.1111/phor.12280"], "referencing": ["IKEY:1100705", "IKEY:4637878", "IKEY:4543779", "IKEY:4160954", "IKEY:6115832", "IKEY:6402532", "IKEY:5643564", "IKEY:5597402", "IKEY:4538852", "IKEY:5336495", "IKEY:6162882", "IKEY:1640781", "IKEY:6126513", "IKEY:6162880", "IKEY:1288525", "IKEY:6162872", "IKEY:6162868", "IKEY:1443240", "IKEY:323794", "IKEY:5509636", "IKEY:5444786", "IKEY:5336497", "IKEY:1100705", "IKEY:4637878", "IKEY:4543779", "IKEY:4160954", "IKEY:6115832", "IKEY:6402532", "IKEY:5643564", "IKEY:5597402", "IKEY:4538852", "IKEY:5336495", "IKEY:6162882", "IKEY:1640781", "IKEY:6126513", "IKEY:6162880", "IKEY:1288525", "IKEY:6162872", "IKEY:6162868", "IKEY:1443240", "IKEY:323794", "IKEY:5509636", "IKEY:5444786", "IKEY:5336497", "IKEY:1100705", "IKEY:4637878", "IKEY:4543779", "IKEY:4160954", "IKEY:6115832", "IKEY:6402532", "IKEY:5643564", "IKEY:5597402", "IKEY:4538852", "IKEY:5336495", "IKEY:6162882", "IKEY:1640781", "IKEY:6126513", "IKEY:6162880", "IKEY:1288525", "IKEY:6162872", "IKEY:6162868", "IKEY:1443240", "IKEY:323794", "IKEY:5509636", "IKEY:5444786", "IKEY:5336497", "10.1145/2371574.2371610", "10.1145/1643928.1643958", "10.1145/1486525.1486530", "10.1145/1141911.1141964", "10.1145/2371574.2371610", "10.1145/1643928.1643958", "10.1145/1486525.1486530", "10.1145/1141911.1141964", "10.1145/2371574.2371610", "10.1145/1643928.1643958", "10.1145/1486525.1486530", "10.1145/1141911.1141964", "10.1016/j.cag.2008.11.002", "10.5244/C.22.6", "10.1017/CBO9780511811685", "10.1007/978-3-540-36728-4_29", "10.1007/978-3-540-88688-4_59", "10.1016/j.cag.2011.04.004", "10.1007/978-3-642-15558-1_6", "10.5244/C.18.90", "10.1007/3-540-47967-8_56", "10.1016/0005-1098(78)90005-5", "10.1007/11744023_34", "10.1214/aos/1176344136", "10.1023/A:1008140928553", "10.1023/A:1020224303087", "10.1007/978-3-540-89639-5_51", "10.1016/j.cag.2008.11.002", "10.5244/C.22.6", "10.1017/CBO9780511811685", "10.1007/978-3-540-36728-4_29", "10.1007/978-3-540-88688-4_59", "10.1016/j.cag.2011.04.004", "10.1007/978-3-642-15558-1_6", "10.5244/C.18.90", "10.1007/3-540-47967-8_56", "10.1016/0005-1098(78)90005-5", "10.1007/11744023_34", "10.1214/aos/1176344136", "10.1023/A:1008140928553", "10.1023/A:1020224303087", "10.1007/978-3-540-89639-5_51", "10.1016/j.cag.2008.11.002", "10.5244/C.22.6", "10.1017/CBO9780511811685", "10.1007/978-3-540-36728-4_29", "10.1007/978-3-540-88688-4_59", "10.1016/j.cag.2011.04.004", "10.1007/978-3-642-15558-1_6", "10.5244/C.18.90", "10.1007/3-540-47967-8_56", "10.1016/0005-1098(78)90005-5", "10.1007/11744023_34", "10.1214/aos/1176344136", "10.1023/A:1008140928553", "10.1023/A:1020224303087", "10.1007/978-3-540-89639-5_51"]}, "10.1109/TVCG.2013.262": {"doi": "10.1109/TVCG.2013.262", "author": ["P. McIlroy", "S. Izadi", "A. Fitzgibbon"], "title": "Kinectrack: 3D Pose Estimation Using a Projected Dense Dot Pattern", "year": "2014", "abstract": "Kinectrack is a novel approach to six-DoF tracking that provides agile real-time pose estimation using only commodity hardware. The dot pattern emitter and IR camera components of the standard Kinect device are separated to allow the emitter to roam freely relative to a fixed camera. The six-DoF pose of the emitter component is recovered by matching the dense dot pattern observed by the camera to a pre-captured reference image. A novel matching technique is introduced to obtain the dense dot pattern correspondences efficiently in wide- and adaptive-baseline scenarios that requires only a small subset of the full dense dot pattern to fall within the field of view of the fixed camera. An auto-calibration process is proposed in order to obtain the intrinsic parameters of the fixed camera and the internal dot pattern reference image of the emitter. The system simultaneously recovers the six-DoF pose of the emitter device and the piecewise planar 3D scene structure. Kinectrack provides a low-cost method for tracking an object without any on-board computation, with small size and only simple electronics. This paper extends the original ISMAR 2012 submission, including a demonstration of robust pose tracking for AR and examples of matching in planar and non-planar scenes.", "keywords": ["augmented reality", "calibration", "cameras", "image capture", "image matching", "image reconstruction", "infrared imaging", "natural scenes", "object tracking", "pose estimation", "Kinectrack", "real-time 3D pose estimation", "commodity hardware", "dot pattern emitter component", "IR camera components", "standard Kinect device", "fixed camera", "six-DoF pose", "precaptured reference image", "dense dot pattern matching technique", "autocalibration process", "internal dot pattern reference image", "piecewise planar 3D scene structure", "object tracking method", "robust pose tracking", "AR", "nonplanar scenes", "augmented reality", "Cameras", "Pattern matching", "Table lookup", "Estimation", "Three-dimensional displays", "Robustness", "Calibration", "Six-DoF tracking", "3D reconstruction", "kinect"], "referenced_by": ["IKEY:8100175", "IKEY:7780956", "IKEY:7436656", "IKEY:8812900", "IKEY:9278920", "10.1007/s00138-017-0901-z", "10.1007/s10851-017-0764-y", "10.1007/978-3-030-01240-3_38", "10.1016/j.optlaseng.2019.05.003"], "referencing": ["IKEY:4160954", "IKEY:803809", "IKEY:6162896", "IKEY:4408982", "IKEY:809883", "IKEY:4560198", "IKEY:880935", "IKEY:4160954", "IKEY:803809", "IKEY:6162896", "IKEY:4408982", "IKEY:809883", "IKEY:4560198", "IKEY:880935", "IKEY:4160954", "IKEY:803809", "IKEY:6162896", "IKEY:4408982", "IKEY:809883", "IKEY:4560198", "IKEY:880935", "10.1145/1964921.1964926", "10.1145/1866029.1866072", "10.1145/2047196.2047254", "10.1145/506486.506542", "10.1145/1101616.1101637", "10.1145/1842993.1843022", "10.1145/1180495.1180506", "10.1145/1964921.1964926", "10.1145/1866029.1866072", "10.1145/2047196.2047254", "10.1145/506486.506542", "10.1145/1101616.1101637", "10.1145/1842993.1843022", "10.1145/1180495.1180506", "10.1145/1964921.1964926", "10.1145/1866029.1866072", "10.1145/2047196.2047254", "10.1145/506486.506542", "10.1145/1101616.1101637", "10.1145/1842993.1843022", "10.1145/1180495.1180506", "10.1016/S0141-9382(02)00039-2", "10.1088/0004-6256/139/5/1782", "10.1017/CBO9780511811685", "10.5244/C.8.60", "10.1016/S0141-9382(02)00039-2", "10.1088/0004-6256/139/5/1782", "10.1017/CBO9780511811685", "10.5244/C.8.60", "10.1016/S0141-9382(02)00039-2", "10.1088/0004-6256/139/5/1782", "10.1017/CBO9780511811685", "10.5244/C.8.60"]}, "10.1109/TVCG.2013.260": {"doi": "10.1109/TVCG.2013.260", "author": ["X. Yang", "K. Cheng"], "title": "Learning Optimized Local Difference Binaries for Scalable Augmented Reality on Mobile Devices", "year": "2014", "abstract": "The efficiency, robustness and distinctiveness of a feature descriptor are critical to the user experience and scalability of a mobile augmented reality (AR) system. However, existing descriptors are either too computationally expensive to achieve real-time performance on a mobile device such as a smartphone or tablet, or not sufficiently robust and distinctive to identify correct matches from a large database. As a result, current mobile AR systems still only have limited capabilities, which greatly restrict their deployment in practice. In this paper, we propose a highly efficient, robust and distinctive binary descriptor, called Learning-based Local Difference Binary (LLDB). LLDB directly computes a binary string for an image patch using simple intensity and gradient difference tests on pairwise grid cells within the patch. To select an optimized set of grid cell pairs, we densely sample grid cells from an image patch and then leverage a modified AdaBoost algorithm to automatically extract a small set of critical ones with the goal of maximizing the Hamming distance between mismatches while minimizing it between matches. Experimental results demonstrate that LLDB is extremely fast to compute and to match against a large database due to its high robustness and distinctiveness. Compared to the state-of-the-art binary descriptors, primarily designed for speed, LLDB has similar efficiency for descriptor construction, while achieving a greater accuracy and faster matching speed when matching over a large database with 2.3M descriptors on mobile devices.", "keywords": ["augmented reality", "image matching", "image sampling", "learning (artificial intelligence)", "mobile computing", "learning-based local difference binary", "LLDB", "mobile devices", "feature descriptor", "user experience", "mobile augmented reality system scalability", "smart phone", "tablet", "image matching", "large database", "mobile AR system scalability", "binary descriptor", "binary string", "image patch", "intensity difference test", "gradient difference test", "pairwise grid cells", "optimized grid cell pair set selection", "grid cells sample", "AdaBoost algorithm", "Hamming distance maximization", "Feature extraction", "Databases", "Mobile handsets", "Robustness", "Scalability", "Runtime", "Mobile communication", "Scalable augmented reality", "binary descriptor", "AdaBoost learning", "mobile devices"], "referenced_by": ["IKEY:7857635", "IKEY:7002689", "IKEY:7206542", "IKEY:8055438", "IKEY:7578627", "IKEY:7968749", "IKEY:8332922", "10.1145/2647868.2654888", "10.1007/978-3-319-24702-1_10", "10.1007/978-3-319-40238-3_11", "10.1007/s11042-018-5864-1", "10.1201/b18703-12", "10.1049/iet-cvi.2018.5203"], "referencing": ["IKEY:1498756", "IKEY:5432199", "IKEY:4637338", "IKEY:5336497", "IKEY:5336495", "IKEY:5871647", "IKEY:1498756", "IKEY:5432199", "IKEY:4637338", "IKEY:5336497", "IKEY:5336495", "IKEY:5871647", "IKEY:1498756", "IKEY:5432199", "IKEY:4637338", "IKEY:5336497", "IKEY:5336495", "IKEY:5871647", "10.1145/358669.358692", "10.1145/1991996.1992031", "10.1145/358669.358692", "10.1145/1991996.1992031", "10.1145/358669.358692", "10.1145/1991996.1992031", "10.1023/B:VISI.0000029664.99615.94", "10.1007/978-3-642-15561-1_56", "10.1023/B:VISI.0000013087.49260.fb", "10.1007/978-3-642-33718-5_18", "10.1006/jcss.1997.1504", "10.1023/B:VISI.0000029664.99615.94", "10.1007/978-3-642-15561-1_56", "10.1023/B:VISI.0000013087.49260.fb", "10.1007/978-3-642-33718-5_18", "10.1006/jcss.1997.1504", "10.1023/B:VISI.0000029664.99615.94", "10.1007/978-3-642-15561-1_56", "10.1023/B:VISI.0000013087.49260.fb", "10.1007/978-3-642-33718-5_18", "10.1006/jcss.1997.1504"]}, "10.1109/TVCG.2014.2298016": {"doi": "10.1109/TVCG.2014.2298016", "author": ["J. Herling", "W. Broll"], "title": "High-Quality Real-Time Video Inpaintingwith PixMix", "year": "2014", "abstract": "While image inpainting has recently become widely available in image manipulation tools, existing approaches to video inpainting typically do not even achieve interactive frame rates yet as they are highly computationally expensive. Further, they either apply severe restrictions on the movement of the camera or do not provide a high-quality coherent video stream. In this paper we will present our approach to high-quality real-time capable image and video inpainting. Our PixMix approach even allows for the manipulation of live video streams, providing the basis for real Diminished Reality (DR) applications. We will show how our approach generates coherent video streams dealing with quite heterogeneous background environments and non-trivial camera movements, even applying constraints in real-time.", "keywords": ["video signal processing", "high-quality real-time video inpainting", "image manipulation tools", "PixMix", "image inpainting", "live video streams manipulation", "diminished reality applications", "DR applications", "Streaming media", "Real-time systems", "Visualization", "Cameras", "Coherence", "Cost function", "Image resolution", "\u00b4Video inpainting", "diminished reality", "real-time", "image inpainting", "image completion", "object removal"], "referenced_by": ["IKEY:7533016", "IKEY:7733832", "IKEY:8088482", "IKEY:7781764", "IKEY:7824726", "IKEY:7112098", "IKEY:7106514", "IKEY:7165658", "IKEY:7180400", "IKEY:7593269", "IKEY:7477633", "IKEY:7869421", "IKEY:7344753", "IKEY:7305789", "IKEY:7253639", "IKEY:6976870", "IKEY:7922581", "IKEY:7931582", "IKEY:8699212", "IKEY:8699270", "IKEY:8919241", "IKEY:8966071", "IKEY:9129266", "IKEY:9184389", "10.1145/3196492", "10.1007/978-3-319-46493-0_7", "10.1007/s11042-016-3550-8", "10.1016/j.sigpro.2015.09.031", "10.1137/16M1103737", "10.3390/mti1030018", "10.1017/ATSIP.2018.13", "10.1007/s11263-018-1132-0", "10.1007/s10851-019-00878-z", "10.1117/12.2524194", "10.1007/978-3-319-17043-5_1", "10.1007/978-3-319-14249-4_53", "10.1007/978-81-322-2752-6_24", "10.1186/s41074-017-0028-1", "10.1007/978-3-030-34995-0_42", "10.1016/j.robot.2020.103563"], "referencing": ["IKEY:1323101", "IKEY:5456222", "IKEY:1608046", "IKEY:4060949", "IKEY:1640787", "IKEY:4069262", "IKEY:4359322", "IKEY:5557884", "IKEY:5482183", "IKEY:1323101", "IKEY:5456222", "IKEY:1608046", "IKEY:4060949", "IKEY:1640787", "IKEY:4069262", "IKEY:4359322", "IKEY:5557884", "IKEY:5482183", "IKEY:1323101", "IKEY:5456222", "IKEY:1608046", "IKEY:4060949", "IKEY:1640787", "IKEY:4069262", "IKEY:4359322", "IKEY:5557884", "IKEY:5482183", "10.1145/1186822.1073274", "10.1145/2185520.2335399", "10.1145/364338.364405", "10.1145/358669.358692", "10.1145/1186562.1015720", "10.1145/1631272.1631350", "10.1145/1531326.1531337", "10.1145/882262.882269", "10.1145/1186822.1073274", "10.1145/2185520.2335399", "10.1145/364338.364405", "10.1145/358669.358692", "10.1145/1186562.1015720", "10.1145/1631272.1631350", "10.1145/1531326.1531337", "10.1145/882262.882269", "10.1145/1186822.1073274", "10.1145/2185520.2335399", "10.1145/364338.364405", "10.1145/358669.358692", "10.1145/1186562.1015720", "10.1145/1631272.1631350", "10.1145/1531326.1531337", "10.1145/882262.882269", "10.1016/j.patrec.2008.03.011", "10.1016/j.patcog.2009.03.004", "10.1111/j.1467-8659.2011.02038.x", "10.1016/j.cag.2006.10.004", "10.1016/j.patrec.2008.03.011", "10.1016/j.patcog.2009.03.004", "10.1111/j.1467-8659.2011.02038.x", "10.1016/j.cag.2006.10.004", "10.1016/j.patrec.2008.03.011", "10.1016/j.patcog.2009.03.004", "10.1111/j.1467-8659.2011.02038.x", "10.1016/j.cag.2006.10.004"]}, "10.1109/TVCG.2014.2312016": {"doi": "10.1109/TVCG.2014.2312016", "author": ["A. Jarabo", "H. Wu", "J. Dorsey", "H. Rushmeier", "D. Gutierrez"], "title": "Effects of Approximate Filtering on the Appearance of Bidirectional Texture Functions", "year": "2014", "abstract": "The BTF data structure was a breakthrough for appearance modeling in computer graphics. More research is needed though to make BTFs practical in rendering applications. We present the first systematic study of the effects of Approximate filtering on the appearance of BTFs, by exploring the spatial, angular and temporal domains over a varied set of stimuli. We perform our initial experiments on simple geometry and lighting, and verify our observations on more complex settings. We consider multi-dimensional filtering versus conventional mipmapping, and find that multi-dimensional filtering produces superior results. We examine the tradeoff between under- and oversampling, and find that different filtering strategies can be applied in each domain, while maintaining visual equivalence with respect to a ground truth. For example, we find that preserving contrast is more important in static than dynamic images, indicating greater levels of spatial filtering are possible for animations. We find that filtering can be performed more aggressively in the angular domain than in the spatial. Additionally, we find that high-level visual descriptors of the BTF are linked to the perceptual performance of pre-filtered approximations. In turn, some of these high-level descriptors correlate with low level statistics of the BTF. We show six different practical applications of applying our findings to improving filtering, rendering and compression strategies.", "keywords": ["computational geometry", "computer animation", "data structures", "filtering theory", "image coding", "image sampling", "image texture", "statistical analysis", "bidirectional texture function appearance modeling", "BTF data structure", "computer graphics", "rendering applications", "spatial domain", "temporal domain", "multidimensional filtering", "mipmapping", "under-sampling", "oversampling", "visual equivalence maintenance", "ground truth", "contrast preservation", "static images", "dynamic images", "spatial filtering", "animations", "angular domain", "high-level visual descriptors", "perceptual performance", "prefiltered approximation", "high-level descriptors", "low-level statistics", "compression strategies", "Rendering (computer graphics)", "Visualization", "Materials", "Geometry", "Lighting", "Approximation methods", "Surface texture", "BTF", "perception", "filtering"], "referenced_by": ["IKEY:8017561", "IKEY:8327022", "IKEY:8292880", "IKEY:9067905", "10.1145/2980179.2980242", "10.1145/2980179.2980228", "10.1145/3301412", "10.1145/3306346.3323036", "10.1145/3306346.3322936", "10.1016/B978-0-12-800645-0.50027-0", "10.1016/j.cag.2015.01.005", "10.1111/cgf.12789", "10.1016/j.cag.2018.06.001", "10.1007/s41095-019-0134-3", "10.1111/cgf.13633", "10.1016/j.cag.2019.07.007"], "referencing": ["IKEY:5753897", "IKEY:4309999", "IKEY:5753897", "IKEY:4309999", "IKEY:5753897", "IKEY:4309999", "10.1145/1409060.1409091", "10.1145/300776.300778", "10.1145/2167076.2167077", "10.1145/800059.801126", "10.1145/1276377.1276412", "10.1145/1053427.1053458", "10.1145/2077434.2077448", "10.1145/1015706.1015795", "10.1145/383259.383284", "10.1145/2010325.2010330", "10.1145/1276377.1276472", "10.1145/1276377.1276473", "10.1145/1140491.1140517", "10.1145/1577755.1577761", "10.1145/882262.882343", "10.1145/1531326.1531334", "10.1145/1882262.1866186", "10.1145/1964921.1964958", "10.1145/2451236.2451244", "10.1145/1753326.1753357", "10.1145/280814.280864", "10.1145/258734.258818", "10.1145/1409060.1409091", "10.1145/300776.300778", "10.1145/2167076.2167077", "10.1145/800059.801126", "10.1145/1276377.1276412", "10.1145/1053427.1053458", "10.1145/2077434.2077448", "10.1145/1015706.1015795", "10.1145/383259.383284", "10.1145/2010325.2010330", "10.1145/1276377.1276472", "10.1145/1276377.1276473", "10.1145/1140491.1140517", "10.1145/1577755.1577761", "10.1145/882262.882343", "10.1145/1531326.1531334", "10.1145/1882262.1866186", "10.1145/1964921.1964958", "10.1145/2451236.2451244", "10.1145/1753326.1753357", "10.1145/280814.280864", "10.1145/258734.258818", "10.1145/1409060.1409091", "10.1145/300776.300778", "10.1145/2167076.2167077", "10.1145/800059.801126", "10.1145/1276377.1276412", "10.1145/1053427.1053458", "10.1145/2077434.2077448", "10.1145/1015706.1015795", "10.1145/383259.383284", "10.1145/2010325.2010330", "10.1145/1276377.1276472", "10.1145/1276377.1276473", "10.1145/1140491.1140517", "10.1145/1577755.1577761", "10.1145/882262.882343", "10.1145/1531326.1531334", "10.1145/1882262.1866186", "10.1145/1964921.1964958", "10.1145/2451236.2451244", "10.1145/1753326.1753357", "10.1145/280814.280864", "10.1145/258734.258818", "10.1111/j.1467-8659.2009.01495.x", "10.1111/j.1467-8659.2009.01585.x", "10.1111/j.1467-8659.2009.01500.x", "10.1111/j.1467-8659.2012.03057.x", "10.1117/12.429504", "10.1111/j.1467-8659.2008.01299.x", "10.1201/b11308", "10.1111/j.1467-8659.2011.01900.x", "10.1016/0042-6989(82)90196-1", "10.1111/j.1467-8659.2009.01495.x", "10.1111/j.1467-8659.2009.01585.x", "10.1111/j.1467-8659.2009.01500.x", "10.1111/j.1467-8659.2012.03057.x", "10.1117/12.429504", "10.1111/j.1467-8659.2008.01299.x", "10.1201/b11308", "10.1111/j.1467-8659.2011.01900.x", "10.1016/0042-6989(82)90196-1", "10.1111/j.1467-8659.2009.01495.x", "10.1111/j.1467-8659.2009.01585.x", "10.1111/j.1467-8659.2009.01500.x", "10.1111/j.1467-8659.2012.03057.x", "10.1117/12.429504", "10.1111/j.1467-8659.2008.01299.x", "10.1201/b11308", "10.1111/j.1467-8659.2011.01900.x", "10.1016/0042-6989(82)90196-1"]}, "10.1109/TVCG.2013.261": {"doi": "10.1109/TVCG.2013.261", "author": ["P. A. Navr\u00e1til", "H. Childs", "D. S. Fussell", "C. Lin"], "title": "Exploring the Spectrum of Dynamic Scheduling Algorithms for Scalable Distributed-MemoryRay Tracing", "year": "2014", "abstract": "This paper extends and evaluates a family of dynamic ray scheduling algorithms that can be performed in-situ on large distributed memory parallel computers. The key idea is to consider both ray state and data accesses when scheduling ray computations. We compare three instances of this family of algorithms against two traditional statically scheduled schemes. We show that our dynamic scheduling approach can render data sets that are larger than aggregate system memory and that cannot be rendered by existing statically scheduled ray tracers. For smaller problems that fit in aggregate memory but are larger than typical shared memory, our dynamic approach is competitive with the best static scheduling algorithm.", "keywords": ["distributed memory systems", "dynamic scheduling", "parallel algorithms", "processor scheduling", "ray tracing", "rendering (computer graphics)", "dynamic ray scheduling algorithms", "large distributed memory parallel computers", "ray state", "data access", "ray computation scheduling", "dynamic scheduling approach", "data set rendering", "static scheduling algorithm", "scalable distributed-memory ray tracing", "Ray tracing", "Dynamic scheduling", "Coherence", "Schedules", "Rendering (computer graphics)", "Processor scheduling", "Lighting", "Distributed memory", "dynamic scheduling", "parallel", "ray tracing"], "referenced_by": ["IKEY:7156388", "IKEY:8388721", "IKEY:8739224", "IKEY:8739241", "IKEY:8790229", "IKEY:8736329", "IKEY:8747344", "IKEY:9185721"], "referencing": ["IKEY:745713", "IKEY:4061561", "IKEY:5362481", "IKEY:5708139", "IKEY:795215", "IKEY:1249045", "IKEY:41466", "IKEY:4634633", "IKEY:4342596", "IKEY:745713", "IKEY:4061561", "IKEY:5362481", "IKEY:5708139", "IKEY:795215", "IKEY:1249045", "IKEY:41466", "IKEY:4634633", "IKEY:4342596", "IKEY:745713", "IKEY:4061561", "IKEY:5362481", "IKEY:5708139", "IKEY:795215", "IKEY:1249045", "IKEY:41466", "IKEY:4634633", "IKEY:4342596", "10.1145/258734.258791", "10.1145/1073204.1073329", "10.1145/346876.348241", "10.1145/1572769.1572792", "10.1145/356625.356626", "10.1145/300523.300537", "10.1145/964965.808592", "10.1145/325334.325247", "10.1145/258734.258791", "10.1145/1073204.1073329", "10.1145/346876.348241", "10.1145/1572769.1572792", "10.1145/356625.356626", "10.1145/300523.300537", "10.1145/964965.808592", "10.1145/325334.325247", "10.1145/258734.258791", "10.1145/1073204.1073329", "10.1145/346876.348241", "10.1145/1572769.1572792", "10.1145/356625.356626", "10.1145/300523.300537", "10.1145/964965.808592", "10.1145/325334.325247", "10.1016/j.parco.2005.02.007", "10.1007/978-3-7091-6242-2_26", "10.1111/j.1467-8659.2008.01313.x", "10.1007/s00371-008-0261-9", "10.1007/BF01901067", "10.1016/S0167-8191(02)00247-8", "10.1111/j.1467-8659.2009.01378.x", "10.1111/1467-8659.00508", "10.1016/B978-0-08-050754-5.50018-9", "10.1007/BF01887592", "10.1016/j.parco.2005.02.007", "10.1007/978-3-7091-6242-2_26", "10.1111/j.1467-8659.2008.01313.x", "10.1007/s00371-008-0261-9", "10.1007/BF01901067", "10.1016/S0167-8191(02)00247-8", "10.1111/j.1467-8659.2009.01378.x", "10.1111/1467-8659.00508", "10.1016/B978-0-08-050754-5.50018-9", "10.1007/BF01887592", "10.1016/j.parco.2005.02.007", "10.1007/978-3-7091-6242-2_26", "10.1111/j.1467-8659.2008.01313.x", "10.1007/s00371-008-0261-9", "10.1007/BF01901067", "10.1016/S0167-8191(02)00247-8", "10.1111/j.1467-8659.2009.01378.x", "10.1111/1467-8659.00508", "10.1016/B978-0-08-050754-5.50018-9", "10.1007/BF01887592"]}, "10.1109/TVCG.2013.258": {"doi": "10.1109/TVCG.2013.258", "author": ["T. Bashford-Rogers", "K. Debattista", "A. Chalmers"], "title": "Importance Driven Environment Map Sampling", "year": "2014", "abstract": "In this paper we present an efficient method for supporting image based lighting (IBL) for bidirectional methods. This improves both sampling of the environment, and the detection and sampling of important regions of the scene, such as windows and doors. These parts of the scene often have a small area proportional to that of the entire scene, so paths which pass through them are generated with a low probability. The method proposed in this paper improves sampling efficiency, by taking into account view importance, and modifies the lighting distribution to use light transport information from the camera. This method automatically constructs a sampling distribution in locations which are relevant to the camera position, thereby improving sampling of light paths. This approach can be applied to several bidirectional rendering methods, and results are shown for bidirectional path tracing, metropolis light transport and progressive photon mapping. When compared to other methods, efficiency results demonstrate speed ups of orders of magnitude.", "keywords": ["image sampling", "lighting", "ray tracing", "rendering (computer graphics)", "importance driven environment map sampling", "IBL", "image based lighting", "region detection", "low probability", "lighting distribution", "light transport information", "camera position", "light path sampling", "bidirectional rendering methods", "bidirectional path tracing method", "progressive photon mapping", "ray tracing", "Cameras", "Rendering (computer graphics)", "Lighting", "Approximation methods", "Photonics", "Light sources", "Equations", "Computer graphics", "raytracing", "sampling", "image based lighting"], "referenced_by": ["10.1145/2963097", "10.1007/s00371-015-1104-0", "10.1111/cgf.12591", "10.1016/B978-0-12-800645-0.50027-0", "10.1007/s00371-018-1577-8", "10.1007/978-3-319-21969-1_8"], "referencing": ["IKEY:1207447", "IKEY:1207447", "IKEY:1207447", "10.1145/1186822.1073328", "10.1145/280814.280864", "10.1145/1186954.1187029", "10.1145/2366145.2366211", "10.1145/1618452.1618487", "10.1145/2019627.2019633", "10.1145/1457515.1409083", "10.1145/2366145.2366210", "10.1145/2185520.2185522", "10.1145/258734.258769", "10.1145/258734.258775", "10.1145/1186822.1073328", "10.1145/280814.280864", "10.1145/1186954.1187029", "10.1145/2366145.2366211", "10.1145/1618452.1618487", "10.1145/2019627.2019633", "10.1145/1457515.1409083", "10.1145/2366145.2366210", "10.1145/2185520.2185522", "10.1145/258734.258769", "10.1145/258734.258775", "10.1145/1186822.1073328", "10.1145/280814.280864", "10.1145/1186954.1187029", "10.1145/2366145.2366211", "10.1145/1618452.1618487", "10.1145/2019627.2019633", "10.1145/1457515.1409083", "10.1145/2366145.2366210", "10.1145/2185520.2185522", "10.1145/258734.258769", "10.1145/258734.258775", "10.1111/j.1467-8659.2011.01979.x", "10.1080/2151237X.2009.10129280", "10.1007/978-3-642-87825-1_14", "10.1007/s00371-006-0055-x", "10.1111/j.1467-8659.2012.03049.x", "10.1201/b10685", "10.1111/1467-8659.t01-1-00703", "10.1007/978-3-7091-6453-2_25", "10.1111/j.1467-8659.2009.01572.x", "10.1111/j.1467-8659.2011.01979.x", "10.1080/2151237X.2009.10129280", "10.1007/978-3-642-87825-1_14", "10.1007/s00371-006-0055-x", "10.1111/j.1467-8659.2012.03049.x", "10.1201/b10685", "10.1111/1467-8659.t01-1-00703", "10.1007/978-3-7091-6453-2_25", "10.1111/j.1467-8659.2009.01572.x", "10.1111/j.1467-8659.2011.01979.x", "10.1080/2151237X.2009.10129280", "10.1007/978-3-642-87825-1_14", "10.1007/s00371-006-0055-x", "10.1111/j.1467-8659.2012.03049.x", "10.1201/b10685", "10.1111/1467-8659.t01-1-00703", "10.1007/978-3-7091-6453-2_25", "10.1111/j.1467-8659.2009.01572.x"]}, "10.1109/TVCG.2013.253": {"doi": "10.1109/TVCG.2013.253", "author": ["H. Li", "W. Zeng", "J. M. Morvan", "L. Chen", "X. D. Gu"], "title": "Surface Meshing with Curvature Convergence", "year": "2014", "abstract": "Surface meshing plays a fundamental role in graphics and visualization. Many geometric processing tasks involve solving geometric PDEs on meshes. The numerical stability, convergence rates and approximation errors are largely determined by the mesh qualities. In practice, Delaunay refinement algorithms offer satisfactory solutions to high quality mesh generations. The theoretical proofs for volume based and surface based Delaunay refinement algorithms have been established, but those for conformal parameterization based ones remain wide open. This work focuses on the curvature measure convergence for the conformal parameterization based Delaunay refinement algorithms. Given a metric surface, the proposed approach triangulates its conformal uniformization domain by the planar Delaunay refinement algorithms, and produces a high quality mesh. We give explicit estimates for the Hausdorff distance, the normal deviation, and the differences in curvature measures between the surface and the mesh. In contrast to the conventional results based on volumetric Delaunay refinement, our stronger estimates are independent of the mesh structure and directly guarantee the convergence of curvature measures. Meanwhile, our result on Gaussian curvature measure is intrinsic to the Riemannian metric and independent of the embedding. In practice, our meshing algorithm is much easier to implement and much more efficient. The experimental results verified our theoretical results and demonstrated the efficiency of the meshing algorithm.", "keywords": ["convergence of numerical methods", "mesh generation", "numerical stability", "surface meshing", "geometric processing tasks", "geometric PDEs", "numerical stability", "convergence rates", "approximation errors", "high quality mesh generations", "surface based Delaunay refinement algorithms", "volume based Delaunay refinement algorithms", "curvature measure convergence", "metric surface", "conformal uniformization domain", "Hausdorff distance", "normal deviation", "Gaussian curvature measure", "Riemannian metric", "conformal parameterization based Delaunay refinement algorithms", "Measurement", "Convergence", "Surface treatment", "Face", "Shape", "Mesh generation", "Approximation methods", "Meshing", "Delaunay refinement", "conformal parameterization", "normal cycle", "curvature measures", "convergence"], "referenced_by": ["10.1007/s10851-017-0728-2", "10.1016/j.proeng.2017.09.811", "10.1007/s41095-015-0022-4", "10.1016/j.cad.2019.01.004", "10.1063/1.5127224"], "referencing": ["IKEY:4483509", "IKEY:4273388", "IKEY:1199601", "IKEY:5988945", "IKEY:1318721", "IKEY:856998", "IKEY:5374410", "IKEY:4483509", "IKEY:4273388", "IKEY:1199601", "IKEY:5988945", "IKEY:1318721", "IKEY:856998", "IKEY:5374410", "IKEY:4483509", "IKEY:4273388", "IKEY:1199601", "IKEY:5988945", "IKEY:1318721", "IKEY:856998", "IKEY:5374410", "10.1145/276884.276889", "10.1145/336154.336207", "10.1145/997817.997861", "10.1145/160985.161150", "10.1145/777837.777839", "10.1145/1360612.1360676", "10.1145/276884.276889", "10.1145/336154.336207", "10.1145/997817.997861", "10.1145/160985.161150", "10.1145/777837.777839", "10.1145/1360612.1360676", "10.1145/276884.276889", "10.1145/336154.336207", "10.1145/997817.997861", "10.1145/160985.161150", "10.1145/777837.777839", "10.1145/1360612.1360676", "10.1111/j.1467-8659.2009.01515.x", "10.1007/s11263-007-0063-y", "10.1016/j.gmod.2005.01.004", "10.1007/3-540-29090-7_21", "10.1016/j.cagd.2007.04.004", "10.1002/nme.2824", "10.1002/nme.3099", "10.1007/978-3-540-33265-7_2", "10.1007/978-3-540-73792-6", "10.1007/s00454-004-1096-4", "10.1512/iumj.1989.38.38035", "10.1006/jagm.1995.1021", "10.1016/S0925-7721(01)00047-5", "10.1137/S0036144599352836", "10.1137/S1064827501391576", "10.1111/j.1467-8659.2009.01521.x", "10.1561/0600000011", "10.1007/3-540-26808-1_9", "10.1111/1467-8659.00580", "10.1007/11566489_81", "10.1016/S1053-8119(00)91398-3", "10.1007/PL00013391", "10.2307/1969840", "10.2307/1969989", "10.1007/s10711-006-9109-5", "10.1111/j.1467-8659.2009.01515.x", "10.1007/s11263-007-0063-y", "10.1016/j.gmod.2005.01.004", "10.1007/3-540-29090-7_21", "10.1016/j.cagd.2007.04.004", "10.1002/nme.2824", "10.1002/nme.3099", "10.1007/978-3-540-33265-7_2", "10.1007/978-3-540-73792-6", "10.1007/s00454-004-1096-4", "10.1512/iumj.1989.38.38035", "10.1006/jagm.1995.1021", "10.1016/S0925-7721(01)00047-5", "10.1137/S0036144599352836", "10.1137/S1064827501391576", "10.1111/j.1467-8659.2009.01521.x", "10.1561/0600000011", "10.1007/3-540-26808-1_9", "10.1111/1467-8659.00580", "10.1007/11566489_81", "10.1016/S1053-8119(00)91398-3", "10.1007/PL00013391", "10.2307/1969840", "10.2307/1969989", "10.1007/s10711-006-9109-5", "10.1111/j.1467-8659.2009.01515.x", "10.1007/s11263-007-0063-y", "10.1016/j.gmod.2005.01.004", "10.1007/3-540-29090-7_21", "10.1016/j.cagd.2007.04.004", "10.1002/nme.2824", "10.1002/nme.3099", "10.1007/978-3-540-33265-7_2", "10.1007/978-3-540-73792-6", "10.1007/s00454-004-1096-4", "10.1512/iumj.1989.38.38035", "10.1006/jagm.1995.1021", "10.1016/S0925-7721(01)00047-5", "10.1137/S0036144599352836", "10.1137/S1064827501391576", "10.1111/j.1467-8659.2009.01521.x", "10.1561/0600000011", "10.1007/3-540-26808-1_9", "10.1111/1467-8659.00580", "10.1007/11566489_81", "10.1016/S1053-8119(00)91398-3", "10.1007/PL00013391", "10.2307/1969840", "10.2307/1969989", "10.1007/s10711-006-9109-5"]}, "10.1109/TVCG.2013.247": {"doi": "10.1109/TVCG.2013.247", "author": ["S. Tak", "A. Toet", "J. van Erp"], "title": "The Perception of Visual UncertaintyRepresentation by Non-Experts", "year": "2014", "abstract": "We tested how non-experts judge point probability for seven different visual representations of uncertainty, using a case from an unfamiliar domain. Participants (n = 140) rated the probability that the boundary between two earth layers passed through a given point, for seven different visualizations of the positional uncertainty of the boundary. For all types of visualizations, most observers appear to construct an internal model of the uncertainty distribution that closely resembles a normal distribution. However, the visual form of the uncertainty range (i.e., the visualization type) affects this internal model and the internal model relates to participants' numeracy. We conclude that perceived certainty is affected by its visual representation. In a follow-up experiment we found no indications that the absence (or presence) of a prominent center line in the visualization affects the internal model. We discuss if and how our results inform which visual representation is most suitable for representing uncertainty and make suggestions for future work.", "keywords": ["data visualisation", "probability", "visual uncertainty representation", "nonexperts", "point probability", "earth layers", "internal model", "uncertainty distribution", "normal distribution", "prominent center line", "Uncertainty", "Visualization", "Data visualization", "Bars", "Image color analysis", "Labeling", "Computational modeling", "Uncertainty visualization", "user study", "non-expert audiences", "spatial data"], "referenced_by": ["IKEY:8258246", "IKEY:7257167", "IKEY:6875915", "IKEY:8017624", "IKEY:8457476", "10.1145/2993901.2993919", "10.1145/3095805", "10.1016/j.envsoft.2016.09.004", "10.1155/2017/3932565", "10.1177/1541931214581364", "10.1177/1555343415591275", "10.1177/2327857915041035", "10.1177/2327857918071009", "10.1111/cgf.13444", "10.1177/1473871618807121", "10.1177/1473871618821747", "10.1016/j.cola.2019.03.002", "10.1007/978-3-319-22723-8_21", "10.1007/978-3-030-29384-0_35", "10.1007/BF03545380", "10.1007/978-3-030-54249-8_9"], "referencing": ["IKEY:5290731", "IKEY:4408049", "IKEY:6327259", "IKEY:5290731", "IKEY:4408049", "IKEY:6327259", "IKEY:5290731", "IKEY:4408049", "IKEY:6327259", "10.1007/978-3-540-30119-6_4", "10.1518/001872005775570916", "10.1177/154193120605000318", "10.1177/154193120004400104", "10.1518/155534309X474460", "10.1016/S0098-3004(97)00011-3", "10.1177/1555343411415793", "10.1177/154193129804200108", "10.1007/s003710050111", "10.1518/155534309X433726", "10.1037/1082-989X.10.4.389", "10.1111/j.1756-8765.2009.01066.x", "10.1016/j.jvlc.2003.09.001", "10.1177/0272989X07304449", "10.1111/j.1539-6924.2005.00608.x", "10.1207/s15328031us0304_5", "10.1016/j.cognition.2012.12.005", "10.1007/978-3-540-30119-6_4", "10.1518/001872005775570916", "10.1177/154193120605000318", "10.1177/154193120004400104", "10.1518/155534309X474460", "10.1016/S0098-3004(97)00011-3", "10.1177/1555343411415793", "10.1177/154193129804200108", "10.1007/s003710050111", "10.1518/155534309X433726", "10.1037/1082-989X.10.4.389", "10.1111/j.1756-8765.2009.01066.x", "10.1016/j.jvlc.2003.09.001", "10.1177/0272989X07304449", "10.1111/j.1539-6924.2005.00608.x", "10.1207/s15328031us0304_5", "10.1016/j.cognition.2012.12.005", "10.1007/978-3-540-30119-6_4", "10.1518/001872005775570916", "10.1177/154193120605000318", "10.1177/154193120004400104", "10.1518/155534309X474460", "10.1016/S0098-3004(97)00011-3", "10.1177/1555343411415793", "10.1177/154193129804200108", "10.1007/s003710050111", "10.1518/155534309X433726", "10.1037/1082-989X.10.4.389", "10.1111/j.1756-8765.2009.01066.x", "10.1016/j.jvlc.2003.09.001", "10.1177/0272989X07304449", "10.1111/j.1539-6924.2005.00608.x", "10.1207/s15328031us0304_5", "10.1016/j.cognition.2012.12.005"]}, "10.1109/TVCG.2013.248": {"doi": "10.1109/TVCG.2013.248", "author": ["O. Karl\u00edk", "M. Ru\u0307z\u0306ic\u0306ka", "V. Gassenbauer", "F. Pellacini", "J. Kr\u0306iv\u00e1nek"], "title": "Toward Evaluating the Usefulness of GlobalIllumination for Novices in Lighting Design Tasks", "year": "2014", "abstract": "Thanks to its ability to improve the realism of computer-generated imagery, the use of global illumination has recently become widespread among digital lighting artists. It remains unclear, though, what impact it has on the lighting design workflows, especially for novice users. In this paper we present a user study which investigates the use of global illumination, large area lights, and non-physical fill lights in lighting design tasks, where 26 novice subjects design lighting with these tools. The collected data suggest that global illumination is not significantly harder to control for novice users that direct illumination, and when given the possibility, most users opt to use it in their designs. The use of global illumination together with large area lights leads to simpler lighting setups with fewer non-physical fill lights. Interestingly, global illumination does not supersede fill lights: users still include them into their globally illuminated lighting setups. We believe that our results will find use in the development of lighting design tools for non-expert users.", "keywords": ["rendering (computer graphics)", "user interfaces", "usefulness evaluation", "global illumination", "computer-generated imagery", "digital lighting artists", "lighting design workflow", "novice users", "large area lights", "nonphysical fill lights", "direct illumination", "lighting setup", "nonexpert users", "point light sources", "rendering", "Lighting", "Computational modeling", "Rendering (computer graphics)", "User interfaces", "Mathematical model", "Electronic mail", "Engines", "Global illumination", "lighting design", "user study"], "referenced_by": ["IKEY:8017561", "10.1111/cgf.12721"], "referencing": ["10.1145/1667239.1667258", "10.1145/1531326.1531332", "10.1145/1833351.1778772", "10.1145/1015706.1015748", "10.1145/2461912.2461980", "10.1145/1073204.1073214", "10.1145/1275808.1276409", "10.1145/1360612.1360636", "10.1145/1141911.1141998", "10.1145/1833349.1778771", "10.1145/1572769.1572792", "10.1145/1667239.1667258", "10.1145/1531326.1531332", "10.1145/1833351.1778772", "10.1145/1015706.1015748", "10.1145/2461912.2461980", "10.1145/1073204.1073214", "10.1145/1275808.1276409", "10.1145/1360612.1360636", "10.1145/1141911.1141998", "10.1145/1833349.1778771", "10.1145/1572769.1572792", "10.1145/1667239.1667258", "10.1145/1531326.1531332", "10.1145/1833351.1778772", "10.1145/1015706.1015748", "10.1145/2461912.2461980", "10.1145/1073204.1073214", "10.1145/1275808.1276409", "10.1145/1360612.1360636", "10.1145/1141911.1141998", "10.1145/1833349.1778771", "10.1145/1572769.1572792", "10.1111/j.1467-8659.2012.03050.x", "10.1201/b10632", "10.1111/j.1467-8659.2008.01260.x", "10.2307/3802789", "10.1136/bmj.292.6522.746", "10.1037/0003-066X.49.12.997", "10.2307/2276774", "10.1111/j.1467-8659.2012.03050.x", "10.1201/b10632", "10.1111/j.1467-8659.2008.01260.x", "10.2307/3802789", "10.1136/bmj.292.6522.746", "10.1037/0003-066X.49.12.997", "10.2307/2276774", "10.1111/j.1467-8659.2012.03050.x", "10.1201/b10632", "10.1111/j.1467-8659.2008.01260.x", "10.2307/3802789", "10.1136/bmj.292.6522.746", "10.1037/0003-066X.49.12.997", "10.2307/2276774"]}}