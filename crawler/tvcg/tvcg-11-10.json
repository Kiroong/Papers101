{"10.1109/TVCG.2010.245": {"doi": "10.1109/TVCG.2010.245", "author": ["S. Henderson", "S. Feiner"], "title": "Exploring the Benefits of Augmented Reality Documentation for Maintenance and Repair", "year": "2011", "abstract": "We explore the development of an experimental augmented reality application that provides benefits to professional mechanics performing maintenance and repair tasks in a field setting. We developed a prototype that supports military mechanics conducting routine maintenance tasks inside an armored vehicle turret, and evaluated it with a user study. Our prototype uses a tracked headworn display to augment a mechanic's natural view with text, labels, arrows, and animated sequences designed to facilitate task comprehension, localization, and execution. A within-subject controlled user study examined professional military mechanics using our system to complete 18 common tasks under field conditions. These tasks included installing and removing fasteners and indicator lights, and connecting cables, all within the cramped interior of an armored personnel carrier turret. An augmented reality condition was tested against two baseline conditions: the same headworn display providing untracked text and graphics and a fixed flat panel display representing an improved version of the laptop-based documentation currently employed in practice. The augmented reality condition allowed mechanics to locate tasks more quickly than when using either baseline, and in some instances, resulted in less overall head movement. A qualitative survey showed that mechanics found the augmented reality condition intuitive and satisfying for the tested sequence of tasks.", "keywords": ["augmented reality", "helmet mounted displays", "maintenance engineering", "military computing", "user interfaces", "augmented reality", "maintenance", "repair", "military mechanics", "routine maintenance task", "armored vehicle turret", "task comprehension", "task localization", "task execution", "within-subject controlled user study", "headworn display", "flat panel display", "laptop-based documentation", "Maintenance engineering", "Prototypes", "Three dimensional displays", "Cameras", "Assembly", "Augmented reality", "Software", "Industrial", "military", "user interfaces", "virtual and augmented reality."], "referenced_by": ["10.1109/ISMAR-Adjunct.2016.0101", "10.1109/ISMAR-Adjunct.2017.32", "10.1109/ISMAR-Adjunct.2017.59", "10.1109/ISMAR.2011.6092386", "10.1109/ISMAR.2012.6402562", "10.1109/ISMAR.2013.6671762", "10.1109/ISMAR.2013.6671771", "10.1109/ISMAR.2013.6671840", "10.1109/ISMAR.2014.6948462", "10.1109/ISMAR.2017.27", "10.1109/IntelliSys.2015.7361172", "10.1109/MC.2017.82", "10.1109/NAVCOMP.2013.23", "10.1109/REV.2012.6293130", "10.1109/SAINT.2011.37", "10.1109/SII.2014.7028005", "10.1109/SMC.2013.745", "10.1109/SOFTCOM.2014.7039073", "10.1109/TETC.2014.2368833", "10.1109/TVCG.2014.2385056", "10.1109/TVCG.2018.2794074", "10.1109/VR.2015.7223429", "10.1109/VR.2015.7223458", "10.1109/VR.2016.7504771", "10.1109/WSC.2015.7408234", "10.1109/3DUI.2017.7893338", "10.1109/ACCESS.2018.2802699", "10.1109/AINA.2014.146", "10.1109/CONMEDIA.2017.8266027", "10.1109/CSPC.2017.8305833", "10.1145/2671015.2671123", "10.1145/2702123.2702490", "10.1155/2015/946034", "10.1177/1541931213601303", "10.1371/journal.pone.0127769", "10.1515/ijfe-2017-0122", "10.1590/s1982-21702016000400045", "10.3182/20130522-3-BR-4036.00073", "10.3182/20130811-5-US-2037.00077", "10.3390/mti1040030", "10.1002/sdtp.10704", "10.1007/978-3-319-08234-9_91-1", "10.1007/978-3-319-33386-1_14", "10.1007/978-3-319-40621-3_22", "10.1007/978-3-319-40621-3_25", "10.1007/978-3-319-44215-0_26", "10.1007/978-3-319-60492-3_14", "10.1007/978-3-319-60922-5_30", "10.1007/978-3-319-62217-0_62", "10.1007/978-3-642-22095-1_26", "10.1007/978-3-662-56551-3_12", "10.1007/978-981-10-6144-8_10", "10.1007/978-981-10-6404-3_4", "10.1007/s00779-013-0747-y", "10.1007/s10111-016-0365-3", "10.1007/s10606-015-9232-7", "10.1007/s10707-015-0235-9", "10.1007/s12599-018-0517-5", "10.1007/s12652-017-0547-8", "10.1007/s40436-015-0131-4"], "referencing": ["10.1109/ISMAR.2009.5336484", "10.1109/ISMAR.2006.297789", "10.1109/ISMAR.2007.4538832", "10.1109/HICSS.1992.183317", "10.1109/MCG.1985.276329", "10.1109/ISMAR.2002.1115059", "10.1109/ISMAR.2009.5336486", "10.1109/VRAIS.1998.658416", "10.1109/ISWC.1998.729527", "10.1109/ISMAR.2006.297800", "10.1109/ISMAR.2008.4637328", "10.1109/ISMAR.2008.4637331", "10.1109/ISMAR.2003.1240707", "10.1109/ISMAR.2009.5336484", "10.1109/ISMAR.2006.297789", "10.1109/ISMAR.2007.4538832", "10.1109/HICSS.1992.183317", "10.1109/MCG.1985.276329", "10.1109/ISMAR.2002.1115059", "10.1109/ISMAR.2009.5336486", "10.1109/VRAIS.1998.658416", "10.1109/ISWC.1998.729527", "10.1109/ISMAR.2006.297800", "10.1109/ISMAR.2008.4637328", "10.1109/ISMAR.2008.4637331", "10.1109/ISMAR.2003.1240707", "10.1109/ISMAR.2009.5336484", "10.1109/ISMAR.2006.297789", "10.1109/ISMAR.2007.4538832", "10.1109/HICSS.1992.183317", "10.1109/MCG.1985.276329", "10.1109/ISMAR.2002.1115059", "10.1109/ISMAR.2009.5336486", "10.1109/VRAIS.1998.658416", "10.1109/ISWC.1998.729527", "10.1109/ISMAR.2006.297800", "10.1109/ISMAR.2008.4637328", "10.1109/ISMAR.2008.4637331", "10.1109/ISMAR.2003.1240707", "10.1145/122718.122732", "10.1145/329124.329154", "10.1145/642625.642626", "10.1145/1450579.1450610", "10.1145/1124772.1124939", "10.1145/159544.159587", "10.1145/989863.989917", "10.1145/1394281.1394283", "10.1145/1324892.1324915", "10.1145/122718.122732", "10.1145/329124.329154", "10.1145/642625.642626", "10.1145/1450579.1450610", "10.1145/1124772.1124939", "10.1145/159544.159587", "10.1145/989863.989917", "10.1145/1394281.1394283", "10.1145/1324892.1324915", "10.1145/122718.122732", "10.1145/329124.329154", "10.1145/642625.642626", "10.1145/1450579.1450610", "10.1145/1124772.1124939", "10.1145/159544.159587", "10.1145/989863.989917", "10.1145/1394281.1394283", "10.1145/1324892.1324915", "10.1007/BF01421808", "10.1080/00207540601064773", "10.1007/978-1-84800-241-8_3", "10.1007/BF01421808", "10.1080/00207540601064773", "10.1007/978-1-84800-241-8_3", "10.1007/BF01421808", "10.1080/00207540601064773", "10.1007/978-1-84800-241-8_3"]}, "10.1109/TVCG.2010.241": {"doi": "10.1109/TVCG.2010.241", "author": ["N. Hagbi", "O. Bergig", "J. El-Sana", "M. Billinghurst"], "title": "Shape Recognition and Pose Estimation for Mobile Augmented Reality", "year": "2011", "abstract": "Nestor is a real-time recognition and camera pose estimation system for planar shapes. The system allows shapes that carry contextual meanings for humans to be used as Augmented Reality (AR) tracking targets. The user can teach the system new shapes in real time. New shapes can be shown to the system frontally, or they can be automatically rectified according to previously learned shapes. Shapes can be automatically assigned virtual content by classification according to a shape class library. Nestor performs shape recognition by analyzing contour structures and generating projective-invariant signatures from their concavities. The concavities are further used to extract features for pose estimation and tracking. Pose refinement is carried out by minimizing the reprojection error between sample points on each image contour and its library counterpart. Sample points are matched by evolving an active contour in real time. Our experiments show that the system provides stable and accurate registration, and runs at interactive frame rates on a Nokia N95 mobile phone.", "keywords": ["augmented reality", "error analysis", "feature extraction", "image classification", "image registration", "mobile computing", "mobile handsets", "pose estimation", "shape recognition", "target tracking", "ubiquitous computing", "shape recognition", "mobile augmented reality", "real-time recognition", "camera pose estimation system", "planar shape", "target tracking", "virtual content", "shape class library", "contour structure", "projective-invariant signature", "feature estimation", "pose refinement", "reprojection error", "image contour", "active contour", "interactive frame rate", "Nokia N95 mobile phone", "Shape", "Libraries", "Estimation", "Feature extraction", "Transforms", "Cameras", "Robustness", "Multimedia information systems", "artificial", "augmented", "and virtual realities", "image processing and computer vision", "scene analysis", "tracking."], "referenced_by": ["10.1109/ICCV.2015.115", "10.1109/ISMAR.2013.6671834", "10.1109/IUSER.2016.7857937", "10.1109/LSP.2013.2279014", "10.1109/OCEANS.2016.7761071", "10.1109/SITIS.2013.128", "10.1109/STSIVA.2015.7330433", "10.1109/TPAMI.2017.2658574", "10.1109/VR.2013.6549393", "10.1109/ICMA.2019.8816210", "10.1109/MCG.2016.39", "10.1109/CVPR42600.2020.00192", "10.1145/2645860", "10.1145/2702109.2633419", "10.1145/2897824.2925971", "10.1007/s11042-013-1710-7", "10.3390/s17091951", "10.1016/j.neucom.2017.03.051", "10.1016/j.neucom.2018.02.093", "10.1016/j.patcog.2015.10.023", "10.1016/j.cag.2016.02.002", "10.1117/12.2180574", "10.1007/s11042-018-6905-5", "10.1080/24725854.2018.1493244", "10.1007/978-3-642-39405-8_20", "10.1007/978-1-4614-7705-1_5", "10.1007/978-3-319-09462-5_11", "10.1016/j.patcog.2019.106965", "10.3390/app10010322", "10.1080/09720529.2020.1721867"], "referencing": ["10.1109/VR.2003.1191164", "10.1109/IVL.2000.853834", "10.1109/ISAR.2000.880934", "10.1109/ISMAR.2004.34", "10.1109/ISMAR.2009.5336498", "10.1109/ISMAR.2008.4637339", "10.1109/IWAR.1999.803809", "10.1109/CVPR.2005.74", "10.1109/ISMAR.2007.4538819", "10.1109/CVPR.1999.784996", "10.1109/CVPR.1988.196257", "10.1109/CVPRW.2006.142", "10.1109/TPAMI.2007.41", "10.1109/VR.2010.5444806", "10.1109/34.765658", "10.1109/VR.2003.1191164", "10.1109/IVL.2000.853834", "10.1109/ISAR.2000.880934", "10.1109/ISMAR.2004.34", "10.1109/ISMAR.2009.5336498", "10.1109/ISMAR.2008.4637339", "10.1109/IWAR.1999.803809", "10.1109/CVPR.2005.74", "10.1109/ISMAR.2007.4538819", "10.1109/CVPR.1999.784996", "10.1109/CVPR.1988.196257", "10.1109/CVPRW.2006.142", "10.1109/TPAMI.2007.41", "10.1109/VR.2010.5444806", "10.1109/34.765658", "10.1109/VR.2003.1191164", "10.1109/IVL.2000.853834", "10.1109/ISAR.2000.880934", "10.1109/ISMAR.2004.34", "10.1109/ISMAR.2009.5336498", "10.1109/ISMAR.2008.4637339", "10.1109/IWAR.1999.803809", "10.1109/CVPR.2005.74", "10.1109/ISMAR.2007.4538819", "10.1109/CVPR.1999.784996", "10.1109/CVPR.1988.196257", "10.1109/CVPRW.2006.142", "10.1109/TPAMI.2007.41", "10.1109/VR.2010.5444806", "10.1109/34.765658", "10.1145/769953.769976", "10.1145/237170.237282", "10.1145/769953.769976", "10.1145/237170.237282", "10.1145/769953.769976", "10.1145/237170.237282", "10.1023/A:1007979827043", "10.1007/BF00133570", "10.1561/0600000001", "10.1117/12.256311", "10.1007/3-540-55426-2_86", "10.1016/0004-3702(95)00023-2", "10.1007/11744023_9", "10.1016/j.imavis.2003.09.004", "10.1080/2151237X.2007.10129236", "10.1007/BF01428193", "10.1007/BF00058751", "10.1023/A:1007979827043", "10.1007/BF00133570", "10.1561/0600000001", "10.1117/12.256311", "10.1007/3-540-55426-2_86", "10.1016/0004-3702(95)00023-2", "10.1007/11744023_9", "10.1016/j.imavis.2003.09.004", "10.1080/2151237X.2007.10129236", "10.1007/BF01428193", "10.1007/BF00058751", "10.1023/A:1007979827043", "10.1007/BF00133570", "10.1561/0600000001", "10.1117/12.256311", "10.1007/3-540-55426-2_86", "10.1016/0004-3702(95)00023-2", "10.1007/11744023_9", "10.1016/j.imavis.2003.09.004", "10.1080/2151237X.2007.10129236", "10.1007/BF01428193", "10.1007/BF00058751"]}, "10.1109/TVCG.2010.249": {"doi": "10.1109/TVCG.2010.249", "author": ["S. Nilsson", "B. J. E. Johansson", "A. Jonsson"], "title": "Cross-Organizational Collaboration Supported by Augmented Reality", "year": "2011", "abstract": "This paper presents a study where Augmented Reality (AR) technology has been used as a tool for supporting collaboration between the rescue services, the police and military personnel in a crisis management scenario. There are few studies on how AR systems should be designed to improve cooperation between actors from different organizations while at the same time supporting individual needs. In the present study, an AR system was utilized for supporting joint planning tasks by providing organization specific views of a shared map. The study involved a simulated emergency event conducted in close to real settings with representatives from the organizations for which the system is developed. As a baseline, a series of trials without the AR system was carried out. Results show that the users were positive toward the AR system and would like to use it in real work. They also experience some performance benefits of using the AR system compared to their traditional tools. Finally, the problem of designing for collaborative work as well as the benefits of using an iterative design processes is discussed.", "keywords": ["augmented reality", "emergency services", "groupware", "military systems", "organisational aspects", "personnel", "police", "cross-organizational collaboration", "augmented reality", "rescue services", "police", "military personnel", "crisis management scenario", "collaborative work", "Collaboration", "Joints", "Collaborative work", "Augmented reality", "Personnel", "Helicopters", "Command and control systems", "Collaborative augmented reality", "augmented reality", "user evaluation."], "referenced_by": ["10.1109/VR.2019.8797812", "10.1109/ISMAR.2019.00021", "10.1016/j.procs.2015.08.358", "10.4018/978-1-5225-5469-1.ch060", "10.4018/978-1-5225-5484-4.ch041", "10.1007/s10606-018-9339-8", "10.1007/s10055-020-00492-0"], "referencing": ["10.1109/VISUAL.1997.663921", "10.1109/ISMAR.2002.1115105", "10.1109/ISMAR.2005.32", "10.1109/IWAR.1999.803809", "10.1109/ISMAR.2005.30", "10.1109/ISMAR.2009.5336522", "10.1109/VISUAL.1997.663921", "10.1109/ISMAR.2002.1115105", "10.1109/ISMAR.2005.32", "10.1109/IWAR.1999.803809", "10.1109/ISMAR.2005.30", "10.1109/ISMAR.2009.5336522", "10.1109/VISUAL.1997.663921", "10.1109/ISMAR.2002.1115105", "10.1109/ISMAR.2005.32", "10.1109/IWAR.1999.803809", "10.1109/ISMAR.2005.30", "10.1109/ISMAR.2009.5336522", "10.1145/514236.514265", "10.1145/1324892.1324915", "10.1145/1358628.1358633", "10.1145/1152760.1152776", "10.1145/1149488.1149504", "10.1145/1518701.1518991", "10.1145/1274892.1274923", "10.1145/514236.514265", "10.1145/1324892.1324915", "10.1145/1358628.1358633", "10.1145/1152760.1152776", "10.1145/1149488.1149504", "10.1145/1518701.1518991", "10.1145/1274892.1274923", "10.1145/514236.514265", "10.1145/1324892.1324915", "10.1145/1358628.1358633", "10.1145/1152760.1152776", "10.1145/1149488.1149504", "10.1145/1518701.1518991", "10.1145/1274892.1274923", "10.1017/CBO9780511620539", "10.4018/978-1-59904-066-0", "10.1007/3-540-45348-2_25", "10.1016/S0020-7373(83)80034-0", "10.1016/S0020-7373(87)80095-0", "10.1016/S1071-5819(03)00053-3", "10.1201/9781420038194", "10.1093/sf/45.3.337", "10.1007/s10111-003-0127-x", "10.1016/S0167-739X(00)00039-X", "10.1023/A:1015269228596", "10.1017/CBO9780511620539", "10.4018/978-1-59904-066-0", "10.1007/3-540-45348-2_25", "10.1016/S0020-7373(83)80034-0", "10.1016/S0020-7373(87)80095-0", "10.1016/S1071-5819(03)00053-3", "10.1201/9781420038194", "10.1093/sf/45.3.337", "10.1007/s10111-003-0127-x", "10.1016/S0167-739X(00)00039-X", "10.1023/A:1015269228596", "10.1017/CBO9780511620539", "10.4018/978-1-59904-066-0", "10.1007/3-540-45348-2_25", "10.1016/S0020-7373(83)80034-0", "10.1016/S0020-7373(87)80095-0", "10.1016/S1071-5819(03)00053-3", "10.1201/9781420038194", "10.1093/sf/45.3.337", "10.1007/s10111-003-0127-x", "10.1016/S0167-739X(00)00039-X", "10.1023/A:1015269228596"]}, "10.1109/TVCG.2010.247": {"doi": "10.1109/TVCG.2010.247", "author": ["K. Pothkow", "H. Hege"], "title": "Positional Uncertainty of Isocontours: Condition Analysis and Probabilistic Measures", "year": "2011", "abstract": "Uncertainty is ubiquitous in science, engineering and medicine. Drawing conclusions from uncertain data is the normal case, not an exception. While the field of statistical graphics is well established, only a few 2D and 3D visualization and feature extraction methods have been devised that consider uncertainty. We present mathematical formulations for uncertain equivalents of isocontours based on standard probability theory and statistics and employ them in interactive visualization methods. As input data, we consider discretized uncertain scalar fields and model these as random fields. To create a continuous representation suitable for visualization we introduce interpolated probability density functions. Furthermore, we introduce numerical condition as a general means in feature-based visualization. The condition number-which potentially diverges in the isocontour problem-describes how errors in the input data are amplified in feature computation. We show how the average numerical condition of isocontours aids the selection of thresholds that correspond to robust isocontours. Additionally, we introduce the isocontour density and the level crossing probability field; these two measures for the spatial distribution of uncertain isocontours are directly based on the probabilistic model of the input data. Finally, we adapt interactive visualization methods to evaluate and display these measures and apply them to 2D and 3D data sets.", "keywords": ["data visualisation", "probability", "isocontour positional uncertainty", "statistical graphics", "3D visualization method", "2D visualization method", "feature extraction method", "probability theory", "interactive visualization method", "probability density function", "feature-based visualization", "isocontour density", "level crossing probability", "Uncertainty", "Measurement uncertainty", "Isosurfaces", "Level set", "Random variables", "Systematics", "Uncertainty", "probability", "isolines", "isosurfaces", "numerical condition", "error analysis", "volume visualization."], "referenced_by": ["10.1109/LDAV.2011.6092313", "10.1109/PacificVis.2013.6596144", "10.1109/SciVis.2015.7429488", "10.1109/TVCG.2012.249", "10.1109/TVCG.2013.143", "10.1109/TVCG.2013.144", "10.1109/TVCG.2013.180", "10.1109/TVCG.2013.208", "10.1109/TVCG.2013.92", "10.1109/TVCG.2014.2307892", "10.1109/TVCG.2014.2346448", "10.1109/TVCG.2015.2410278", "10.1109/TVCG.2015.2467204", "10.1109/TVCG.2015.2467958", "10.1109/TVCG.2016.2598604", "10.1109/TVCG.2016.2598619", "10.1109/TVCG.2016.2598869", "10.1109/TVCG.2016.2637333", "10.1109/TVCG.2017.2744099", "10.1109/TVCG.2015.2467031", "10.1109/TVCG.2017.2779501", "10.1109/TVCG.2018.2864801", "10.1109/TVCG.2018.2864432", "10.1109/TVCG.2018.2864815", "10.1109/TVCG.2018.2853721", "10.1109/TVCG.2019.2934256", "10.1109/TVCG.2019.2934242", "10.1109/VISUAL.2019.8933720", "10.1109/TVCG.2018.2879866", "10.1007/978-3-319-25135-6_32", "10.1007/s00371-017-1359-8", "10.1007/s11069-015-1596-y", "10.1016/j.cag.2013.10.012", "10.1016/j.cag.2014.01.007", "10.1016/j.cag.2015.08.008", "10.1111/cgf.12100", "10.1111/cgf.12899", "10.1111/cgf.12912", "10.1111/cgf.13173", "10.1111/cgf.13262", "10.1111/j.1467-8659.2012.03097.x", "10.1111/j.1467-8659.2012.03127.x", "10.1177/1555343415591275", "10.1190/segam2014-1282.1", "10.1201/b15025-18", "10.4018/978-1-4666-4309-3.ch004", "10.4018/978-1-4666-9840-6.ch014", "10.1117/12.2036465", "10.1117/12.2043659", "10.5194/gmd-8-2329-2015", "10.3390/e20070540", "10.1016/j.cag.2018.12.005", "10.1007/978-3-642-27343-8_11", "10.1007/978-1-4471-6497-5_4", "10.1111/j.1467-8659.2011.01942.x", "10.1111/cgf.13731", "10.1007/978-3-030-14227-8_10", "10.1007/s12650-019-00598-x", "10.5194/gmdd-8-2101-2015"], "referencing": ["10.1109/2945.537309", "10.1109/VISUAL.2005.1532853", "10.1109/TVCG.2007.70530", "10.1109/VISUAL.2005.1532807", "10.1109/TVCG.2007.70518", "10.1109/38.865880", "10.1109/TVCG.2008.140", "10.1109/MCG.2003.1231171", "10.1109/TVCG.2004.30", "10.1109/VISUAL.2003.1250414", "10.1109/TVCG.2008.160", "10.1109/TVCG.2007.1053", "10.1109/VISUAL.1997.663875", "10.1109/VISUAL.2001.964515", "10.1109/VISUAL.2003.1250384", "10.1109/2945.537309", "10.1109/VISUAL.2005.1532853", "10.1109/TVCG.2007.70530", "10.1109/VISUAL.2005.1532807", "10.1109/TVCG.2007.70518", "10.1109/38.865880", "10.1109/TVCG.2008.140", "10.1109/MCG.2003.1231171", "10.1109/TVCG.2004.30", "10.1109/VISUAL.2003.1250414", "10.1109/TVCG.2008.160", "10.1109/TVCG.2007.1053", "10.1109/VISUAL.1997.663875", "10.1109/VISUAL.2001.964515", "10.1109/VISUAL.2003.1250384", "10.1109/2945.537309", "10.1109/VISUAL.2005.1532853", "10.1109/TVCG.2007.70530", "10.1109/VISUAL.2005.1532807", "10.1109/TVCG.2007.70518", "10.1109/38.865880", "10.1109/TVCG.2008.140", "10.1109/MCG.2003.1231171", "10.1109/TVCG.2004.30", "10.1109/VISUAL.2003.1250414", "10.1109/TVCG.2008.160", "10.1109/TVCG.2007.1053", "10.1109/VISUAL.1997.663875", "10.1109/VISUAL.2001.964515", "10.1109/VISUAL.2003.1250384", "10.1145/37401.37422", "10.1145/37401.37422", "10.1145/37401.37422", "10.1117/12.768317", "10.1111/j.1467-8659.2009.01604.x", "10.1016/j.cageo.2010.02.010", "10.1559/1523040054738936", "10.1007/978-0-387-78650-6", "10.1887/0750308400", "10.1016/S0019-9958(65)90241-X", "10.1016/S0097-8493(02)00055-9", "10.1002/9780470434642", "10.1007/978-0-387-21584-6", "10.1016/j.atmosenv.2008.12.013", "10.1088/0031-9155/44/12/403", "10.1002/sca.4950230506", "10.1007/s003710050111", "10.1117/12.768317", "10.1111/j.1467-8659.2009.01604.x", "10.1016/j.cageo.2010.02.010", "10.1559/1523040054738936", "10.1007/978-0-387-78650-6", "10.1887/0750308400", "10.1016/S0019-9958(65)90241-X", "10.1016/S0097-8493(02)00055-9", "10.1002/9780470434642", "10.1007/978-0-387-21584-6", "10.1016/j.atmosenv.2008.12.013", "10.1088/0031-9155/44/12/403", "10.1002/sca.4950230506", "10.1007/s003710050111", "10.1117/12.768317", "10.1111/j.1467-8659.2009.01604.x", "10.1016/j.cageo.2010.02.010", "10.1559/1523040054738936", "10.1007/978-0-387-78650-6", "10.1887/0750308400", "10.1016/S0019-9958(65)90241-X", "10.1016/S0097-8493(02)00055-9", "10.1002/9780470434642", "10.1007/978-0-387-21584-6", "10.1016/j.atmosenv.2008.12.013", "10.1088/0031-9155/44/12/403", "10.1002/sca.4950230506", "10.1007/s003710050111"]}, "10.1109/TVCG.2010.244": {"doi": "10.1109/TVCG.2010.244", "author": ["V. Prckovska", "T. H. J. M. Peeters", "M. van Almsick", "B. t. H. Romeny", "A. Vilanova i Bartroli"], "title": "Fused DTI/HARDI Visualization", "year": "2011", "abstract": "High-angular resolution diffusion imaging (HARDI) is a diffusion weighted MRI technique that overcomes some of the decisive limitations of its predecessor, diffusion tensor imaging (DTI), in the areas of composite nerve fiber structure. Despite its advantages, HARDI raises several issues: complex modeling of the data, nonintuitive and computationally demanding visualization, inability to interactively explore and transform the data, etc. To overcome these drawbacks, we present a novel, multifield visualization framework that adopts the benefits of both DTI and HARDI. By applying a classification scheme based on HARDI anisotropy measures, the most suitable model per imaging voxel is automatically chosen. This classification allows simplification of the data in areas with single fiber bundle coherence. To accomplish fast and interactive visualization for both HARDI and DTI modalities, we exploit the capabilities of modern GPUs for glyph rendering and adopt DTI fiber tracking in suitable regions. The resulting framework, allows user-friendly data exploration of fused HARDI and DTI data. Many incorporated features such as sharpening, normalization, maxima enhancement and different types of color coding of the HARDI glyphs, simplify the data and enhance its features. We provide a qualitative user evaluation that shows the potentials of our visualization tools in several HARDI applications.", "keywords": ["biomedical MRI", "data visualisation", "medical image processing", "rendering (computer graphics)", "DTI/HARDI visualization", "high-angular resolution diffusion imaging", "diffusion weighted MRI", "diffusion tensor imaging", "multifield visualization framework", "modern GPU", "glyph rendering", "DTI fiber tracking", "Diffusion tensor imaging", "Data visualization", "Tensile stress", "Rendering (computer graphics)", "Anisotropic magnetoresistance", "Ellipsoids", "Harmonic analysis", "DTI", "HARDI", "diffusion", "GPU", "glyphs", "multifield.", "Adult", "Algorithms", "Animals", "Anisotropy", "Brain", "Diffusion Tensor Imaging", "Female", "Humans", "Image Processing, Computer-Assisted", "Nerve Fibers", "Phantoms, Imaging", "Rats", "Reproducibility of Results"], "referenced_by": ["10.1109/TVCG.2014.2346411", "10.1109/TVCG.2016.2598472", "10.1109/JBHI.2014.2367026", "10.1007/s12650-014-0260-z", "10.1016/B978-0-12-415873-3.00035-3", "10.1016/j.jneumeth.2015.06.016", "10.1016/j.neuroimage.2013.04.111", "10.1227/NEU.0b013e318270d9fb", "10.1371/journal.pone.0070973", "10.1371/journal.pone.0081453", "10.1002/nbm.3902", "10.1007/978-3-642-38085-3_5", "10.1007/978-3-662-45289-9_20", "10.1007/978-3-662-45283-7_26"], "referencing": ["10.1109/TVCG.2008.128", "10.1109/PACIFICVIS.2009.4906849", "10.1109/PACIFICVIS.2009.4906851", "10.1109/ISBI.2007.356962", "10.1109/TVCG.2008.128", "10.1109/PACIFICVIS.2009.4906849", "10.1109/PACIFICVIS.2009.4906851", "10.1109/ISBI.2007.356962", "10.1109/TVCG.2008.128", "10.1109/PACIFICVIS.2009.4906849", "10.1109/PACIFICVIS.2009.4906851", "10.1109/ISBI.2007.356962", "10.1002/mrm.10156", "10.1002/mrm.20931", "10.1007/978-3-540-76858-6_34", "10.1007/11505730_5", "10.1016/j.neuroimage.2007.02.016", "10.1002/mrm.1105", "10.1002/mrm.10209", "10.1002/mrm.20667", "10.1016/S0006-3495(94)80775-1", "10.1002/mrm.20411", "10.1002/mrm.20279", "10.1002/mrm.20948", "10.1002/mrm.21277", "10.1016/j.neuroimage.2007.04.039", "10.1111/j.1467-8659.2008.01132.x", "10.1002/nbm.781", "10.1002/mrm.10596", "10.1016/j.neuroimage.2006.01.024", "10.1002/mrm.10156", "10.1002/mrm.20931", "10.1007/978-3-540-76858-6_34", "10.1007/11505730_5", "10.1016/j.neuroimage.2007.02.016", "10.1002/mrm.1105", "10.1002/mrm.10209", "10.1002/mrm.20667", "10.1016/S0006-3495(94)80775-1", "10.1002/mrm.20411", "10.1002/mrm.20279", "10.1002/mrm.20948", "10.1002/mrm.21277", "10.1016/j.neuroimage.2007.04.039", "10.1111/j.1467-8659.2008.01132.x", "10.1002/nbm.781", "10.1002/mrm.10596", "10.1016/j.neuroimage.2006.01.024", "10.1002/mrm.10156", "10.1002/mrm.20931", "10.1007/978-3-540-76858-6_34", "10.1007/11505730_5", "10.1016/j.neuroimage.2007.02.016", "10.1002/mrm.1105", "10.1002/mrm.10209", "10.1002/mrm.20667", "10.1016/S0006-3495(94)80775-1", "10.1002/mrm.20411", "10.1002/mrm.20279", "10.1002/mrm.20948", "10.1002/mrm.21277", "10.1016/j.neuroimage.2007.04.039", "10.1111/j.1467-8659.2008.01132.x", "10.1002/nbm.781", "10.1002/mrm.10596", "10.1016/j.neuroimage.2006.01.024"]}, "10.1109/TVCG.2010.234": {"doi": "10.1109/TVCG.2010.234", "author": ["T. Meng", "A. Entezari", "B. Smith", "T. Moller", "D. Weiskopf", "A. E. Kirkpatrick"], "title": "Visual Comparability of 3D Regular Sampling and Reconstruction", "year": "2011", "abstract": "The Body-Centered Cubic (BCC) and Face-Centered Cubic (FCC) lattices have been analytically shown to be more efficient sampling lattices than the traditional Cartesian Cubic (CC) lattice, but there has been no estimate of their visual comparability. Two perceptual studies (each with N = 12 participants) compared the visual quality of images rendered from BCC and FCC lattices to images rendered from the CC lattice. Images were generated from two signals: the commonly used Marschner-Lobb synthetic function and a computed tomography scan of a fish tail. Observers found that BCC and FCC could produce images of comparable visual quality to CC, using 30-35 percent fewer samples. For the images used in our studies, the L2 error metric shows high correlation with the judgement of human observers. Using the L2 metric as a proxy, the results of the experiments appear to extend across a wide range of images and parameter choices.", "keywords": ["image reconstruction", "rendering (computer graphics)", "sampling methods", "visual comparability", "3D regular sampling", "3D reconstruction", "body-centered cubic lattice", "face-centered cubic lattice", "sampling lattice", "image visual quality", "image rendering", "Marschner-Lobb synthetic function", "fish tail tomography scan", "L2 error metric", "Lattices", "FCC", "Image reconstruction", "Image resolution", "Visualization", "Marine animals", "Observers", "Visual comparability", "perceptual quality", "3D regular sampling and reconstruction", "cartesian cubic (CC) lattice", "body-centered cubic (BCC) lattice", "face-centered cubic (FCC) lattice.", "Algorithms", "Animals", "Fishes", "Humans", "Image Processing, Computer-Assisted", "Image Processing, Computer-Assisted", "Models, Theoretical", "Tail", "Tomography, X-Ray Computed"], "referenced_by": ["10.1109/CADGraphics.2013.46", "10.1109/TVCG.2013.7", "10.1109/CONTROLO.2018.8514300", "10.1111/cgf.12364"], "referencing": ["10.1109/83.210873", "10.1109/TIT.2004.840864", "10.1109/VISUAL.1994.346331", "10.1109/VISUAL.2004.65", "10.1109/TVCG.2007.70429", "10.1109/5.843002", "10.1109/83.210873", "10.1109/TIT.2004.840864", "10.1109/VISUAL.1994.346331", "10.1109/VISUAL.2004.65", "10.1109/TVCG.2007.70429", "10.1109/5.843002", "10.1109/83.210873", "10.1109/TIT.2004.840864", "10.1109/VISUAL.1994.346331", "10.1109/VISUAL.2004.65", "10.1109/TVCG.2007.70429", "10.1109/5.843002", "10.1145/1268517.1268560", "10.1145/378456.378514", "10.1145/1268517.1268560", "10.1145/378456.378514", "10.1145/1268517.1268560", "10.1145/378456.378514", "10.1111/1467-8659.00161", "10.1016/B978-012387582-2/50009-5", "10.1016/j.image.2003.08.003", "10.1080/01621459.1987.10478410", "10.1016/S0019-9958(62)90633-2", "10.3758/BF03194544", "10.3758/BF03194545", "10.1111/1467-8659.00161", "10.1016/B978-012387582-2/50009-5", "10.1016/j.image.2003.08.003", "10.1080/01621459.1987.10478410", "10.1016/S0019-9958(62)90633-2", "10.3758/BF03194544", "10.3758/BF03194545", "10.1111/1467-8659.00161", "10.1016/B978-012387582-2/50009-5", "10.1016/j.image.2003.08.003", "10.1080/01621459.1987.10478410", "10.1016/S0019-9958(62)90633-2", "10.3758/BF03194544", "10.3758/BF03194545"]}, "10.1109/TVCG.2010.235": {"doi": "10.1109/TVCG.2010.235", "author": ["J. Reininghaus", "C. Lowen", "I. Hotz"], "title": "Fast Combinatorial Vector Field Topology", "year": "2011", "abstract": "This paper introduces a novel approximation algorithm for the fundamental graph problem of combinatorial vector field topology (CVT). CVT is a combinatorial approach based on a sound theoretical basis given by Forman's work on a discrete Morse theory for dynamical systems. A computational framework for this mathematical model of vector field topology has been developed recently. The applicability of this framework is however severely limited by the quadratic complexity of its main computational kernel. In this work, we present an approximation algorithm for CVT with a significantly lower complexity. This new algorithm reduces the runtime by several orders of magnitude and maintains the main advantages of CVT over the continuous approach. Due to the simplicity of our algorithm it can be easily parallelized to improve the runtime further.", "keywords": ["approximation theory", "computational complexity", "data analysis", "data visualisation", "graph theory", "combinatorial vector field topology", "Morse dynamical systems theory", "quadratic complexity", "approximation algorithm", "vector field visualization", "topological data analysis", "graph problem", "Approximation algorithms", "Topology", "Prediction algorithms", "Approximation methods", "Skeleton", "Runtime", "Orbits", "Flow visualization", "graph algorithms."], "referenced_by": ["10.1109/PacificVis.2014.17", "10.1109/TVCG.2011.107", "10.1109/TVCG.2011.284", "10.1109/TVCG.2012.147", "10.1109/TVCG.2012.209", "10.1109/TVCG.2013.229", "10.1109/TVCG.2015.2440250", "10.1109/TVCG.2016.2534538", "10.1109/TVCG.2011.265", "10.1109/TVCG.2018.2864848", "10.1007/s00200-014-0246-z", "10.1016/j.cagd.2012.03.012", "10.1016/j.cagd.2012.03.022", "10.1016/j.patrec.2016.05.034", "10.1007/978-3-319-44684-4_11", "10.1007/978-3-319-04099-8_2", "10.1007/978-3-642-23175-9_10", "10.1007/978-3-642-23175-9_1", "10.1007/978-3-319-04099-8_1", "10.1007/978-3-319-04099-8_3", "10.1007/978-3-319-21963-9_27", "10.1111/j.1467-8659.2012.03087.x", "10.1111/j.1467-8659.2012.03104.x", "10.1111/j.1467-8659.2012.03089.x"], "referencing": ["10.1109/VISUAL.2001.964507", "10.1109/VISUAL.2005.1532842", "10.1109/TVCG.2007.1021", "10.1109/2.35197", "10.1109/2945.928168", "10.1109/TVCG.2006.57", "10.1109/TVCG.2004.18", "10.1109/VISUAL.2001.964507", "10.1109/VISUAL.2005.1532842", "10.1109/TVCG.2007.1021", "10.1109/2.35197", "10.1109/2945.928168", "10.1109/TVCG.2006.57", "10.1109/TVCG.2004.18", "10.1109/VISUAL.2001.964507", "10.1109/VISUAL.2005.1532842", "10.1109/TVCG.2007.1021", "10.1109/2.35197", "10.1109/2945.928168", "10.1109/TVCG.2006.57", "10.1109/TVCG.2004.18", "10.1145/777792.777846", "10.1145/777792.777846", "10.1145/777792.777846", "10.1006/aima.1997.1650", "10.1007/PL00004638", "10.1002/nav.3800020109", "10.1007/978-3-540-77220-0_21", "10.1007/978-3-7091-6215-6_12", "10.1007/978-3-540-70823-0_3", "10.1007/s00454-002-2885-2", "10.1090/conm/453/08802", "10.1007/978-3-540-70823-0_1", "10.1006/aima.1997.1650", "10.1007/PL00004638", "10.1002/nav.3800020109", "10.1007/978-3-540-77220-0_21", "10.1007/978-3-7091-6215-6_12", "10.1007/978-3-540-70823-0_3", "10.1007/s00454-002-2885-2", "10.1090/conm/453/08802", "10.1007/978-3-540-70823-0_1", "10.1006/aima.1997.1650", "10.1007/PL00004638", "10.1002/nav.3800020109", "10.1007/978-3-540-77220-0_21", "10.1007/978-3-7091-6215-6_12", "10.1007/978-3-540-70823-0_3", "10.1007/s00454-002-2885-2", "10.1090/conm/453/08802", "10.1007/978-3-540-70823-0_1"]}, "10.1109/TVCG.2010.237": {"doi": "10.1109/TVCG.2010.237", "author": ["L. Bartram", "M. C. Stone"], "title": "Whisper, Don't Scream: Grids and Transparency", "year": "2011", "abstract": "Visual elements such as grids, labels, and contour lines act as reference structures that support the primary information being presented. Such structures need to be usefully visible, but not so obtrusive that they clutter the presentation. Visual designers know how to carefully manage transparency and layering in an image to balance these elements. We want the presentation of these structures in complex, dynamic, computer-generated visualizations to reflect the same subtlety and comfort of good design. Our goal is to determine the physical, perceptual, and cognitive characteristics of such structures in a way that enables automatic presentation. Our approach to this problem does not try to characterize \"ideal\u201d or \"best,\u201d but instead seeks boundary conditions that define a range of visible yet subtle legibility. All presentations that are clearly bad lie outside of this range, and can easily be avoided. In this paper, we report three experiments investigating the effects of grid color and spacing on these boundary conditions, defined by manipulating the transparency (alpha) of thin rectangular grids over scatter plots. Our results show that while there is some variation due to user preference and image properties, bounding alpha allows us to reliably predict a range of usable yet unobtrusive grids over a wide variety of conditions.", "keywords": ["data visualisation", "image colour analysis", "user interfaces", "grid element", "line element", "contour lines", "visual designers", "image transparency", "image layering", "computer-generated visualization", "grid color effect", "user preference", "bounding alpha", "image property", "Visualization", "Rendering (computer graphics)", "Data visualization", "Image color analysis", "Art", "Complexity theory", "Measurement", "Index Terms\u2014Information visualization", "automated presentation", "applied perception", "visual design."], "referenced_by": ["10.1109/TVCG.2013.163", "10.1109/TVCG.2011.242", "10.1109/PacificVis.2013.6596122", "10.1109/TVCG.2017.2747545", "10.1109/VAST.2018.8802449", "10.1109/TVCG.2019.2934432", "10.1016/B978-0-12-809715-1.00007-9", "10.1016/j.cag.2012.04.009"], "referencing": ["10.1109/TVCG.2008.29", "10.1109/TVCG.2006.180", "10.1109/TVCG.2007.70559", "10.1109/38.329093", "10.1109/MCG.2005.102", "10.1109/ICIAP.2007.4362786", "10.1109/MCG.2005.91", "10.1109/TVCG.2006.58", "10.1109/MCG.2004.20", "10.1109/TVCG.2008.29", "10.1109/TVCG.2006.180", "10.1109/TVCG.2007.70559", "10.1109/38.329093", "10.1109/MCG.2005.102", "10.1109/ICIAP.2007.4362786", "10.1109/MCG.2005.91", "10.1109/TVCG.2006.58", "10.1109/MCG.2004.20", "10.1109/TVCG.2008.29", "10.1109/TVCG.2006.180", "10.1109/TVCG.2007.70559", "10.1109/38.329093", "10.1109/MCG.2005.102", "10.1109/ICIAP.2007.4362786", "10.1109/MCG.2005.91", "10.1109/TVCG.2006.58", "10.1109/MCG.2004.20", "10.1145/166117.166126", "10.1145/146443.146467", "10.1145/234526.234532", "10.1145/1120212.1120348", "10.1145/238386.238583", "10.1145/215585.215669", "10.1145/1753326.1753357", "10.1145/965500.965505", "10.1145/166117.166126", "10.1145/146443.146467", "10.1145/234526.234532", "10.1145/1120212.1120348", "10.1145/238386.238583", "10.1145/215585.215669", "10.1145/1753326.1753357", "10.1145/965500.965505", "10.1145/166117.166126", "10.1145/146443.146467", "10.1145/234526.234532", "10.1145/1120212.1120348", "10.1145/238386.238583", "10.1145/215585.215669", "10.1145/1753326.1753357", "10.1145/965500.965505", "10.1016/S0098-3004(97)00018-6", "10.1038/scientificamerican0474-90", "10.1037/0033-295X.109.3.492", "10.2307/1419876", "10.1093/acprof:oso/9780198524793.001.0001", "10.1111/j.1467-9280.2005.01588.x", "10.1016/0042-6989(87)90028-9", "10.1016/S0098-3004(97)00018-6", "10.1038/scientificamerican0474-90", "10.1037/0033-295X.109.3.492", "10.2307/1419876", "10.1093/acprof:oso/9780198524793.001.0001", "10.1111/j.1467-9280.2005.01588.x", "10.1016/0042-6989(87)90028-9", "10.1016/S0098-3004(97)00018-6", "10.1038/scientificamerican0474-90", "10.1037/0033-295X.109.3.492", "10.2307/1419876", "10.1093/acprof:oso/9780198524793.001.0001", "10.1111/j.1467-9280.2005.01588.x", "10.1016/0042-6989(87)90028-9"]}, "10.1109/TVCG.2010.236": {"doi": "10.1109/TVCG.2010.236", "author": ["M. Cabral", "N. Bonneel", "S. Lefebvre", "G. Drettakis"], "title": "Relighting Photographs of Tree Canopies", "year": "2011", "abstract": "We present an image-based approach to relighting photographs of tree canopies. Our goal is to minimize capture overhead; thus the only input required is a set of photographs of the tree taken at a single time of day, while allowing relighting at any other time. We first analyze lighting in a tree canopy both theoretically and using simulations. From this analysis, we observe that tree canopy lighting is similar to volumetric illumination. We assume a single-scattering volumetric lighting model for tree canopies, and diffuse leaf reflectance; we validate our assumptions with synthetic renderings. We create a volumetric representation of the tree from 10-12 images taken at a single time of day and use a single-scattering participating media lighting model. An analytical sun and sky illumination model provides consistent representation of lighting for the captured input and unknown target times. We relight the input image by applying a ratio of the target and input time lighting representations. We compute this representation efficiently by simultaneously coding transmittance from the sky and to the eye in spherical harmonics. We validate our method by relighting images of synthetic trees and comparing to path-traced solutions. We also present results for photographs, validating with time-lapse ground truth sequences.", "keywords": ["image representation", "image sequences", "lighting", "rendering (computer graphics)", "vegetation", "photograph relighting", "tree canopy lighting", "image-based approach", "single-scattering volumetric lighting model", "leaf reflectance diffusion", "synthetic renderings", "volumetric representation", "sun illumination model", "sky illumination model", "input time lighting representations", "target time lighting representations", "time-lapse ground truth sequences", "image-based rendering", "Lighting", "Computational modeling", "Rendering (computer graphics)", "Approximation methods", "Sun", "Pixel", "Media", "Image-based rendering", "relighting."], "referenced_by": ["10.1109/ICCV.2017.567", "10.1111/cgf.13149"], "referencing": ["10.1109/2945.895874", "10.1109/38.988744", "10.1109/34.908964", "10.1109/CVPR.2000.855872", "10.1109/TPAMI.2007.1177", "10.1109/2945.764865", "10.1109/38.920627", "10.1109/2945.895874", "10.1109/38.988744", "10.1109/34.908964", "10.1109/CVPR.2000.855872", "10.1109/TPAMI.2007.1177", "10.1109/2945.764865", "10.1109/38.920627", "10.1109/2945.895874", "10.1109/38.988744", "10.1109/34.908964", "10.1109/CVPR.2000.855872", "10.1109/TPAMI.2007.1177", "10.1109/2945.764865", "10.1109/38.920627", "10.1145/280814.280874", "10.1145/311535.311559", "10.1145/882262.882315", "10.1145/383259.383270", "10.1145/344779.344855", "10.1145/1276377.1276442", "10.1145/1276377.1276487", "10.1145/383259.383289", "10.1145/964965.808594", "10.1145/566570.566612", "10.1145/1730804.1730831", "10.1145/311535.311545", "10.1145/1618452.1618505", "10.1145/636886.636890", "10.1145/1015706.1015785", "10.1145/280814.280864", "10.1145/1409060.1409061", "10.1145/280814.280874", "10.1145/311535.311559", "10.1145/882262.882315", "10.1145/383259.383270", "10.1145/344779.344855", "10.1145/1276377.1276442", "10.1145/1276377.1276487", "10.1145/383259.383289", "10.1145/964965.808594", "10.1145/566570.566612", "10.1145/1730804.1730831", "10.1145/311535.311545", "10.1145/1618452.1618505", "10.1145/636886.636890", "10.1145/1015706.1015785", "10.1145/280814.280864", "10.1145/1409060.1409061", "10.1145/280814.280874", "10.1145/311535.311559", "10.1145/882262.882315", "10.1145/383259.383270", "10.1145/344779.344855", "10.1145/1276377.1276442", "10.1145/1276377.1276487", "10.1145/383259.383289", "10.1145/964965.808594", "10.1145/566570.566612", "10.1145/1730804.1730831", "10.1145/311535.311545", "10.1145/1618452.1618505", "10.1145/636886.636890", "10.1145/1015706.1015785", "10.1145/280814.280864", "10.1145/1409060.1409061", "10.1364/AO.28.004735", "10.1016/S0168-1923(97)00097-X", "10.1007/s00371-005-0287-1", "10.1111/j.1467-8659.2008.01257.x", "10.1029/93JD02072", "10.1007/s11263-007-0107-3", "10.1364/AO.28.004735", "10.1016/S0168-1923(97)00097-X", "10.1007/s00371-005-0287-1", "10.1111/j.1467-8659.2008.01257.x", "10.1029/93JD02072", "10.1007/s11263-007-0107-3", "10.1364/AO.28.004735", "10.1016/S0168-1923(97)00097-X", "10.1007/s00371-005-0287-1", "10.1111/j.1467-8659.2008.01257.x", "10.1029/93JD02072", "10.1007/s11263-007-0107-3"]}, "10.1109/TVCG.2010.254": {"doi": "10.1109/TVCG.2010.254", "author": ["G. Zhang", "H. Jiang", "J. Huang", "J. Jia", "T. Wong", "K. Zhou", "H. Bao"], "title": "Motion Imitation with a Handheld Camera", "year": "2011", "abstract": "In this paper, we present a novel method to extract motion of a dynamic object from a video that is captured by a handheld camera, and apply it to a 3D character. Unlike the motion capture techniques, neither special sensors/trackers nor a controllable environment is required. Our system significantly automates motion imitation which is traditionally conducted by professional animators via manual keyframing. Given the input video sequence, we track the dynamic reference object to obtain trajectories of both 2D and 3D tracking points. With them as constraints, we then transfer the motion to the target 3D character by solving an optimization problem to maintain the motion gradients. We also provide a user-friendly editing environment for users to fine tune the motion details. As casual videos can be used, our system, therefore, greatly increases the supply source of motion data. Examples of imitating various types of animal motion are shown.", "keywords": ["cameras", "image motion analysis", "image sequences", "optimisation", "video signal processing", "motion imitation", "handheld camera", "motion extraction", "motion capture techniques", "video sequence", "optimization problem", "Three dimensional displays", "Target tracking", "Cameras", "Solid modeling", "Deformable models", "Shape", "Motion imitation", "motion gradient", "mesh deformation", "depth recovery", "motion tracking."], "referenced_by": [], "referencing": ["10.1109/CVPR.2006.19", "10.1109/CVPR.2008.4587495", "10.1109/TPAMI.2007.70752", "10.1109/CVPR.2008.4587679", "10.1109/CA.2002.1017510", "10.1109/TVCG.2006.47", "10.1109/CVPR.2007.383118", "10.1109/TPAMI.2009.52", "10.1109/TMI.2004.835603", "10.1109/CVPR.2006.158", "10.1109/CVPR.2006.19", "10.1109/CVPR.2008.4587495", "10.1109/TPAMI.2007.70752", "10.1109/CVPR.2008.4587679", "10.1109/CA.2002.1017510", "10.1109/TVCG.2006.47", "10.1109/CVPR.2007.383118", "10.1109/TPAMI.2009.52", "10.1109/TMI.2004.835603", "10.1109/CVPR.2006.158", "10.1109/CVPR.2006.19", "10.1109/CVPR.2008.4587495", "10.1109/TPAMI.2007.70752", "10.1109/CVPR.2008.4587679", "10.1109/CA.2002.1017510", "10.1109/TVCG.2006.47", "10.1109/CVPR.2007.383118", "10.1109/TPAMI.2009.52", "10.1109/TMI.2004.835603", "10.1109/CVPR.2006.158", "10.1145/1276377.1276486", "10.1145/1276377.1276485", "10.1145/1015706.1015766", "10.1145/1360612.1360698", "10.1145/882262.882310", "10.1145/344779.344862", "10.1145/1073204.1073229", "10.1145/258734.258863", "10.1145/1141911.1142000", "10.1145/1015706.1015774", "10.1145/1073204.1073217", "10.1145/1073204.1073219", "10.1145/1073204.1073324", "10.1145/1141911.1142003", "10.1145/1276377.1276482", "10.1145/1015706.1015736", "10.1145/566654.566595", "10.1145/1276377.1276421", "10.1145/280814.280820", "10.1145/1360612.1360626", "10.1145/1276377.1276486", "10.1145/1276377.1276485", "10.1145/1015706.1015766", "10.1145/1360612.1360698", "10.1145/882262.882310", "10.1145/344779.344862", "10.1145/1073204.1073229", "10.1145/258734.258863", "10.1145/1141911.1142000", "10.1145/1015706.1015774", "10.1145/1073204.1073217", "10.1145/1073204.1073219", "10.1145/1073204.1073324", "10.1145/1141911.1142003", "10.1145/1276377.1276482", "10.1145/1015706.1015736", "10.1145/566654.566595", "10.1145/1276377.1276421", "10.1145/280814.280820", "10.1145/1360612.1360626", "10.1145/1276377.1276486", "10.1145/1276377.1276485", "10.1145/1015706.1015766", "10.1145/1360612.1360698", "10.1145/882262.882310", "10.1145/344779.344862", "10.1145/1073204.1073229", "10.1145/258734.258863", "10.1145/1141911.1142000", "10.1145/1015706.1015774", "10.1145/1073204.1073217", "10.1145/1073204.1073219", "10.1145/1073204.1073324", "10.1145/1141911.1142003", "10.1145/1276377.1276482", "10.1145/1015706.1015736", "10.1145/566654.566595", "10.1145/1276377.1276421", "10.1145/280814.280820", "10.1145/1360612.1360626", "10.1016/j.cviu.2006.08.002", "10.1016/j.cviu.2006.10.016", "10.1016/j.gmod.2005.04.002", "10.1017/CBO9780511811685", "10.1023/B:VISI.0000025798.50602.3a", "10.1016/j.cviu.2006.08.002", "10.1016/j.cviu.2006.10.016", "10.1016/j.gmod.2005.04.002", "10.1017/CBO9780511811685", "10.1023/B:VISI.0000025798.50602.3a", "10.1016/j.cviu.2006.08.002", "10.1016/j.cviu.2006.10.016", "10.1016/j.gmod.2005.04.002", "10.1017/CBO9780511811685", "10.1023/B:VISI.0000025798.50602.3a"]}, "10.1109/TVCG.2010.229": {"doi": "10.1109/TVCG.2010.229", "author": ["J. Lawrence", "S. Arietta", "M. Kazhdan", "D. Lepage", "C. O'Hagan"], "title": "A User-Assisted Approach to Visualizing Multidimensional Images", "year": "2011", "abstract": "We present a new technique for fusing together an arbitrary number of aligned images into a single color or intensity image. We approach this fusion problem from the context of Multidimensional Scaling (MDS) and describe an algorithm that preserves the relative distances between pairs of pixel values in the input (vectors of measurements) as perceived differences in a color image. The two main advantages of our approach over existing techniques are that it can incorporate user constraints into the mapping process and allows adaptively compressing or exaggerating features in the input in order to make better use of the output's limited dynamic range. We demonstrate these benefits by showing applications in various scientific domains and comparing our algorithm to previously proposed techniques.", "keywords": ["data visualisation", "image colour analysis", "user interfaces", "user-assisted approach", "multidimensional image visualization", "multidimensional scaling context", "color image", "intensity image", "mapping process", "Pixel", "Image color analysis", "Stress", "Equations", "Linear systems", "Laplace equations", "Color", "Multidimensional images", "visualization techniques", "dimensionality reduction", "multidimensional scaling", "physical sciences and engineering", "life and medical sciences."], "referenced_by": ["10.1109/TVCG.2018.2808489", "10.1007/978-3-319-58771-4_54", "10.1016/j.ins.2014.03.048", "10.1016/j.neucom.2015.05.071", "10.1080/19479832.2011.622723", "10.1007/978-3-030-03243-2_827-1"], "referencing": ["10.1109/ICCV.1993.378222", "10.1109/TGRS.2003.808879", "10.1109/TGRS.2005.857623", "10.1109/TCOM.1973.1091550", "10.1109/TIP.2002.801588", "10.1109/36.752192", "10.1109/T-C.1974.224051", "10.1109/83.535844", "10.1109/36.739109", "10.1109/TGRS.2008.916203", "10.1109/TGRS.2008.2010129", "10.1109/83.536897", "10.1109/CNE.2003.1196824", "10.1109/TCOM.1983.1095851", "10.1109/34.142909", "10.1109/CVPR.1999.786958", "10.1109/TVCG.2008.85", "10.1109/ICCV.1993.378222", "10.1109/TGRS.2003.808879", "10.1109/TGRS.2005.857623", "10.1109/TCOM.1973.1091550", "10.1109/TIP.2002.801588", "10.1109/36.752192", "10.1109/T-C.1974.224051", "10.1109/83.535844", "10.1109/36.739109", "10.1109/TGRS.2008.916203", "10.1109/TGRS.2008.2010129", "10.1109/83.536897", "10.1109/CNE.2003.1196824", "10.1109/TCOM.1983.1095851", "10.1109/34.142909", "10.1109/CVPR.1999.786958", "10.1109/TVCG.2008.85", "10.1109/ICCV.1993.378222", "10.1109/TGRS.2003.808879", "10.1109/TGRS.2005.857623", "10.1109/TCOM.1973.1091550", "10.1109/TIP.2002.801588", "10.1109/36.752192", "10.1109/T-C.1974.224051", "10.1109/83.535844", "10.1109/36.739109", "10.1109/TGRS.2008.916203", "10.1109/TGRS.2008.2010129", "10.1109/83.536897", "10.1109/CNE.2003.1196824", "10.1109/TCOM.1983.1095851", "10.1109/34.142909", "10.1109/CVPR.1999.786958", "10.1109/TVCG.2008.85", "10.1145/1073204.1073241", "10.1145/566570.566574", "10.1145/566570.566573", "10.1145/566570.566575", "10.1145/1276377.1276441", "10.1145/1360612.1360666", "10.1145/1073204.1073241", "10.1145/566570.566574", "10.1145/566570.566573", "10.1145/566570.566575", "10.1145/1276377.1276441", "10.1145/1360612.1360666", "10.1145/1073204.1073241", "10.1145/566570.566574", "10.1145/566570.566573", "10.1145/566570.566575", "10.1145/1276377.1276441", "10.1145/1360612.1360666", "10.1080/014311698215748", "10.1007/BF01211447", "10.1006/gmip.1995.1022", "10.7155/jgaa.00089", "10.1117/12.453367", "10.1016/S0165-1684(00)00273-5", "10.1126/science.290.5500.2323", "10.1111/j.1467-8659.2005.00867.x", "10.1111/j.1467-8659.2008.01116.x", "10.1117/12.408573", "10.1016/0734-189X(86)90223-9", "10.1007/BF02289565", "10.1016/S0034-4257(03)00130-5", "10.1016/j.inffus.2005.09.006", "10.1080/014311698215748", "10.1007/BF01211447", "10.1006/gmip.1995.1022", "10.7155/jgaa.00089", "10.1117/12.453367", "10.1016/S0165-1684(00)00273-5", "10.1126/science.290.5500.2323", "10.1111/j.1467-8659.2005.00867.x", "10.1111/j.1467-8659.2008.01116.x", "10.1117/12.408573", "10.1016/0734-189X(86)90223-9", "10.1007/BF02289565", "10.1016/S0034-4257(03)00130-5", "10.1016/j.inffus.2005.09.006", "10.1080/014311698215748", "10.1007/BF01211447", "10.1006/gmip.1995.1022", "10.7155/jgaa.00089", "10.1117/12.453367", "10.1016/S0165-1684(00)00273-5", "10.1126/science.290.5500.2323", "10.1111/j.1467-8659.2005.00867.x", "10.1111/j.1467-8659.2008.01116.x", "10.1117/12.408573", "10.1016/0734-189X(86)90223-9", "10.1007/BF02289565", "10.1016/S0034-4257(03)00130-5", "10.1016/j.inffus.2005.09.006"]}, "10.1109/TVCG.2011.31": {"doi": "10.1109/TVCG.2011.31", "author": ["L. Wan", "S. Mak", "T. Wong", "C. Leung"], "title": "Spatiotemporal Sampling of Dynamic Environment Sequences", "year": "2011", "abstract": "Environment sampling is a popular technique for rendering scenes with distant environment illumination. However, the temporal consistency of animations synthesized under dynamic environment sequences has not been fully studied. This paper addresses this problem and proposes a novel method, namely spatiotemporal sampling, to fully exploit both the temporal and spatial coherence of environment sequences. Our method treats an environment sequence as a spatiotemporal volume and samples the sequence by stratifying the volume adaptively. For this purpose, we first present a new metric to measure the importance of each stratified volume. A stratification algorithm is then proposed to adaptively suppress the abrupt temporal and spatial changes in the generated sampling patterns. The proposed method is able to automatically adjust the number of samples for each environment frame and produce temporally coherent sampling patterns. Comparative experiments demonstrate the capability of our method to produce smooth and consistent animations under dynamic environment sequences.", "keywords": ["computer animation", "rendering (computer graphics)", "sampling methods", "spatiotemporal sampling method", "environment sequence", "scene rendering", "animation consistency", "spatiotemporal volume", "stratification algorithm", "environment illumination", "environment sampling", "Lighting", "Measurement", "Rendering (computer graphics)", "Monte Carlo methods", "Animation", "Time domain analysis", "Binary trees", "Spatiotemporal sampling", "dynamic environment sequences", "temporal consistency", "importance metric", "adaptive volume stratification."], "referenced_by": ["10.1109/TVCG.2007.1020", "10.1109/TVCG.2007.1034", "10.1109/TVCG.2009.56", "10.1109/TVCG.2011.31", "10.1109/TVCG.2015.2407398", "10.1109/TVCG.2015.2500236", "10.1145/2670473.2670478", "10.1016/j.image.2013.08.004", "10.1111/cgf.12591"], "referencing": ["10.1109/MCG.1986.276658", "10.1109/TVCG.2011.31", "10.1109/TPAMI.2010.24", "10.1109/MCG.1986.276658", "10.1109/TVCG.2011.31", "10.1109/TPAMI.2010.24", "10.1109/MCG.1986.276658", "10.1109/TVCG.2011.31", "10.1109/TPAMI.2010.24", "10.1145/360349.360353", "10.1145/280814.280864", "10.1145/258734.258884", "10.1145/882262.882314", "10.1145/1015706.1015750", "10.1145/1186954.1187029", "10.1145/1015706.1015751", "10.1145/1186822.1073328", "10.1145/1360612.1360633", "10.1145/964965.808600", "10.1145/142920.134078", "10.1145/360349.360353", "10.1145/280814.280864", "10.1145/258734.258884", "10.1145/882262.882314", "10.1145/1015706.1015750", "10.1145/1186954.1187029", "10.1145/1015706.1015751", "10.1145/1186822.1073328", "10.1145/1360612.1360633", "10.1145/964965.808600", "10.1145/142920.134078", "10.1145/360349.360353", "10.1145/280814.280864", "10.1145/258734.258884", "10.1145/882262.882314", "10.1145/1015706.1015750", "10.1145/1186954.1187029", "10.1145/1015706.1015751", "10.1145/1186822.1073328", "10.1145/1360612.1360633", "10.1145/964965.808600", "10.1145/142920.134078", "10.1111/j.1467-8659.2008.01166.x", "10.1111/j.1467-8659.2009.01398.x", "10.1111/j.1467-8659.2008.01248.x", "10.1111/j.1467-8659.2008.01166.x", "10.1111/j.1467-8659.2009.01398.x", "10.1111/j.1467-8659.2008.01248.x", "10.1111/j.1467-8659.2008.01166.x", "10.1111/j.1467-8659.2009.01398.x", "10.1111/j.1467-8659.2008.01248.x"]}, "10.1109/TVCG.2011.28": {"doi": "10.1109/TVCG.2011.28", "author": ["D. Panozzo", "E. Puppo", "M. Tarini", "N. Pietroni", "P. Cignoni"], "title": "Automatic Construction of Quad-Based Subdivision Surfaces Using Fitmaps", "year": "2011", "abstract": "We present an automatic method to produce a Catmull-Clark subdivision surface that fits a given input mesh. Its control mesh is coarse and adaptive, and it is obtained by simplifying an initial mesh at high resolution. Simplification occurs progressively via local operators and addresses both quality of surface and faithfulness to the input shape throughout the whole process. The method is robust and performs well on rather complex shapes. Displacement mapping or normal mapping can be applied to approximate the input shape arbitrarily well.", "keywords": ["computational geometry", "mesh generation", "quad-based subdivision surface automatic construction", "Fitmaps", "Catmull-Clark subdivision surface", "displacement mapping", "normal mapping", "quadrilateral meshes", "mesh compression", "Shape", "Surface treatment", "Approximation methods", "Accuracy", "Smoothing methods", "Polynomials", "Rendering (computer graphics)", "Quadrilateral meshes", "subdivision surfaces", "displacement mapping", "mesh compression."], "referenced_by": ["10.1109/MCG.2015.26", "10.1109/TVCG.2011.165", "10.1109/TVCG.2012.308", "10.1145/2843947", "10.1145/3072959.3073647", "10.1145/3197517.3201389", "10.1145/2185520.2185606", "10.1007/s00170-015-7774-y", "10.1007/s41095-017-0088-2", "10.1016/j.cagd.2014.10.001", "10.1111/cgf.12014", "10.1111/cgf.12050", "10.1111/cgf.12461", "10.1111/cgf.13153"], "referencing": ["10.1109/PCCGA.2004.1348330", "10.1109/PCCGA.2002.1167835", "10.1109/PCCGA.2004.1348330", "10.1109/PCCGA.2002.1167835", "10.1109/PCCGA.2004.1348330", "10.1109/PCCGA.2002.1167835", "10.1145/1330511.1330519", "10.1145/1507149.1507172", "10.1145/1183287.1183297", "10.1145/1186562.1015817", "10.1145/1141911.1141993", "10.1145/344779.344829", "10.1145/1778765.1778854", "10.1145/192161.192233", "10.1145/258734.258849", "10.1145/1507149.1507174", "10.1145/1330511.1330519", "10.1145/1507149.1507172", "10.1145/1183287.1183297", "10.1145/1186562.1015817", "10.1145/1141911.1141993", "10.1145/344779.344829", "10.1145/1778765.1778854", "10.1145/192161.192233", "10.1145/258734.258849", "10.1145/1507149.1507174", "10.1145/1330511.1330519", "10.1145/1507149.1507172", "10.1145/1183287.1183297", "10.1145/1186562.1015817", "10.1145/1141911.1141993", "10.1145/344779.344829", "10.1145/1778765.1778854", "10.1145/192161.192233", "10.1145/258734.258849", "10.1145/1507149.1507174", "10.1111/j.1467-8659.2007.01060.x", "10.1016/0010-4485(78)90110-0", "10.1016/S0010-4485(03)00160-X", "10.1111/j.1467-8659.2009.01520.x", "10.1111/j.1467-8659.2009.01519.x", "10.1111/j.1467-8659.2009.01610.x", "10.1111/j.1467-8659.2007.01060.x", "10.1016/0010-4485(78)90110-0", "10.1016/S0010-4485(03)00160-X", "10.1111/j.1467-8659.2009.01520.x", "10.1111/j.1467-8659.2009.01519.x", "10.1111/j.1467-8659.2009.01610.x", "10.1111/j.1467-8659.2007.01060.x", "10.1016/0010-4485(78)90110-0", "10.1016/S0010-4485(03)00160-X", "10.1111/j.1467-8659.2009.01520.x", "10.1111/j.1467-8659.2009.01519.x", "10.1111/j.1467-8659.2009.01610.x"]}, "10.1109/TVCG.2010.264": {"doi": "10.1109/TVCG.2010.264", "author": ["Y. Zheng", "H. Fu", "O. K. Au", "C. Tai"], "title": "Bilateral Normal Filtering for Mesh Denoising", "year": "2011", "abstract": "Decoupling local geometric features from the spatial location of a mesh is crucial for feature-preserving mesh denoising. This paper focuses on first order features, i.e., facet normals, and presents a simple yet effective anisotropic mesh denoising framework via normal field denoising. Unlike previous denoising methods based on normal filtering, which process normals defined on the Gauss sphere, our method considers normals as a surface signal defined over the original mesh. This allows the design of a novel bilateral normal filter that depends on both spatial distance and signal distance. Our bilateral filter is a more natural extension of the elegant bilateral filter for image denoising than those used in previous bilateral mesh denoising methods. Besides applying this bilateral normal filter in a local, iterative scheme, as common in most of previous works, we present for the first time a global, noniterative scheme for an isotropic denoising. We show that the former scheme is faster and more effective for denoising extremely noisy meshes while the latter scheme is more robust to irregular surface sampling. We demonstrate that both our feature-preserving schemes generally produce visually and numerically better denoising results than previous methods, especially at challenging regions with sharp features or irregular sampling.", "keywords": ["filtering theory", "image denoising", "iterative methods", "bilateral normal filtering", "feature-preserving mesh denoising", "normal field denoising", "Gauss sphere", "surface signal", "spatial distance", "signal distance", "image denoising", "noniterative scheme", "isotropic denoising", "irregular surface sampling", "Noise reduction", "Noise", "Mathematical model", "Equations", "Optimization", "Laplace equations", "Robustness", "Mesh denoising", "bilateral normal filtering", "feature preserving", "irregular surface sampling."], "referenced_by": ["10.1109/3DV.2015.13", "10.1109/BMEI.2015.7401516", "10.1109/CADGRAPHICS.2015.26", "10.1109/ICADW.2016.7942513", "10.1109/ICCV.2015.32", "10.1109/ICIST.2014.6920516", "10.1109/ISCID.2014.134", "10.1109/NCVPRIPG.2013.6776193", "10.1109/SIBGRAPI.2013.34", "10.1109/TASE.2016.2553449", "10.1109/TENCON.2016.7848730", "10.1109/TMECH.2016.2581808", "10.1109/TVCG.2014.2326872", "10.1109/TVCG.2015.2398432", "10.1109/TVCG.2015.2500222", "10.1109/TIP.2015.2507400", "10.1109/TVCG.2015.2461163", "10.1109/TVCG.2017.2731771", "10.1109/TVCG.2017.2740384", "10.1109/ICME.2018.8486541", "10.1109/TVCG.2018.2802926", "10.1109/SIBGRAPI.2018.00007", "10.1109/ACCESS.2019.2894533", "10.1109/TVCG.2018.2816926", "10.1109/TVCG.2018.2818146", "10.1109/ICSP.2018.8652439", "10.1109/ICASSP.2019.8683548", "10.1109/TVCG.2018.2828818", "10.1109/ISIVC.2018.8709194", "10.1049/iet-ipr.2014.0447", "10.1007/978-3-319-66471-2_2", "10.1007/978-981-10-4211-9_18", "10.1007/s00371-017-1391-8", "10.1007/s00371-017-1431-4", "10.1007/s11042-017-5258-9", "10.1007/s11042-018-5735-9", "10.1007/s13319-017-0146-7", "10.1016/j.cad.2014.01.003", "10.1016/j.cad.2018.01.003", "10.1016/j.cag.2013.10.025", "10.1016/j.cag.2015.05.012", "10.1016/j.cagd.2017.02.011", "10.1016/j.cagd.2018.03.004", "10.1016/j.gmod.2012.03.010", "10.1016/j.gmod.2012.04.005", "10.1016/j.gmod.2013.05.002", "10.1016/j.gmod.2014.03.006", "10.1016/j.neucom.2016.01.012", "10.1016/j.optlaseng.2013.04.018", "10.1016/j.optlaseng.2014.05.002", "10.1016/j.optlaseng.2016.09.003", "10.1016/j.optlaseng.2017.11.014", "10.1016/j.patrec.2012.02.008", "10.1080/00207543.2014.974851", "10.1111/cgf.12139", "10.1111/cgf.12245", "10.1111/cgf.12742", "10.1111/cgf.12743", "10.1111/cgf.13069"], "referencing": ["10.1109/SMI.2008.4547940", "10.1109/VISUAL.2002.1183766", "10.1109/TPAMI.2002.1008390", "10.1109/ICCV.1998.710815", "10.1109/SMI.2006.38", "10.1109/TVCG.2007.1065", "10.1109/GMAP.2002.1027503", "10.1109/TVCG.2004.1272725", "10.1109/CGI.2003.1214444", "10.1109/SMI.2009.5170156", "10.1109/VISUAL.2000.885721", "10.1109/SMI.2008.4547940", "10.1109/VISUAL.2002.1183766", "10.1109/TPAMI.2002.1008390", "10.1109/ICCV.1998.710815", "10.1109/SMI.2006.38", "10.1109/TVCG.2007.1065", "10.1109/GMAP.2002.1027503", "10.1109/TVCG.2004.1272725", "10.1109/CGI.2003.1214444", "10.1109/SMI.2009.5170156", "10.1109/VISUAL.2000.885721", "10.1109/SMI.2008.4547940", "10.1109/VISUAL.2002.1183766", "10.1109/TPAMI.2002.1008390", "10.1109/ICCV.1998.710815", "10.1109/SMI.2006.38", "10.1109/TVCG.2007.1065", "10.1109/GMAP.2002.1027503", "10.1109/TVCG.2004.1272725", "10.1109/CGI.2003.1214444", "10.1109/SMI.2009.5170156", "10.1109/VISUAL.2000.885721", "10.1145/944020.944024", "10.1145/882262.882367", "10.1145/218380.218473", "10.1145/311535.311576", "10.1145/1141911.1142001", "10.1145/882262.882368", "10.1145/1174429.1174494", "10.1145/1073204.1073226", "10.1145/1281500.1281640", "10.1145/588272.588276", "10.1145/944020.944024", "10.1145/882262.882367", "10.1145/218380.218473", "10.1145/311535.311576", "10.1145/1141911.1142001", "10.1145/882262.882368", "10.1145/1174429.1174494", "10.1145/1073204.1073226", "10.1145/1281500.1281640", "10.1145/588272.588276", "10.1145/944020.944024", "10.1145/882262.882367", "10.1145/218380.218473", "10.1145/311535.311576", "10.1145/1141911.1142001", "10.1145/882262.882368", "10.1145/1174429.1174494", "10.1145/1073204.1073226", "10.1145/1281500.1281640", "10.1145/588272.588276", "10.1016/j.cagd.2007.12.008", "10.1111/j.1467-8659.2006.00999.x", "10.1007/11537908_5", "10.1111/j.1467-8659.2008.01275.x", "10.1111/j.1467-8659.2004.00770.x", "10.1016/j.cagd.2007.12.008", "10.1111/j.1467-8659.2006.00999.x", "10.1007/11537908_5", "10.1111/j.1467-8659.2008.01275.x", "10.1111/j.1467-8659.2004.00770.x", "10.1016/j.cagd.2007.12.008", "10.1111/j.1467-8659.2006.00999.x", "10.1007/11537908_5", "10.1111/j.1467-8659.2008.01275.x", "10.1111/j.1467-8659.2004.00770.x"]}, "10.1109/TVCG.2010.231": {"doi": "10.1109/TVCG.2010.231", "author": ["H. Wu", "C. Pan", "H. Zha", "Q. Yang", "S. Ma"], "title": "Partwise Cross-Parameterization via Nonregular Convex Hull Domains", "year": "2011", "abstract": "In this paper, we propose a novel partwise framework for cross-parameterization between 3D mesh models. Unlike most existing methods that use regular parameterization domains, our framework uses nonregular approximation domains to build the cross-parameterization. Once the nonregular approximation domains are constructed for 3D models, different (and complex) input shapes are transformed into similar (and simple) shapes, thus facilitating the cross-parameterization process. Specifically, a novel nonregular domain, the convex hull, is adopted to build shape correspondence. We first construct convex hulls for each part of the segmented model, and then adopt our convex-hull cross-parameterization method to generate compatible meshes. Our method exploits properties of the convex hull, e.g., good approximation ability and linear convex representation for interior vertices. After building an initial cross-parameterization via convex-hull domains, we use compatible remeshing algorithms to achieve an accurate approximation of the target geometry and to ensure a complete surface matching. Experimental results show that the compatible meshes constructed are well suited for shape blending and other geometric applications.", "keywords": ["approximation theory", "solid modelling", "partwise cross-parameterization", "nonregular convex hull domain", "3D mesh model", "nonregular approximation domain", "compatible remeshing algorithm", "surface matching", "shape blending", "Shape", "Approximation methods", "Three dimensional displays", "Measurement", "Geometry", "Approximation algorithms", "Solid modeling", "Cross-parameterization", "nonregular approximation domains", "convex hull", "critical points", "compatible remeshing", "sketch-based segmentation."], "referenced_by": ["10.1109/ICCV.2011.6126292", "10.1111/cgf.12718"], "referencing": ["10.1109/ICCV.2007.4408908", "10.1109/CVPR.2010.5540180", "10.1109/2945.817348", "10.1109/ICCV.1995.466840", "10.1109/PG.2007.40", "10.1109/ICCV.2007.4408908", "10.1109/CVPR.2010.5540180", "10.1109/2945.817348", "10.1109/ICCV.1995.466840", "10.1109/PG.2007.40", "10.1109/ICCV.2007.4408908", "10.1109/CVPR.2010.5540180", "10.1109/2945.817348", "10.1109/ICCV.1995.466840", "10.1109/PG.2007.40", "10.1145/1186562.1015811", "10.1145/383259.383277", "10.1145/882262.882274", "10.1145/1015706.1015812", "10.1145/604471.604502", "10.1145/1186562.1015736", "10.1145/311535.311602", "10.1145/1015706.1015775", "10.1145/344779.344831", "10.1145/1186822.1073229", "10.1145/1122501.1122507", "10.1145/1201775.882311", "10.1145/1186562.1015811", "10.1145/383259.383277", "10.1145/882262.882274", "10.1145/1015706.1015812", "10.1145/604471.604502", "10.1145/1186562.1015736", "10.1145/311535.311602", "10.1145/1015706.1015775", "10.1145/344779.344831", "10.1145/1186822.1073229", "10.1145/1122501.1122507", "10.1145/1201775.882311", "10.1145/1186562.1015811", "10.1145/383259.383277", "10.1145/882262.882274", "10.1145/1015706.1015812", "10.1145/604471.604502", "10.1145/1186562.1015736", "10.1145/311535.311602", "10.1145/1015706.1015775", "10.1145/344779.344831", "10.1145/1186822.1073229", "10.1145/1122501.1122507", "10.1145/1201775.882311", "10.1111/1467-8659.00581", "10.1111/j.1467-8659.2008.01283.x", "10.1007/s11263-009-0301-6", "10.1007/s11263-009-0250-0", "10.1007/11784203_14", "10.1117/12.811463", "10.1111/j.1467-8659.2008.01285.x", "10.1111/1467-8659.00575", "10.1016/S0167-8396(03)00002-5", "10.1016/0010-0277(84)90022-2", "10.1111/1467-8659.00236", "10.1016/j.cagd.2008.05.003", "10.1016/S0925-7721(96)00024-7", "10.1007/s00371-005-0344-9", "10.1016/j.cagd.2005.04.002", "10.1007/s00371-007-0197-5", "10.1016/j.cag.2009.03.010", "10.1111/j.1467-8659.2006.00947.x", "10.1111/j.1467-8659.2006.00999.x", "10.1111/j.1467-8659.2005.00885.x", "10.1007/s11390-010-9347-8", "10.1111/1467-8659.00581", "10.1111/j.1467-8659.2008.01283.x", "10.1007/s11263-009-0301-6", "10.1007/s11263-009-0250-0", "10.1007/11784203_14", "10.1117/12.811463", "10.1111/j.1467-8659.2008.01285.x", "10.1111/1467-8659.00575", "10.1016/S0167-8396(03)00002-5", "10.1016/0010-0277(84)90022-2", "10.1111/1467-8659.00236", "10.1016/j.cagd.2008.05.003", "10.1016/S0925-7721(96)00024-7", "10.1007/s00371-005-0344-9", "10.1016/j.cagd.2005.04.002", "10.1007/s00371-007-0197-5", "10.1016/j.cag.2009.03.010", "10.1111/j.1467-8659.2006.00947.x", "10.1111/j.1467-8659.2006.00999.x", "10.1111/j.1467-8659.2005.00885.x", "10.1007/s11390-010-9347-8", "10.1111/1467-8659.00581", "10.1111/j.1467-8659.2008.01283.x", "10.1007/s11263-009-0301-6", "10.1007/s11263-009-0250-0", "10.1007/11784203_14", "10.1117/12.811463", "10.1111/j.1467-8659.2008.01285.x", "10.1111/1467-8659.00575", "10.1016/S0167-8396(03)00002-5", "10.1016/0010-0277(84)90022-2", "10.1111/1467-8659.00236", "10.1016/j.cagd.2008.05.003", "10.1016/S0925-7721(96)00024-7", "10.1007/s00371-005-0344-9", "10.1016/j.cagd.2005.04.002", "10.1007/s00371-007-0197-5", "10.1016/j.cag.2009.03.010", "10.1111/j.1467-8659.2006.00947.x", "10.1111/j.1467-8659.2006.00999.x", "10.1111/j.1467-8659.2005.00885.x", "10.1007/s11390-010-9347-8"]}}