{"10.1109/TVCG.2012.295": {"doi": "10.1109/TVCG.2012.295", "author": ["S. DiVerdi", "A. Krishnaswamy", "R. M\u00c4ch", "D. Ito"], "title": "Painting with Polygons: A Procedural Watercolor Engine", "year": "2013", "abstract": "Existing natural media painting simulations have produced high-quality results, but have required powerful compute hardware and have been limited to screen resolutions. Digital artists would like to be able to use watercolor-like painting tools, but at print resolutions and on lower end hardware such as laptops or even slates. We present a procedural algorithm for generating watercolor-like dynamic paint behaviors in a lightweight manner. Our goal is not to exactly duplicate watercolor painting, but to create a range of dynamic behaviors that allow users to achieve a similar style of process and result, while at the same time having a unique character of its own. Our stroke representation is vector based, allowing for rendering at arbitrary resolutions, and our procedural pigment advection algorithm is fast enough to support painting on slate devices. We demonstrate our technique in a commercially available slate application used by professional artists. Finally, we present a detailed analysis of the different vector-rendering technologies available.", "keywords": ["art", "geometry", "image resolution", "painting", "pigments", "rendering (computer graphics)", "screens (display)", "vectors", "natural media painting simulation", "screen resolutions", "digital artists", "watercolor-like painting tools", "print resolution", "watercolor-like dynamic paint behaviors", "dynamic behaviors", "vector based stroke representation", "arbitrary resolutions", "procedural pigment advection algorithm", "slate devices", "vector-rendering technologies", "procedural watercolor engine", "polygons", "Painting", "Paints", "Vectors", "Pigments", "Brushes", "Heuristic algorithms", "Tablet computers", "Natural media", "watercolor painting", "vector graphics", "real time", "Algorithms", "Color", "Computer Systems", "Imaging, Three-Dimensional", "Paint", "Paintings", "Software", "User-Computer Interface"], "referenced_by": ["IKEY:6468045", "IKEY:7030191", "IKEY:6732968", "IKEY:7042343", "10.1145/2766981", "10.1145/2816795.2818066", "10.1145/2461912.2461956", "10.1007/s11042-016-3408-0", "10.1016/j.cag.2017.03.002", "10.1016/j.cag.2017.11.001", "10.1111/cgf.12222", "10.1111/cgf.12995", "10.1002/9781118967317.ch5", "10.1016/j.cag.2019.02.001", "10.1111/cgf.13955"], "referencing": ["IKEY:1210867", "IKEY:1210867", "IKEY:1210867", "10.1145/2159616.2159627", "10.1145/340916.340917", "10.1145/1730804.1730825", "10.1145/1124728.1124751", "10.1145/258734.258896", "10.1145/987657.987665", "10.1145/1809939.1809943", "10.1145/1399504.1360691", "10.1145/1809939.1809954", "10.1145/1183287.1183295", "10.1145/1186822.1073229", "10.1145/2159616.2159627", "10.1145/340916.340917", "10.1145/1730804.1730825", "10.1145/1124728.1124751", "10.1145/258734.258896", "10.1145/987657.987665", "10.1145/1809939.1809943", "10.1145/1399504.1360691", "10.1145/1809939.1809954", "10.1145/1183287.1183295", "10.1145/1186822.1073229", "10.1145/2159616.2159627", "10.1145/340916.340917", "10.1145/1730804.1730825", "10.1145/1124728.1124751", "10.1145/258734.258896", "10.1145/987657.987665", "10.1145/1809939.1809943", "10.1145/1399504.1360691", "10.1145/1809939.1809954", "10.1145/1183287.1183295", "10.1145/1186822.1073229", "10.1002/cav.95", "10.1016/0925-7721(91)90012-4", "10.1002/cav.95", "10.1016/0925-7721(91)90012-4", "10.1002/cav.95", "10.1016/0925-7721(91)90012-4"]}, "10.1109/TVCG.2012.307": {"doi": "10.1109/TVCG.2012.307", "author": ["M. Qi", "T. Cao", "T. Tan"], "title": "Computing 2D Constrained Delaunay Triangulation Using the GPU", "year": "2013", "abstract": "We propose the first graphics processing unit (GPU) solution to compute the 2D constrained Delaunay triangulation (CDT) of a planar straight line graph (PSLG) consisting of points and edges. There are many existing CPU algorithms to solve the CDT problem in computational geometry, yet there has been no prior approach to solve this problem efficiently using the parallel computing power of the GPU. For the special case of the CDT problem where the PSLG consists of just points, which is simply the normal Delaunay triangulation (DT) problem, a hybrid approach using the GPU together with the CPU to partially speed up the computation has already been presented in the literature. Our work, on the other hand, accelerates the entire computation on the GPU. Our implementation using the CUDA programming model on NVIDIA GPUs is numerically robust, and runs up to an order of magnitude faster than the best sequential implementations on the CPU. This result is reflected in our experiment with both randomly generated PSLGs and real-world GIS data having millions of points and edges.", "keywords": ["graphics processing units", "mesh generation", "parallel architectures", "computing 2D constrained Delaunay triangulation", "graphics processing unit", "CDT", "planar straight line graph", "PSLG", "computational geometry", "parallel computing power", "CUDA programming model", "NVIDIA GPU", "Graphics processing units", "Instruction sets", "Arrays", "Strips", "Standards", "Color", "GPGPU", "parallel computation", "computational geometry", "Voronoi diagram", "image vectorization", "Algorithms", "Computer Graphics", "Image Enhancement", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Imaging, Three-Dimensional", "Numerical Analysis, Computer-Assisted", "Reproducibility of Results", "Sensitivity and Specificity", "Signal Processing, Computer-Assisted"], "referenced_by": ["IKEY:7378671", "IKEY:7887682", "IKEY:7406755", "IKEY:8692354", "IKEY:9231067", "10.1145/2964284.2967284", "10.1007/s00371-014-0948-z", "10.1007/s13369-014-1406-y", "10.1016/j.ocecoaman.2014.05.016", "10.1080/00396265.2016.1264180", "10.1155/2015/720249", "10.1088/1361-6560/aa5342", "10.1080/13658816.2017.1300804", "10.1016/j.comgeo.2018.01.004", "10.1115/1.4034363", "10.15587/1729-4061.2019.174010", "10.1155/2020/9267854"], "referencing": ["IKEY:4567872", "IKEY:391486", "IKEY:4567872", "IKEY:391486", "IKEY:4567872", "IKEY:391486", "10.1145/116873.116880", "10.1145/1730804.1730818", "10.1145/311535.311567", "10.1145/2159616.2159623", "10.1145/1342250.1342264", "10.1145/237218.237337", "10.1145/116873.116880", "10.1145/1730804.1730818", "10.1145/311535.311567", "10.1145/2159616.2159623", "10.1145/1342250.1342264", "10.1145/237218.237337", "10.1145/116873.116880", "10.1145/1730804.1730818", "10.1145/311535.311567", "10.1145/2159616.2159623", "10.1145/1342250.1342264", "10.1145/237218.237337", "10.1016/S0734-189X(88)80028-8", "10.1007/BF01553881", "10.1007/BF01840356", "10.1080/2151237X.2006.10129229", "10.1007/BF01840357", "10.1016/0020-0190(72)90045-2", "10.1007/BF01758770", "10.1016/0020-0190(82)90116-8", "10.1007/BF02187695", "10.1016/j.patcog.2005.10.014", "10.1007/978-1-4612-1098-6", "10.1007/BFb0014497", "10.1016/S0925-7721(96)00025-9", "10.1016/S0734-189X(88)80028-8", "10.1007/BF01553881", "10.1007/BF01840356", "10.1080/2151237X.2006.10129229", "10.1007/BF01840357", "10.1016/0020-0190(72)90045-2", "10.1007/BF01758770", "10.1016/0020-0190(82)90116-8", "10.1007/BF02187695", "10.1016/j.patcog.2005.10.014", "10.1007/978-1-4612-1098-6", "10.1007/BFb0014497", "10.1016/S0925-7721(96)00025-9", "10.1016/S0734-189X(88)80028-8", "10.1007/BF01553881", "10.1007/BF01840356", "10.1080/2151237X.2006.10129229", "10.1007/BF01840357", "10.1016/0020-0190(72)90045-2", "10.1007/BF01758770", "10.1016/0020-0190(82)90116-8", "10.1007/BF02187695", "10.1016/j.patcog.2005.10.014", "10.1007/978-1-4612-1098-6", "10.1007/BFb0014497", "10.1016/S0925-7721(96)00025-9"]}, "10.1109/TVCG.2012.298": {"doi": "10.1109/TVCG.2012.298", "author": ["M. M. Bagher", "C. Soler", "K. Subr", "L. Belcour", "N. Holzschuch"], "title": "Interactive Rendering of Acquired Materials on Dynamic Geometry Using Frequency Analysis", "year": "2013", "abstract": "Shading acquired materials with high-frequency illumination is computationally expensive. Estimating the shading integral requires multiple samples of the incident illumination. The number of samples required may vary across the image, and the image itself may have high- and low-frequency variations, depending on a combination of several factors. Adaptively distributing computational budget across the pixels for shading is a challenging problem. In this paper, we depict complex materials such as acquired reflectances, interactively, without any precomputation based on geometry. In each frame, we first estimate the frequencies in the local light field arriving at each pixel, as well as the variance of the shading integrand. Our frequency analysis accounts for combinations of a variety of factors: the reflectance of the object projecting to the pixel, the nature of the illumination, the local geometry and the camera position relative to the geometry and lighting. We then exploit this frequency information (bandwidth and variance) to adaptively sample for reconstruction and integration. For example, fewer pixels per unit area are shaded for pixels projecting onto diffuse objects, and fewer samples are used for integrating illumination incident on specular objects.", "keywords": ["image reconstruction", "rendering (computer graphics)", "interactive rendering", "acquired materials", "dynamic geometry", "frequency analysis", "high-frequency illumination", "shading integral", "incident illumination", "high-frequency variations", "low-frequency variations", "shading integrand", "pixel", "camera position", "image reconstruction", "image integration", "Bandwidth", "Lighting", "Materials", "Light sources", "Geometry", "Rendering (computer graphics)", "Convolution", "Computer graphics", "rendering", "illumination simulation", "measured reflectance", "Fourier analysis", "Algorithms", "Computer Graphics", "Data Interpretation, Statistical", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Lighting", "Reproducibility of Results", "Sensitivity and Specificity", "Signal Processing, Computer-Assisted"], "referenced_by": ["10.1145/2897826.2927356", "10.1111/cgf.12592", "10.1364/JOSAA.36.000C40"], "referencing": ["IKEY:5226625", "IKEY:5226625", "IKEY:5226625", "10.1145/566654.566612", "10.1145/1073204.1073320", "10.1145/2159616.2159637", "10.1145/378456.378468", "10.1145/1778765.1778804", "10.1145/311535.311554", "10.1145/311625.312153", "10.1145/566654.566610", "10.1145/1268517.1268546", "10.1145/1531326.1531399", "10.1145/1507149.1507162", "10.1145/1283900.1283909", "10.1145/1618452.1618478", "10.1145/1275808.1276411", "10.1145/882262.882343", "10.1145/566654.566612", "10.1145/1073204.1073320", "10.1145/2159616.2159637", "10.1145/378456.378468", "10.1145/1778765.1778804", "10.1145/311535.311554", "10.1145/311625.312153", "10.1145/566654.566610", "10.1145/1268517.1268546", "10.1145/1531326.1531399", "10.1145/1507149.1507162", "10.1145/1283900.1283909", "10.1145/1618452.1618478", "10.1145/1275808.1276411", "10.1145/882262.882343", "10.1145/566654.566612", "10.1145/1073204.1073320", "10.1145/2159616.2159637", "10.1145/378456.378468", "10.1145/1778765.1778804", "10.1145/311535.311554", "10.1145/311625.312153", "10.1145/566654.566610", "10.1145/1268517.1268546", "10.1145/1531326.1531399", "10.1145/1507149.1507162", "10.1145/1283900.1283909", "10.1145/1618452.1618478", "10.1145/1275808.1276411", "10.1145/882262.882343", "10.1111/j.1467-8659.2010.01723.x", "10.1561/0600000021", "10.1111/j.1467-8659.2010.01723.x", "10.1561/0600000021", "10.1111/j.1467-8659.2010.01723.x", "10.1561/0600000021"]}, "10.1109/TVCG.2012.314": {"doi": "10.1109/TVCG.2012.314", "author": ["D. Casas", "M. Tejera", "J. Guillemaut", "A. Hilton"], "title": "Interactive Animation of 4D Performance Capture", "year": "2013", "abstract": "A 4D parametric motion graph representation is presented for interactive animation from actor performance capture in a multiple camera studio. The representation is based on a 4D model database of temporally aligned mesh sequence reconstructions for multiple motions. High-level movement controls such as speed and direction are achieved by blending multiple mesh sequences of related motions. A real-time mesh sequence blending approach is introduced, which combines the realistic deformation of previous nonlinear solutions with efficient online computation. Transitions between different parametric motion spaces are evaluated in real time based on surface shape and motion similarity. Four-dimensional parametric motion graphs allow real-time interactive character animation while preserving the natural dynamics of the captured performance.", "keywords": ["computer animation", "data visualisation", "image motion analysis", "image representation", "solid modelling", "interactive animation", "4D performance capture", "4D parametric motion graph representation", "actor performance capture", "multiple camera studio", "4D model database", "mesh sequence reconstruction", "high-level movement control", "mesh sequence blending approach", "parametric motion space", "surface shape", "motion similarity", "four-dimensional parametric motion graph", "real-time interactive character animation", "natural dynamics", "Animation", "Real-time systems", "Databases", "Aerospace electronics", "Interpolation", "Mesh generation", "Shape", "Character animation", "3D video", "real-time animation", "multiview reconstruction", "video-based animation", "4D modeling", "4D performance capture", "Algorithms", "Artificial Intelligence", "Computer Graphics", "Humans", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Locomotion", "Numerical Analysis, Computer-Assisted", "Pattern Recognition, Automated", "Reproducibility of Results", "Sensitivity and Specificity", "Signal Processing, Computer-Assisted", "Subtraction Technique", "User-Computer Interface"], "referenced_by": ["IKEY:6599072", "IKEY:7169830", "IKEY:6826482", "IKEY:6547685", "IKEY:8491003", "IKEY:8352750", "IKEY:8886095", "IKEY:9090565", "10.1145/2699643", "10.1007/978-3-319-30808-1_9-1", "10.1007/s00170-015-7050-1", "10.1007/s11390-017-1681-7", "10.1111/cgf.12296", "10.1111/cgf.12756", "10.1201/b18154-30", "10.3389/frvir.2020.00011"], "referencing": ["IKEY:708559", "IKEY:4178157", "IKEY:580394", "IKEY:1388274", "IKEY:5995438", "IKEY:626968", "IKEY:6103286", "IKEY:708559", "IKEY:4178157", "IKEY:580394", "IKEY:1388274", "IKEY:5995438", "IKEY:626968", "IKEY:6103286", "IKEY:708559", "IKEY:4178157", "IKEY:580394", "IKEY:1388274", "IKEY:5995438", "IKEY:626968", "IKEY:6103286", "10.1145/566570.566605", "10.1145/566570.566607", "10.1145/1230100.1230123", "10.1145/1399504.1360697", "10.1145/1399504.1360696", "10.1145/1186562.1015766", "10.1145/1576246.1531342", "10.1145/1882262.1866161", "10.1145/2159616.2159633", "10.1145/1201775.882309", "10.1145/1073368.1073375", "10.1145/258734.258880", "10.1145/344779.345012", "10.1145/1507149.1507182", "10.1145/1356682.1356685", "10.1145/1275808.1276482", "10.1145/253284.253321", "10.1145/311535.311539", "10.1145/311535.311536", "10.1145/1640443.1640452", "10.1145/1186562.1015760", "10.1145/1186822.1073313", "10.1145/1186562.1015736", "10.1145/218380.218422", "10.1145/566570.566605", "10.1145/566570.566607", "10.1145/1230100.1230123", "10.1145/1399504.1360697", "10.1145/1399504.1360696", "10.1145/1186562.1015766", "10.1145/1576246.1531342", "10.1145/1882262.1866161", "10.1145/2159616.2159633", "10.1145/1201775.882309", "10.1145/1073368.1073375", "10.1145/258734.258880", "10.1145/344779.345012", "10.1145/1507149.1507182", "10.1145/1356682.1356685", "10.1145/1275808.1276482", "10.1145/253284.253321", "10.1145/311535.311539", "10.1145/311535.311536", "10.1145/1640443.1640452", "10.1145/1186562.1015760", "10.1145/1186822.1073313", "10.1145/1186562.1015736", "10.1145/218380.218422", "10.1145/566570.566605", "10.1145/566570.566607", "10.1145/1230100.1230123", "10.1145/1399504.1360697", "10.1145/1399504.1360696", "10.1145/1186562.1015766", "10.1145/1576246.1531342", "10.1145/1882262.1866161", "10.1145/2159616.2159633", "10.1145/1201775.882309", "10.1145/1073368.1073375", "10.1145/258734.258880", "10.1145/344779.345012", "10.1145/1507149.1507182", "10.1145/1356682.1356685", "10.1145/1275808.1276482", "10.1145/253284.253321", "10.1145/311535.311539", "10.1145/311535.311536", "10.1145/1640443.1640452", "10.1145/1186562.1015760", "10.1145/1186822.1073313", "10.1145/1186562.1015736", "10.1145/218380.218422", "10.1111/j.1467-8659.2006.00999.x", "10.1111/j.1467-8659.2006.00999.x", "10.1111/j.1467-8659.2006.00999.x"]}, "10.1109/TVCG.2012.149": {"doi": "10.1109/TVCG.2012.149", "author": ["M. Mahmudi", "M. Kallmann"], "title": "Analyzing Locomotion Synthesis with Feature-Based Motion Graphs", "year": "2013", "abstract": "We propose feature-based motion graphs for realistic locomotion synthesis among obstacles. Among several advantages, feature-based motion graphs achieve improved results in search queries, eliminate the need of postprocessing for foot skating removal, and reduce the computational requirements in comparison to traditional motion graphs. Our contributions are threefold. First, we show that choosing transitions based on relevant features significantly reduces graph construction time and leads to improved search performances. Second, we employ a fast channel search method that confines the motion graph search to a free channel with guaranteed clearance among obstacles, achieving faster and improved results that avoid expensive collision checking. Lastly, we present a motion deformation model based on Inverse Kinematics applied over the transitions of a solution branch. Each transition is assigned a continuous deformation range that does not exceed the original transition cost threshold specified by the user for the graph construction. The obtained deformation improves the reachability of the feature-based motion graph and in turn also reduces the time spent during search. The results obtained by the proposed methods are evaluated and quantified, and they demonstrate significant improvements in comparison to traditional motion graph techniques.", "keywords": ["collision avoidance", "computer animation", "inverse problems", "motion control", "reachability analysis", "search problems", "locomotion synthesis analyzing", "feature-based motion graph", "realistic locomotion synthesis", "search query", "foot skating removal", "graph construction time", "search performance", "fast channel search method", "motion graph search", "free channel", "obstacle clearance", "collision checking", "motion deformation model", "inverse kinematics", "continuous deformation range", "transition cost threshold", "reachability", "motion graph technique", "animation", "Motion segmentation", "Feature extraction", "Image segmentation", "Detectors", "Joints", "Databases", "Foot", "Computer animation", "locomotion", "motion capture", "human-like motion planning", "Algorithms", "Biomimetics", "Computer Graphics", "Humans", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Locomotion", "Pattern Recognition, Automated", "Reproducibility of Results", "Sensitivity and Specificity", "User-Computer Interface"], "referenced_by": ["10.1007/s11042-017-4677-y", "10.3390/s17112589"], "referencing": ["IKEY:708559", "IKEY:86079", "IKEY:708559", "IKEY:86079", "IKEY:708559", "IKEY:86079", "10.1145/1186822.1073247", "10.1145/1275808.1276386", "10.1145/566570.566605", "10.1145/1201775.882284", "10.1145/566570.566607", "10.1145/566570.566608", "10.1145/566654.566604", "10.1145/545261.545279", "10.1145/1073368.1073373", "10.1145/1230100.1230125", "10.1145/1073368.1073410", "10.1145/1073368.1073408", "10.1145/1276377.1276510", "10.1145/1289603.1289609", "10.1145/1186822.1073247", "10.1145/1275808.1276386", "10.1145/566570.566605", "10.1145/1201775.882284", "10.1145/566570.566607", "10.1145/566570.566608", "10.1145/566654.566604", "10.1145/545261.545279", "10.1145/1073368.1073373", "10.1145/1230100.1230125", "10.1145/1073368.1073410", "10.1145/1073368.1073408", "10.1145/1276377.1276510", "10.1145/1289603.1289609", "10.1145/1186822.1073247", "10.1145/1275808.1276386", "10.1145/566570.566605", "10.1145/1201775.882284", "10.1145/566570.566607", "10.1145/566570.566608", "10.1145/566654.566604", "10.1145/545261.545279", "10.1145/1073368.1073373", "10.1145/1230100.1230125", "10.1145/1073368.1073410", "10.1145/1073368.1073408", "10.1145/1276377.1276510", "10.1145/1289603.1289609", "10.1007/978-3-642-25090-3_4", "10.1111/j.1467-8659.2009.01624.x", "10.1007/978-3-540-73011-8_22", "10.1002/cav.387", "10.1007/978-3-642-25090-3_4", "10.1111/j.1467-8659.2009.01624.x", "10.1007/978-3-540-73011-8_22", "10.1002/cav.387", "10.1007/978-3-642-25090-3_4", "10.1111/j.1467-8659.2009.01624.x", "10.1007/978-3-540-73011-8_22", "10.1002/cav.387"]}, "10.1109/TVCG.2012.173": {"doi": "10.1109/TVCG.2012.173", "author": ["H. Xu", "W. Yu", "S. Gu", "X. Li"], "title": "Biharmonic Volumetric Mapping Using Fundamental Solutions", "year": "2013", "abstract": "We propose a biharmonic model for cross-object volumetric mapping. This new computational model aims to facilitate the mapping of solid models with complicated geometry or heterogeneous inner structures. In order to solve cross-shape mapping between such models through divide and conquer, solid models can be decomposed into subparts upon which mappings is computed individually. The biharmonic volumetric mapping can be performed in each subregion separately. Unlike the widely used harmonic mapping which only allows C0 continuity along the segmentation boundary interfaces, this biharmonic model can provide C1 smoothness. We demonstrate the efficacy of our mapping framework on various geometric models with complex geometry (which are decomposed into subparts with simpler and solvable geometry) or heterogeneous interior structures (whose different material layers can be segmented and processed separately).", "keywords": ["computational geometry", "divide and conquer methods", "solid modelling", "biharmonic volumetric mapping", "biharmonic model", "cross-object volumetric mapping", "computational model", "solid models", "heterogeneous inner structures", "divide and conquer method", "segmentation boundary interfaces", "geometric models", "complex geometry", "heterogeneous interior structures", "Computational modeling", "Harmonic analysis", "Mathematical model", "Equations", "Geometry", "Shape", "Boundary conditions", "Volumetric mapping", "biharmonic mapping", "Algorithms", "Computer Graphics", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Reproducibility of Results", "Sensitivity and Specificity"], "referenced_by": ["IKEY:8085500", "IKEY:7852735", "IKEY:7558244", "IKEY:7250338", "IKEY:7250335", "IKEY:8230210", "IKEY:8536417", "10.1049/iet-ipr.2014.0920"], "referencing": []}, "10.1109/TVCG.2012.147": {"doi": "10.1109/TVCG.2012.147", "author": ["A. Szymczak"], "title": "Hierarchy of Stable Morse Decompositions", "year": "2013", "abstract": "We introduce an algorithm for construction of the Morse hierarchy, i.e., a hierarchy of Morse decompositions of a piecewise constant vector field on a surface driven by stability of the Morse sets with respect to perturbation of the vector field. Our approach builds upon earlier work on stable Morse decompositions, which can be used to obtain Morse sets of user-prescribed stability. More stable Morse decompositions are coarser, i.e., they consist of larger Morse sets. In this work, we develop an algorithm for tracking the growth of Morse sets and topological events (mergers) that they undergo as their stability is gradually increased. The resulting Morse hierarchy can be explored interactively. We provide examples demonstrating that it can provide a useful coarse overview of the vector field topology.", "keywords": ["computer graphics", "differential geometry", "piecewise constant techniques", "set theory", "vectors", "stable Morse decomposition hierarchy", "piecewise constant vector field", "Morse set stability", "vector field perturbation", "topological events", "vector field topology", "Vectors", "Trajectory", "Numerical stability", "Stability criteria", "Topology", "Indexes", "Morse decomposition", "persistence", "vector field", "Algorithms", "Computer Graphics", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Numerical Analysis, Computer-Assisted", "Reproducibility of Results", "Sensitivity and Specificity"], "referenced_by": ["IKEY:8278161", "IKEY:6634162", "IKEY:8457259", "IKEY:8794517", "10.1007/s12650-016-0348-8", "10.1137/18M1198946", "10.1088/1755-1315/237/3/032006", "10.1007/978-3-319-04099-8_3", "10.1007/s41468-020-00055-x", "10.1016/j.smhl.2020.100142"], "referencing": ["IKEY:6051431", "IKEY:5928334", "IKEY:4293020", "IKEY:4447667", "IKEY:1634313", "IKEY:35197", "IKEY:79452", "IKEY:1333662", "IKEY:1372179", "IKEY:5620895", "IKEY:6143903", "IKEY:928168", "IKEY:6051431", "IKEY:5928334", "IKEY:4293020", "IKEY:4447667", "IKEY:1634313", "IKEY:35197", "IKEY:79452", "IKEY:1333662", "IKEY:1372179", "IKEY:5620895", "IKEY:6143903", "IKEY:928168", "IKEY:6051431", "IKEY:5928334", "IKEY:4293020", "IKEY:4447667", "IKEY:1634313", "IKEY:35197", "IKEY:79452", "IKEY:1333662", "IKEY:1372179", "IKEY:5620895", "IKEY:6143903", "IKEY:928168", "10.1145/378583.378626", "10.1145/77635.77639", "10.1145/1183287.1183290", "10.1145/378583.378626", "10.1145/77635.77639", "10.1145/1183287.1183290", "10.1145/378583.378626", "10.1145/77635.77639", "10.1145/1183287.1183290", "10.1007/s00454-002-2885-2", "10.1007/s00791-011-0152-x", "10.1007/PL00004638", "10.1111/j.1467-8659.2004.00753.x", "10.1111/j.1467-8659.2011.01934.x", "10.1137/0201010", "10.1007/s00454-002-2885-2", "10.1007/s00791-011-0152-x", "10.1007/PL00004638", "10.1111/j.1467-8659.2004.00753.x", "10.1111/j.1467-8659.2011.01934.x", "10.1137/0201010", "10.1007/s00454-002-2885-2", "10.1007/s00791-011-0152-x", "10.1007/PL00004638", "10.1111/j.1467-8659.2004.00753.x", "10.1111/j.1467-8659.2011.01934.x", "10.1137/0201010"]}, "10.1109/TVCG.2012.174": {"doi": "10.1109/TVCG.2012.174", "author": ["Y. Yang", "X. Guo", "J. Vick", "L. G. Torres", "T. F. Campbell"], "title": "Physics-Based Deformable Tongue Visualization", "year": "2013", "abstract": "In this paper, a physics-based framework is presented to visualize the human tongue deformation. The tongue is modeled with the Finite Element Method (FEM) and driven by the motion capture data gathered during speech production. Several novel deformation visualization techniques are presented for in-depth data analysis and exploration. To reveal the hidden semantic information of the tongue deformation, we present a novel physics-based volume segmentation algorithm. This is accomplished by decomposing the tongue model into segments based on its deformation pattern with the computation of deformation subspaces and fitting the target deformation locally at each segment. In addition, the strain energy is utilized to provide an intuitive low-dimensional visualization for the high-dimensional sequential motion. Energy-interpolation-based morphing is also equipped to effectively highlight the subtle differences of the 3D deformed shapes without any visual occlusion. Our experimental results and analysis demonstrate the effectiveness of this framework. The proposed methods, though originally designed for the exploration of the tongue deformation, are also valid for general deformation analysis of other shapes.", "keywords": ["data analysis", "data visualisation", "deformation", "finite element analysis", "image segmentation", "interpolation", "speech processing", "physics-based deformable tongue visualization", "physics-based framework", "human tongue deformation visualization", "finite element method", "FEM", "motion capture data", "speech production", "deformation visualization techniques", "in-depth data analysis", "hidden semantic information", "physics-based volume segmentation algorithm", "deformation subspace computation", "local target deformation", "strain energy", "intuitive low-dimensional visualization", "high-dimensional sequential motion", "energy interpolation-based morphing", "3D deformed shapes", "visual occlusion", "Tongue", "Sensors", "Speech", "Production", "Shape", "Deformable models", "Visualization", "Deformable model", "tongue", "finite element method", "modal analysis", "Algorithms", "Biophysics", "Computer Graphics", "Computer Simulation", "Elastic Modulus", "Humans", "Imaging, Three-Dimensional", "Models, Biological", "Movement", "Reproducibility of Results", "Sensitivity and Specificity", "Speech", "Tongue", "Tongue", "User-Computer Interface"], "referenced_by": ["IKEY:7472705", "IKEY:8297109", "IKEY:8291424", "IKEY:7892238", "IKEY:8462096", "10.1016/B978-0-12-804009-6.00019-5", "10.1016/j.cagd.2016.02.014", "10.1080/13873954.2016.1220015", "10.1108/EC-08-2015-0235", "10.2197/ipsjjip.22.401"], "referencing": ["IKEY:5290758", "IKEY:1359737", "IKEY:5557868", "IKEY:5290752", "IKEY:4658146", "IKEY:5290758", "IKEY:1359737", "IKEY:5557868", "IKEY:5290752", "IKEY:4658146", "IKEY:5290758", "IKEY:1359737", "IKEY:5557868", "IKEY:5290752", "IKEY:4658146", "10.1145/344779.344859", "10.1145/545261.545269", "10.1145/74334.74355", "10.1145/1073204.1073208", "10.1145/1186822.1073218", "10.1145/97879.565650", "10.1145/344779.344859", "10.1145/545261.545269", "10.1145/74334.74355", "10.1145/1073204.1073208", "10.1145/1186822.1073218", "10.1145/97879.565650", "10.1145/344779.344859", "10.1145/545261.545269", "10.1145/74334.74355", "10.1145/1073204.1073208", "10.1145/1186822.1073218", "10.1145/97879.565650", "10.1006/jpho.2002.0166", "10.1016/0730-725X(87)90477-2", "10.1002/cav.100", "10.1121/1.3204306", "10.1250/ast.30.277", "10.1142/4134", "10.1007/978-3-540-25968-8_9", "10.1044/jslhr.4301.239", "10.1111/j.1467-8659.2009.01380.x", "10.1002/vis.249", "10.3109/02699206.2011.620678", "10.1002/cav.246", "10.1044/jslhr.4006.1341", "10.1111/j.1467-8659.2007.01103.x", "10.1121/1.386930", "10.1080/10255841003762034", "10.1002/cnm.1423", "10.1121/1.399188", "10.1044/1092-4388(2001/081)", "10.1121/1.414969", "10.1044/1092-4388(2001/009)", "10.1007/11790273_3", "10.1121/1.411871", "10.1002/cav.48", "10.1002/cav.373", "10.1016/S0167-6393(98)00048-X", "10.1006/jpho.2002.0166", "10.1016/0730-725X(87)90477-2", "10.1002/cav.100", "10.1121/1.3204306", "10.1250/ast.30.277", "10.1142/4134", "10.1007/978-3-540-25968-8_9", "10.1044/jslhr.4301.239", "10.1111/j.1467-8659.2009.01380.x", "10.1002/vis.249", "10.3109/02699206.2011.620678", "10.1002/cav.246", "10.1044/jslhr.4006.1341", "10.1111/j.1467-8659.2007.01103.x", "10.1121/1.386930", "10.1080/10255841003762034", "10.1002/cnm.1423", "10.1121/1.399188", "10.1044/1092-4388(2001/081)", "10.1121/1.414969", "10.1044/1092-4388(2001/009)", "10.1007/11790273_3", "10.1121/1.411871", "10.1002/cav.48", "10.1002/cav.373", "10.1016/S0167-6393(98)00048-X", "10.1006/jpho.2002.0166", "10.1016/0730-725X(87)90477-2", "10.1002/cav.100", "10.1121/1.3204306", "10.1250/ast.30.277", "10.1142/4134", "10.1007/978-3-540-25968-8_9", "10.1044/jslhr.4301.239", "10.1111/j.1467-8659.2009.01380.x", "10.1002/vis.249", "10.3109/02699206.2011.620678", "10.1002/cav.246", "10.1044/jslhr.4006.1341", "10.1111/j.1467-8659.2007.01103.x", "10.1121/1.386930", "10.1080/10255841003762034", "10.1002/cnm.1423", "10.1121/1.399188", "10.1044/1092-4388(2001/081)", "10.1121/1.414969", "10.1044/1092-4388(2001/009)", "10.1007/11790273_3", "10.1121/1.411871", "10.1002/cav.48", "10.1002/cav.373", "10.1016/S0167-6393(98)00048-X"]}, "10.1109/TVCG.2012.148": {"doi": "10.1109/TVCG.2012.148", "author": ["T. Chen", "P. Tan", "L. Ma", "M. Cheng", "A. Shamir", "S. Hu"], "title": "PoseShop: Human Image Database Construction and Personalized Content Synthesis", "year": "2013", "abstract": "We present PoseShop - a pipeline to construct segmented human image database with minimal manual intervention. By downloading, analyzing, and filtering massive amounts of human images from the Internet, we achieve a database which contains 400 thousands human figures that are segmented out of their background. The human figures are organized based on action semantic, clothes attributes, and indexed by the shape of their poses. They can be queried using either silhouette sketch or a skeleton to find a given pose. We demonstrate applications for this database for multiframe personalized content synthesis in the form of comic-strips, where the main character is the user or his/her friends. We address the two challenges of such synthesis, namely personalization and consistency over a set of frames, by introducing head swapping and clothes swapping techniques. We also demonstrate an action correlation analysis application to show the usefulness of the database for vision application.", "keywords": ["bone", "image segmentation", "indexing", "information filtering", "Internet", "visual databases", "PoseShop", "segmented human image database", "human image filtering", "Internet", "human figures", "action semantic", "clothe attributes", "indexing", "pose shape", "silhouette sketch", "skeleton", "multiframe personalized content synthesis", "comic strips", "personalization", "head swapping", "action correlation analysis application", "vision application", "Humans", "Skin", "Image segmentation", "Image databases", "Image color analysis", "Shape", "Image database", "image composition", "Algorithms", "Computer Graphics", "Database Management Systems", "Databases, Factual", "Humans", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Information Storage and Retrieval", "Posture", "Reproducibility of Results", "Sensitivity and Specificity", "User-Computer Interface", "Whole Body Imaging"], "referenced_by": ["IKEY:6909816", "IKEY:6751300", "IKEY:7281113", "IKEY:7514714", "IKEY:6469201", "IKEY:7368936", "IKEY:7469342", "IKEY:6871397", "IKEY:8089792", "IKEY:7045886", "IKEY:8237749", "IKEY:7226841", "IKEY:8579079", "IKEY:8866746", "IKEY:9157030", "10.1145/2661229.2661278", "10.1145/2897824.2925954", "10.1007/s00371-013-0867-4", "10.1007/s00371-013-0897-y", "10.1007/s00530-016-0507-8", "10.1007/s10799-015-0224-6", "10.1007/s11042-015-2622-5", "10.1007/s11390-015-1543-0", "10.1007/s11390-017-1681-7", "10.1007/s41095-017-0084-6", "10.1016/j.gmod.2013.10.006", "10.1016/j.patrec.2013.07.016", "10.1111/cgf.12665", "10.1111/cgf.12758", "10.1111/cgf.13099", "10.12720/ijsps.1.2.218-224", "10.5057/jjske.TJSKE-D-16-00070", "10.1007/s41095-018-0120-1", "10.1117/1.JEI.26.2.023022", "10.3390/s19071670", "10.1007/s00371-012-0755-3", "10.1007/s11390-020-0305-9", "10.1002/cpe.5951"], "referencing": ["IKEY:927464", "IKEY:4657363", "IKEY:1640954", "IKEY:5728806", "IKEY:5959134", "IKEY:1626186", "IKEY:993558", "IKEY:4250466", "IKEY:4359322", "IKEY:946629", "IKEY:5374413", "IKEY:927464", "IKEY:4657363", "IKEY:1640954", "IKEY:5728806", "IKEY:5959134", "IKEY:1626186", "IKEY:993558", "IKEY:4250466", "IKEY:4359322", "IKEY:946629", "IKEY:5374413", "IKEY:927464", "IKEY:4657363", "IKEY:1640954", "IKEY:5728806", "IKEY:5959134", "IKEY:1626186", "IKEY:993558", "IKEY:4250466", "IKEY:4359322", "IKEY:946629", "IKEY:5374413", "10.1145/2070781.2024188", "10.1145/1276377.1276382", "10.1145/1360612.1360638", "10.1145/1531326.1531374", "10.1145/1882261.1866172", "10.1145/2070781.2024190", "10.1145/1618452.1618470", "10.1145/2070781.2024189", "10.1145/237170.237260", "10.1145/1073204.1073246", "10.1145/1778765.1778863", "10.1145/2010324.1964927", "10.1145/1015706.1015720", "10.1145/1015706.1015719", "10.1145/2070781.2024188", "10.1145/1276377.1276382", "10.1145/1360612.1360638", "10.1145/1531326.1531374", "10.1145/1882261.1866172", "10.1145/2070781.2024190", "10.1145/1618452.1618470", "10.1145/2070781.2024189", "10.1145/237170.237260", "10.1145/1073204.1073246", "10.1145/1778765.1778863", "10.1145/2010324.1964927", "10.1145/1015706.1015720", "10.1145/1015706.1015719", "10.1145/2070781.2024188", "10.1145/1276377.1276382", "10.1145/1360612.1360638", "10.1145/1531326.1531374", "10.1145/1882261.1866172", "10.1145/2070781.2024190", "10.1145/1618452.1618470", "10.1145/2070781.2024189", "10.1145/237170.237260", "10.1145/1073204.1073246", "10.1145/1778765.1778863", "10.1145/2010324.1964927", "10.1145/1015706.1015720", "10.1145/1015706.1015719", "10.1007/s00371-011-0638-z", "10.1007/s11263-007-0090-8", "10.1007/978-3-540-27814-6_37", "10.1111/j.1467-8659.2006.00960.x", "10.1007/3-540-47969-4_42", "10.1023/B:VISI.0000022288.19776.77", "10.1023/A:1013200319198", "10.1007/s00371-011-0583-x", "10.1007/s00371-011-0638-z", "10.1007/s11263-007-0090-8", "10.1007/978-3-540-27814-6_37", "10.1111/j.1467-8659.2006.00960.x", "10.1007/3-540-47969-4_42", "10.1023/B:VISI.0000022288.19776.77", "10.1023/A:1013200319198", "10.1007/s00371-011-0583-x", "10.1007/s00371-011-0638-z", "10.1007/s11263-007-0090-8", "10.1007/978-3-540-27814-6_37", "10.1111/j.1467-8659.2006.00960.x", "10.1007/3-540-47969-4_42", "10.1023/B:VISI.0000022288.19776.77", "10.1023/A:1013200319198", "10.1007/s00371-011-0583-x"]}, "10.1109/TVCG.2012.159": {"doi": "10.1109/TVCG.2012.159", "author": ["R. Carnecky", "R. Fuchs", "S. Mehl", "Y. Jang", "R. Peikert"], "title": "Smart Transparency for Illustrative Visualization of Complex Flow Surfaces", "year": "2013", "abstract": "The perception of transparency and the underlying neural mechanisms have been subject to extensive research in the cognitive sciences. However, we have yet to develop visualization techniques that optimally convey the inner structure of complex transparent shapes. In this paper, we apply the findings of perception research to develop a novel illustrative rendering method that enhances surface transparency nonlocally. Rendering of transparent geometry is computationally expensive since many optimizations, such as visibility culling, are not applicable and fragments have to be sorted by depth for correct blending. In order to overcome these difficulties efficiently, we propose the illustration buffer. This novel data structure combines the ideas of the A and G-buffers to store a list of all surface layers for each pixel. A set of local and nonlocal operators is then used to process these depth-lists to generate the final image. Our technique is interactive on current graphics hardware and is only limited by the available graphics memory. Based on this framework, we present an efficient algorithm for a nonlocal transparency enhancement that creates expressive renderings of transparent surfaces. A controlled quantitative double blind user study shows that the presented approach improves the understanding of complex transparent surfaces significantly.", "keywords": ["buffer storage", "data visualisation", "rendering (computer graphics)", "smart transparency", "illustrative visualization", "complex flow surface", "neural mechanism", "cognitive science", "complex transparent shape", "illustrative rendering", "surface transparency", "transparent geometry", "visibility culling", "illustration buffer", "graphics memory", "nonlocal transparency enhancement", "A-buffer", "G-buffer", "Rendering (computer graphics)", "Buffer storage", "Image color analysis", "Surface treatment", "Indexes", "Graphics processing unit", "Illustrative rendering", "transparency", "flow visualization", "integral surface", "user study", "diffusion", "a-buffer", "illustration buffer", "perception", "Algorithms", "Computer Graphics", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Reproducibility of Results", "Rheology", "Sensitivity and Specificity", "User-Computer Interface"], "referenced_by": ["IKEY:7465255", "IKEY:7070744", "IKEY:8038807", "IKEY:8805465", "IKEY:8713907", "10.1016/j.cag.2015.01.002", "10.1111/cgf.12627", "10.1111/cgf.12746", "10.1111/cgf.13262", "10.1111/cgf.13322", "10.1111/cgf.14019"], "referencing": ["IKEY:4376160", "IKEY:5613472", "IKEY:5613473", "IKEY:480795", "IKEY:568110", "IKEY:1196000", "IKEY:5290740", "IKEY:5290742", "IKEY:999781", "IKEY:4658198", "IKEY:31463", "IKEY:1210862", "IKEY:5613487", "IKEY:4376160", "IKEY:5613472", "IKEY:5613473", "IKEY:480795", "IKEY:568110", "IKEY:1196000", "IKEY:5290740", "IKEY:5290742", "IKEY:999781", "IKEY:4658198", "IKEY:31463", "IKEY:1210862", "IKEY:5613487", "IKEY:4376160", "IKEY:5613472", "IKEY:5613473", "IKEY:480795", "IKEY:568110", "IKEY:1196000", "IKEY:5290740", "IKEY:5290742", "IKEY:999781", "IKEY:4658198", "IKEY:31463", "IKEY:1210862", "IKEY:5613487", "10.1145/1141911.1142016", "10.1145/1842993.1842999", "10.1145/97879.97901", "10.1145/1276377.1276401", "10.1145/1507149.1507170", "10.1145/882262.882354", "10.1145/965103.807437", "10.1145/280814.280950", "10.1145/1531326.1531331", "10.1145/800031.808585", "10.1145/1230100.1230117", "10.1145/1141911.1142016", "10.1145/1842993.1842999", "10.1145/97879.97901", "10.1145/1276377.1276401", "10.1145/1507149.1507170", "10.1145/882262.882354", "10.1145/965103.807437", "10.1145/280814.280950", "10.1145/1531326.1531331", "10.1145/800031.808585", "10.1145/1230100.1230117", "10.1145/1141911.1142016", "10.1145/1842993.1842999", "10.1145/97879.97901", "10.1145/1276377.1276401", "10.1145/1507149.1507170", "10.1145/882262.882354", "10.1145/965103.807437", "10.1145/280814.280950", "10.1145/1531326.1531331", "10.1145/800031.808585", "10.1145/1230100.1230117", "10.1038/nn1853", "10.1111/1467-8659.00591", "10.1007/s00371-010-0541-z", "10.1057/palgrave.ivs.9500024", "10.1111/j.1467-8659.2010.01725.x", "10.1016/j.visres.2007.06.004", "10.1068/p190497", "10.1016/S0734-189X(85)80002-5", "10.1037/0033-295X.110.4.785", "10.1017/CBO9780511611483", "10.1038/nn1853", "10.1111/1467-8659.00591", "10.1007/s00371-010-0541-z", "10.1057/palgrave.ivs.9500024", "10.1111/j.1467-8659.2010.01725.x", "10.1016/j.visres.2007.06.004", "10.1068/p190497", "10.1016/S0734-189X(85)80002-5", "10.1037/0033-295X.110.4.785", "10.1017/CBO9780511611483", "10.1038/nn1853", "10.1111/1467-8659.00591", "10.1007/s00371-010-0541-z", "10.1057/palgrave.ivs.9500024", "10.1111/j.1467-8659.2010.01725.x", "10.1016/j.visres.2007.06.004", "10.1068/p190497", "10.1016/S0734-189X(85)80002-5", "10.1037/0033-295X.110.4.785", "10.1017/CBO9780511611483"]}, "10.1109/TVCG.2012.162": {"doi": "10.1109/TVCG.2012.162", "author": ["B. C. Lucas", "M. Kazhdan", "R. H. Taylor"], "title": "Spring Level Sets: A Deformable Model Representation to Provide Interoperability between Meshes and Level Sets", "year": "2013", "abstract": "A new type of deformable model is presented that merges meshes and level sets into one representation to provide interoperability between methods designed for either. This includes the ability to circumvent the CFL time step restriction for methods that require large step sizes. The key idea is to couple a constellation of disconnected triangular surface elements (springls) with a level set that tracks the moving constellation. The target application for Spring Level Sets (SpringLS) is to implement comprehensive imaging pipelines that require a mixture of deformable model representations to achieve the best performance. We demonstrate how to implement key components of a comprehensive imaging pipeline with SpringLS, including image segmentation, registration, tracking, and atlasing.", "keywords": ["image registration", "image segmentation", "object tracking", "spring level sets", "interoperability", "meshes", "CFL time step restriction", "disconnected triangular surface elements", "moving constellation", "Spring Level Sets", "SpringLS", "imaging pipelines", "deformable model representations", "comprehensive imaging", "image segmentation", "image registration", "tracking", "atlasing", "Level set", "Deformable models", "Springs", "Image segmentation", "Imaging", "Materials", "Computational modeling", "Segmentation", "registration", "tracking", "atlas", "shape model", "Algorithms", "Animals", "Computer Graphics", "Computer Simulation", "Elastic Modulus", "Humans", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Imaging, Three-Dimensional", "Models, Biological", "Reproducibility of Results", "Sensitivity and Specificity"], "referenced_by": ["IKEY:8265312", "IKEY:8265360", "10.1007/s00371-013-0802-8"], "referencing": ["IKEY:4520155", "IKEY:1563218", "IKEY:1201824", "IKEY:1194625", "IKEY:661186", "IKEY:1242349", "IKEY:1500327", "IKEY:4520155", "IKEY:1563218", "IKEY:1201824", "IKEY:1194625", "IKEY:661186", "IKEY:1242349", "IKEY:1500327", "IKEY:4520155", "IKEY:1563218", "IKEY:1201824", "IKEY:1194625", "IKEY:661186", "IKEY:1242349", "IKEY:1500327", "10.1145/37402.37427", "10.1145/1576246.1531382", "10.1145/1833349.1778787", "10.1145/1576246.1531382", "10.1145/1833349.1778786", "10.1145/1122501.1122503", "10.1145/566654.566578", "10.1145/1599470.1599488", "10.1145/1275808.1276397", "10.1145/1599470.1599501", "10.1145/882262.882319", "10.1145/1667239.1667257", "10.1145/344779.344936", "10.1145/192161.192227", "10.1145/37402.37422", "10.1145/1073204.1073227", "10.1145/237170.237269", "10.1145/1836845.1836903", "10.1145/1186223.1186303", "10.1145/1275808.1276467", "10.1145/1073204.1073296", "10.1145/37402.37427", "10.1145/1576246.1531382", "10.1145/1833349.1778787", "10.1145/1576246.1531382", "10.1145/1833349.1778786", "10.1145/1122501.1122503", "10.1145/566654.566578", "10.1145/1599470.1599488", "10.1145/1275808.1276397", "10.1145/1599470.1599501", "10.1145/882262.882319", "10.1145/1667239.1667257", "10.1145/344779.344936", "10.1145/192161.192227", "10.1145/37402.37422", "10.1145/1073204.1073227", "10.1145/237170.237269", "10.1145/1836845.1836903", "10.1145/1186223.1186303", "10.1145/1275808.1276467", "10.1145/1073204.1073296", "10.1145/37402.37427", "10.1145/1576246.1531382", "10.1145/1833349.1778787", "10.1145/1576246.1531382", "10.1145/1833349.1778786", "10.1145/1122501.1122503", "10.1145/566654.566578", "10.1145/1599470.1599488", "10.1145/1275808.1276397", "10.1145/1599470.1599501", "10.1145/882262.882319", "10.1145/1667239.1667257", "10.1145/344779.344936", "10.1145/192161.192227", "10.1145/37402.37422", "10.1145/1073204.1073227", "10.1145/237170.237269", "10.1145/1836845.1836903", "10.1145/1186223.1186303", "10.1145/1275808.1276467", "10.1145/1073204.1073296", "10.1006/cviu.1995.1004", "10.1007/978-3-642-23629-7_54", "10.1007/978-3-540-76390-1_17", "10.1111/j.1467-8659.2006.01000.x", "10.1016/j.compstruc.2004.04.024", "10.1111/j.1467-8659.2007.01068.x", "10.1016/j.jcp.2005.04.013", "10.1111/j.1467-8659.2010.01782.x", "10.1111/j.1467-8659.2006.00958.x", "10.1073/pnas.93.4.1591", "10.1023/A:1008036829907", "10.1006/jcph.2002.7166", "10.1137/0733033", "10.1016/j.jcp.2006.05.036", "10.1023/A:1007979827043", "10.1006/cviu.1995.1004", "10.1007/978-3-642-23629-7_54", "10.1007/978-3-540-76390-1_17", "10.1111/j.1467-8659.2006.01000.x", "10.1016/j.compstruc.2004.04.024", "10.1111/j.1467-8659.2007.01068.x", "10.1016/j.jcp.2005.04.013", "10.1111/j.1467-8659.2010.01782.x", "10.1111/j.1467-8659.2006.00958.x", "10.1073/pnas.93.4.1591", "10.1023/A:1008036829907", "10.1006/jcph.2002.7166", "10.1137/0733033", "10.1016/j.jcp.2006.05.036", "10.1023/A:1007979827043", "10.1006/cviu.1995.1004", "10.1007/978-3-642-23629-7_54", "10.1007/978-3-540-76390-1_17", "10.1111/j.1467-8659.2006.01000.x", "10.1016/j.compstruc.2004.04.024", "10.1111/j.1467-8659.2007.01068.x", "10.1016/j.jcp.2005.04.013", "10.1111/j.1467-8659.2010.01782.x", "10.1111/j.1467-8659.2006.00958.x", "10.1073/pnas.93.4.1591", "10.1023/A:1008036829907", "10.1006/jcph.2002.7166", "10.1137/0733033", "10.1016/j.jcp.2006.05.036", "10.1023/A:1007979827043"]}, "10.1109/TVCG.2012.160": {"doi": "10.1109/TVCG.2012.160", "author": ["J. E. Kyprianidis", "J. Collomosse", "T. Wang", "T. Isenberg"], "title": "State of the \"Art\u201d: A Taxonomy of Artistic Stylization Techniques for Images and Video", "year": "2013", "abstract": "This paper surveys the field of nonphotorealistic rendering (NPR), focusing on techniques for transforming 2D input (images and video) into artistically stylized renderings. We first present a taxonomy of the 2D NPR algorithms developed over the past two decades, structured according to the design characteristics and behavior of each technique. We then describe a chronology of development from the semiautomatic paint systems of the early nineties, through to the automated painterly rendering systems of the late nineties driven by image gradient analysis. Two complementary trends in the NPR literature are then addressed, with reference to our taxonomy. First, the fusion of higher level computer vision and NPR, illustrating the trends toward scene analysis to drive artistic abstraction and diversity of style. Second, the evolution of local processing approaches toward edge-aware filtering for real-time stylization of images and video. The survey then concludes with a discussion of open challenges for 2D NPR identified in recent NPR symposia, including topics such as user and aesthetic evaluation.", "keywords": ["art", "computer vision", "filtering theory", "gradient methods", "real-time systems", "rendering (computer graphics)", "video signal processing", "taxonomy", "artistic stylization techniques", "nonphotorealistic rendering", "artistically stylized renderings", "2D NPR algorithms", "design characteristics", "semiautomatic paint systems", "automated painterly rendering systems", "image gradient analysis", "NPR literature", "computer vision", "scene analysis", "artistic abstraction", "edge-aware filtering", "real-time stylization", "NPR symposia", "user evaluation", "aesthetic evaluation", "Rendering (computer graphics)", "Painting", "Image color analysis", "Taxonomy", "Algorithm design and analysis", "Image edge detection", "Image and video stylization", "nonphotorealistic rendering (NPR)", "artistic rendering", "Computer Graphics", "Creativity", "Forecasting", "Imaging, Three-Dimensional", "Paintings", "User-Computer Interface", "Video Recording"], "referenced_by": ["10.1145/2601097.2601133", "10.1145/2617570", "10.1145/3072959.3073660", "10.1002/cav.1725", "10.1007/978-3-319-24589-8_38", "10.1007/978-3-319-40259-8_18", "10.1007/978-3-319-48496-9_62", "10.1007/978-3-662-56006-8_3", "10.1007/s00371-013-0881-6", "10.1007/s00371-015-1073-3", "10.1007/s00371-018-1474-1", "10.1007/s11042-015-2867-z", "10.1007/s11042-016-3951-8", "10.1007/s11042-016-4175-7", "10.1007/s11042-017-4882-8", "10.1007/s11042-017-5190-z", "10.1007/s11042-018-5672-7", "10.1007/s11554-016-0643-6", "10.1007/s41095-015-0017-1", "10.1016/j.cag.2015.02.001", "10.1016/j.cag.2015.12.001", "10.1016/j.cag.2017.05.001", "10.1016/j.jvcir.2016.01.012", "10.1080/13658816.2014.922686", "10.1111/cgf.12721", "10.1111/cgf.12729", "10.1111/cgf.12733", "10.1111/cgf.13322", "10.1111/cgf.13334", "10.1142/S0218001417590261"], "referencing": ["10.1145/508530.508554", "10.1145/1015706.1015764", "10.1145/1124728.1124751", "10.1145/166117.166151", "10.1145/508530.508553", "10.1145/1413634.1413690", "10.1145/258734.258896", "10.1145/1124728.1124741", "10.1145/1809939.1809960", "10.1145/566570.566650", "10.1145/508530.508550", "10.1145/383259.383296", "10.1145/1809939.1809959", "10.1145/508530.508545", "10.1145/966131.966133", "10.1145/97879.97902", "10.1145/383259.383327", "10.1145/987657.987676", "10.1145/1809939.1809957", "10.1145/280814.280951", "10.1145/508530.508546", "10.1145/383259.383295", "10.1145/340916.340917", "10.1145/1572614.1572623", "10.1145/2030441.2030446", "10.1145/1124728.1124747", "10.1145/2024676.2024701", "10.1145/1274871.1274878", "10.1145/566654.566633", "10.1145/1572614.1572622", "10.1145/508530.508534", "10.1145/1141911.1141916", "10.1145/2024676.2024686", "10.1145/37401.37407", "10.1145/1809939.1809945", "10.1145/1809939.1809948", "10.1145/258734.258893", "10.1145/1073204.1073223", "10.1145/1730804.1730825", "10.1145/2010324.1964995", "10.1145/237170.237288", "10.1145/1572614.1572617", "10.1145/1377980.1377991", "10.1145/1124728.1124738", "10.1145/1377980.1377997", "10.1145/1274871.1274888", "10.1145/311535.311604", "10.1145/311535.311605", "10.1145/192161.192188", "10.1145/1360612.1360688", "10.1145/1124728.1124742", "10.1145/1409060.1409108", "10.1145/237170.237286", "10.1145/192161.192185", "10.1145/258734.258890", "10.1145/508530.508544", "10.1145/987657.987669", "10.1145/344779.345012", "10.1145/1274871.1274874", "10.1145/508530.508537", "10.1145/340916.340923", "10.1145/1124728.1124744", "10.1145/1073368.1073397", "10.1145/15922.15911", "10.1145/1141911.1142010", "10.1145/1809939.1809955", "10.1145/344779.345009", "10.1145/1124728.1124737", "10.1145/2024676.2024700", "10.1145/1179352.1142018", "10.1145/1268517.1268527", "10.1145/1377980.1377990", "10.1145/1809939.1809951", "10.1145/2024676.2024696", "10.1145/508530.508554", "10.1145/1015706.1015764", "10.1145/1124728.1124751", "10.1145/166117.166151", "10.1145/508530.508553", "10.1145/1413634.1413690", "10.1145/258734.258896", "10.1145/1124728.1124741", "10.1145/1809939.1809960", "10.1145/566570.566650", "10.1145/508530.508550", "10.1145/383259.383296", "10.1145/1809939.1809959", "10.1145/508530.508545", "10.1145/966131.966133", "10.1145/97879.97902", "10.1145/383259.383327", "10.1145/987657.987676", "10.1145/1809939.1809957", "10.1145/280814.280951", "10.1145/508530.508546", "10.1145/383259.383295", "10.1145/340916.340917", "10.1145/1572614.1572623", "10.1145/2030441.2030446", "10.1145/1124728.1124747", "10.1145/2024676.2024701", "10.1145/1274871.1274878", "10.1145/566654.566633", "10.1145/1572614.1572622", "10.1145/508530.508534", "10.1145/1141911.1141916", "10.1145/2024676.2024686", "10.1145/37401.37407", "10.1145/1809939.1809945", "10.1145/1809939.1809948", "10.1145/258734.258893", "10.1145/1073204.1073223", "10.1145/1730804.1730825", "10.1145/2010324.1964995", "10.1145/237170.237288", "10.1145/1572614.1572617", "10.1145/1377980.1377991", "10.1145/1124728.1124738", "10.1145/1377980.1377997", "10.1145/1274871.1274888", "10.1145/311535.311604", "10.1145/311535.311605", "10.1145/192161.192188", "10.1145/1360612.1360688", "10.1145/1124728.1124742", "10.1145/1409060.1409108", "10.1145/237170.237286", "10.1145/192161.192185", "10.1145/258734.258890", "10.1145/508530.508544", "10.1145/987657.987669", "10.1145/344779.345012", "10.1145/1274871.1274874", "10.1145/508530.508537", "10.1145/340916.340923", "10.1145/1124728.1124744", "10.1145/1073368.1073397", "10.1145/15922.15911", "10.1145/1141911.1142010", "10.1145/1809939.1809955", "10.1145/344779.345009", "10.1145/1124728.1124737", "10.1145/2024676.2024700", "10.1145/1179352.1142018", "10.1145/1268517.1268527", "10.1145/1377980.1377990", "10.1145/1809939.1809951", "10.1145/2024676.2024696", "10.1145/508530.508554", "10.1145/1015706.1015764", "10.1145/1124728.1124751", "10.1145/166117.166151", "10.1145/508530.508553", "10.1145/1413634.1413690", "10.1145/258734.258896", "10.1145/1124728.1124741", "10.1145/1809939.1809960", "10.1145/566570.566650", "10.1145/508530.508550", "10.1145/383259.383296", "10.1145/1809939.1809959", "10.1145/508530.508545", "10.1145/966131.966133", "10.1145/97879.97902", "10.1145/383259.383327", "10.1145/987657.987676", "10.1145/1809939.1809957", "10.1145/280814.280951", "10.1145/508530.508546", "10.1145/383259.383295", "10.1145/340916.340917", "10.1145/1572614.1572623", "10.1145/2030441.2030446", "10.1145/1124728.1124747", "10.1145/2024676.2024701", "10.1145/1274871.1274878", "10.1145/566654.566633", "10.1145/1572614.1572622", "10.1145/508530.508534", "10.1145/1141911.1141916", "10.1145/2024676.2024686", "10.1145/37401.37407", "10.1145/1809939.1809945", "10.1145/1809939.1809948", "10.1145/258734.258893", "10.1145/1073204.1073223", "10.1145/1730804.1730825", "10.1145/2010324.1964995", "10.1145/237170.237288", "10.1145/1572614.1572617", "10.1145/1377980.1377991", "10.1145/1124728.1124738", "10.1145/1377980.1377997", "10.1145/1274871.1274888", "10.1145/311535.311604", "10.1145/311535.311605", "10.1145/192161.192188", "10.1145/1360612.1360688", "10.1145/1124728.1124742", "10.1145/1409060.1409108", "10.1145/237170.237286", "10.1145/192161.192185", "10.1145/258734.258890", "10.1145/508530.508544", "10.1145/987657.987669", "10.1145/344779.345012", "10.1145/1274871.1274874", "10.1145/508530.508537", "10.1145/340916.340923", "10.1145/1124728.1124744", "10.1145/1073368.1073397", "10.1145/15922.15911", "10.1145/1141911.1142010", "10.1145/1809939.1809955", "10.1145/344779.345009", "10.1145/1124728.1124737", "10.1145/2024676.2024700", "10.1145/1179352.1142018", "10.1145/1268517.1268527", "10.1145/1377980.1377990", "10.1145/1809939.1809951", "10.1145/2024676.2024696", "10.5244/C.17.58", "10.1111/j.1467-8659.2011.02075.x", "10.1007/978-3-540-71805-5_55", "10.1007/978-3-540-32003-6_44", "10.1111/1467-8659.00413", "10.1111/1467-8659.00396", "10.1007/s00371-005-0292-4", "10.1007/978-3-540-32003-6_46", "10.1007/s00371-002-0175-x", "10.1117/1.2898894", "10.1111/1467-8659.00699", "10.1111/j.1467-8659.2008.01322.x", "10.1007/BF00133570", "10.1111/j.1467-8659.2008.01259.x", "10.1007/978-3-642-13544-6_17", "10.1007/978-1-4684-0769-3_13", "10.1111/j.1467-8659.2011.01882.x", "10.1111/j.1467-8659.2009.01574.x", "10.1111/j.1467-8659.2010.01752.x", "10.1016/j.cag.2010.11.006", "10.1137/0727053", "10.1561/0600000020", "10.1007/978-3-540-75274-5_9", "10.1016/j.cag.2010.11.003", "10.1111/j.1467-8659.2005.00838.x", "10.1016/j.gmod.2010.12.001", "10.1111/1467-8659.00268", "10.1111/1467-8659.1330455", "10.1007/3-540-44745-8_14", "10.1007/s10516-004-5449-7", "10.1111/j.1467-8659.2009.01566.x", "10.5244/C.17.58", "10.1111/j.1467-8659.2011.02075.x", "10.1007/978-3-540-71805-5_55", "10.1007/978-3-540-32003-6_44", "10.1111/1467-8659.00413", "10.1111/1467-8659.00396", "10.1007/s00371-005-0292-4", "10.1007/978-3-540-32003-6_46", "10.1007/s00371-002-0175-x", "10.1117/1.2898894", "10.1111/1467-8659.00699", "10.1111/j.1467-8659.2008.01322.x", "10.1007/BF00133570", "10.1111/j.1467-8659.2008.01259.x", "10.1007/978-3-642-13544-6_17", "10.1007/978-1-4684-0769-3_13", "10.1111/j.1467-8659.2011.01882.x", "10.1111/j.1467-8659.2009.01574.x", "10.1111/j.1467-8659.2010.01752.x", "10.1016/j.cag.2010.11.006", "10.1137/0727053", "10.1561/0600000020", "10.1007/978-3-540-75274-5_9", "10.1016/j.cag.2010.11.003", "10.1111/j.1467-8659.2005.00838.x", "10.1016/j.gmod.2010.12.001", "10.1111/1467-8659.00268", "10.1111/1467-8659.1330455", "10.1007/3-540-44745-8_14", "10.1007/s10516-004-5449-7", "10.1111/j.1467-8659.2009.01566.x", "10.5244/C.17.58", "10.1111/j.1467-8659.2011.02075.x", "10.1007/978-3-540-71805-5_55", "10.1007/978-3-540-32003-6_44", "10.1111/1467-8659.00413", "10.1111/1467-8659.00396", "10.1007/s00371-005-0292-4", "10.1007/978-3-540-32003-6_46", "10.1007/s00371-002-0175-x", "10.1117/1.2898894", "10.1111/1467-8659.00699", "10.1111/j.1467-8659.2008.01322.x", "10.1007/BF00133570", "10.1111/j.1467-8659.2008.01259.x", "10.1007/978-3-642-13544-6_17", "10.1007/978-1-4684-0769-3_13", "10.1111/j.1467-8659.2011.01882.x", "10.1111/j.1467-8659.2009.01574.x", "10.1111/j.1467-8659.2010.01752.x", "10.1016/j.cag.2010.11.006", "10.1137/0727053", "10.1561/0600000020", "10.1007/978-3-540-75274-5_9", "10.1016/j.cag.2010.11.003", "10.1111/j.1467-8659.2005.00838.x", "10.1016/j.gmod.2010.12.001", "10.1111/1467-8659.00268", "10.1111/1467-8659.1330455", "10.1007/3-540-44745-8_14", "10.1007/s10516-004-5449-7", "10.1111/j.1467-8659.2009.01566.x"]}, "10.1109/TVCG.2012.163": {"doi": "10.1109/TVCG.2012.163", "author": ["E. D. Ragan", "R. Kopper", "P. Schuchardt", "D. A. Bowman"], "title": "Studying the Effects of Stereo, Head Tracking, and Field of Regard on a Small-Scale Spatial Judgment Task", "year": "2013", "abstract": "Spatial judgments are important for many real-world tasks in engineering and scientific visualization. While existing research provides evidence that higher levels of display and interaction fidelity in virtual reality systems offer advantages for spatial understanding, few investigations have focused on small-scale spatial judgments or employed experimental tasks similar to those used in real-world applications. After an earlier study that considered a broad analysis of various spatial understanding tasks, we present the results of a follow-up study focusing on small-scale spatial judgments. In this research, we independently controlled field of regard, stereoscopy, and head-tracked rendering to study their effects on the performance of a task involving precise spatial inspections of complex 3D structures. Measuring time and errors, we asked participants to distinguish between structural gaps and intersections between components of 3D models designed to be similar to real underground cave systems. The overall results suggest that the addition of the higher fidelity system features support performance improvements in making small-scale spatial judgments. Through analyses of the effects of individual system components, the experiment shows that participants made significantly fewer errors with either an increased field of regard or with the addition of head-tracked rendering. The results also indicate that participants performed significantly faster when the system provided the combination of stereo and head-tracked rendering.", "keywords": ["rendering (computer graphics)", "stereo image processing", "virtual reality", "complex 3D structure", "spatial understanding task", "virtual reality", "small-scale spatial judgment task", "head-tracked rendering", "stereoscopy", "Visualization", "Electron tubes", "Navigation", "Data visualization", "Head", "Tracking", "Rendering (computer graphics)", "Artificial", "augmented", "and virtual realities", "graphical user interfaces", "Adolescent", "Adult", "Aged", "Cues", "Depth Perception", "Female", "Head Movements", "Humans", "Male", "Middle Aged", "Orientation", "Psychomotor Performance", "Space Perception", "Visual Fields", "Young Adult"], "referenced_by": ["IKEY:7131730", "IKEY:7460028", "IKEY:7460040", "IKEY:7893318", "IKEY:7160104", "IKEY:7004282", "IKEY:8231855", "IKEY:8172387", "IKEY:7300727", "IKEY:7517276", "IKEY:6777465", "IKEY:7042312", "IKEY:7118232", "IKEY:7547900", "IKEY:7817889", "IKEY:7504781", "IKEY:7892227", "IKEY:7957707", "IKEY:8672601", "IKEY:8642297", "IKEY:8797777", "IKEY:8424067", "IKEY:8943683", "IKEY:9004783", "IKEY:8554159", "IKEY:9223497", "IKEY:9212653", "10.1145/2702123.2702138", "10.1145/2983310.2985761", "10.1145/2983310.2985762", "10.1145/2330667.2330687", "10.1007/s10055-014-0254-0", "10.1007/s10055-016-0287-7", "10.1016/j.acalib.2017.09.003", "10.1016/j.chb.2016.06.026", "10.1016/j.cmpb.2016.07.026", "10.1016/j.displa.2017.07.001", "10.1080/03098265.2015.1066314", "10.1111/cgf.12939", "10.1111/cgf.13169", "10.1201/b17360-56", "10.3233/AIS-160368", "10.1080/10447318.2018.1498654", "10.1007/978-3-030-01388-2_2", "10.3154/jvs.37.146_2", "10.1002/pra2.2018.14505501033", "10.1007/978-3-319-27048-7_13", "10.1007/978-1-4471-6651-1_9", "10.1007/978-3-319-14645-4_7", "10.1080/10095020.2019.1621544", "10.4018/IJVAR.2019070103", "10.3389/fpsyg.2019.02529", "10.1080/02640414.2019.1689807", "10.1016/j.aei.2020.101061", "10.3390/mti4010003", "10.1007/s10055-020-00433-x"], "referencing": ["IKEY:4287241", "IKEY:6165144", "IKEY:1310069", "IKEY:511855", "IKEY:6165141", "IKEY:1191146", "IKEY:4287241", "IKEY:6165144", "IKEY:1310069", "IKEY:511855", "IKEY:6165141", "IKEY:1191146", "IKEY:4287241", "IKEY:6165144", "IKEY:1310069", "IKEY:511855", "IKEY:6165141", "IKEY:1191146", "10.1145/234972.234975", "10.1145/1315184.1315205", "10.1145/258734.258744", "10.1145/1836049.1836063", "10.1145/234972.234975", "10.1145/1315184.1315205", "10.1145/258734.258744", "10.1145/1836049.1836063", "10.1145/234972.234975", "10.1145/1315184.1315205", "10.1145/258734.258744", "10.1145/1836049.1836063", "10.3758/BF03211566", "10.1162/105474698565631", "10.1162/105474698565659", "10.1016/0045-7949(91)90255-K", "10.1098/rstb.2009.0138", "10.1037/h0043883", "10.1068/p080125", "10.1016/0042-6989(82)90126-2", "10.1111/j.1475-1313.1993.tb00496.x", "10.1016/0042-6989(95)00018-U", "10.1016/0042-6989(94)90106-6", "10.1163/15685680252875174", "10.1016/S0042-6989(99)00088-7", "10.1016/0042-6989(93)90075-8", "10.1167/4.12.1", "10.1016/j.visres.2005.11.018", "10.1016/j.neures.2004.11.006", "10.1016/j.neuropsychologia.2004.11.003", "10.1162/105474699566143", "10.1167/10.6.19", "10.3758/BF03211566", "10.1162/105474698565631", "10.1162/105474698565659", "10.1016/0045-7949(91)90255-K", "10.1098/rstb.2009.0138", "10.1037/h0043883", "10.1068/p080125", "10.1016/0042-6989(82)90126-2", "10.1111/j.1475-1313.1993.tb00496.x", "10.1016/0042-6989(95)00018-U", "10.1016/0042-6989(94)90106-6", "10.1163/15685680252875174", "10.1016/S0042-6989(99)00088-7", "10.1016/0042-6989(93)90075-8", "10.1167/4.12.1", "10.1016/j.visres.2005.11.018", "10.1016/j.neures.2004.11.006", "10.1016/j.neuropsychologia.2004.11.003", "10.1162/105474699566143", "10.1167/10.6.19", "10.3758/BF03211566", "10.1162/105474698565631", "10.1162/105474698565659", "10.1016/0045-7949(91)90255-K", "10.1098/rstb.2009.0138", "10.1037/h0043883", "10.1068/p080125", "10.1016/0042-6989(82)90126-2", "10.1111/j.1475-1313.1993.tb00496.x", "10.1016/0042-6989(95)00018-U", "10.1016/0042-6989(94)90106-6", "10.1163/15685680252875174", "10.1016/S0042-6989(99)00088-7", "10.1016/0042-6989(93)90075-8", "10.1167/4.12.1", "10.1016/j.visres.2005.11.018", "10.1016/j.neures.2004.11.006", "10.1016/j.neuropsychologia.2004.11.003", "10.1162/105474699566143", "10.1167/10.6.19"]}}