{"10.1109/TVCG.2018.2816059": {"doi": "10.1109/TVCG.2018.2816059", "author": ["M. Berger", "J. Li", "J. A. Levine"], "title": "A Generative Model for Volume Rendering", "year": "2019", "abstract": "We present a technique to synthesize and analyze volume-rendered images using generative models. We use the Generative Adversarial Network (GAN) framework to compute a model from a large collection of volume renderings, conditioned on (1) viewpoint and (2) transfer functions for opacity and color. Our approach facilitates tasks for volume analysis that are challenging to achieve using existing rendering techniques such as ray casting or texture-based methods. We show how to guide the user in transfer function editing by quantifying expected change in the output image. Additionally, the generative model transforms transfer functions into a view-invariant latent space specifically designed to synthesize volume-rendered images. We use this space directly for rendering, enabling the user to explore the space of volume-rendered images. As our model is independent of the choice of volume rendering process, we show how to analyze volume-rendered images produced by direct and global illumination lighting, for a variety of volume datasets.", "keywords": ["image colour analysis", "rendering (computer graphics)", "transfer functions", "volume rendering process", "generative adversarial network framework", "GAN framework", "volume-rendered image analysis", "ray casting", "texture-based methods", "transfer function", "view-invariant latent space", "volume-rendered image synthesis", "global illumination lighting", "direct illumination lighting", "generative model transforms transfer functions", "Rendering (computer graphics)", "Transfer functions", "Solid modeling", "Gallium nitride", "Image color analysis", "Computational modeling", "Sensitivity", "Volume rendering", "generative models", "deep learning", "generative adversarial networks"], "referenced_by": ["IKEY:8802285", "IKEY:8805426", "IKEY:9006507", "IKEY:9086293", "IKEY:9279880", "IKEY:9308043"], "referencing": ["IKEY:468400", "IKEY:1021579", "IKEY:4658153", "IKEY:5290762", "IKEY:5416704", "IKEY:7539599", "IKEY:920623", "IKEY:7192682", "IKEY:5290763", "IKEY:1250414", "IKEY:4015460", "IKEY:5429615", "IKEY:4276082", "IKEY:6064956", "IKEY:1703376", "IKEY:6327238", "IKEY:5613497", "IKEY:7013022", "IKEY:8237891", "IKEY:7780647", "IKEY:8100115", "IKEY:7298761", "IKEY:7780459", "IKEY:5459199", "IKEY:5539973", "IKEY:468400", "IKEY:1021579", "IKEY:4658153", "IKEY:5290762", "IKEY:5416704", "IKEY:7539599", "IKEY:920623", "IKEY:7192682", "IKEY:5290763", "IKEY:1250414", "IKEY:4015460", "IKEY:5429615", "IKEY:4276082", "IKEY:6064956", "IKEY:1703376", "IKEY:6327238", "IKEY:5613497", "IKEY:7013022", "IKEY:8237891", "IKEY:7780647", "IKEY:8100115", "IKEY:7298761", "IKEY:7780459", "IKEY:5459199", "IKEY:5539973", "IKEY:468400", "IKEY:1021579", "IKEY:4658153", "IKEY:5290762", "IKEY:5416704", "IKEY:7539599", "IKEY:920623", "IKEY:7192682", "IKEY:5290763", "IKEY:1250414", "IKEY:4015460", "IKEY:5429615", "IKEY:4276082", "IKEY:6064956", "IKEY:1703376", "IKEY:6327238", "IKEY:5613497", "IKEY:7013022", "IKEY:8237891", "IKEY:7780647", "IKEY:8100115", "IKEY:7298761", "IKEY:7780459", "IKEY:5459199", "IKEY:5539973", "10.1145/258734.258887", "10.1145/2993901.2993907", "10.1145/258734.258887", "10.1145/2993901.2993907", "10.1145/258734.258887", "10.1145/2993901.2993907", "10.1111/j.1467-8659.2009.01689.x", "10.1126/science.1127647", "10.1111/cgf.12934", "10.1111/cgf.12280", "10.1111/cgf.12367", "10.1111/cgf.12623", "10.1007/978-3-319-46493-0_20", "10.1016/B978-1-4832-1446-7.50035-2", "10.1111/j.1467-8659.2009.01689.x", "10.1126/science.1127647", "10.1111/cgf.12934", "10.1111/cgf.12280", "10.1111/cgf.12367", "10.1111/cgf.12623", "10.1007/978-3-319-46493-0_20", "10.1016/B978-1-4832-1446-7.50035-2", "10.1111/j.1467-8659.2009.01689.x", "10.1126/science.1127647", "10.1111/cgf.12934", "10.1111/cgf.12280", "10.1111/cgf.12367", "10.1111/cgf.12623", "10.1007/978-3-319-46493-0_20", "10.1016/B978-1-4832-1446-7.50035-2"]}, "10.1109/TVCG.2018.2818146": {"doi": "10.1109/TVCG.2018.2818146", "author": ["M. Wei", "Y. Tian", "W. Pang", "C. C. L. Wang", "M. Pang", "J. Wang", "J. Qin", "P. Heng"], "title": "Bas-Relief Modeling from Normal Layers", "year": "2019", "abstract": "Bas-relief is characterized by its unique presentation of intrinsic shape properties and/or detailed appearance using materials raised up in different degrees above a background. However, many bas-relief modeling methods could not manipulate scene details well. We propose a simple and effective solution for two kinds of bas-relief modeling (i.e., structure-preserving and detail-preserving) which is different from the prior tone mapping alike methods. Our idea originates from an observation on typical 3D models, which are decomposed into a piecewise smooth base layer and a detail layer in normal field. Proper manipulation of the two layers contributes to both structure-preserving and detail-preserving bas-relief modeling. We solve the modeling problem in a discrete geometry processing setup that uses normal-based mesh processing as a theoretical foundation. Specifically, using the two-step mesh smoothing mechanism as a bridge, we transfer the bas-relief modeling problem into a discrete space, and solve it in a least-squares manner. Experiments and comparisons to other methods show that (i) geometry details are better preserved in the scenario with high compression ratios, and (ii) structures are clearly preserved without shape distortion and interference from details.", "keywords": ["art", "computational geometry", "feature extraction", "image enhancement", "mesh generation", "smoothing methods", "solid modelling", "intrinsic shape properties", "bas-relief modeling methods", "scene details", "detail-preserving bas-relief modeling", "3D models", "two-step mesh smoothing mechanism", "discrete geometry processing setup", "normal-based mesh processing", "structure-preserving bas-relief modeling", "Three-dimensional displays", "Geometry", "Shape", "Computational modeling", "Solid modeling", "Surface reconstruction", "Smoothing methods", "Bas-relief modeling", "normal decomposition", "detail-preserving", "structure-preserving", "discrete geometry processing"], "referenced_by": ["IKEY:8434353", "IKEY:9017978", "IKEY:8611145", "IKEY:9187871", "IKEY:9206834", "IKEY:8730533"], "referencing": ["IKEY:6975236", "IKEY:6684153", "IKEY:5674028", "IKEY:4276075", "IKEY:7482721", "IKEY:4273383", "IKEY:6909679", "IKEY:6822598", "IKEY:710815", "IKEY:885721", "IKEY:4547940", "IKEY:56205", "IKEY:273735", "IKEY:6975236", "IKEY:6684153", "IKEY:5674028", "IKEY:4276075", "IKEY:7482721", "IKEY:4273383", "IKEY:6909679", "IKEY:6822598", "IKEY:710815", "IKEY:885721", "IKEY:4547940", "IKEY:56205", "IKEY:273735", "IKEY:6975236", "IKEY:6684153", "IKEY:5674028", "IKEY:4276075", "IKEY:7482721", "IKEY:4273383", "IKEY:6909679", "IKEY:6822598", "IKEY:710815", "IKEY:885721", "IKEY:4547940", "IKEY:56205", "IKEY:273735", "10.1145/2591011", "10.1145/1073204.1073292", "10.1145/566654.566573", "10.1145/1276377.1276417", "10.1145/1174429.1174494", "10.1145/882262.882368", "10.1145/1778765.1778797", "10.1145/882262.882367", "10.1145/588272.588276", "10.1145/2557449", "10.1145/1618452.1618482", "10.1145/2591011", "10.1145/1073204.1073292", "10.1145/566654.566573", "10.1145/1276377.1276417", "10.1145/1174429.1174494", "10.1145/882262.882368", "10.1145/1778765.1778797", "10.1145/882262.882367", "10.1145/588272.588276", "10.1145/2557449", "10.1145/1618452.1618482", "10.1145/2591011", "10.1145/1073204.1073292", "10.1145/566654.566573", "10.1145/1276377.1276417", "10.1145/1174429.1174494", "10.1145/882262.882368", "10.1145/1778765.1778797", "10.1145/882262.882367", "10.1145/588272.588276", "10.1145/2557449", "10.1145/1618452.1618482", "10.1016/S0010-4485(00)00129-9", "10.1111/cgf.12433", "10.1111/j.1467-8659.2012.03185.x", "10.1016/0262-8856(93)90066-P", "10.1111/1467-8659.00334", "10.1111/cgf.12557", "10.1080/10867651.1997.10487476", "10.1111/cgf.13028", "10.3722/cadaps.2010.465-478", "10.1016/j.gmod.2012.10.003", "10.1080/16864360.2014.846073", "10.1016/j.cad.2012.11.002", "10.1016/j.gmod.2014.02.002", "10.1016/j.gmod.2013.10.001", "10.1007/s11042-016-3924-y", "10.1111/cgf.12245", "10.1007/978-3-319-10578-9_53", "10.1111/j.2517-6161.1977.tb01600.x", "10.1016/S0010-4485(00)00129-9", "10.1111/cgf.12433", "10.1111/j.1467-8659.2012.03185.x", "10.1016/0262-8856(93)90066-P", "10.1111/1467-8659.00334", "10.1111/cgf.12557", "10.1080/10867651.1997.10487476", "10.1111/cgf.13028", "10.3722/cadaps.2010.465-478", "10.1016/j.gmod.2012.10.003", "10.1080/16864360.2014.846073", "10.1016/j.cad.2012.11.002", "10.1016/j.gmod.2014.02.002", "10.1016/j.gmod.2013.10.001", "10.1007/s11042-016-3924-y", "10.1111/cgf.12245", "10.1007/978-3-319-10578-9_53", "10.1111/j.2517-6161.1977.tb01600.x", "10.1016/S0010-4485(00)00129-9", "10.1111/cgf.12433", "10.1111/j.1467-8659.2012.03185.x", "10.1016/0262-8856(93)90066-P", "10.1111/1467-8659.00334", "10.1111/cgf.12557", "10.1080/10867651.1997.10487476", "10.1111/cgf.13028", "10.3722/cadaps.2010.465-478", "10.1016/j.gmod.2012.10.003", "10.1080/16864360.2014.846073", "10.1016/j.cad.2012.11.002", "10.1016/j.gmod.2014.02.002", "10.1016/j.gmod.2013.10.001", "10.1007/s11042-016-3924-y", "10.1111/cgf.12245", "10.1007/978-3-319-10578-9_53", "10.1111/j.2517-6161.1977.tb01600.x"]}, "10.1109/TVCG.2018.2818156": {"doi": "10.1109/TVCG.2018.2818156", "author": ["C. Koniaris", "M. Kosek", "D. Sinclair", "K. Mitchell"], "title": "Compressed Animated Light Fields with Real-Time View-Dependent Reconstruction", "year": "2019", "abstract": "We propose an end-to-end solution for presenting movie quality animated graphics to the user while still allowing the sense of presence afforded by free viewpoint head motion. By transforming offline rendered movie content into a novel immersive representation, we display the content in real-time according to the tracked head pose. For each frame, we generate a set of cubemap images per frame (colors and depths) using a sparse set of of cameras placed in the vicinity of the potential viewer locations. The cameras are placed with an optimization process so that the rendered data maximise coverage with minimum redundancy, depending on the lighting environment complexity. We compress the colors and depths separately, introducing an integrated spatial and temporal scheme tailored to high performance on GPUs for Virtual Reality applications. A view-dependent decompression algorithm decodes only the parts of the compressed video streams that are visible to users. We detail a real-time rendering algorithm using multi-view ray casting, with a variant that can handle strong view dependent effects such as mirror surfaces and glass. Compression rates of 150:1 and greater are demonstrated with quantitative analysis of image reconstruction quality and performance.", "keywords": ["computer animation", "data compression", "data visualisation", "image coding", "image reconstruction", "rendering (computer graphics)", "video streaming", "virtual reality", "temporal scheme", "view-dependent decompression algorithm", "compressed video streams", "real-time rendering algorithm", "multiview ray casting", "strong view dependent effects", "compression rates", "image reconstruction quality", "animated light fields", "real-time view-dependent reconstruction", "movie quality", "free viewpoint head motion", "movie content", "novel immersive representation", "tracked head", "cubemap images", "sparse set", "cameras", "optimization process", "rendered data maximise coverage", "lighting environment complexity", "integrated spatial", "virtual reality applications", "viewer locations", "image reconstruction performance", "compressed animated light fields", "Rendering (computer graphics)", "Real-time systems", "Image reconstruction", "Cameras", "Streaming media", "Probes", "Image color analysis", "Image-based rendering", "video compression", "light field rendering", "multi-view"], "referenced_by": ["IKEY:9198138", "IKEY:9301838", "10.1111/cgf.13835", "10.1364/OE.383606"], "referencing": ["IKEY:7350981", "IKEY:4036950", "IKEY:4378926", "IKEY:1640800", "IKEY:7350981", "IKEY:4036950", "IKEY:4378926", "IKEY:1640800", "IKEY:7350981", "IKEY:4036950", "IKEY:4378926", "IKEY:1640800", "10.1145/2766945", "10.1145/237170.237200", "10.1145/15886.15902", "10.1145/2461912.2461926", "10.1145/2929490.2929496", "10.1145/2742647.2742656", "10.1145/237170.237199", "10.1145/3023368.3023378", "10.1145/2766945", "10.1145/237170.237200", "10.1145/15886.15902", "10.1145/2461912.2461926", "10.1145/2929490.2929496", "10.1145/2742647.2742656", "10.1145/237170.237199", "10.1145/3023368.3023378", "10.1145/2766945", "10.1145/237170.237200", "10.1145/15886.15902", "10.1145/2461912.2461926", "10.1145/2929490.2929496", "10.1145/2742647.2742656", "10.1145/237170.237199", "10.1145/3023368.3023378", "10.1080/10867651.1997.10487480", "10.1111/j.1467-8659.2012.03002.x", "10.1002/sdtp.10282", "10.1016/j.image.2008.10.010", "10.1111/cgf.13032", "10.1111/j.1467-8659.2005.0m894.x", "10.1080/10867651.1997.10487480", "10.1111/j.1467-8659.2012.03002.x", "10.1002/sdtp.10282", "10.1016/j.image.2008.10.010", "10.1111/cgf.13032", "10.1111/j.1467-8659.2005.0m894.x", "10.1080/10867651.1997.10487480", "10.1111/j.1467-8659.2012.03002.x", "10.1002/sdtp.10282", "10.1016/j.image.2008.10.010", "10.1111/cgf.13032", "10.1111/j.1467-8659.2005.0m894.x"]}, "10.1109/TVCG.2018.2817209": {"doi": "10.1109/TVCG.2018.2817209", "author": ["L. Zhang", "Q. Zheng", "H. Huang"], "title": "Intrinsic Motion Stability Assessment for Video Stabilization", "year": "2019", "abstract": "This paper presents a novel algorithm for assessing the motion stability of a video after stabilization. The assessment works in a non-reference manner that directly measures the intrinsic smoothness of the video motion path. Specifically, the motion path is cast as a curve embedded in the Lie group of homographies, and its smoothness is mathematically characterized by the intrinsic geodesic curvature. A bundle of paths are adopted to handle spatially variant motions through the frames. Then, we compute the weighted curvature for a holistic assessment on the motion stability. Other factors related to video stabilization, e.g., distortion and cropping, are also investigated as supplement. We collect 160 shaky video clips and their stabilized results for verification, and the experimental evidence shows the effectiveness of our algorithm in good correlation with human subjective judgements.", "keywords": ["differential geometry", "image motion analysis", "image sequences", "Lie groups", "motion estimation", "video signal processing", "intrinsic geodesic curvature", "spatially variant motions", "intrinsic motion stability assessment", "video stabilization", "nonreference manner", "intrinsic smoothness", "video motion path", "shaky video clips", "Stability criteria", "Motion measurement", "Quality assessment", "Manifolds", "Visualization", "Level measurement", "Stabilization", "non-reference", "assessment", "geodesic curvature"], "referenced_by": ["IKEY:8451475", "IKEY:8515019", "IKEY:8624247", "IKEY:8676301", "IKEY:8966057", "IKEY:8951447", "IKEY:8737754"], "referencing": ["IKEY:1467248", "IKEY:7331626", "IKEY:6420828", "IKEY:7305789", "IKEY:7867768", "IKEY:4036622", "IKEY:6706422", "IKEY:4362878", "IKEY:1467248", "IKEY:7331626", "IKEY:6420828", "IKEY:7305789", "IKEY:7867768", "IKEY:4036622", "IKEY:6706422", "IKEY:4362878", "IKEY:1467248", "IKEY:7331626", "IKEY:6420828", "IKEY:7305789", "IKEY:7867768", "IKEY:4036622", "IKEY:6706422", "IKEY:4362878", "10.1145/1531326.1531350", "10.1145/1899404.1899408", "10.1145/2461912.2461995", "10.1145/2461912.2461939", "10.1145/2980179.2980243", "10.1145/1531326.1531350", "10.1145/1899404.1899408", "10.1145/2461912.2461995", "10.1145/2461912.2461939", "10.1145/2980179.2980243", "10.1145/1531326.1531350", "10.1145/1899404.1899408", "10.1145/2461912.2461995", "10.1145/2461912.2461939", "10.1145/2980179.2980243", "10.2200/S00010ED1V01Y200508IVM003", "10.2307/2323277", "10.1007/s41095-015-0013-5", "10.1007/b98852", "10.1017/CBO9780511546877", "10.1017/CBO9780511811685", "10.1137/130928352", "10.4310/jdg/1214429069", "10.1007/s10851-013-0470-3", "10.1016/j.cviu.2007.09.014", "10.1007/s41095-016-0074-0", "10.2200/S00010ED1V01Y200508IVM003", "10.2307/2323277", "10.1007/s41095-015-0013-5", "10.1007/b98852", "10.1017/CBO9780511546877", "10.1017/CBO9780511811685", "10.1137/130928352", "10.4310/jdg/1214429069", "10.1007/s10851-013-0470-3", "10.1016/j.cviu.2007.09.014", "10.1007/s41095-016-0074-0", "10.2200/S00010ED1V01Y200508IVM003", "10.2307/2323277", "10.1007/s41095-015-0013-5", "10.1007/b98852", "10.1017/CBO9780511546877", "10.1017/CBO9780511811685", "10.1137/130928352", "10.4310/jdg/1214429069", "10.1007/s10851-013-0470-3", "10.1016/j.cviu.2007.09.014", "10.1007/s41095-016-0074-0"]}, "10.1109/TVCG.2018.2827998": {"doi": "10.1109/TVCG.2018.2827998", "author": ["J. Zhang", "J. Cao", "X. Liu", "H. Chen", "B. Li", "L. Liu"], "title": "Multi-Normal Estimation via Pair Consistency Voting", "year": "2019", "abstract": "The normals of feature points, i.e., the intersection points of multiple smooth surfaces, are ambiguous and undefined. This paper presents a unified definition for point cloud normals of feature and non-feature points, which allows feature points to possess multiple normals. This definition facilitates several succeeding operations, such as feature points extraction and point cloud filtering. We also develop a feature preserving normal estimation method which outputs multiple normals per feature point. The core of the method is a pair consistency voting scheme. All neighbor point pairs vote for the local tangent plane. Each vote takes the fitting residuals of the pair of points and their preliminary normal consistency into consideration. Thus the pairs from the same subspace and relatively far off features dominate the voting. An adaptive strategy is designed to overcome sampling anisotropy. In addition, we introduce an error measure compatible with traditional normal estimators, and present the first benchmark for normal estimation, composed of 152 synthesized data with various features and sampling densities, and 288 real scans with different noise levels. Comprehensive and quantitative experiments show that our method generates faithful feature preserving normals and outperforms previous cutting edge normal estimation methods, including the latest deep learning based method.", "keywords": ["computational geometry", "estimation theory", "feature extraction", "filtering theory", "learning (artificial intelligence)", "point cloud normals", "nonfeature points", "feature point", "multiple normals", "normal estimation method", "pair consistency voting scheme", "neighbor point pairs vote", "previous cutting edge normal estimation methods", "multinormal estimation", "intersection points", "Estimation", "Three-dimensional displays", "Benchmark testing", "Feature extraction", "Robustness", "Anisotropic magnetoresistance", "Face", "Normal estimation", "point clouds", "sharp feature", "subspace", "sampling anisotropy"], "referenced_by": ["IKEY:9103529", "IKEY:9156499", "IKEY:8730533", "IKEY:9293685", "10.1016/j.cad.2020.102860", "10.1016/j.cad.2020.102850", "10.1016/j.cad.2020.102857"], "referencing": ["IKEY:1310211", "IKEY:964489", "IKEY:1310211", "IKEY:964489", "IKEY:1310211", "IKEY:964489", "10.1145/344779.344940", "10.1145/383259.383300", "10.1145/133994.134011", "10.1145/2421636.2421645", "10.1145/882262.882319", "10.1145/1275808.1276406", "10.1145/1073204.1073227", "10.1145/2980179.2980232", "10.1145/344779.344940", "10.1145/383259.383300", "10.1145/133994.134011", "10.1145/2421636.2421645", "10.1145/882262.882319", "10.1145/1275808.1276406", "10.1145/1073204.1073227", "10.1145/2980179.2980232", "10.1145/344779.344940", "10.1145/383259.383300", "10.1145/133994.134011", "10.1145/2421636.2421645", "10.1145/882262.882319", "10.1145/1275808.1276406", "10.1145/1073204.1073227", "10.1145/2980179.2980232", "10.1016/j.cagd.2005.06.010", "10.5194/isprs-archives-XLII-2-W3-339-2017", "10.1111/1467-8659.00675", "10.1016/j.cad.2006.12.005", "10.1111/j.1467-8659.2012.03181.x", "10.1016/j.cag.2010.01.004", "10.1016/j.cag.2013.05.008", "10.1007/PL00009475", "10.1016/j.cad.2004.11.005", "10.1016/j.comgeo.2005.10.006", "10.1111/j.1467-8659.2009.01388.x", "10.1142/S0218195904001470", "10.1016/j.cad.2007.02.008", "10.1016/j.cad.2013.06.003", "10.1111/cgf.12187", "10.1016/j.cag.2015.05.024", "10.1111/cgf.12983", "10.1016/j.cagd.2015.03.011", "10.1007/s00371-017-1391-8", "10.1631/jzus.C1100324", "10.1016/j.cagd.2005.06.010", "10.5194/isprs-archives-XLII-2-W3-339-2017", "10.1111/1467-8659.00675", "10.1016/j.cad.2006.12.005", "10.1111/j.1467-8659.2012.03181.x", "10.1016/j.cag.2010.01.004", "10.1016/j.cag.2013.05.008", "10.1007/PL00009475", "10.1016/j.cad.2004.11.005", "10.1016/j.comgeo.2005.10.006", "10.1111/j.1467-8659.2009.01388.x", "10.1142/S0218195904001470", "10.1016/j.cad.2007.02.008", "10.1016/j.cad.2013.06.003", "10.1111/cgf.12187", "10.1016/j.cag.2015.05.024", "10.1111/cgf.12983", "10.1016/j.cagd.2015.03.011", "10.1007/s00371-017-1391-8", "10.1631/jzus.C1100324", "10.1016/j.cagd.2005.06.010", "10.5194/isprs-archives-XLII-2-W3-339-2017", "10.1111/1467-8659.00675", "10.1016/j.cad.2006.12.005", "10.1111/j.1467-8659.2012.03181.x", "10.1016/j.cag.2010.01.004", "10.1016/j.cag.2013.05.008", "10.1007/PL00009475", "10.1016/j.cad.2004.11.005", "10.1016/j.comgeo.2005.10.006", "10.1111/j.1467-8659.2009.01388.x", "10.1142/S0218195904001470", "10.1016/j.cad.2007.02.008", "10.1016/j.cad.2013.06.003", "10.1111/cgf.12187", "10.1016/j.cag.2015.05.024", "10.1111/cgf.12983", "10.1016/j.cagd.2015.03.011", "10.1007/s00371-017-1391-8", "10.1631/jzus.C1100324"]}, "10.1109/TVCG.2018.2820121": {"doi": "10.1109/TVCG.2018.2820121", "author": ["D. Iwai", "M. Aoki", "K. Sato"], "title": "Non-Contact Thermo-Visual Augmentation by IR-RGB Projection", "year": "2019", "abstract": "This paper presents an approach for non-contact haptic augmentation with spatial augmented reality (SAR). We construct a thermo-visual projection system by combining a standard RGB projector and a fabricated infrared (IR) projector. The primary contribution of this paper is that we conduct thorough psychophysical experiments to investigate a design guideline for spatiotemporal projection patterns for both RGB and IR projectors to render a warm object with high presence. We develop application systems to evaluate the validity of the proposed system and design guideline. The evaluation results demonstrate that the proposed system can render warm objects with significantly higher presence than a standard SAR system.", "keywords": ["augmented reality", "haptic interfaces", "optical projectors", "rendering (computer graphics)", "noncontact thermo-visual augmentation", "IR-RGB projection", "noncontact haptic augmentation", "spatial augmented reality", "thermo-visual projection system", "standard RGB projector", "primary contribution", "psychophysical experiments", "design guideline", "spatiotemporal projection patterns", "SAR system", "infrared projector", "Visualization", "Haptic interfaces", "Skin", "Mirrors", "Spatial resolution", "Temperature measurement", "Heating systems", "Spatial augmented reality", "projection mapping", "IR projector", "cross modal", "non-contact haptic feedback"], "referenced_by": ["IKEY:8943693"], "referencing": ["IKEY:6162895", "IKEY:7014259", "IKEY:4543167", "IKEY:6664767", "IKEY:840369", "IKEY:7165660", "IKEY:6549357", "IKEY:6162895", "IKEY:7014259", "IKEY:4543167", "IKEY:6664767", "IKEY:840369", "IKEY:7165660", "IKEY:6549357", "IKEY:6162895", "IKEY:7014259", "IKEY:4543167", "IKEY:6664767", "IKEY:840369", "IKEY:7165660", "IKEY:6549357", "10.1145/280814.280861", "10.1145/2818048.2819965", "10.1145/2818466.2818481", "10.1145/2642918.2647383", "10.1145/2508363.2508416", "10.1145/2493432.2493463", "10.1145/2461912.2462007", "10.1145/2642918.2647407", "10.1145/2858036.2858481", "10.1145/1180495.1180519", "10.1145/280814.280861", "10.1145/2818048.2819965", "10.1145/2818466.2818481", "10.1145/2642918.2647383", "10.1145/2508363.2508416", "10.1145/2493432.2493463", "10.1145/2461912.2462007", "10.1145/2642918.2647407", "10.1145/2858036.2858481", "10.1145/1180495.1180519", "10.1145/280814.280861", "10.1145/2818048.2819965", "10.1145/2818466.2818481", "10.1145/2642918.2647383", "10.1145/2508363.2508416", "10.1145/2493432.2493463", "10.1145/2461912.2462007", "10.1145/2642918.2647407", "10.1145/2858036.2858481", "10.1145/1180495.1180519", "10.1201/b10624", "10.1111/j.1467-8659.2008.01175.x", "10.1364/OE.22.013492", "10.1007/s10055-010-0168-4", "10.1007/s10055-014-0250-4", "10.1364/AIO.2014.JTu4A.23", "10.1007/978-3-540-69057-3_64", "10.1371/journal.pone.0047293", "10.1002/cphy.cp010319", "10.3758/BF03203885", "10.1037/0096-1523.23.6.1680", "10.1007/s10055-010-0159-5", "10.1364/OE.22.026919", "10.1201/b10624", "10.1111/j.1467-8659.2008.01175.x", "10.1364/OE.22.013492", "10.1007/s10055-010-0168-4", "10.1007/s10055-014-0250-4", "10.1364/AIO.2014.JTu4A.23", "10.1007/978-3-540-69057-3_64", "10.1371/journal.pone.0047293", "10.1002/cphy.cp010319", "10.3758/BF03203885", "10.1037/0096-1523.23.6.1680", "10.1007/s10055-010-0159-5", "10.1364/OE.22.026919", "10.1201/b10624", "10.1111/j.1467-8659.2008.01175.x", "10.1364/OE.22.013492", "10.1007/s10055-010-0168-4", "10.1007/s10055-014-0250-4", "10.1364/AIO.2014.JTu4A.23", "10.1007/978-3-540-69057-3_64", "10.1371/journal.pone.0047293", "10.1002/cphy.cp010319", "10.3758/BF03203885", "10.1037/0096-1523.23.6.1680", "10.1007/s10055-010-0159-5", "10.1364/OE.22.026919"]}, "10.1109/TVCG.2018.2820068": {"doi": "10.1109/TVCG.2018.2820068", "author": ["P. Paczkowski", "J. Dorsey", "H. Rushmeier", "M. H. Kim"], "title": "PaperCraft3D: Paper-Based 3D Modeling and Scene Fabrication", "year": "2019", "abstract": "A 3D modeling system with all-inclusive functionality is too demanding for a casual 3D modeler to learn. There has been a shift towards more approachable systems, with easy-to-learn, intuitive interfaces. However, most modeling systems still employ mouse and keyboard interfaces, despite the ubiquity of tablet devices and the benefits of multi-touch interfaces. We introduce an alternative 3D modeling and fabrication paradigm using developable surfaces, inspired by traditional papercrafting, and we implement it as a complete system designed for a multi-touch tablet, allowing a user to fabricate 3D scenes. We demonstrate the modeling and fabrication process of assembling complex 3D scenes from a collection of simpler models, in turn shaped through operations applied to virtual paper. Our fabrication method facilitates the assembly of the scene with real paper by automatically converting scenes into a series of cutouts with appropriately added fiducial markers and supporting structures. Our system assists users in creating occluded supporting structures to help maintain the spatial and rigid properties of a scene without compromising its aesthetic qualities. We demonstrate several 3D scenes modeled and fabricated in our system, and evaluate the faithfulness of our fabrications relative to their virtual counterparts and 3D-printed fabrications.", "keywords": ["human computer interaction", "interactive systems", "notebook computers", "solid modelling", "touch sensitive screens", "user interfaces", "virtual reality", "PaperCraft3D", "paper-based 3D modeling", "scene fabrication", "3D modeling system", "all-inclusive functionality", "casual 3D modeler", "approachable systems", "intuitive interfaces", "mouse", "keyboard interfaces", "tablet devices", "multitouch interfaces", "fabrication paradigm", "traditional papercrafting", "complete system", "multitouch tablet", "fabrication process", "simpler models", "virtual paper", "fabrication method", "appropriately added fiducial markers", "supporting structures", "Three-dimensional displays", "Solid modeling", "Fabrication", "Computational modeling", "Tools", "Printing", "Two dimensional displays", "Multi-touch interface", "3D modeling", "fabrication", "papercraft"], "referenced_by": ["IKEY:8936801"], "referencing": ["IKEY:4142840", "IKEY:5444709", "IKEY:6383158", "IKEY:4392725", "IKEY:7016103", "IKEY:4142840", "IKEY:5444709", "IKEY:6383158", "IKEY:4392725", "IKEY:7016103", "IKEY:4142840", "IKEY:5444709", "IKEY:6383158", "IKEY:4392725", "IKEY:7016103", "10.1145/2642918.2647416", "10.1145/317456.317461", "10.1145/1240624.1240798", "10.1145/1520340.1520589", "10.1145/3126594.3126611", "10.1145/1978942.1979141", "10.1145/2470654.2470689", "10.1145/1449715.1449728", "10.1145/311535.311602", "10.1145/2079216.2079218", "10.1145/2069618.2069665", "10.1145/2619195.2656293", "10.1145/2542355.2542361", "10.1145/1015706.1015711", "10.1145/1935701.1935717", "10.1145/1833349.1778848", "10.1145/2185520.2185545", "10.1145/1610252.1610275", "10.1145/3072959.3073709", "10.1145/3022227.3022322", "10.1145/1517664.1517692", "10.1145/2148131.2148143", "10.1145/1709886.1709924", "10.1145/2380116.2380191", "10.1145/1935701.1935716", "10.1145/2470654.2481361", "10.1145/2556288.2557310", "10.1145/2642918.2647359", "10.1145/2642918.2647388", "10.1145/2185520.2185544", "10.1145/2642918.2647416", "10.1145/317456.317461", "10.1145/1240624.1240798", "10.1145/1520340.1520589", "10.1145/3126594.3126611", "10.1145/1978942.1979141", "10.1145/2470654.2470689", "10.1145/1449715.1449728", "10.1145/311535.311602", "10.1145/2079216.2079218", "10.1145/2069618.2069665", "10.1145/2619195.2656293", "10.1145/2542355.2542361", "10.1145/1015706.1015711", "10.1145/1935701.1935717", "10.1145/1833349.1778848", "10.1145/2185520.2185545", "10.1145/1610252.1610275", "10.1145/3072959.3073709", "10.1145/3022227.3022322", "10.1145/1517664.1517692", "10.1145/2148131.2148143", "10.1145/1709886.1709924", "10.1145/2380116.2380191", "10.1145/1935701.1935716", "10.1145/2470654.2481361", "10.1145/2556288.2557310", "10.1145/2642918.2647359", "10.1145/2642918.2647388", "10.1145/2185520.2185544", "10.1145/2642918.2647416", "10.1145/317456.317461", "10.1145/1240624.1240798", "10.1145/1520340.1520589", "10.1145/3126594.3126611", "10.1145/1978942.1979141", "10.1145/2470654.2470689", "10.1145/1449715.1449728", "10.1145/311535.311602", "10.1145/2079216.2079218", "10.1145/2069618.2069665", "10.1145/2619195.2656293", "10.1145/2542355.2542361", "10.1145/1015706.1015711", "10.1145/1935701.1935717", "10.1145/1833349.1778848", "10.1145/2185520.2185545", "10.1145/1610252.1610275", "10.1145/3072959.3073709", "10.1145/3022227.3022322", "10.1145/1517664.1517692", "10.1145/2148131.2148143", "10.1145/1709886.1709924", "10.1145/2380116.2380191", "10.1145/1935701.1935716", "10.1145/2470654.2481361", "10.1145/2556288.2557310", "10.1145/2642918.2647359", "10.1145/2642918.2647388", "10.1145/2185520.2185544", "10.1016/j.jcde.2016.04.003", "10.1016/j.jcde.2014.11.005", "10.1111/j.1467-8659.2012.03044.x", "10.1016/j.cag.2012.09.004", "10.1111/j.1467-8659.2012.03197.x", "10.1007/978-3-642-22571-0_5", "10.1201/b10971-24", "10.1002/(SICI)1099-1778(199601)7:1&lt;25::AID-VIS134&gt;3.0.CO;2-V", "10.1007/s00371-006-0067-6", "10.1111/cgf.12050", "10.1111/j.1467-8659.2012.03037.x", "10.1007/s00371-011-0564-0", "10.1007/978-3-642-02115-2_6", "10.1111/j.1467-8659.2008.01318.x", "10.1016/j.jcde.2016.04.003", "10.1016/j.jcde.2014.11.005", "10.1111/j.1467-8659.2012.03044.x", "10.1016/j.cag.2012.09.004", "10.1111/j.1467-8659.2012.03197.x", "10.1007/978-3-642-22571-0_5", "10.1201/b10971-24", "10.1002/(SICI)1099-1778(199601)7:1&lt;25::AID-VIS134&gt;3.0.CO;2-V", "10.1007/s00371-006-0067-6", "10.1111/cgf.12050", "10.1111/j.1467-8659.2012.03037.x", "10.1007/s00371-011-0564-0", "10.1007/978-3-642-02115-2_6", "10.1111/j.1467-8659.2008.01318.x", "10.1016/j.jcde.2016.04.003", "10.1016/j.jcde.2014.11.005", "10.1111/j.1467-8659.2012.03044.x", "10.1016/j.cag.2012.09.004", "10.1111/j.1467-8659.2012.03197.x", "10.1007/978-3-642-22571-0_5", "10.1201/b10971-24", "10.1002/(SICI)1099-1778(199601)7:1&lt;25::AID-VIS134&gt;3.0.CO;2-V", "10.1007/s00371-006-0067-6", "10.1111/cgf.12050", "10.1111/j.1467-8659.2012.03037.x", "10.1007/s00371-011-0564-0", "10.1007/978-3-642-02115-2_6", "10.1111/j.1467-8659.2008.01318.x"]}, "10.1109/TVCG.2018.2817557": {"doi": "10.1109/TVCG.2018.2817557", "author": ["G. E. Marai", "C. Ma", "A. T. Burks", "F. Pellolio", "G. Canahuate", "D. M. Vock", "A. S. R. Mohamed", "C. D. Fuller"], "title": "Precision Risk Analysis of Cancer Therapy with Interactive Nomograms and Survival Plots", "year": "2019", "abstract": "We present the design and evaluation of an integrated problem solving environment for cancer therapy analysis. The environment intertwines a statistical martingale model and a K Nearest Neighbor approach with visual encodings, including novel interactive nomograms, in order to compute and explain a patient's probability of survival as a function of similar patient results. A coordinated views paradigm enables exploration of the multivariate, heterogeneous and few-valued data from a large head and neck cancer repository. A visual scaffolding approach further enables users to build from familiar representations to unfamiliar ones. Evaluation with domain experts show how this visualization approach and set of streamlined workflows enable the systematic and precise analysis of a patient prognosis in the context of cohorts of similar patients. We describe the design lessons learned from this successful, multi-site remote collaboration.", "keywords": ["cancer", "data visualisation", "groupware", "medical computing", "probability", "problem solving", "radiation therapy", "risk analysis", "statistical analysis", "user interfaces", "precision risk analysis", "integrated problem solving environment", "cancer therapy analysis", "statistical martingale model", "K Nearest Neighbor approach", "visual encodings", "novel interactive nomograms", "similar patient results", "coordinated views paradigm", "multivariate valued data", "heterogeneous valued data", "few-valued data", "neck cancer repository", "visual scaffolding approach", "familiar representations", "unfamiliar ones", "visualization approach", "systematic analysis", "precise analysis", "patient prognosis", "Cancer", "Visualization", "Collaboration", "Medical treatment", "Encoding", "Head", "Neck", "Visual analytics", "precision medicine", "design studies", "nomograms", "parallel coordinate plots", "activity-centered design", "Computer Graphics", "Female", "Humans", "Male", "Neoplasms", "Nomograms", "Precision Medicine", "Survival Analysis"], "referenced_by": ["IKEY:8440850", "IKEY:8809842"], "referencing": ["IKEY:6634119", "IKEY:6876009", "IKEY:6785926", "IKEY:6327248", "IKEY:6876000", "IKEY:5290695", "IKEY:8017610", "IKEY:5342407", "IKEY:5290699", "IKEY:4376132", "IKEY:6634119", "IKEY:6876009", "IKEY:6785926", "IKEY:6327248", "IKEY:6876000", "IKEY:5290695", "IKEY:8017610", "IKEY:5342407", "IKEY:5290699", "IKEY:4376132", "IKEY:6634119", "IKEY:6876009", "IKEY:6785926", "IKEY:6327248", "IKEY:6876000", "IKEY:5290695", "IKEY:8017610", "IKEY:5342407", "IKEY:5290699", "IKEY:4376132", "10.1145/1282480.1282484", "10.1145/1879831.1879836", "10.1145/1282480.1282484", "10.1145/1879831.1879836", "10.1145/1282480.1282484", "10.1145/1879831.1879836", "10.1016/j.ijrobp.2005.12.023", "10.4236/ijmpcero.2013.24016", "10.1016/j.ijrobp.2015.12.157", "10.1016/j.ijrobp.2015.12.116", "10.1186/s12911-015-0218-7", "10.1177/1473871614526077", "10.1371/journal.pone.0014683", "10.1007/978-3-642-39146-0_1", "10.1007/978-3-540-33037-0_7", "10.1057/palgrave.ivs.9500025", "10.1016/j.jclinepi.2007.04.021", "10.1111/cgf.12651", "10.1016/j.ijrobp.2008.02.062", "10.1007/s00405-005-0916-3", "10.1038/nrclinonc.2009.40", "10.1172/JCI31809", "10.1201/b17511", "10.1080/01621459.1952.10501187", "10.1016/S0140-6736(02)08594-X", "10.1038/nature03672", "10.1371/journal.pone.0023525", "10.1007/s001840000041", "10.1023/A:1008716330212", "10.1016/j.ijrobp.2005.12.023", "10.4236/ijmpcero.2013.24016", "10.1016/j.ijrobp.2015.12.157", "10.1016/j.ijrobp.2015.12.116", "10.1186/s12911-015-0218-7", "10.1177/1473871614526077", "10.1371/journal.pone.0014683", "10.1007/978-3-642-39146-0_1", "10.1007/978-3-540-33037-0_7", "10.1057/palgrave.ivs.9500025", "10.1016/j.jclinepi.2007.04.021", "10.1111/cgf.12651", "10.1016/j.ijrobp.2008.02.062", "10.1007/s00405-005-0916-3", "10.1038/nrclinonc.2009.40", "10.1172/JCI31809", "10.1201/b17511", "10.1080/01621459.1952.10501187", "10.1016/S0140-6736(02)08594-X", "10.1038/nature03672", "10.1371/journal.pone.0023525", "10.1007/s001840000041", "10.1023/A:1008716330212", "10.1016/j.ijrobp.2005.12.023", "10.4236/ijmpcero.2013.24016", "10.1016/j.ijrobp.2015.12.157", "10.1016/j.ijrobp.2015.12.116", "10.1186/s12911-015-0218-7", "10.1177/1473871614526077", "10.1371/journal.pone.0014683", "10.1007/978-3-642-39146-0_1", "10.1007/978-3-540-33037-0_7", "10.1057/palgrave.ivs.9500025", "10.1016/j.jclinepi.2007.04.021", "10.1111/cgf.12651", "10.1016/j.ijrobp.2008.02.062", "10.1007/s00405-005-0916-3", "10.1038/nrclinonc.2009.40", "10.1172/JCI31809", "10.1201/b17511", "10.1080/01621459.1952.10501187", "10.1016/S0140-6736(02)08594-X", "10.1038/nature03672", "10.1371/journal.pone.0023525", "10.1007/s001840000041", "10.1023/A:1008716330212"]}, "10.1109/TVCG.2018.2818721": {"doi": "10.1109/TVCG.2018.2818721", "author": ["S. Lee", "S. Lee"], "title": "Projective Motion Correction with Contact Optimization", "year": "2019", "abstract": "When motion capture data is applied to virtual characters, the applied motion often exhibits geometric and physical errors, which necessitates a cumbersome refinement process. We present a novel framework to efficiently obtain a corrected motion as well as its supporting contact information from multi-contact motion capture data. To this end, first, we present a projective dynamics-based method for optimizing character motions. By carefully defining objective functions and constraints using differential representation of motions, we develop a highly efficient motion optimizer that can create geometrically and dynamically adjusted motions given reference motion data and contact information. Second, we develop a contact optimizer that finds a set of contacts that allows the motion optimizer to generate a motion that best follows the reference motion under dynamic and geometric constraints. This is achieved by iteratively improving the hypothesis on the best set of contacts by getting feedback from the motion optimizer. We demonstrate that our method significantly improves the naturalness of a wide range of motion capture data, from walking to rolling.", "keywords": ["computer animation", "image motion analysis", "iterative methods", "motion estimation", "optimisation", "contact optimizer", "dynamic constraints", "geometric constraints", "projective motion correction", "contact optimization", "virtual characters", "cumbersome refinement process", "supporting contact information", "multicontact motion capture data", "projective dynamics-based method", "character motions", "highly efficient motion optimizer", "dynamically adjusted motions", "Dynamics", "Optimization", "PD control", "Kinematics", "Convergence", "Trajectory", "Planning", "Character animation", "motion capture", "motion retargeting", "multi-contact"], "referenced_by": [], "referencing": ["IKEY:1314505", "IKEY:1206800", "IKEY:1573553", "IKEY:1242196", "IKEY:1014737", "IKEY:7363479", "IKEY:1314505", "IKEY:1206800", "IKEY:1573553", "IKEY:1242196", "IKEY:1014737", "IKEY:7363479", "IKEY:1314505", "IKEY:1206800", "IKEY:1573553", "IKEY:1242196", "IKEY:1014737", "IKEY:7363479", "10.1145/545261.545277", "10.1145/3072959.3073663", "10.1145/2983616", "10.1145/1778765.1778865", "10.1145/2601097.2601116", "10.1145/1276377.1276510", "10.1145/1778765.1778770", "10.1145/1360612.1360679", "10.1145/1531326.1531385", "10.1145/1276377.1276509", "10.1145/2893476", "10.1145/1778765.1781155", "10.1145/1531326.1531387", "10.1145/1028523.1028546", "10.1145/2998559.2998564", "10.1145/1073204.1073314", "10.1145/882262.882286", "10.1145/311535.311536", "10.1145/1531326.1531365", "10.1145/2185520.2185539", "10.1145/2983619", "10.1145/1391989.1391995", "10.1145/279232.279236", "10.1145/545261.545277", "10.1145/3072959.3073663", "10.1145/2983616", "10.1145/1778765.1778865", "10.1145/2601097.2601116", "10.1145/1276377.1276510", "10.1145/1778765.1778770", "10.1145/1360612.1360679", "10.1145/1531326.1531385", "10.1145/1276377.1276509", "10.1145/2893476", "10.1145/1778765.1781155", "10.1145/1531326.1531387", "10.1145/1028523.1028546", "10.1145/2998559.2998564", "10.1145/1073204.1073314", "10.1145/882262.882286", "10.1145/311535.311536", "10.1145/1531326.1531365", "10.1145/2185520.2185539", "10.1145/2983619", "10.1145/1391989.1391995", "10.1145/279232.279236", "10.1145/545261.545277", "10.1145/3072959.3073663", "10.1145/2983616", "10.1145/1778765.1778865", "10.1145/2601097.2601116", "10.1145/1276377.1276510", "10.1145/1778765.1778770", "10.1145/1360612.1360679", "10.1145/1531326.1531385", "10.1145/1276377.1276509", "10.1145/2893476", "10.1145/1778765.1781155", "10.1145/1531326.1531387", "10.1145/1028523.1028546", "10.1145/2998559.2998564", "10.1145/1073204.1073314", "10.1145/882262.882286", "10.1145/311535.311536", "10.1145/1531326.1531365", "10.1145/2185520.2185539", "10.1145/2983619", "10.1145/1391989.1391995", "10.1145/279232.279236", "10.1007/s10514-013-9341-4", "10.1111/1467-8659.00436", "10.1111/cgf.12468", "10.1177/0278364913506757", "10.1016/j.robot.2013.01.008", "10.1177/0278364908098447", "10.1111/j.2006.0030-1299.14714.x", "10.1007/s10514-013-9341-4", "10.1111/1467-8659.00436", "10.1111/cgf.12468", "10.1177/0278364913506757", "10.1016/j.robot.2013.01.008", "10.1177/0278364908098447", "10.1111/j.2006.0030-1299.14714.x", "10.1007/s10514-013-9341-4", "10.1111/1467-8659.00436", "10.1111/cgf.12468", "10.1177/0278364913506757", "10.1016/j.robot.2013.01.008", "10.1177/0278364908098447", "10.1111/j.2006.0030-1299.14714.x"]}, "10.1109/TVCG.2018.2818701": {"doi": "10.1109/TVCG.2018.2818701", "author": ["P. A. Govyadinov", "T. Womack", "J. L. Eriksen", "G. Chen", "D. Mayerich"], "title": "Robust Tracing and Visualization of Heterogeneous Microvascular Networks", "year": "2019", "abstract": "Advances in high-throughput imaging allow researchers to collect three-dimensional images of whole organ microvascular networks. These extremely large images contain networks that are highly complex, time consuming to segment, and difficult to visualize. In this paper, we present a framework for segmenting and visualizing vascular networks from terabyte-sized three-dimensional images collected using high-throughput microscopy. While these images require terabytes of storage, the volume devoted to the fiber network is $\\approx 4$ percent of the total volume size. While the networks themselves are sparse, they are tremendously complex, interconnected, and vary widely in diameter. We describe a parallel GPU-based predictor-corrector method for tracing filaments that is robust to noise and sampling errors common in these data sets. We also propose a number of visualization techniques designed to convey the complex statistical descriptions of fibers across large tissue sections\u2014including commonly studied microvascular characteristics, such as orientation and volume.", "keywords": ["Data visualization", "Diseases", "Robustness", "Microscopy", "Image segmentation", "Biomedical imaging", "Anisotropic magnetoresistance", "Microvessel", "network tracking", "glyph visualization", "predictor-corrector", "segmantation", "spherical harmonics", "superquadrics", "KESM", "Algorithms", "Animals", "Brain", "Computer Graphics", "Imaging, Three-Dimensional", "Mice", "Microscopy", "Microvessels"], "referenced_by": [], "referencing": ["IKEY:1006304", "IKEY:4695828", "IKEY:5290767", "IKEY:4658182", "IKEY:7192722", "IKEY:1006304", "IKEY:4695828", "IKEY:5290767", "IKEY:4658182", "IKEY:7192722", "IKEY:1006304", "IKEY:4695828", "IKEY:5290767", "IKEY:4658182", "IKEY:7192722", "10.1145/2487228.2487235", "10.1145/325165.325242", "10.1145/2487228.2487235", "10.1145/325165.325242", "10.1145/2487228.2487235", "10.1145/325165.325242", "10.1148/radiology.161.3.3786721", "10.1016/j.jacc.2010.10.011", "10.1016/j.neurobiolaging.2007.07.015", "10.1111/j.1365-2990.2010.01139.x", "10.1038/35025220", "10.1126/science.1104819", "10.1111/j.1365-2818.2008.02024.x", "10.1038/nrm1979", "10.1016/j.devcel.2006.12.007", "10.1016/S1361-8415(98)80009-1", "10.1016/j.neuroimage.2007.09.024", "10.1016/j.brainres.2009.12.007", "10.1016/S0896-6273(03)00370-2", "10.1038/nmeth.1854", "10.1016/j.media.2014.07.003", "10.1016/j.media.2014.10.012", "10.1016/j.cma.2007.02.009", "10.1117/12.237852", "10.1023/A:1023437403657", "10.1117/12.185183", "10.1016/j.neucom.2014.07.059", "10.3389/fncom.2016.00082", "10.1371/journal.pcbi.1005392", "10.1124/pr.57.2.4", "10.1038/nm1210-1370", "10.1074/jbc.R116.760215", "10.1016/j.ajpath.2013.10.014", "10.1016/j.devcel.2016.03.015", "10.1016/j.neubiorev.2017.04.003", "10.1016/j.cag.2011.01.011", "10.1111/cgf.12890", "10.1371/journal.pone.0088067", "10.1186/1471-2105-13-S8-S7", "10.1111/j.1537-2995.2011.03418.x", "10.1089/ten.2006.0156", "10.1016/B978-012387582-2/50040-X", "10.1148/radiology.161.3.3786721", "10.1016/j.jacc.2010.10.011", "10.1016/j.neurobiolaging.2007.07.015", "10.1111/j.1365-2990.2010.01139.x", "10.1038/35025220", "10.1126/science.1104819", "10.1111/j.1365-2818.2008.02024.x", "10.1038/nrm1979", "10.1016/j.devcel.2006.12.007", "10.1016/S1361-8415(98)80009-1", "10.1016/j.neuroimage.2007.09.024", "10.1016/j.brainres.2009.12.007", "10.1016/S0896-6273(03)00370-2", "10.1038/nmeth.1854", "10.1016/j.media.2014.07.003", "10.1016/j.media.2014.10.012", "10.1016/j.cma.2007.02.009", "10.1117/12.237852", "10.1023/A:1023437403657", "10.1117/12.185183", "10.1016/j.neucom.2014.07.059", "10.3389/fncom.2016.00082", "10.1371/journal.pcbi.1005392", "10.1124/pr.57.2.4", "10.1038/nm1210-1370", "10.1074/jbc.R116.760215", "10.1016/j.ajpath.2013.10.014", "10.1016/j.devcel.2016.03.015", "10.1016/j.neubiorev.2017.04.003", "10.1016/j.cag.2011.01.011", "10.1111/cgf.12890", "10.1371/journal.pone.0088067", "10.1186/1471-2105-13-S8-S7", "10.1111/j.1537-2995.2011.03418.x", "10.1089/ten.2006.0156", "10.1016/B978-012387582-2/50040-X", "10.1148/radiology.161.3.3786721", "10.1016/j.jacc.2010.10.011", "10.1016/j.neurobiolaging.2007.07.015", "10.1111/j.1365-2990.2010.01139.x", "10.1038/35025220", "10.1126/science.1104819", "10.1111/j.1365-2818.2008.02024.x", "10.1038/nrm1979", "10.1016/j.devcel.2006.12.007", "10.1016/S1361-8415(98)80009-1", "10.1016/j.neuroimage.2007.09.024", "10.1016/j.brainres.2009.12.007", "10.1016/S0896-6273(03)00370-2", "10.1038/nmeth.1854", "10.1016/j.media.2014.07.003", "10.1016/j.media.2014.10.012", "10.1016/j.cma.2007.02.009", "10.1117/12.237852", "10.1023/A:1023437403657", "10.1117/12.185183", "10.1016/j.neucom.2014.07.059", "10.3389/fncom.2016.00082", "10.1371/journal.pcbi.1005392", "10.1124/pr.57.2.4", "10.1038/nm1210-1370", "10.1074/jbc.R116.760215", "10.1016/j.ajpath.2013.10.014", "10.1016/j.devcel.2016.03.015", "10.1016/j.neubiorev.2017.04.003", "10.1016/j.cag.2011.01.011", "10.1111/cgf.12890", "10.1371/journal.pone.0088067", "10.1186/1471-2105-13-S8-S7", "10.1111/j.1537-2995.2011.03418.x", "10.1089/ten.2006.0156", "10.1016/B978-012387582-2/50040-X"]}, "10.1109/TVCG.2018.2816926": {"doi": "10.1109/TVCG.2018.2816926", "author": ["J. Zhang", "B. Deng", "Y. Hong", "Y. Peng", "W. Qin", "L. Liu"], "title": "Static/Dynamic Filtering for Mesh Geometry", "year": "2019", "abstract": "The joint bilateral filter, which enables feature-preserving signal smoothing according to the structural information from a guidance, has been applied for various tasks in geometry processing. Existing methods either rely on a static guidance that may be inconsistent with the input and lead to unsatisfactory results, or a dynamic guidance that is automatically updated but sensitive to noises and outliers. Inspired by recent advances in image filtering, we propose a new geometry filtering technique called static/dynamic filter, which utilizes both static and dynamic guidances to achieve state-of-the-art results. The proposed filter is based on a nonlinear optimization that enforces smoothness of the signal while preserving variations that correspond to features of certain scales. We develop an efficient iterative solver for the problem, which unifies existing filters that are based on static or dynamic guidances. The filter can be applied to mesh face normals followed by vertex position update, to achieve scale-aware and feature-preserving filtering of mesh geometry. It also works well for other types of signals defined on mesh surfaces, such as texture colors. Extensive experimental results demonstrate the effectiveness of the proposed filter for various geometry processing applications such as mesh denoising, geometry feature enhancement, and texture color filtering.", "keywords": ["computational geometry", "feature extraction", "image colour analysis", "image denoising", "image enhancement", "image filtering", "image texture", "iterative methods", "mesh generation", "nonlinear programming", "smoothing methods", "joint bilateral filter", "static guidance", "dynamic guidance", "image filtering", "geometry filtering technique", "feature-preserving filtering", "mesh geometry", "geometry processing applications", "geometry feature enhancement", "texture color filtering", "static/dynamic filtering", "feature-preserving signal smoothing", "nonlinear optimization", "iterative solver", "vertex position update", "mesh surfaces", "mesh denoising", "Geometry", "Face", "Optimization", "Smoothing methods", "Robustness", "Noise reduction", "Image processing", "Geometry processing", "mesh filtering", "mesh denoising"], "referenced_by": ["IKEY:8434353", "IKEY:8824104", "IKEY:9063501", "IKEY:9157422", "IKEY:8730533", "IKEY:9253344"], "referencing": ["IKEY:710815", "IKEY:5674028", "IKEY:7299115", "IKEY:1310211", "IKEY:1634326", "IKEY:6265062", "IKEY:7029103", "IKEY:56205", "IKEY:4276075", "IKEY:710815", "IKEY:5674028", "IKEY:7299115", "IKEY:1310211", "IKEY:1634326", "IKEY:6265062", "IKEY:7029103", "IKEY:56205", "IKEY:4276075", "IKEY:710815", "IKEY:5674028", "IKEY:7299115", "IKEY:1310211", "IKEY:1634326", "IKEY:6265062", "IKEY:7029103", "IKEY:56205", "IKEY:4276075", "10.1145/1015706.1015778", "10.1145/1015706.1015777", "10.1145/2601097.2601188", "10.1145/882262.882368", "10.1145/882262.882367", "10.1145/2816795.2818068", "10.1145/218380.218473", "10.1145/311535.311576", "10.1145/2010324.1964952", "10.1145/1276377.1276497", "10.1145/2070781.2024208", "10.1145/2461912.2461965", "10.1145/1057432.1057456", "10.1145/1015706.1015778", "10.1145/1015706.1015777", "10.1145/2601097.2601188", "10.1145/882262.882368", "10.1145/882262.882367", "10.1145/2816795.2818068", "10.1145/218380.218473", "10.1145/311535.311576", "10.1145/2010324.1964952", "10.1145/1276377.1276497", "10.1145/2070781.2024208", "10.1145/2461912.2461965", "10.1145/1057432.1057456", "10.1145/1015706.1015778", "10.1145/1015706.1015777", "10.1145/2601097.2601188", "10.1145/882262.882368", "10.1145/882262.882367", "10.1145/2816795.2818068", "10.1145/218380.218473", "10.1145/311535.311576", "10.1145/2010324.1964952", "10.1145/1276377.1276497", "10.1145/2070781.2024208", "10.1145/2461912.2461965", "10.1145/1057432.1057456", "10.1007/978-3-319-10578-9_53", "10.1111/cgf.12742", "10.1016/S0010-4485(01)00095-1", "10.1016/0167-2789(92)90242-F", "10.1111/j.1467-8659.2009.01515.x", "10.1111/j.1467-8659.2008.01122.x", "10.1111/j.1467-8659.2010.01655.x", "10.1111/j.1467-8659.2012.03171.x", "10.1007/978-3-319-10578-9_53", "10.1111/cgf.12742", "10.1016/S0010-4485(01)00095-1", "10.1016/0167-2789(92)90242-F", "10.1111/j.1467-8659.2009.01515.x", "10.1111/j.1467-8659.2008.01122.x", "10.1111/j.1467-8659.2010.01655.x", "10.1111/j.1467-8659.2012.03171.x", "10.1007/978-3-319-10578-9_53", "10.1111/cgf.12742", "10.1016/S0010-4485(01)00095-1", "10.1016/0167-2789(92)90242-F", "10.1111/j.1467-8659.2009.01515.x", "10.1111/j.1467-8659.2008.01122.x", "10.1111/j.1467-8659.2010.01655.x", "10.1111/j.1467-8659.2012.03171.x"]}, "10.1109/TVCG.2018.2825424": {"doi": "10.1109/TVCG.2018.2825424", "author": ["L. Stopar", "P. Skraba", "M. Grobelnik", "D. Mladenic"], "title": "StreamStory: Exploring Multivariate Time Series on Multiple Scales", "year": "2019", "abstract": "This paper presents an approach for the interactive visualization, exploration and interpretation of large multivariate time series. Interesting patterns in such datasets usually appear as periodic or recurrent behavior often caused by the interaction between variables. To identify such patterns, we summarize the data as conceptual states, modeling temporal dynamics as transitions between the states. This representation can visualize large datasets with potentially billions of examples. We extend the representation to multiple spatial granularities allowing the user to find patterns on multiple scales. The result is an interactive web-based tool called StreamStory. StreamStory couples the abstraction with several tools that map the abstractions back to domain-specific concepts using techniques from statistics and machine learning. It is aimed at users who are not experts in data analytics, minimizing the number of parameters to configure out-of-the-box. We use three real-world datasets to demonstrate how StreamStory can be used to perform three main visual analytics tasks: identify the main states of a complex system and map them back to data-specific concepts, find high-level and long-term periodic behavior and traverse the scales to identify which scales exhibit interesting phenomena. We find and interpret several known, as well as previously unknown patterns in these datasets.", "keywords": ["data visualisation", "learning (artificial intelligence)", "pattern classification", "time series", "multivariate time series", "recurrent behavior", "temporal dynamics", "multiple spatial granularities", "StreamStory couples", "domain-specific concepts", "data analytics", "real-world datasets", "main visual analytics tasks", "data-specific concepts", "long-term periodic behavior", "unknown patterns", "interactive Web-based tool", "Data visualization", "Time series analysis", "Tools", "Data models", "Markov processes", "Clutter", "Meteorology", "Time series analysis", "visualization systems and software", "data and knowledge visualization", "markov processes", "multivariate visualization", "data mining"], "referenced_by": ["IKEY:8768367", "IKEY:8930535"], "referencing": ["IKEY:885098", "IKEY:5290711", "IKEY:7332976", "IKEY:7192639", "IKEY:6064965", "IKEY:4515862", "IKEY:6378590", "IKEY:1249011", "IKEY:1196005", "IKEY:5746509", "IKEY:146402", "IKEY:885098", "IKEY:5290711", "IKEY:7332976", "IKEY:7192639", "IKEY:6064965", "IKEY:4515862", "IKEY:6378590", "IKEY:1249011", "IKEY:1196005", "IKEY:5746509", "IKEY:146402", "IKEY:885098", "IKEY:5290711", "IKEY:7332976", "IKEY:7192639", "IKEY:6064965", "IKEY:4515862", "IKEY:6378590", "IKEY:1249011", "IKEY:1196005", "IKEY:5746509", "IKEY:146402", "10.1145/1385569.1385584", "10.1145/1385569.1385584", "10.1145/1385569.1385584", "10.1007/978-0-85729-079-3", "10.1057/palgrave.ivs.9500061", "10.18637/jss.v025.c01", "10.1016/j.cag.2009.06.003", "10.1007/978-3-642-04921-7_63", "10.1007/b107408", "10.5539/mas.v4n5p162", "10.1155/2014/502808", "10.1504/IJIEI.2011.040177", "10.1137/1.9781611972726.1", "10.1007/978-3-642-30217-6_42", "10.1016/j.laa.2004.09.003", "10.1016/j.laa.2011.01.030", "10.1007/BFb0091924", "10.1007/978-0-85729-079-3", "10.1057/palgrave.ivs.9500061", "10.18637/jss.v025.c01", "10.1016/j.cag.2009.06.003", "10.1007/978-3-642-04921-7_63", "10.1007/b107408", "10.5539/mas.v4n5p162", "10.1155/2014/502808", "10.1504/IJIEI.2011.040177", "10.1137/1.9781611972726.1", "10.1007/978-3-642-30217-6_42", "10.1016/j.laa.2004.09.003", "10.1016/j.laa.2011.01.030", "10.1007/BFb0091924", "10.1007/978-0-85729-079-3", "10.1057/palgrave.ivs.9500061", "10.18637/jss.v025.c01", "10.1016/j.cag.2009.06.003", "10.1007/978-3-642-04921-7_63", "10.1007/b107408", "10.5539/mas.v4n5p162", "10.1155/2014/502808", "10.1504/IJIEI.2011.040177", "10.1137/1.9781611972726.1", "10.1007/978-3-642-30217-6_42", "10.1016/j.laa.2004.09.003", "10.1016/j.laa.2011.01.030", "10.1007/BFb0091924"]}, "10.1109/TVCG.2018.2824822": {"doi": "10.1109/TVCG.2018.2824822", "author": ["P. Riehmann", "D. Kiesel", "M. Kohlhaas", "B. Froehlich"], "title": "Visualizing a Thinker's Life", "year": "2019", "abstract": "This paper presents a visualization framework that aids readers in understanding and analyzing the contents of medium-sized text collections that are typical for the opus of a single or few authors. We contribute several document-based visualization techniques to facilitate the exploration of the work of the German author Bazon Brock by depicting various aspects of its texts, such as the TextGenetics that shows the structure of the collection along with its chronology. The ConceptCircuit augments the TextGenetics with entities - persons and locations that were crucial to his work. All visualizations are sensitive to a wildcard-based phrase search that allows complex requests towards the author's work. Further development, as well as expert reviews and discussions with the author Bazon Brock, focused on the assessment and comparison of visualizations based on automatic topic extraction against ones that are based on expert knowledge.", "keywords": ["cognition", "data visualisation", "text analysis", "thinker", "visualization framework", "readers", "medium-sized text collections", "document-based visualization techniques", "TextGenetics", "persons", "locations", "wildcard-based phrase search", "German author", "ConceptCircuit", "Visualization", "Data visualization", "Tag clouds", "Layout", "Periodic structures", "Tools", "Focusing", "Glyph-based techniques", "text and document data", "coordinated and multiple views"], "referenced_by": [], "referencing": ["IKEY:5333443", "IKEY:5429600", "IKEY:6065008", "IKEY:981848", "IKEY:7042493", "IKEY:6634167", "IKEY:8130851", "IKEY:4388991", "IKEY:6400485", "IKEY:6758829", "IKEY:6691709", "IKEY:841121", "IKEY:4389004", "IKEY:4658133", "IKEY:6175895", "IKEY:5333443", "IKEY:5429600", "IKEY:6065008", "IKEY:981848", "IKEY:7042493", "IKEY:6634167", "IKEY:8130851", "IKEY:4388991", "IKEY:6400485", "IKEY:6758829", "IKEY:6691709", "IKEY:841121", "IKEY:4389004", "IKEY:4658133", "IKEY:6175895", "IKEY:5333443", "IKEY:5429600", "IKEY:6065008", "IKEY:981848", "IKEY:7042493", "IKEY:6634167", "IKEY:8130851", "IKEY:4388991", "IKEY:6400485", "IKEY:6758829", "IKEY:6691709", "IKEY:841121", "IKEY:4389004", "IKEY:4658133", "IKEY:6175895", "10.1145/1835804.1835827", "10.1145/1124772.1124919", "10.1145/3020165.3020182", "10.1145/1557019.1557077", "10.1145/2133806.2133826", "10.1145/1143844.1143859", "10.1145/1667053.1667056", "10.1145/1242572.1242579", "10.1145/1935826.1935855", "10.1145/2598153.2598187", "10.1145/223904.223912", "10.1145/2254556.2254572", "10.1145/1835804.1835827", "10.1145/1124772.1124919", "10.1145/3020165.3020182", "10.1145/1557019.1557077", "10.1145/2133806.2133826", "10.1145/1143844.1143859", "10.1145/1667053.1667056", "10.1145/1242572.1242579", "10.1145/1935826.1935855", "10.1145/2598153.2598187", "10.1145/223904.223912", "10.1145/2254556.2254572", "10.1145/1835804.1835827", "10.1145/1124772.1124919", "10.1145/3020165.3020182", "10.1145/1557019.1557077", "10.1145/2133806.2133826", "10.1145/1143844.1143859", "10.1145/1667053.1667056", "10.1145/1242572.1242579", "10.1145/1935826.1935855", "10.1145/2598153.2598187", "10.1145/223904.223912", "10.1145/2254556.2254572", "10.1007/978-3-642-36763-2_39", "10.1057/PALGRAVE.IVS.9500023", "10.1214/07-AOAS114", "10.1198/016214506000000302", "10.1073/pnas.94.13.6815", "10.1186/1471-2105-6-139", "10.1163/187633108X00283", "10.3115/1219840.1219885", "10.1038/nmeth.2807", "10.1007/978-3-642-36763-2_39", "10.1057/PALGRAVE.IVS.9500023", "10.1214/07-AOAS114", "10.1198/016214506000000302", "10.1073/pnas.94.13.6815", "10.1186/1471-2105-6-139", "10.1163/187633108X00283", "10.3115/1219840.1219885", "10.1038/nmeth.2807", "10.1007/978-3-642-36763-2_39", "10.1057/PALGRAVE.IVS.9500023", "10.1214/07-AOAS114", "10.1198/016214506000000302", "10.1073/pnas.94.13.6815", "10.1186/1471-2105-6-139", "10.1163/187633108X00283", "10.3115/1219840.1219885", "10.1038/nmeth.2807"]}}