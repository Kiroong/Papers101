{"10.1109/TVCG.2017.2661538": {"doi": "10.1109/TVCG.2017.2661538", "author": [""], "title": "IEEE", "year": "2017", "abstract": "Lists the cover page for this issue of the publication.", "keywords": [""], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2658838": {"doi": "10.1109/TVCG.2017.2658838", "author": [""], "title": "Contents", "year": "2017", "abstract": "Presents the table of contents for this issue of the publication.", "keywords": [""], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2658778": {"doi": "10.1109/TVCG.2017.2658778", "author": ["L. De Floriani", "D. Schmalstieg"], "title": "Introducing the IEEE Virtual Reality 2017 Special Issue", "year": "2017", "abstract": "The papers in this special issue were presented at the IEEE Virtual Reality (VR) Conference that was held in Los Angeles, CA, from March 18-22, 2017. ", "keywords": ["Special issues and sections", "Meetings", "Augmented reality", "Solid modeling", "Visualization"], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2658798": {"doi": "10.1109/TVCG.2017.2658798", "author": [""], "title": "Preface", "year": "2017", "abstract": "Presents the introductory editorial from this issue of the publications which features papers from the 2017 IEEE Virtual Reality Conference (IEEE VR 2017), held March 18\u201322, 2017 in Los Angeles, California. ", "keywords": [""], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2658878": {"doi": "10.1109/TVCG.2017.2658878", "author": ["C. T. Silva"], "title": "IEEE Visualization and Graphics Technical Committee (VGTC)", "year": "2017", "abstract": "Presents a listing of the technical committee from the 2017 IEEE Virtual Reality Conference (IEEE VR 2017).", "keywords": [""], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2658898": {"doi": "10.1109/TVCG.2017.2658898", "author": [""], "title": "Conference Committee", "year": "2017", "abstract": "Presents a listing of the conference committee from the 2017 IEEE Virtual Reality Conference (IEEE VR 2017).", "keywords": [""], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2658899": {"doi": "10.1109/TVCG.2017.2658899", "author": [""], "title": "International Program Committee", "year": "2017", "abstract": "Presents a listing of the International Program Committee from the 2017 IEEE Virtual Reality Conference (IEEE VR 2017).", "keywords": [""], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2658818": {"doi": "10.1109/TVCG.2017.2658818", "author": [""], "title": "Papers Reviewers", "year": "2017", "abstract": "Presents a listing of the papers' reviewers from the 2017 IEEE Virtual Reality Conference (IEEE VR 2017).", "keywords": [""], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2658819": {"doi": "10.1109/TVCG.2017.2658819", "author": ["R. Mehra"], "title": "The 2016 VGTC Virtual Reality: Best Dissertation Award", "year": "2017", "abstract": "The 2016 IEEE VGTC Virtual Reality Best Dissertation Award goes to Ravish Mehra, a 2014 graduate from the University of North Carolina at Chapel Hill, for his dissertation entitled: \u201cEfficient Techniques for Wave-Based Sound Propagation in Interactive Applications\u201d.", "keywords": ["Three-dimensional displays", "Algorithm design and analysis", "Electromagnetic scattering", "Transfer functions", "Data analysis", "Virtual environments"], "referenced_by": [], "referencing": []}, "10.1109/TVCG.2017.2656958": {"doi": "10.1109/TVCG.2017.2656958", "author": ["C. Li", "W. Liang", "C. Quigley", "Y. Zhao", "L. Yu"], "title": "Earthquake Safety Training through Virtual Drills", "year": "2017", "abstract": "Recent popularity of consumer-grade virtual reality devices, such as the Oculus Rift and the HTC Vive, has enabled household users to experience highly immersive virtual environments. We take advantage of the commercial availability of these devices to provide an immersive and novel virtual reality training approach, designed to teach individuals how to survive earthquakes, in common indoor environments. Our approach makes use of virtual environments realistically populated with furniture objects for training. During a training, a virtual earthquake is simulated. The user navigates in, and manipulates with, the virtual environments to avoid getting hurt, while learning the observation and self-protection skills to survive an earthquake. We demonstrated our approach for common scene types such as offices, living rooms and dining rooms. To test the effectiveness of our approach, we conducted an evaluation by asking users to train in several rooms of a given scene type and then test in a new room of the same type. Evaluation results show that our virtual reality training approach is effective, with the participants who are trained by our approach performing better, on average, than those trained by alternative approaches in terms of the capabilities to avoid physical damage and to detect potentially dangerous objects.", "keywords": ["computer based training", "earthquakes", "safety", "virtual reality", "earthquake safety training", "virtual drills", "consumer-grade virtual reality devices", "highly immersive virtual environments", "virtual reality training", "Training", "Earthquakes", "Virtual environments", "Solid modeling", "Safety", "Injuries", "Virtual reality", "modeling and simulation", "virtual worlds training simulations"], "referenced_by": ["10.1109/VR.2018.8448287", "10.1109/VR.2018.8448290", "10.1109/TVCG.2019.2898721", "10.1109/VR.2019.8798371", "10.1109/VR.2019.8797705", "10.1109/ICRA.2019.8794230", "10.1109/VS-Games.2019.8864599", "10.1109/SeGAH.2019.8882429", "10.1109/VR46266.2020.00075", "10.1109/VR46266.2020.00065", "10.1109/VRW50115.2020.00020", "10.1109/ISSC49989.2020.9180166", "10.1109/ICRA40945.2020.9197494", "10.1117/12.2292718", "10.3390/ijgi7060215", "10.1371/journal.pone.0197964", "10.1002/cae.21987", "10.1016/j.cja.2018.08.011", "10.1016/j.compedu.2018.09.002", "10.1016/j.ifacol.2018.08.125", "10.1016/j.aei.2018.08.018", "10.1007/s12193-018-0288-9", "10.1016/j.ssci.2019.01.015", "10.1002/cav.1873", "10.32390/ksmer.2018.55.6.614", "10.1016/j.pdisas.2019.100012", "10.1111/jcal.12375", "10.3390/app9173465", "10.1007/s11596-019-2093-4", "10.1016/j.autcon.2019.102999", "10.1177/1071181319631013", "10.9728/dcs.2020.21.1.1", "10.1007/978-3-030-41816-8_14", "10.1016/j.ssci.2020.104837", "10.1007/978-3-030-61814-8_3", "10.1016/j.cogsys.2020.11.002", "10.1186/s41239-020-00228-9", "10.1111/jcal.12507", "10.1016/j.jnlssr.2020.11.004", "10.1016/j.compedu.2020.104096", "10.1007/s10758-020-09489-9", "10.1007/s10055-020-00492-0"], "referencing": ["10.1109/IV.2007.100", "10.1109/TVCG.2007.70625", "10.1109/TVCG.2015.2391853", "10.1109/TVCG.2012.60", "10.1109/3DV.2016.18", "10.1109/MCG.2008.61", "10.1109/TVCG.2015.2417575", "10.1109/IV.2007.100", "10.1109/TVCG.2007.70625", "10.1109/TVCG.2015.2391853", "10.1109/TVCG.2012.60", "10.1109/3DV.2016.18", "10.1109/MCG.2008.61", "10.1109/TVCG.2015.2417575", "10.1109/IV.2007.100", "10.1109/TVCG.2007.70625", "10.1109/TVCG.2015.2391853", "10.1109/TVCG.2012.60", "10.1109/3DV.2016.18", "10.1109/MCG.2008.61", "10.1109/TVCG.2015.2417575", "10.1145/2670291.2670295", "10.1145/1964921.1964981", "10.1145/2670291.2670295", "10.1145/1964921.1964981", "10.1145/2670291.2670295", "10.1145/1964921.1964981", "10.1111/j.1553-2712.2010.00728.x", "10.1016/j.firesaf.2012.01.004", "10.1193/1.2894831", "10.1029/01EO00354", "10.1089/109493102760147150", "10.1093/jpepsy/jsj030", "10.1097/FCH.0b013e3181994662", "10.1111/j.1553-2712.2002.tb01172.x", "10.1016/j.aap.2008.03.005", "10.1155/2016/5302538", "10.1111/1467-7717.00191", "10.1162/105474600300040376", "10.1111/j.1553-2712.2010.00728.x", "10.1016/j.firesaf.2012.01.004", "10.1193/1.2894831", "10.1029/01EO00354", "10.1089/109493102760147150", "10.1093/jpepsy/jsj030", "10.1097/FCH.0b013e3181994662", "10.1111/j.1553-2712.2002.tb01172.x", "10.1016/j.aap.2008.03.005", "10.1155/2016/5302538", "10.1111/1467-7717.00191", "10.1162/105474600300040376", "10.1111/j.1553-2712.2010.00728.x", "10.1016/j.firesaf.2012.01.004", "10.1193/1.2894831", "10.1029/01EO00354", "10.1089/109493102760147150", "10.1093/jpepsy/jsj030", "10.1097/FCH.0b013e3181994662", "10.1111/j.1553-2712.2002.tb01172.x", "10.1016/j.aap.2008.03.005", "10.1155/2016/5302538", "10.1111/1467-7717.00191", "10.1162/105474600300040376"]}, "10.1109/TVCG.2017.2656978": {"doi": "10.1109/TVCG.2017.2656978", "author": ["A. Zenner", "A. Kr\u00fcger"], "title": "Shifty: A Weight-Shifting Dynamic Passive Haptic Proxy to Enhance Object Perception in Virtual Reality", "year": "2017", "abstract": "We define the concept of Dynamic Passive Haptic Feedback (DPHF) for virtual reality by introducing the weight-shifting physical DPHF proxy object Shifty. This concept combines actuators known from active haptics and physical proxies known from passive haptics to construct proxies that automatically adapt their passive haptic feedback. We describe the concept behind our ungrounded weight-shifting DPHF proxy Shifty and the implementation of our prototype. We then investigate how Shifty can, by automatically changing its internal weight distribution, enhance the user's perception of virtual objects interacted with in two experiments. In a first experiment, we show that Shifty can enhance the perception of virtual objects changing in shape, especially in length and thickness. Here, Shifty was shown to increase the user's fun and perceived realism significantly, compared to an equivalent passive haptic proxy. In a second experiment, Shifty is used to pick up virtual objects of different virtual weights. The results show that Shifty enhances the perception of weight and thus the perceived realism by adapting its kinesthetic feedback to the picked-up virtual object. In the same experiment, we additionally show that specific combinations of haptic, visual and auditory feedback during the pick-up interaction help to compensate for visual-haptic mismatch perceived during the shifting process.", "keywords": ["actuators", "haptic interfaces", "human computer interaction", "virtual reality", "visual perception", "object perception", "dynamic passive haptic feedback", "virtual reality", "weight-shifting physical DPHF proxy object", "Shifty", "actuators", "kinesthetic feedback", "virtual object", "auditory feedback", "visual feedback", "visual-haptic mismatch", "Haptic interfaces", "Visualization", "Actuators", "Shape", "Augmented reality", "Augmented virtuality", "Dynamic passive haptic feedback", "input devices", "virtual reality", "haptics", "perception"], "referenced_by": ["10.1109/ISMAR-Adjunct.2017.54", "10.1109/ROBOSOFT.2018.8404930", "10.1109/VR.2018.8446053", "10.1109/VR.2018.8446524", "10.1109/TVCG.2017.2772236", "10.1109/ACCESS.2018.2880882", "10.1109/VR.2019.8798143", "10.1109/VR.2019.8797865", "10.1109/VR.2019.8798255", "10.1109/VR.2019.8798220", "10.1109/VR.2019.8798285", "10.1109/VR.2019.8797718", "10.1109/ACCESS.2019.2937937", "10.1109/TVCG.2020.2973056", "10.1109/TVCG.2020.2973476", "10.1109/VR46266.2020.00044", "10.1109/VRW50115.2020.00126", "10.1109/VR46266.2020.00035", "10.1109/VR46266.2020.00043", "10.1109/VRW50115.2020.00069", "10.1109/ISMAR50242.2020.00042", "10.1109/ISMAR50242.2020.00047", "10.1145/3369394", "10.1016/j.entcom.2018.02.006", "10.1007/978-3-319-08234-9_254-1", "10.3390/app9183692"], "referencing": ["10.1109/VR.2015.7223325", "10.1109/VR.2005.1492749", "10.1109/VR.2015.7223322", "10.1109/TVCG.2013.121", "10.1109/TVCG.2014.45", "10.1109/ISMAR.2009.5336463", "10.1109/CW.2008.53", "10.1109/VR.2015.7223325", "10.1109/VR.2005.1492749", "10.1109/VR.2015.7223322", "10.1109/TVCG.2013.121", "10.1109/TVCG.2014.45", "10.1109/ISMAR.2009.5336463", "10.1109/CW.2008.53", "10.1109/VR.2015.7223325", "10.1109/VR.2005.1492749", "10.1109/VR.2015.7223322", "10.1109/TVCG.2013.121", "10.1109/TVCG.2014.45", "10.1109/ISMAR.2009.5336463", "10.1109/CW.2008.53", "10.1145/2207676.2208731", "10.1145/2858036.2858487", "10.1145/1753846.1753922", "10.1145/2470654.2470738", "10.1145/2702123.2702389", "10.1145/958432.958445", "10.1145/2658779.2659116", "10.1145/2207676.2208731", "10.1145/2858036.2858487", "10.1145/1753846.1753922", "10.1145/2470654.2470738", "10.1145/2702123.2702389", "10.1145/958432.958445", "10.1145/2658779.2659116", "10.1145/2207676.2208731", "10.1145/2858036.2858487", "10.1145/1753846.1753922", "10.1145/2470654.2470738", "10.1145/2702123.2702389", "10.1145/958432.958445", "10.1145/2658779.2659116", "10.3758/BF03206793", "10.1162/pres.18.5.387", "10.5772/8712", "10.1007/978-3-642-87512-0_1", "10.1037/0003-066X.51.11.1134", "10.3758/BF03206793", "10.1162/pres.18.5.387", "10.5772/8712", "10.1007/978-3-642-87512-0_1", "10.1037/0003-066X.51.11.1134", "10.3758/BF03206793", "10.1162/pres.18.5.387", "10.5772/8712", "10.1007/978-3-642-87512-0_1", "10.1037/0003-066X.51.11.1134"]}, "10.1109/TVCG.2017.2656979": {"doi": "10.1109/TVCG.2017.2656979", "author": ["M. Regan", "G. S. P. Miller"], "title": "The Problem of Persistence with Rotating Displays", "year": "2017", "abstract": "Motion-to-photon latency causes images to sway from side to side in a VR/AR system, while display persistence causes smearing; both of these are undesirable artifacts. We show that once latency is reduced or eliminated, smearing due to display persistence becomes the dominant visual artifact, even with accurate tracker prediction. We investigate the human perceptual mechanisms responsible for this and we demonstrate a modified 3D rotation display controller architecture for driving a high speed digital display which minimizes latency and persistence. We simulate it in software and we built a testbench based on a very high frame rate (2880 fps 1-bit images) display system mounted on a mechanical rotation gantry which emulates display rotation during head rotation in an HMD.", "keywords": ["augmented reality", "helmet mounted displays", "motion-to-photon latency", "VR/AR system", "display persistence", "visual artifact", "modified 3D rotation display controller architecture", "high speed digital display", "HMD", "helmet mounted displays", "Head", "Visualization", "Retina", "Resists", "Three-dimensional displays", "Standards", "Image resolution", "Virtual reality", "latency", "persistence", "display modulation"], "referenced_by": ["10.1109/TVCG.2019.2899233", "10.1109/ICEEE2019.2019.00048", "10.1109/VR.2019.8797876", "10.1109/TCSVT.2019.2927344", "10.1111/cgf.13387", "10.1007/978-3-030-13940-7_2", "10.1002/jsid.912", "10.1016/j.adhoc.2020.102256", "10.1002/sdtp.13854"], "referencing": ["10.1109/TCSVT.2014.2352500", "10.1109/TVCG.2016.2518038", "10.1109/TCSVT.2014.2352500", "10.1109/TVCG.2016.2518038", "10.1109/TCSVT.2014.2352500", "10.1109/TVCG.2016.2518038", "10.1145/1186562.1015804", "10.1145/1275808.1276427", "10.1145/192161.192192", "10.1145/1186562.1015804", "10.1145/1275808.1276427", "10.1145/192161.192192", "10.1145/1186562.1015804", "10.1145/1275808.1276427", "10.1145/192161.192192", "10.2307/1418795", "10.1117/12.20962", "10.1111/j.1749-6632.2001.tb03781.x", "10.1364/JOSA.65.000847", "10.1889/1.2785299", "10.2307/1418795", "10.1117/12.20962", "10.1111/j.1749-6632.2001.tb03781.x", "10.1364/JOSA.65.000847", "10.1889/1.2785299", "10.2307/1418795", "10.1117/12.20962", "10.1111/j.1749-6632.2001.tb03781.x", "10.1364/JOSA.65.000847", "10.1889/1.2785299"]}, "10.1109/TVCG.2017.2657018": {"doi": "10.1109/TVCG.2017.2657018", "author": ["J. Orlosky", "Y. Itoh", "M. Ranchet", "K. Kiyokawa", "J. Morgan", "H. Devos"], "title": "Emulation of Physician Tasks in Eye-Tracked Virtual Reality for Remote Diagnosis of Neurodegenerative Disease", "year": "2017", "abstract": "For neurodegenerative conditions like Parkinson's disease, early and accurate diagnosis is still a difficult task. Evaluations can be time consuming, patients must often travel to metropolitan areas or different cities to see experts, and misdiagnosis can result in improper treatment. To date, only a handful of assistive or remote methods exist to help physicians evaluate patients with suspected neurological disease in a convenient and consistent way. In this paper, we present a low-cost VR interface designed to support evaluation and diagnosis of neurodegenerative disease and test its use in a clinical setting. Using a commercially available VR display with an infrared camera integrated into the lens, we have constructed a 3D virtual environment designed to emulate common tasks used to evaluate patients, such as fixating on a point, conducting smooth pursuit of an object, or executing saccades. These virtual tasks are designed to elicit eye movements commonly associated with neurodegenerative disease, such as abnormal saccades, square wave jerks, and ocular tremor. Next, we conducted experiments with 9 patients with a diagnosis of Parkinson's disease and 7 healthy controls to test the system's potential to emulate tasks for clinical diagnosis. We then applied eye tracking algorithms and image enhancement to the eye recordings taken during the experiment and conducted a short follow-up study with two physicians for evaluation. Results showed that our VR interface was able to elicit five common types of movements usable for evaluation, physicians were able to confirm three out of four abnormalities, and visualizations were rated as potentially useful for diagnosis.", "keywords": ["diseases", "gaze tracking", "image enhancement", "medical image processing", "virtual reality", "eye-tracked virtual reality", "neurodegenerative diseases remote diagnosis", "VR interface", "VR display", "infrared camera", "3D virtual environment", "patient evaluation", "Parkinsons disease", "clinical diagnosis", "image enhancement", "Diseases", "Gaze tracking", "Cameras", "Visualization", "Three-dimensional displays", "Lenses", "Virtual reality", "eye tracking", "diagnosis", "visualization", "Eye Movements", "Female", "Humans", "Image Interpretation, Computer-Assisted", "Male", "Neurodegenerative Diseases", "Parkinson Disease", "Task Performance and Analysis", "Telemedicine", "Video Recording", "Virtual Reality"], "referenced_by": ["10.1109/ICCSE.2017.8085473", "10.1109/TVCG.2020.2973052", "10.1109/ACCESS.2020.2985095", "10.1049/htl.2016.0081", "10.3389/fnagi.2018.00090", "10.3389/fnagi.2017.00286", "10.1016/j.bbr.2017.03.043", "10.3928/23258160-20180501-08", "10.3758/s13428-018-1074-z", "10.3390/s18082486", "10.1007/s40474-019-00169-7", "10.1007/978-3-030-49698-2_28", "10.1016/j.micpro.2020.103350"], "referencing": ["10.1109/TVCG.2015.2473855", "10.1109/VR.2000.840364", "10.1109/TVCG.2015.2473855", "10.1109/VR.2000.840364", "10.1109/TVCG.2015.2473855", "10.1109/VR.2000.840364", "10.1145/2638728.2641695", "10.1145/1073204.1073223", "10.1145/2757710.2776816", "10.1145/2168556.2168585", "10.1145/2185520.2185561", "10.1145/2638728.2641695", "10.1145/1073204.1073223", "10.1145/2757710.2776816", "10.1145/2168556.2168585", "10.1145/2185520.2185561", "10.1145/2638728.2641695", "10.1145/1073204.1073223", "10.1145/2757710.2776816", "10.1145/2168556.2168585", "10.1145/2185520.2185561", "10.3233/JPD-150686", "10.1037/0033-2909.91.2.276", "10.1212/01.wnl.0000326262.67613.fe", "10.1016/j.neuropsychologia.2011.07.029", "10.1016/j.ijpsycho.2009.01.011", "10.1001/archneurol.2012.70", "10.1162/105474600566790", "10.1016/S0167-8760(02)00122-8", "10.1016/0169-2607(86)90076-3", "10.1167/14.14.12", "10.1212/WNL.5.9.631", "10.3389/fnbeh.2012.00088", "10.1007/978-3-319-07788-8_27", "10.1007/s00415-009-5131-5", "10.1016/j.neuropsychologia.2011.12.013", "10.1162/105474600566808", "10.1097/00001199-200210000-00002", "10.1016/j.ijpsycho.2008.10.010", "10.1016/S0733-8619(05)70259-0", "10.1111/j.1469-8986.2003.00148.x", "10.1093/brain/aww175", "10.3233/JPD-150686", "10.1037/0033-2909.91.2.276", "10.1212/01.wnl.0000326262.67613.fe", "10.1016/j.neuropsychologia.2011.07.029", "10.1016/j.ijpsycho.2009.01.011", "10.1001/archneurol.2012.70", "10.1162/105474600566790", "10.1016/S0167-8760(02)00122-8", "10.1016/0169-2607(86)90076-3", "10.1167/14.14.12", "10.1212/WNL.5.9.631", "10.3389/fnbeh.2012.00088", "10.1007/978-3-319-07788-8_27", "10.1007/s00415-009-5131-5", "10.1016/j.neuropsychologia.2011.12.013", "10.1162/105474600566808", "10.1097/00001199-200210000-00002", "10.1016/j.ijpsycho.2008.10.010", "10.1016/S0733-8619(05)70259-0", "10.1111/j.1469-8986.2003.00148.x", "10.1093/brain/aww175", "10.3233/JPD-150686", "10.1037/0033-2909.91.2.276", "10.1212/01.wnl.0000326262.67613.fe", "10.1016/j.neuropsychologia.2011.07.029", "10.1016/j.ijpsycho.2009.01.011", "10.1001/archneurol.2012.70", "10.1162/105474600566790", "10.1016/S0167-8760(02)00122-8", "10.1016/0169-2607(86)90076-3", "10.1167/14.14.12", "10.1212/WNL.5.9.631", "10.3389/fnbeh.2012.00088", "10.1007/978-3-319-07788-8_27", "10.1007/s00415-009-5131-5", "10.1016/j.neuropsychologia.2011.12.013", "10.1162/105474600566808", "10.1097/00001199-200210000-00002", "10.1016/j.ijpsycho.2008.10.010", "10.1016/S0733-8619(05)70259-0", "10.1111/j.1469-8986.2003.00148.x", "10.1093/brain/aww175"]}, "10.1109/TVCG.2017.2657038": {"doi": "10.1109/TVCG.2017.2657038", "author": ["A. L. Simeone", "I. Mavridou", "W. Powell"], "title": "Altering User Movement Behaviour in Virtual Environments", "year": "2017", "abstract": "In immersive Virtual Reality systems, users tend to move in a Virtual Environment as they would in an analogous physical environment. In this work, we investigated how user behaviour is affected when the Virtual Environment differs from the physical space. We created two sets of four environments each, plus a virtual replica of the physical environment as a baseline. The first focused on aesthetic discrepancies, such as a water surface in place of solid ground. The second focused on mixing immaterial objects together with those paired to tangible objects. For example, barring an area with walls or obstacles. We designed a study where participants had to reach three waypoints laid out in such a way to prompt a decision on which path to follow based on the conflict between the mismatching visual stimuli and their awareness of the real layout of the room. We analysed their performances to determine whether their trajectories were altered significantly from the shortest route. Our results indicate that participants altered their trajectories in presence of surfaces representing higher walking difficulty (for example, water instead of grass). However, when the graphical appearance was found to be ambiguous, there was no significant trajectory alteration. The environments mixing immaterial with physical objects had the most impact on trajectories with a mean deviation from the shortest route of 60 cm against the 37 cm of environments with aesthetic alterations. The co-existance of paired and unpaired virtual objects was reported to support the idea that all objects participants saw were backed by physical props. From these results and our observations, we derive guidelines on how to alter user movement behaviour in Virtual Environments.", "keywords": ["user interfaces", "virtual reality", "user movement behaviour", "virtual environments", "immersive virtual reality systems", "virtual replica", "physical environment", "aesthetic discrepancies", "visual stimuli", "Legged locomotion", "Trajectory", "Virtual environments", "Visualization", "Navigation", "Tracking", "Virtual reality", "Locomotion", "User behaviour"], "referenced_by": ["10.1109/SITIS.2017.86", "10.1109/VR.2018.8446177", "10.1109/VR.2019.8798360", "10.1109/VR.2019.8798074", "10.1109/VR.2019.8798043", "10.1109/VR.2019.8797983", "10.1109/WEVR.2019.8809590", "10.1109/VS-Games.2019.8864514", "10.1109/VR46266.2020.00085", "10.1109/VR46266.2020.00082", "10.1007/978-3-319-08234-9_254-1", "10.1016/j.entcom.2018.02.006", "10.1016/B978-0-12-800965-9.16001-5", "10.3390/bs10090130", "10.1016/j.actpsy.2020.103239"], "referencing": ["10.1109/TVCG.2013.34", "10.1109/3DUI.2008.4476598", "10.1109/2.391038", "10.1109/TVCG.2012.43", "10.1109/TVCG.2011.275", "10.1109/TVCG.2008.191", "10.1109/WEVR.2015.7151690", "10.1109/MCG.2009.55", "10.1109/TVCG.2009.62", "10.1109/CW.2008.53", "10.1109/VR.2012.6180877", "10.1109/TVCG.2009.93", "10.1109/MCG.2012.121", "10.1109/TVCG.2005.92", "10.1109/TVCG.2013.34", "10.1109/3DUI.2008.4476598", "10.1109/2.391038", "10.1109/TVCG.2012.43", "10.1109/TVCG.2011.275", "10.1109/TVCG.2008.191", "10.1109/WEVR.2015.7151690", "10.1109/MCG.2009.55", "10.1109/TVCG.2009.62", "10.1109/CW.2008.53", "10.1109/VR.2012.6180877", "10.1109/TVCG.2009.93", "10.1109/MCG.2012.121", "10.1109/TVCG.2005.92", "10.1109/TVCG.2013.34", "10.1109/3DUI.2008.4476598", "10.1109/2.391038", "10.1109/TVCG.2012.43", "10.1109/TVCG.2011.275", "10.1109/TVCG.2008.191", "10.1109/WEVR.2015.7151690", "10.1109/MCG.2009.55", "10.1109/TVCG.2009.62", "10.1109/CW.2008.53", "10.1109/VR.2012.6180877", "10.1109/TVCG.2009.93", "10.1109/MCG.2012.121", "10.1109/TVCG.2005.92", "10.1145/1227134.1227136", "10.1145/642611.642703", "10.1145/1152399.1152451", "10.1145/1044588.1044629", "10.1145/1502800.1502805", "10.1145/2465780.2465785", "10.1145/2702123.2702389", "10.1145/210079.210084", "10.1145/2043603.2043607", "10.1145/1620993.1620998", "10.1145/1450579.1450611", "10.1145/311535.311589", "10.1145/2010325.2010329", "10.1145/1272582.1272590", "10.1145/1227134.1227136", "10.1145/642611.642703", "10.1145/1152399.1152451", "10.1145/1044588.1044629", "10.1145/1502800.1502805", "10.1145/2465780.2465785", "10.1145/2702123.2702389", "10.1145/210079.210084", "10.1145/2043603.2043607", "10.1145/1620993.1620998", "10.1145/1450579.1450611", "10.1145/311535.311589", "10.1145/2010325.2010329", "10.1145/1272582.1272590", "10.1145/1227134.1227136", "10.1145/642611.642703", "10.1145/1152399.1152451", "10.1145/1044588.1044629", "10.1145/1502800.1502805", "10.1145/2465780.2465785", "10.1145/2702123.2702389", "10.1145/210079.210084", "10.1145/2043603.2043607", "10.1145/1620993.1620998", "10.1145/1450579.1450611", "10.1145/311535.311589", "10.1145/2010325.2010329", "10.1145/1272582.1272590", "10.1007/978-3-642-29050-3_1", "10.1007/978-1-4419-8432-6_4", "10.1037/h0074626", "10.1080/088395100117142", "10.1162/1054746041944849", "10.1098/rstb.2009.0138", "10.1162/105474600566925", "10.1007/978-3-7091-9433-1_12", "10.1162/105474699566512", "10.1007/978-3-540-74479-5_3", "10.1007/978-3-642-29050-3_1", "10.1007/978-1-4419-8432-6_4", "10.1037/h0074626", "10.1080/088395100117142", "10.1162/1054746041944849", "10.1098/rstb.2009.0138", "10.1162/105474600566925", "10.1007/978-3-7091-9433-1_12", "10.1162/105474699566512", "10.1007/978-3-540-74479-5_3", "10.1007/978-3-642-29050-3_1", "10.1007/978-1-4419-8432-6_4", "10.1037/h0074626", "10.1080/088395100117142", "10.1162/1054746041944849", "10.1098/rstb.2009.0138", "10.1162/105474600566925", "10.1007/978-3-7091-9433-1_12", "10.1162/105474699566512", "10.1007/978-3-540-74479-5_3"]}, "10.1109/TVCG.2017.2657058": {"doi": "10.1109/TVCG.2017.2657058", "author": ["D. Dunn", "C. Tippets", "K. Torell", "P. Kellnhofer", "K. Ak\u015fit", "P. Didyk", "K. Myszkowski", "D. Luebke", "H. Fuchs"], "title": "Wide Field Of View Varifocal Near-Eye Display Using See-Through Deformable Membrane Mirrors", "year": "2017", "abstract": "Accommodative depth cues, a wide field of view, and ever-higher resolutions all present major hardware design challenges for near-eye displays. Optimizing a design to overcome one of these challenges typically leads to a trade-off in the others. We tackle this problem by introducing an all-in-one solution - a new wide field of view, gaze-tracked near-eye display for augmented reality applications. The key component of our solution is the use of a single see-through, varifocal deformable membrane mirror for each eye reflecting a display. They are controlled by airtight cavities and change the effective focal power to present a virtual image at a target depth plane which is determined by the gaze tracker. The benefits of using the membranes include wide field of view (100\u00b0 diagonal) and fast depth switching (from 20 cm to infinity within 300 ms). Our subjective experiment verifies the prototype and demonstrates its potential benefits for near-eye see-through displays.", "keywords": ["augmented reality", "gaze tracking", "image processing", "mirrors", "field of view", "FOV", "near-eye display", "NED", "varifocal deformable membrane mirror", "gaze tracking", "augmented reality", "AR", "virtual image", "Mirrors", "Image resolution", "Prototypes", "Optical imaging", "Holography", "Holographic optical components", "Augmented reality", "displays", "focus accommodation", "perception", "user study"], "referenced_by": ["10.1109/TVCG.2018.2793680", "10.1109/TVCG.2017.2734427", "10.1109/TVCG.2017.2754257", "10.1109/VR.2018.8446391", "10.1109/TVCG.2018.2868532", "10.1109/TVCG.2018.2868570", "10.1109/TVCG.2019.2898821", "10.1109/TVCG.2019.2898781", "10.1109/VR.2019.8797780", "10.1109/TVCG.2019.2932238", "10.1109/ISMAR-Adjunct.2019.00050", "10.1109/ACCESS.2020.3026332", "10.1109/TVCG.2020.3023601", "10.1109/ISMAR50242.2020.00033", "10.1109/ISMAR50242.2020.00057", "10.1109/ISMAR50242.2020.00056", "10.1109/ISMAR50242.2020.00029", "10.1109/ISMAR50242.2020.00028", "10.1145/3130800.3130846", "10.1145/3072959.3073590", "10.1145/3272127.3275032", "10.1145/3306346.3322987", "10.1145/3355089.3356577", "10.1162/PRES_a_00284", "10.1364/AO.56.009390", "10.1364/OE.26.001161", "10.1364/OE.26.003394", "10.3169/mta.5.78", "10.3390/mti1040022", "10.1117/1.OE.57.6.063106", "10.1016/j.optcom.2018.09.011", "10.1016/j.preteyeres.2018.09.004", "10.1364/AO.57.008508", "10.1002/jsid.739", "10.1364/OE.26.032802", "10.1117/12.2509143", "10.1038/s41598-019-42507-0", "10.1117/1.OE.58.4.045103", "10.1111/cgf.13654", "10.1016/j.ijleo.2019.06.001", "10.4018/IJMHCI.2019040101", "10.1126/sciadv.aav6187", "10.1364/OE.27.025154", "10.1364/OSAC.2.002694", "10.1364/OE.381200", "10.1364/OE.383386", "10.1364/OE.380945", "10.1186/s43074-020-00010-0"], "referencing": ["10.1109/TVCG.2015.2473855", "10.1109/TVCG.2015.2440272", "10.1109/MSPEC.1969.5213672", "10.1109/JMEMS.2008.928712", "10.1109/TVCG.2015.2473855", "10.1109/TVCG.2015.2440272", "10.1109/MSPEC.1969.5213672", "10.1109/JMEMS.2008.928712", "10.1109/TVCG.2015.2473855", "10.1109/TVCG.2015.2440272", "10.1109/MSPEC.1969.5213672", "10.1109/JMEMS.2008.928712", "10.1145/2807442.2807493", "10.1145/2782782.2792493", "10.1145/2508363.2508366", "10.1145/2614066.2614080", "10.1145/2858036.2858140", "10.1145/2807442.2807493", "10.1145/2782782.2792493", "10.1145/2508363.2508366", "10.1145/2614066.2614080", "10.1145/2858036.2858140", "10.1145/2807442.2807493", "10.1145/2782782.2792493", "10.1145/2508363.2508366", "10.1145/2614066.2614080", "10.1145/2858036.2858140", "10.1016/j.visres.2004.07.040", "10.1080/713826091", "10.1113/jphysiol.1960.sp006438", "10.1007/s11042-010-0660-6", "10.1016/S0042-6989(00)00282-0", "10.1167/8.3.33", "10.1364/OE.22.013896", "10.1364/OE.22.013484", "10.1364/3D.2016.TT4A.1", "10.1016/j.visres.2003.08.004", "10.1068/p150007", "10.1162/pres.15.5.588", "10.1159/000264746", "10.1097/00006324-197205000-00001", "10.1016/j.sna.2015.04.011", "10.1364/JOSA.52.000672", "10.1016/j.visres.2004.01.001", "10.1016/j.survophthal.2005.11.003", "10.1016/j.visres.2004.07.040", "10.1080/713826091", "10.1113/jphysiol.1960.sp006438", "10.1007/s11042-010-0660-6", "10.1016/S0042-6989(00)00282-0", "10.1167/8.3.33", "10.1364/OE.22.013896", "10.1364/OE.22.013484", "10.1364/3D.2016.TT4A.1", "10.1016/j.visres.2003.08.004", "10.1068/p150007", "10.1162/pres.15.5.588", "10.1159/000264746", "10.1097/00006324-197205000-00001", "10.1016/j.sna.2015.04.011", "10.1364/JOSA.52.000672", "10.1016/j.visres.2004.01.001", "10.1016/j.survophthal.2005.11.003", "10.1016/j.visres.2004.07.040", "10.1080/713826091", "10.1113/jphysiol.1960.sp006438", "10.1007/s11042-010-0660-6", "10.1016/S0042-6989(00)00282-0", "10.1167/8.3.33", "10.1364/OE.22.013896", "10.1364/OE.22.013484", "10.1364/3D.2016.TT4A.1", "10.1016/j.visres.2003.08.004", "10.1068/p150007", "10.1162/pres.15.5.588", "10.1159/000264746", "10.1097/00006324-197205000-00001", "10.1016/j.sna.2015.04.011", "10.1364/JOSA.52.000672", "10.1016/j.visres.2004.01.001", "10.1016/j.survophthal.2005.11.003"]}, "10.1109/TVCG.2017.2657078": {"doi": "10.1109/TVCG.2017.2657078", "author": ["A. Schollmeyer", "S. Schneegans", "S. Beck", "A. Steed", "B. Froehlich"], "title": "Efficient Hybrid Image Warping for High Frame-Rate Stereoscopic Rendering", "year": "2017", "abstract": "Modern virtual reality simulations require a constant high-frame rate from the rendering engine. They may also require very low latency and stereo images. Previous rendering engines for virtual reality applications have exploited spatial and temporal coherence by using image-warping to re-use previous frames or to render a stereo pair at lower cost than running the full render pipeline twice. However these previous approaches have shown artifacts or have not scaled well with image size. We present a new image-warping algorithm that has several novel contributions: an adaptive grid generation algorithm for proxy geometry for image warping; a low-pass hole-filling algorithm to address un-occlusion; and support for transparent surfaces by efficiently ray casting transparent fragments stored in per-pixel linked lists of an A-Buffer. We evaluate our algorithm with a variety of challenging test cases. The results show that it achieves better quality image-warping than state-of-the-art techniques and that it can support transparent surfaces effectively. Finally, we show that our algorithm can achieve image warping at rates suitable for practical use in a variety of applications on modern virtual reality equipment.", "keywords": ["geometry", "ray tracing", "rendering (computer graphics)", "stereo image processing", "virtual reality", "hybrid image warping algorithm", "stereoscopic rendering", "virtual reality simulation", "stereo image", "adaptive grid generation algorithm", "proxy geometry", "low-pass hole-filling algorithm", "ray casting", "Rendering (computer graphics)", "Three-dimensional displays", "Casting", "Stereo image processing", "Engines", "Pipelines", "Visualization", "Image warping", "stereoscopic rendering", "transparency warping", "A-buffer ray casting", "image warping strategies", "surface estimation quadtree"], "referenced_by": ["10.1109/VR.2019.8798283", "10.1109/VR46266.2020.00107", "10.1145/3306346.3323033", "10.1162/pres_a_00297", "10.1016/B978-0-12-800965-9.16001-5", "10.1111/cgf.14176"], "referencing": ["10.1109/38.376612", "10.1109/TVCG.2014.30", "10.1109/TIP.2013.2268940", "10.1109/TIP.2003.819861", "10.1109/TBC.2005.846190", "10.1109/38.376612", "10.1109/TVCG.2014.30", "10.1109/TIP.2013.2268940", "10.1109/TIP.2003.819861", "10.1109/TBC.2005.846190", "10.1109/38.376612", "10.1109/TVCG.2014.30", "10.1109/TIP.2013.2268940", "10.1109/TIP.2003.819861", "10.1109/TBC.2005.846190", "10.1145/800031.808585", "10.1145/166117.166153", "10.1145/253284.253292", "10.1145/2668904.2668931", "10.1145/97879.97901", "10.1145/280814.280882", "10.1145/1315184.1315212", "10.1145/1342250.1342279", "10.1145/237091.237098", "10.1145/97879.97919", "10.1145/2024156.2024184", "10.1145/800031.808585", "10.1145/166117.166153", "10.1145/253284.253292", "10.1145/2668904.2668931", "10.1145/97879.97901", "10.1145/280814.280882", "10.1145/1315184.1315212", "10.1145/1342250.1342279", "10.1145/237091.237098", "10.1145/97879.97919", "10.1145/2024156.2024184", "10.1145/800031.808585", "10.1145/166117.166153", "10.1145/253284.253292", "10.1145/2668904.2668931", "10.1145/97879.97901", "10.1145/280814.280882", "10.1145/1315184.1315212", "10.1145/1342250.1342279", "10.1145/237091.237098", "10.1145/97879.97919", "10.1145/2024156.2024184", "10.1111/j.1467-8659.2012.03002.x", "10.1201/b16721-3", "10.1117/12.205865", "10.1111/j.1467-8659.2012.03075.x", "10.1111/cgf.12746", "10.1111/j.1467-8659.2012.03002.x", "10.1201/b16721-3", "10.1117/12.205865", "10.1111/j.1467-8659.2012.03075.x", "10.1111/cgf.12746", "10.1111/j.1467-8659.2012.03002.x", "10.1201/b16721-3", "10.1117/12.205865", "10.1111/j.1467-8659.2012.03075.x", "10.1111/cgf.12746"]}, "10.1109/TVCG.2017.2657098": {"doi": "10.1109/TVCG.2017.2657098", "author": ["M. Fischbach", "D. Wiebusch", "M. E. Latoschik"], "title": "Semantic Entity-Component State Management Techniques to Enhance Software Quality for Multimodal VR-Systems", "year": "2017", "abstract": "Modularity, modifiability, reusability, and API usability are important software qualities that determine the maintainability of software architectures. Virtual, Augmented, and Mixed Reality (VR, AR, MR) systems, modern computer games, as well as interactive human-robot systems often include various dedicated input-, output-, and processing subsystems. These subsystems collectively maintain a real-time simulation of a coherent application state. The resulting interdependencies between individual state representations, mutual state access, overall synchronization, and flow of control implies a conceptual close coupling whereas software quality asks for a decoupling to develop maintainable solutions. This article presents five semantics-based software techniques that address this contradiction: Semantic grounding, code from semantics, grounded actions, semantic queries, and decoupling by semantics. These techniques are applied to extend the well-established entity-component-system (ECS) pattern to overcome some of this pattern's deficits with respect to the implied state access. A walk-through of central implementation aspects of a multimodal (speech and gesture) VR-interface is used to highlight the techniques' benefits. This use-case is chosen as a prototypical example of complex architectures with multiple interacting subsystems found in many VR, AR and MR architectures. Finally, implementation hints are given, lessons learned regarding maintainability pointed-out, and performance implications discussed.", "keywords": ["augmented reality", "programming language semantics", "software quality", "semantic entity-component state management techniques", "software quality", "multimodal VR-systems", "semantic grounding", "semantics code", "grounded actions", "semantic queries", "decoupling by semantics", "entity-component-system pattern", "ECS pattern", "AR", "MR", "mixed reality", "augmented reality", "virtual reality", "Semantics", "Couplings", "Software quality", "Computer architecture", "Data models", "Virtual environments", "Real-time interactive systems", "virtual reality systems", "software architecture", "multimodal processing"], "referenced_by": ["10.1109/VR.2018.8446151", "10.1109/ICECCE49384.2020.9179394", "10.1007/978-3-662-59351-6_15", "10.1111/cgf.13887", "10.1016/j.jmsy.2020.07.007"], "referencing": ["10.1109/MIC.2011.82", "10.1109/TCIAIG.2015.2505404", "10.1109/SEARIS.2016.7551582", "10.1109/SEARIS.2016.7551583", "10.1109/ESEM.2009.5314233", "10.1109/TCYB.2013.2271563", "10.1109/SEARIS.2012.6231168", "10.1109/MIC.2011.82", "10.1109/TCIAIG.2015.2505404", "10.1109/SEARIS.2016.7551582", "10.1109/SEARIS.2016.7551583", "10.1109/ESEM.2009.5314233", "10.1109/TCYB.2013.2271563", "10.1109/SEARIS.2012.6231168", "10.1109/MIC.2011.82", "10.1109/TCIAIG.2015.2505404", "10.1109/SEARIS.2016.7551582", "10.1109/SEARIS.2016.7551583", "10.1109/ESEM.2009.5314233", "10.1109/TCYB.2013.2271563", "10.1109/SEARIS.2012.6231168", "10.1145/2070481.2070521", "10.1145/800250.807503", "10.1145/1027933.1027975", "10.1145/266180.266328", "10.1145/1647314.1647360", "10.1145/2818346.2823308", "10.1145/2070481.2070500", "10.1145/259963.260487", "10.1145/1088463.1088479", "10.1145/1570433.1570480", "10.1145/1358628.1358881", "10.1145/1979742.1979703", "10.1145/2502081.2502223", "10.1145/2407336.2407365", "10.1145/2993369.2996310", "10.1145/2070481.2070521", "10.1145/800250.807503", "10.1145/1027933.1027975", "10.1145/266180.266328", "10.1145/1647314.1647360", "10.1145/2818346.2823308", "10.1145/2070481.2070500", "10.1145/259963.260487", "10.1145/1088463.1088479", "10.1145/1570433.1570480", "10.1145/1358628.1358881", "10.1145/1979742.1979703", "10.1145/2502081.2502223", "10.1145/2407336.2407365", "10.1145/2993369.2996310", "10.1145/2070481.2070521", "10.1145/800250.807503", "10.1145/1027933.1027975", "10.1145/266180.266328", "10.1145/1647314.1647360", "10.1145/2818346.2823308", "10.1145/2070481.2070500", "10.1145/259963.260487", "10.1145/1088463.1088479", "10.1145/1570433.1570480", "10.1145/1358628.1358881", "10.1145/1979742.1979703", "10.1145/2502081.2502223", "10.1145/2407336.2407365", "10.1145/2993369.2996310", "10.1016/j.robot.2015.03.002", "10.1007/978-3-319-07233-3_29", "10.1007/s10664-015-9381-9", "10.3115/1075434.1075499", "10.1016/B978-0-12-374825-6.00010-1", "10.1016/j.robot.2015.03.002", "10.1007/978-3-319-07233-3_29", "10.1007/s10664-015-9381-9", "10.3115/1075434.1075499", "10.1016/B978-0-12-374825-6.00010-1", "10.1016/j.robot.2015.03.002", "10.1007/978-3-319-07233-3_29", "10.1007/s10664-015-9381-9", "10.3115/1075434.1075499", "10.1016/B978-0-12-374825-6.00010-1"]}, "10.1109/TVCG.2017.2657138": {"doi": "10.1109/TVCG.2017.2657138", "author": ["I. Bergstr\u00f6m", "S. Azevedo", "P. Papiotis", "N. Saldanha", "M. Slater"], "title": "The Plausibility of a String Quartet Performance in Virtual Reality", "year": "2017", "abstract": "We describe an experiment that explores the contribution of auditory and other features to the illusion of plausibility in a virtual environment that depicts the performance of a string quartet. `Plausibility' refers to the component of presence that is the illusion that the perceived events in the virtual environment are really happening. The features studied were: Gaze (the musicians ignored the participant, the musicians sometimes looked towards and followed the participant's movements), Sound Spatialization (Mono, Stereo, Spatial), Auralization (no sound reflections, reflections corresponding to a room larger than the one perceived, reflections that exactly matched the virtual room), and Environment (no sound from outside of the room, birdsong and wind corresponding to the outside scene). We adopted the methodology based on color matching theory, where 20 participants were first able to assess their feeling of plausibility in the environment with each of the four features at their highest setting. Then five times participants started from a low setting on all features and were able to make transitions from one system configuration to another until they matched their original feeling of plausibility. From these transitions a Markov transition matrix was constructed, and also probabilities of a match conditional on feature configuration. The results show that Environment and Gaze were individually the most important factors influencing the level of plausibility. The highest probability transitions were to improve Environment and Gaze, and then Auralization and Spatialization. We present this work as both a contribution to the methodology of assessing presence without questionnaires, and showing how various aspects of a musical performance can influence plausibility.", "keywords": ["human computer interaction", "Markov processes", "music", "virtual reality", "string quartet performance", "virtual reality", "sound spatialization", "auralization", "color matching theory", "Markov transition matrix", "plausibility level", "musical performance", "Reflection", "Virtual environments", "Electronic mail", "Instruments", "Auditory system", "Music", "Presence", "plausibility", "place illusion", "user studies", "experimental methods", "multimodal interaction", "entertainment"], "referenced_by": ["10.1109/AIVR.2018.00025", "10.1109/TVCG.2019.2898823", "10.1109/WEVR.2019.8809590", "10.1109/VS-Games.2019.8864514", "10.1109/TVCG.2020.2973077", "10.1109/VR46266.2020.00098", "10.1145/3208159.3208171", "10.1145/3134301", "10.3389/fnins.2018.00021", "10.1007/978-3-319-08234-9_251-1", "10.3389/frobt.2018.00081", "10.3389/frobt.2018.00112", "10.1371/journal.pone.0203358", "10.1016/j.ijhcs.2019.02.001"], "referencing": ["10.1109/MMUL.2017.3", "10.1109/MCG.2009.55", "10.1109/VR.2003.1191132", "10.1109/VR.2013.6549396", "10.1109/VR.1999.756955", "10.1109/TVCG.2015.2391858", "10.1109/MMUL.2017.3", "10.1109/MCG.2009.55", "10.1109/VR.2003.1191132", "10.1109/VR.2013.6549396", "10.1109/VR.1999.756955", "10.1109/TVCG.2015.2391858", "10.1109/MMUL.2017.3", "10.1109/MCG.2009.55", "10.1109/VR.2003.1191132", "10.1109/VR.2013.6549396", "10.1109/VR.1999.756955", "10.1109/TVCG.2015.2391858", "10.1145/2931002.2963134", "10.1145/1394281.1394283", "10.1145/642611.642703", "10.1145/1460563.1460593", "10.1145/566570.566630", "10.1145/2931002.2963134", "10.1145/1394281.1394283", "10.1145/642611.642703", "10.1145/1460563.1460593", "10.1145/566570.566630", "10.1145/2931002.2963134", "10.1145/1394281.1394283", "10.1145/642611.642703", "10.1145/1460563.1460593", "10.1145/566570.566630", "10.1162/pres.1992.1.1.109", "10.1162/pres.1992.1.1.120", "10.1162/pres.1992.1.1.113", "10.1162/pres.1992.1.2.262", "10.1098/rstb.2009.0138", "10.1080/15213269.2015.1015740", "10.1017/S0140525X01000115", "10.1162/pres.1996.5.2.241", "10.1162/pres.1997.6.6.603", "10.1007/BF02009709", "10.1016/S0141-9382(98)00041-9", "10.1162/pres.1996.5.3.274", "10.1162/pres.1996.5.3.263", "10.1162/pres.1994.3.2.130", "10.1038/nrn1651", "10.1162/pres.1996.5.3.290", "10.1162/105474605323384645", "10.1162/105474698565686", "10.1518/001872098779591395", "10.1121/1.426899", "10.1177/0146167203029007002", "10.1162/PRES_a_00205", "10.1162/pres.1996.5.2.247", "10.1371/journal.pone.0052766", "10.1371/journal.pone.0146837", "10.1162/pres.1992.1.1.109", "10.1162/pres.1992.1.1.120", "10.1162/pres.1992.1.1.113", "10.1162/pres.1992.1.2.262", "10.1098/rstb.2009.0138", "10.1080/15213269.2015.1015740", "10.1017/S0140525X01000115", "10.1162/pres.1996.5.2.241", "10.1162/pres.1997.6.6.603", "10.1007/BF02009709", "10.1016/S0141-9382(98)00041-9", "10.1162/pres.1996.5.3.274", "10.1162/pres.1996.5.3.263", "10.1162/pres.1994.3.2.130", "10.1038/nrn1651", "10.1162/pres.1996.5.3.290", "10.1162/105474605323384645", "10.1162/105474698565686", "10.1518/001872098779591395", "10.1121/1.426899", "10.1177/0146167203029007002", "10.1162/PRES_a_00205", "10.1162/pres.1996.5.2.247", "10.1371/journal.pone.0052766", "10.1371/journal.pone.0146837", "10.1162/pres.1992.1.1.109", "10.1162/pres.1992.1.1.120", "10.1162/pres.1992.1.1.113", "10.1162/pres.1992.1.2.262", "10.1098/rstb.2009.0138", "10.1080/15213269.2015.1015740", "10.1017/S0140525X01000115", "10.1162/pres.1996.5.2.241", "10.1162/pres.1997.6.6.603", "10.1007/BF02009709", "10.1016/S0141-9382(98)00041-9", "10.1162/pres.1996.5.3.274", "10.1162/pres.1996.5.3.263", "10.1162/pres.1994.3.2.130", "10.1038/nrn1651", "10.1162/pres.1996.5.3.290", "10.1162/105474605323384645", "10.1162/105474698565686", "10.1518/001872098779591395", "10.1121/1.426899", "10.1177/0146167203029007002", "10.1162/PRES_a_00205", "10.1162/pres.1996.5.2.247", "10.1371/journal.pone.0052766", "10.1371/journal.pone.0146837"]}, "10.1109/TVCG.2017.2657139": {"doi": "10.1109/TVCG.2017.2657139", "author": ["M. Kim", "S. Cho", "T. Q. Tran", "S. Kim", "O. Kwon", "J. Han"], "title": "Scaled Jump in Gravity-Reduced Virtual Environments", "year": "2017", "abstract": "The reduced gravity experienced in lunar or Martian surfaces can be simulated on the earth using a cable-driven system, where the cable lifts a person to reduce his or her weight. This paper presents a novel cable-driven system designed for the purpose. It is integrated with a head-mounted display and a motion capture system. Focusing on jump motion within the system, this paper proposes to scale the jump and reports the experiments made for quantifying the extent to which a jump can be scaled without the discrepancy between physical and virtual jumps being noticed by the user. With the tolerable range of scaling computed from these experiments, an application named retargeted jump is developed, where a user can jump up onto virtual objects while physically jumping in the real-world flat floor. The core techniques presented in this paper can be extended to develop extreme-sport simulators such as parasailing and skydiving.", "keywords": ["helmet mounted displays", "virtual reality", "scaled jump", "gravity-reduced virtual environments", "cable-driven system", "head-mounted display", "motion capture system", "jump motion", "physical jumps", "virtual jumps", "retargeted jump", "virtual objects", "extreme-sport simulators", "parasailing", "skydiving", "virtual reality", "Moon", "Gravity", "Resists", "Wires", "Earth", "Winches", "Virtual environments", "Virtual reality", "reduced gravity", "scaled jump", "detection thresholds", "visual gain"], "referenced_by": ["10.1109/VR.2019.8798251", "10.1109/VR.2019.8797989", "10.1109/VR.2019.8798300", "10.1109/VR.2019.8798154", "10.1109/TVCG.2020.2973498", "10.1109/ICTC49870.2020.9289448", "10.1007/s00530-018-0592-y", "10.1007/978-3-030-29390-1_19", "10.1016/j.mechmachtheory.2018.07.019", "10.1007/s00371-020-01891-9"], "referencing": ["10.1109/3DUI.2013.6550200", "10.1109/3DUI.2012.6184193", "10.1109/3DUI.2016.7460038", "10.1109/TVCG.2012.43", "10.1109/TVCG.2014.21", "10.1109/TVCG.2009.62", "10.1109/VR.2011.5759455", "10.1109/3DUI.2013.6550200", "10.1109/3DUI.2012.6184193", "10.1109/3DUI.2016.7460038", "10.1109/TVCG.2012.43", "10.1109/TVCG.2014.21", "10.1109/TVCG.2009.62", "10.1109/VR.2011.5759455", "10.1109/3DUI.2013.6550200", "10.1109/3DUI.2012.6184193", "10.1109/3DUI.2016.7460038", "10.1109/TVCG.2012.43", "10.1109/TVCG.2014.21", "10.1109/TVCG.2009.62", "10.1109/VR.2011.5759455", "10.1145/2858036.2858226", "10.1145/2671015.2671026", "10.1145/2821592.2821612", "10.1145/1166087.1166091", "10.1145/2492494.2492514", "10.1145/2858036.2858226", "10.1145/2671015.2671026", "10.1145/2821592.2821612", "10.1145/1166087.1166091", "10.1145/2492494.2492514", "10.1145/2858036.2858226", "10.1145/2671015.2671026", "10.1145/2821592.2821612", "10.1145/1166087.1166091", "10.1145/2492494.2492514", "10.2514/3.21736", "10.1207/s15327108ijap0303_3", "10.2514/2.5085", "10.1162/105474600566989", "10.2514/3.21736", "10.1207/s15327108ijap0303_3", "10.2514/2.5085", "10.1162/105474600566989", "10.2514/3.21736", "10.1207/s15327108ijap0303_3", "10.2514/2.5085", "10.1162/105474600566989"]}, "10.1109/TVCG.2017.2657158": {"doi": "10.1109/TVCG.2017.2657158", "author": ["R. Skarbez", "S. Neyret", "F. P. Brooks", "M. Slater", "M. C. Whitton"], "title": "A Psychophysical Experiment Regarding Components of the Plausibility Illusion", "year": "2017", "abstract": "We report on the design and results of an experiment investigating factors influencing Slater's Plausibility Illusion (Psi) in virtual environments (VEs). Slater proposed Psi and Place Illusion (PI) as orthogonal components of virtual experience which contribute to realistic response in a VE. PI corresponds to the traditional conception of presence as \u201cbeing there,\u201d so there exists a substantial body of previous research relating to PI, but very little relating to Psi. We developed this experiment to investigate the components of plausibility illusion using subjective matching techniques similar to those used in color science. Twenty-one participants each experienced a scenario with the highest level of coherence (the extent to which a scenario matches user expectations and is internally consistent), then in eight different trials chose transitions from lower-coherence to higher-coherence scenarios with the goal of matching the level of Psi they felt in the highest-coherence scenario. At each transition, participants could change one of the following coherence characteristics: the behavior of the other virtual humans in the environment, the behavior of their own body, the physical behavior of objects, or the appearance of the environment. Participants tended to choose improvements to the virtual body before any other improvements. This indicates that having an accurate and well-behaved representation of oneself in the virtual environment is the most important contributing factor to Psi. This study is the first to our knowledge to focus specifically on coherence factors in virtual environments.", "keywords": ["virtual reality", "plausibility illusion", "PI", "subjective matching techniques", "color science", "place illusion", "Psi level matching", "virtual environment", "Coherence", "Virtual environments", "Avatars", "Animation", "Legged locomotion", "Visualization", "Correlation", "Virtual reality", "virtual environments", "presence", "place illusion", "plausibility illusion", "immersion", "coherence", "psychophysics", "user studies"], "referenced_by": ["10.1109/TVCG.2019.2898823", "10.1109/ISMAR.2019.00030", "10.1109/TVCG.2020.2973056", "10.1109/TVCG.2020.2973077", "10.1109/VR46266.2020.00098", "10.1109/TNSRE.2020.2985308", "10.1109/VR46266.2020.00014", "10.1109/ETFA46521.2020.9212039", "10.1145/3134301", "10.1145/3349609", "10.1016/j.cag.2017.11.003", "10.3389/frobt.2018.00074", "10.1007/978-3-319-08234-9_251-1", "10.3389/frobt.2018.00112", "10.3389/frobt.2018.00114", "10.1371/journal.pone.0203358", "10.1108/EJM-10-2017-0733", "10.1007/s10055-019-00400-1", "10.3389/fneur.2020.566731"], "referencing": ["10.1109/MCG.2009.55", "10.1109/MCG.2009.55", "10.1109/MCG.2009.55", "10.1162/105474601300343595", "10.1080/15213269.2015.1015740", "10.1017/S0140525X01000115", "10.2352/ISSN.2470-1173.2016.4.ERVR-418", "10.3389/neuro.08.059.2009", "10.1111/j.1468-2885.2009.01340.x", "10.1098/rstb.2009.0138", "10.1162/105474600566989", "10.1162/105474601300343595", "10.1080/15213269.2015.1015740", "10.1017/S0140525X01000115", "10.2352/ISSN.2470-1173.2016.4.ERVR-418", "10.3389/neuro.08.059.2009", "10.1111/j.1468-2885.2009.01340.x", "10.1098/rstb.2009.0138", "10.1162/105474600566989", "10.1162/105474601300343595", "10.1080/15213269.2015.1015740", "10.1017/S0140525X01000115", "10.2352/ISSN.2470-1173.2016.4.ERVR-418", "10.3389/neuro.08.059.2009", "10.1111/j.1468-2885.2009.01340.x", "10.1098/rstb.2009.0138", "10.1162/105474600566989"]}, "10.1109/TVCG.2017.2657178": {"doi": "10.1109/TVCG.2017.2657178", "author": ["T. Rhee", "L. Petikam", "B. Allen", "A. Chalmers"], "title": "MR360: Mixed Reality Rendering for 360\u00b0 Panoramic Videos", "year": "2017", "abstract": "This paper presents a novel immersive system called MR360 that provides interactive mixed reality (MR) experiences using a conventional low dynamic range (LDR) 360\u00b0 panoramic video (360-video) shown in head mounted displays (HMDs). MR360 seamlessly composites 3D virtual objects into a live 360-video using the input panoramic video as the lighting source to illuminate the virtual objects. Image based lighting (IBL) is perceptually optimized to provide fast and believable results using the LDR 360-video as the lighting source. Regions of most salient lights in the input panoramic video are detected to optimize the number of lights used to cast perceptible shadows. Then, the areas of the detected lights adjust the penumbra of the shadow to provide realistic soft shadows. Finally, our real-time differential rendering synthesizes illumination of the virtual 3D objects into the 360-video. MR360 provides the illusion of interacting with objects in a video, which are actually 3D virtual objects seamlessly composited into the background of the 360-video. MR360 was implemented in a commercial game engine and tested using various 360-videos. Since our MR360 pipeline does not require any pre-computation, it can synthesize an interactive MR scene using a live 360-video stream while providing realistic high performance rendering suitable for HMDs.", "keywords": ["computer games", "helmet mounted displays", "interactive systems", "rendering (computer graphics)", "MR360", "mixed reality rendering", "immersive system", "interactive mixed reality", "low dynamic range 360\u00b0 panoramic video", "head mounted displays", "3D virtual objects", "lighting source", "image based lighting", "LDR 360-video", "real-time differential rendering", "illumination", "commercial game engine", "HMD", "Rendering (computer graphics)", "Videos", "Virtual reality", "Lighting", "Real-time systems", "Three-dimensional displays", "Visualization", "Mixed reality rendering", "image based lighting", "image based shadowing", "360\u00b0 panoramic video"], "referenced_by": ["10.1109/ISMAR.2017.25", "10.1109/ICCV.2017.484", "10.1109/VR.2018.8446391", "10.1109/ICPR.2018.8545663", "10.1109/VR.2019.8798261", "10.1109/VR.2019.8798067", "10.1109/VR.2019.8798226", "10.1109/VR.2019.8798002", "10.1109/EUROCON.2019.8861587", "10.1109/ISMAR.2019.00-24", "10.1109/ISMAR.2019.00-25", "10.1109/JSTSP.2019.2957952", "10.1109/SoutheastCon42311.2019.9020588", "10.1109/TVCG.2020.2973065", "10.1109/VRW50115.2020.00177", "10.1109/ICMEW46912.2020.9105984", "10.1109/TVCG.2019.2894627", "10.1109/ISMAR50242.2020.00040", "10.1109/IVCNZ51579.2020.9290734", "10.4236/jcc.2018.61020", "10.1117/12.2281021", "10.1155/2018/2306031", "10.1016/j.procs.2018.10.062", "10.1111/cgf.13564", "10.1007/s11596-019-1992-8", "10.1007/978-3-030-22514-8_1", "10.1007/978-3-030-25999-0_16", "10.1111/cgf.13857", "10.1007/s41095-020-0162-z", "10.1002/rcs.2120", "10.1007/978-3-662-61983-4_2", "10.1007/s11554-020-01022-6", "10.1007/978-3-030-59990-4_8", "10.1515/icom-2020-0014", "10.3390/electronics9101623", "10.3390/app10238679", "10.1049/ipr2.12111"], "referencing": ["10.1109/38.988744", "10.1109/ISMAR.2013.6671772", "10.1109/MCG.1986.276658", "10.1109/VR.2014.6802044", "10.1109/VR.2015.7223334", "10.1109/ISMAR.2012.6402546", "10.1109/ISMAR.2010.5643556", "10.1109/ISMAR.2011.6092378", "10.1109/38.988744", "10.1109/ISMAR.2013.6671772", "10.1109/MCG.1986.276658", "10.1109/VR.2014.6802044", "10.1109/VR.2015.7223334", "10.1109/ISMAR.2012.6402546", "10.1109/ISMAR.2010.5643556", "10.1109/ISMAR.2011.6092378", "10.1109/38.988744", "10.1109/ISMAR.2013.6671772", "10.1109/MCG.1986.276658", "10.1109/VR.2014.6802044", "10.1109/VR.2015.7223334", "10.1109/ISMAR.2012.6402546", "10.1109/ISMAR.2010.5643556", "10.1109/ISMAR.2011.6092378", "10.1145/1276377.1276425", "10.1145/1531326.1531349", "10.1145/218380.218395", "10.1145/166117.166153", "10.1145/280814.280864", "10.1145/1185657.1185688", "10.1145/218380.218398", "10.1145/882262.882280", "10.1145/1186562.1015749", "10.1145/383259.383317", "10.1145/566654.566611", "10.1145/566654.566612", "10.1145/258734.258861", "10.1145/1599301.1599393", "10.1145/1276377.1276425", "10.1145/1531326.1531349", "10.1145/218380.218395", "10.1145/166117.166153", "10.1145/280814.280864", "10.1145/1185657.1185688", "10.1145/218380.218398", "10.1145/882262.882280", "10.1145/1186562.1015749", "10.1145/383259.383317", "10.1145/566654.566611", "10.1145/566654.566612", "10.1145/258734.258861", "10.1145/1599301.1599393", "10.1145/1276377.1276425", "10.1145/1531326.1531349", "10.1145/218380.218395", "10.1145/166117.166153", "10.1145/280814.280864", "10.1145/1185657.1185688", "10.1145/218380.218398", "10.1145/882262.882280", "10.1145/1186562.1015749", "10.1145/383259.383317", "10.1145/566654.566611", "10.1145/566654.566612", "10.1145/258734.258861", "10.1145/1599301.1599393", "10.1111/cgf.12591", "10.1007/978-3-319-13969-2_19", "10.1111/cgf.12541", "10.1364/JOSAA.18.002448", "10.1111/cgf.12591", "10.1007/978-3-319-13969-2_19", "10.1111/cgf.12541", "10.1364/JOSAA.18.002448", "10.1111/cgf.12591", "10.1007/978-3-319-13969-2_19", "10.1111/cgf.12541", "10.1364/JOSAA.18.002448"]}, "10.1109/TVCG.2017.2657220": {"doi": "10.1109/TVCG.2017.2657220", "author": ["E. Langbehn", "P. Lubos", "G. Bruder", "F. Steinicke"], "title": "Bending the Curve: Sensitivity to Bending of Curved Paths and Application in Room-Scale VR", "year": "2017", "abstract": "Redirected walking (RDW) promises to allow near-natural walking in an infinitely large virtual environment (VE) by subtle manipulations of the virtual camera. Previous experiments analyzed the human sensitivity to RDW manipulations by focusing on the worst-case scenario, in which users walk perfectly straight ahead in the VE, whereas they are redirected on a circular path in the real world. The results showed that a physical radius of at least 22 meters is required for undetectable RDW. However, users do not always walk exactly straight in a VE. So far, it has not been investigated how much a physical path can be bent in situations in which users walk a virtual curved path instead of a straight one. Such curved walking paths can be often observed, for example, when users walk on virtual trails, through bent corridors, or when circling around obstacles. In such situations the question is not, whether or not the physical path can be bent, but how much the bending of the physical path may vary from the bending of the virtual path. In this article, we analyze this question and present redirection by means of bending gains that describe the discrepancy between the bending of curved paths in the real and virtual environment. Furthermore, we report the psychophysical experiments in which we analyzed the human sensitivity to these gains. The results reveal encouragingly wider detection thresholds than for straightforward walking. Based on our findings, we discuss the potential of curved walking and present a first approach to leverage bent paths in a way that can provide undetectable RDW manipulations even in room-scale VR.", "keywords": ["cameras", "gait analysis", "virtual reality", "curved walking path", "virtual reality", "VR", "redirected walking", "RDW manipulation", "near-natural walking", "virtual environment", "VE", "virtual camera", "human sensitivity", "worst-case scenario", "Legged locomotion", "Sensitivity", "Virtual environments", "Cameras", "Visualization", "Space vehicles", "Human computer interaction", "Virtual reality", "redirected walking", "room-scale", "bending gains"], "referenced_by": ["10.1109/TVCG.2018.2793679", "10.1109/VR.2017.7892373", "10.1109/MCG.2018.111125628", "10.1109/VR.2018.8446521", "10.1109/VR.2018.8446216", "10.1109/VR.2018.8446587", "10.1109/VR.2018.8446167", "10.1109/VR.2018.8446479", "10.1109/VR.2018.8446062", "10.1109/VR.2018.8446263", "10.1109/VR.2018.8448288", "10.1109/ISMAR.2018.00041", "10.1109/TVCG.2019.2899228", "10.1109/VR.2019.8798248", "10.1109/VR.2019.8798121", "10.1109/WEVR.2019.8809587", "10.1109/ACCESS.2019.2937937", "10.1109/TVCG.2020.2973498", "10.1109/TVCG.2018.2887379", "10.1109/VR46266.2020.00032", "10.1109/VR46266.2020.00035", "10.1109/VRW50115.2020.00032", "10.1109/VR46266.2020.00034", "10.1109/VR46266.2020.00082", "10.1109/VR46266.2020.00028", "10.1109/ISMAR-Adjunct51615.2020.00059", "10.1145/3197517.3201335", "10.1145/3131277.3132177", "10.1145/3345554", "10.1145/3414685.3417773", "10.1007/978-3-319-08234-9_253-1", "10.1038/s41598-018-36035-6", "10.1017/dsi.2019.195", "10.1007/978-3-030-29390-1_19", "10.3389/frvir.2020.598282"], "referencing": ["10.1109/WEVR.2016.7859537", "10.1109/VR.2002.996544", "10.1109/TVCG.2012.55", "10.1109/TVCG.2015.2391864", "10.1109/3DUI.2009.4811208", "10.1109/TVCG.2013.28", "10.1109/TVCG.2014.34", "10.1109/38.799737", "10.1109/MCG.2005.5", "10.1109/TVCG.2011.275", "10.1109/VR.2016.7504752", "10.1109/TVCG.2009.62", "10.1109/VR.2012.6180877", "10.1109/TVCG.2012.47", "10.1109/TVCG.2013.88", "10.1109/WEVR.2016.7859537", "10.1109/VR.2002.996544", "10.1109/TVCG.2012.55", "10.1109/TVCG.2015.2391864", "10.1109/3DUI.2009.4811208", "10.1109/TVCG.2013.28", "10.1109/TVCG.2014.34", "10.1109/38.799737", "10.1109/MCG.2005.5", "10.1109/TVCG.2011.275", "10.1109/VR.2016.7504752", "10.1109/TVCG.2009.62", "10.1109/VR.2012.6180877", "10.1109/TVCG.2012.47", "10.1109/TVCG.2013.88", "10.1109/WEVR.2016.7859537", "10.1109/VR.2002.996544", "10.1109/TVCG.2012.55", "10.1109/TVCG.2015.2391864", "10.1109/3DUI.2009.4811208", "10.1109/TVCG.2013.28", "10.1109/TVCG.2014.34", "10.1109/38.799737", "10.1109/MCG.2005.5", "10.1109/TVCG.2011.275", "10.1109/VR.2016.7504752", "10.1109/TVCG.2009.62", "10.1109/VR.2012.6180877", "10.1109/TVCG.2012.47", "10.1109/TVCG.2013.88", "10.1145/1242073.1242098", "10.1145/2043603.2043604", "10.1145/1179133.1179162", "10.1145/2993369.2993379", "10.1145/2929464.2929482", "10.1145/1502800.1502805", "10.1145/210079.210084", "10.1145/311535.311589", "10.1145/2804408.2814180", "10.1145/1242073.1242098", "10.1145/2043603.2043604", "10.1145/1179133.1179162", "10.1145/2993369.2993379", "10.1145/2929464.2929482", "10.1145/1502800.1502805", "10.1145/210079.210084", "10.1145/311535.311589", "10.1145/2804408.2814180", "10.1145/1242073.1242098", "10.1145/2043603.2043604", "10.1145/1179133.1179162", "10.1145/2993369.2993379", "10.1145/2929464.2929482", "10.1145/1502800.1502805", "10.1145/210079.210084", "10.1145/311535.311589", "10.1145/2804408.2814180", "10.1016/S0042-6989(00)00134-6", "10.1007/978-3-642-46354-9_25", "10.1007/11590323_5", "10.3758/BF03194552", "10.1016/S1364-6613(99)01364-9", "10.1007/978-3-319-39516-6_4", "10.1007/978-3-540-73107-8_102", "10.1007/978-1-4419-8432-6", "10.1007/s002210050411", "10.1016/S0042-6989(00)00134-6", "10.1007/978-3-642-46354-9_25", "10.1007/11590323_5", "10.3758/BF03194552", "10.1016/S1364-6613(99)01364-9", "10.1007/978-3-319-39516-6_4", "10.1007/978-3-540-73107-8_102", "10.1007/978-1-4419-8432-6", "10.1007/s002210050411", "10.1016/S0042-6989(00)00134-6", "10.1007/978-3-642-46354-9_25", "10.1007/11590323_5", "10.3758/BF03194552", "10.1016/S1364-6613(99)01364-9", "10.1007/978-3-319-39516-6_4", "10.1007/978-3-540-73107-8_102", "10.1007/978-1-4419-8432-6", "10.1007/s002210050411"]}, "10.1109/TVCG.2017.2657235": {"doi": "10.1109/TVCG.2017.2657235", "author": ["T. Ye", "S. Qi", "J. Kubricht", "Y. Zhu", "H. Lu", "S. Zhu"], "title": "The Martian: Examining Human Physical Judgments across Virtual Gravity Fields", "year": "2017", "abstract": "This paper examines how humans adapt to novel physical situations with unknown gravitational acceleration in immersive virtual environments. We designed four virtual reality experiments with different tasks for participants to complete: strike a ball to hit a target, trigger a ball to hit a target, predict the landing location of a projectile, and estimate the flight duration of a projectile. The first two experiments compared human behavior in the virtual environment with real-world performance reported in the literature. The last two experiments aimed to test the human ability to adapt to novel gravity fields by measuring their performance in trajectory prediction and time estimation tasks. The experiment results show that: 1) based on brief observation of a projectile's initial trajectory, humans are accurate at predicting the landing location even under novel gravity fields, and 2) humans' time estimation in a familiar earth environment fluctuates around the ground truth flight duration, although the time estimation in unknown gravity fields indicates a bias toward earth's gravity.", "keywords": ["human computer interaction", "virtual reality", "virtual gravity fields", "human physical judgments", "gravitational acceleration", "immersive virtual environments", "virtual reality", "Gravity", "Virtual environments", "Trajectory", "Earth", "Cognition", "Acceleration", "Virtual reality", "intuitive physics", "mental simulation"], "referenced_by": ["10.1109/VR.2018.8448287", "10.1109/ICRA.2019.8794230", "10.1177/0031512519857869", "10.1016/j.copsyc.2020.04.010"], "referencing": ["10.1109/TVCG.2014.22", "10.1109/TVCG.2016.2518137", "10.1109/TVCG.2014.22", "10.1109/TVCG.2016.2518137", "10.1109/TVCG.2014.22", "10.1109/TVCG.2016.2518137", "10.1145/2671015.2671026", "10.1145/2992138.2992144", "10.1145/2398356.2398381", "10.1145/2671015.2671026", "10.1145/2992138.2992144", "10.1145/2398356.2398381", "10.1145/2671015.2671026", "10.1145/2992138.2992144", "10.1145/2398356.2398381", "10.1073/pnas.1306572110", "10.1119/1.12989", "10.1037/a0027805", "10.1016/j.cub.2014.06.046", "10.1037/0096-1523.15.2.372", "10.1016/0166-2236(92)90344-8", "10.1037/0278-7393.18.5.1084", "10.1016/j.tics.2004.04.001", "10.3758/BF03200867", "10.3758/BF03202508", "10.1037/0278-7393.11.1-4.795", "10.1037/0096-1523.18.3.669", "10.1037/0278-7393.19.4.952", "10.1038/scientificamerican0483-122", "10.1126/science.210.4474.1139", "10.1037/0278-7393.9.4.636", "10.1111/j.1745-6916.2006.00008.x", "10.1037/0033-295X.107.3.525", "10.1037/a0031912", "10.1006/cogp.1996.0006", "10.1037/0278-7393.25.1.116", "10.1068/p050241", "10.1119/1.4938057", "10.1016/j.neuron.2006.08.006", "10.1068/p110325", "10.1037/0096-1523.31.5.880", "10.1016/0010-0277(88)90026-1", "10.3758/s13414-013-0473-6", "10.1073/pnas.1306572110", "10.1119/1.12989", "10.1037/a0027805", "10.1016/j.cub.2014.06.046", "10.1037/0096-1523.15.2.372", "10.1016/0166-2236(92)90344-8", "10.1037/0278-7393.18.5.1084", "10.1016/j.tics.2004.04.001", "10.3758/BF03200867", "10.3758/BF03202508", "10.1037/0278-7393.11.1-4.795", "10.1037/0096-1523.18.3.669", "10.1037/0278-7393.19.4.952", "10.1038/scientificamerican0483-122", "10.1126/science.210.4474.1139", "10.1037/0278-7393.9.4.636", "10.1111/j.1745-6916.2006.00008.x", "10.1037/0033-295X.107.3.525", "10.1037/a0031912", "10.1006/cogp.1996.0006", "10.1037/0278-7393.25.1.116", "10.1068/p050241", "10.1119/1.4938057", "10.1016/j.neuron.2006.08.006", "10.1068/p110325", "10.1037/0096-1523.31.5.880", "10.1016/0010-0277(88)90026-1", "10.3758/s13414-013-0473-6", "10.1073/pnas.1306572110", "10.1119/1.12989", "10.1037/a0027805", "10.1016/j.cub.2014.06.046", "10.1037/0096-1523.15.2.372", "10.1016/0166-2236(92)90344-8", "10.1037/0278-7393.18.5.1084", "10.1016/j.tics.2004.04.001", "10.3758/BF03200867", "10.3758/BF03202508", "10.1037/0278-7393.11.1-4.795", "10.1037/0096-1523.18.3.669", "10.1037/0278-7393.19.4.952", "10.1038/scientificamerican0483-122", "10.1126/science.210.4474.1139", "10.1037/0278-7393.9.4.636", "10.1111/j.1745-6916.2006.00008.x", "10.1037/0033-295X.107.3.525", "10.1037/a0031912", "10.1006/cogp.1996.0006", "10.1037/0278-7393.25.1.116", "10.1068/p050241", "10.1119/1.4938057", "10.1016/j.neuron.2006.08.006", "10.1068/p110325", "10.1037/0096-1523.31.5.880", "10.1016/0010-0277(88)90026-1", "10.3758/s13414-013-0473-6"]}, "10.1109/TVCG.2017.2657238": {"doi": "10.1109/TVCG.2017.2657238", "author": ["V. A. de Jesus Oliveira", "L. Brayda", "L. Nedel", "A. Maciel"], "title": "Designing a Vibrotactile Head-Mounted Display for Spatial Awareness in 3D Spaces", "year": "2017", "abstract": "Due to the perceptual characteristics of the head, vibrotactile Head-mounted Displays are built with low actuator density. Therefore, vibrotactile guidance is mostly assessed by pointing towards objects in the azimuthal plane. When it comes to multisensory interaction in 3D environments, it is also important to convey information about objects in the elevation plane. In this paper, we design and assess a haptic guidance technique for 3D environments. First, we explore the modulation of vibration frequency to indicate the position of objects in the elevation plane. Then, we assessed a vibrotactile HMD made to render the position of objects in a 3D space around the subject by varying both stimulus loci and vibration frequency. Results have shown that frequencies modulated with a quadratic growth function allowed a more accurate, precise, and faster target localization in an active head pointing task. The technique presented high usability and a strong learning effect for a haptic search across different scenarios in an immersive VR setup.", "keywords": ["haptic interfaces", "helmet mounted displays", "human computer interaction", "vibrations", "virtual reality", "vibrotactile head-mounted display", "3D spaces spatial awareness", "haptic guidance technique", "vibration frequency modulation", "HMD", "stimulus loci", "quadratic growth function", "target localization", "usability", "immersive VR setup", "Three-dimensional displays", "Frequency modulation", "Vibrations", "Azimuthal plane", "Haptic interfaces", "Visualization", "Skin", "Vibrotactile head-mounted display", "haptic interaction", "spatial awereness", "3D environments"], "referenced_by": ["10.1109/CompComm.2017.8322599", "10.1109/AMC.2019.8371091", "10.1109/IoT-SIU.2018.8519919", "10.1109/VR.2019.8798036", "10.1109/ACCESS.2019.2937937", "10.1109/TOH.2019.2925799", "10.1109/ISMAR.2019.000-3", "10.1109/TVCG.2020.2973441", "10.1109/TVCG.2020.3023607", "10.1109/TVCG.2020.3023605", "10.1145/3267782.3267789", "10.1145/3266037.3271634", "10.1007/s41133-017-0008-0", "10.3390/mi8090270", "10.1016/j.cag.2018.07.007", "10.1007/978-3-030-01388-2_3", "10.1016/j.cag.2019.10.005", "10.1016/j.vrih.2020.05.005", "10.1108/SR-04-2020-0097", "10.1080/01691864.2020.1854114"], "referencing": ["10.1109/TSMCC.2009.2021255", "10.1109/TBME.2012.2196433", "10.1109/ICMI.2002.1167035", "10.1109/M-RA.2007.907921", "10.1109/M-RA.2007.914919", "10.1109/WHC.2005.68", "10.1109/TOH.2012.51", "10.1109/TSMCC.2009.2021255", "10.1109/TBME.2012.2196433", "10.1109/ICMI.2002.1167035", "10.1109/M-RA.2007.907921", "10.1109/M-RA.2007.914919", "10.1109/WHC.2005.68", "10.1109/TOH.2012.51", "10.1109/TSMCC.2009.2021255", "10.1109/TBME.2012.2196433", "10.1109/ICMI.2002.1167035", "10.1109/M-RA.2007.907921", "10.1109/M-RA.2007.914919", "10.1109/WHC.2005.68", "10.1109/TOH.2012.51", "10.1145/1979742.1979857", "10.1145/2851581.2892292", "10.1145/2851581.2892355", "10.1145/2957265.2965022", "10.1145/1400885.1401026", "10.1145/1518701.1518946", "10.1145/1060581.1060585", "10.1145/1979742.1979857", "10.1145/2851581.2892292", "10.1145/2851581.2892355", "10.1145/2957265.2965022", "10.1145/1400885.1401026", "10.1145/1518701.1518946", "10.1145/1060581.1060585", "10.1145/1979742.1979857", "10.1145/2851581.2892292", "10.1145/2851581.2892355", "10.1145/2957265.2965022", "10.1145/1400885.1401026", "10.1145/1518701.1518946", "10.1145/1060581.1060585", "10.1016/j.neuropsychologia.2009.03.014", "10.1016/j.ijhcs.2007.11.002", "10.3758/BF03194989", "10.1177/154193120605000909", "10.1518/001872008X250638", "10.1007/978-3-662-44196-1_8", "10.21236/ADA519112", "10.1007/s10055-015-0267-3", "10.1007/3-540-44589-7_18", "10.1177/1541931213601363", "10.1016/j.neuropsychologia.2009.03.014", "10.1016/j.ijhcs.2007.11.002", "10.3758/BF03194989", "10.1177/154193120605000909", "10.1518/001872008X250638", "10.1007/978-3-662-44196-1_8", "10.21236/ADA519112", "10.1007/s10055-015-0267-3", "10.1007/3-540-44589-7_18", "10.1177/1541931213601363", "10.1016/j.neuropsychologia.2009.03.014", "10.1016/j.ijhcs.2007.11.002", "10.3758/BF03194989", "10.1177/154193120605000909", "10.1518/001872008X250638", "10.1007/978-3-662-44196-1_8", "10.21236/ADA519112", "10.1007/s10055-015-0267-3", "10.1007/3-540-44589-7_18", "10.1177/1541931213601363"]}, "10.1109/TVCG.2017.2657239": {"doi": "10.1109/TVCG.2017.2657239", "author": ["L. J. Gerry"], "title": "Paint with Me: Stimulating Creativity and Empathy While Painting with a Painter in Virtual Reality", "year": "2017", "abstract": "While nothing can be more vivid, immediate and real than our own sensorial experiences, emerging virtual reality technologies are playing with the possibility of being able to share someone else's sensory reality. The Painter Project is a virtual environment where users see a video from a painter's point of view in tandem with a tracked rendering of their own hand while they paint on a physical canvas. The end result is an experiment in superimposition of one experiential reality on top of another, hopefully opening a new window into an artist's creative process. This explorative study tested this virtual environment on stimulating empathy and creativity. The findings indicate potential for this technology as a new expert-novice mentorship simulation.", "keywords": ["art", "rendering (computer graphics)", "virtual reality", "creativity", "empathy", "painting", "virtual reality", "virtual environment", "rendering", "expert-novice mentorship simulation", "Avatars", "Virtual environments", "Solid modeling", "Rubber", "Paints", "Creativity", "Embodied simulations", "virtual environments", "mixed reality", "creativity", "empathy", "painting"], "referenced_by": ["10.1109/VRW50115.2020.00209"], "referencing": ["10.1109/TVCG.2013.32", "10.1109/TVCG.2013.32", "10.1109/TVCG.2013.32", "10.1080/15213269.2012.755877", "10.1037/0022-3514.63.4.596", "10.1037/0022-3514.73.2.345", "10.1038/35784", "10.1037/0022-3514.76.6.893", "10.1100/tsw.2006.221", "10.1016/j.chb.2014.12.035", "10.1126/science.175.4028.1382", "10.1080/15534510802643750", "10.1111/j.1467-6494.1993.tb00783.x", "10.1162/pres.15.4.455", "10.1098/rstb.2015.0083", "10.1016/j.tics.2014.11.001", "10.1038/srep13899", "10.1016/j.concog.2013.04.016", "10.1371/journal.pone.0003832", "10.1037/0096-1523.31.1.62", "10.1038/scientificamerican1106-54", "10.1007/s11097-011-9243-x", "10.1111/jcc4.12107", "10.1111/j.1468-2958.2007.00299.x", "10.1177/0093650208330254", "10.1080/15213269.2012.755877", "10.1037/0022-3514.63.4.596", "10.1037/0022-3514.73.2.345", "10.1038/35784", "10.1037/0022-3514.76.6.893", "10.1100/tsw.2006.221", "10.1016/j.chb.2014.12.035", "10.1126/science.175.4028.1382", "10.1080/15534510802643750", "10.1111/j.1467-6494.1993.tb00783.x", "10.1162/pres.15.4.455", "10.1098/rstb.2015.0083", "10.1016/j.tics.2014.11.001", "10.1038/srep13899", "10.1016/j.concog.2013.04.016", "10.1371/journal.pone.0003832", "10.1037/0096-1523.31.1.62", "10.1038/scientificamerican1106-54", "10.1007/s11097-011-9243-x", "10.1111/jcc4.12107", "10.1111/j.1468-2958.2007.00299.x", "10.1177/0093650208330254", "10.1080/15213269.2012.755877", "10.1037/0022-3514.63.4.596", "10.1037/0022-3514.73.2.345", "10.1038/35784", "10.1037/0022-3514.76.6.893", "10.1100/tsw.2006.221", "10.1016/j.chb.2014.12.035", "10.1126/science.175.4028.1382", "10.1080/15534510802643750", "10.1111/j.1467-6494.1993.tb00783.x", "10.1162/pres.15.4.455", "10.1098/rstb.2015.0083", "10.1016/j.tics.2014.11.001", "10.1038/srep13899", "10.1016/j.concog.2013.04.016", "10.1371/journal.pone.0003832", "10.1037/0096-1523.31.1.62", "10.1038/scientificamerican1106-54", "10.1007/s11097-011-9243-x", "10.1111/jcc4.12107", "10.1111/j.1468-2958.2007.00299.x", "10.1177/0093650208330254"]}, "10.1109/TVCG.2017.2658900": {"doi": "10.1109/TVCG.2017.2658900", "author": [""], "title": "Author Index", "year": "2017", "abstract": "Presents the author index for papers presented in this issue of the publication.", "keywords": [""], "referenced_by": [], "referencing": []}}