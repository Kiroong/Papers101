{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import os\n",
    "import nltk\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-18.bib\n",
      "papers-19.bib\n",
      "papers-09.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-08.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-90.bib\n",
      "papers-85.bib\n",
      "papers-91.bib\n",
      "papers-87.bib\n",
      "papers-93.bib\n",
      "papers-92.bib\n",
      "papers-86.bib\n",
      "papers-82.bib\n",
      "papers-96.bib\n",
      "papers-97.bib\n",
      "papers-83.bib\n",
      "papers-95.bib\n",
      "papers-81.bib\n",
      "papers-94.bib\n",
      "papers-99.bib\n",
      "papers-98.bib\n",
      "papers-88.bib\n",
      "papers-89.bib\n",
      "papers-11.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-05.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-04.bib\n",
      "papers-10.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-06.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-12.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-13.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-07.bib\n",
      "papers-03.bib\n",
      "papers-17.bib\n",
      "papers-16.bib\n",
      "papers-02.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-14.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers-00.bib\n",
      "papers-01.bib\n",
      "papers-15.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type dataset not standard. Not considered.\n"
     ]
    }
   ],
   "source": [
    "bib_database = []\n",
    "for filename in os.listdir(os.getcwd()+'/bibs'):\n",
    "    if '.bib' in filename:\n",
    "        print(filename)\n",
    "        with open('bibs/'+filename) as file:\n",
    "            bib_database.append(bibtexparser.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bib_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_entries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in bib_database:\n",
    "    for entry in db.entries:\n",
    "        db_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8412"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(db_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.abstract = df.abstract.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_papers = 0\n",
    "# abstracts_by_year = []\n",
    "\n",
    "# for i in range(len(bib_database)):\n",
    "#     abstracts=[]\n",
    "#     for j in range(len(bib_database[i].entries)):\n",
    "#         if 'abstract' in bib_database[i].entries[j]:\n",
    "#             abstracts.append(bib_database[i].entries[j]['abstract'])\n",
    "#     if len(abstracts) >= 1:\n",
    "#         abstracts_by_year.append(abstracts)\n",
    "# #             print(bib_database[i].entries[j]['abstract'])\n",
    "#     #         bib_database[i].entries[j]['abstract']\n",
    "# #         break\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(abstracts_by_year[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       news media, cybersecurity, usable privacy and ...\n",
       "1       sensing, material recognition, deep learning, ...\n",
       "2                                                     NaN\n",
       "3       sustainability, smart homes, domestic, desider...\n",
       "4                                                     NaN\n",
       "                              ...                        \n",
       "8407    trackpad, clutching, performance, pointing, to...\n",
       "8408    eye-tracking, interaction science, menus, visu...\n",
       "8409    creativity, color picker, generative design, c...\n",
       "8410    eye movements, interaction science, reinforcem...\n",
       "8411    selective undo, creativity support, bitmap editor\n",
       "Name: keywords, Length: 6914, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-196-294b32cb5b2d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Token_abstract'] = df['abstract'].apply(nltk_tokenizer)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>location</th>\n",
       "      <th>keywords</th>\n",
       "      <th>numpages</th>\n",
       "      <th>pages</th>\n",
       "      <th>booktitle</th>\n",
       "      <th>abstract</th>\n",
       "      <th>doi</th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>...</th>\n",
       "      <th>author</th>\n",
       "      <th>ENTRYTYPE</th>\n",
       "      <th>ID</th>\n",
       "      <th>month</th>\n",
       "      <th>journal</th>\n",
       "      <th>issn</th>\n",
       "      <th>number</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue_date</th>\n",
       "      <th>Token_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHI '18</td>\n",
       "      <td>Montreal QC, Canada</td>\n",
       "      <td>news media, cybersecurity, usable privacy and ...</td>\n",
       "      <td>12</td>\n",
       "      <td>1–12</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>News coverage of security and privacy (S&amp;amp;P...</td>\n",
       "      <td>10.1145/3173574.3173575</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173575</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Das, Sauvik and Lo, Joanne and Dabbish, Laura ...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/3173574.3173575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[news, coverage, security, privacy, amp, p, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHI '18</td>\n",
       "      <td>Montreal QC, Canada</td>\n",
       "      <td>sensing, material recognition, deep learning, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>1–13</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>We introduce Deep Thermal Imaging, a new appro...</td>\n",
       "      <td>10.1145/3173574.3173576</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173576</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Cho, Youngjun and Bianchi-Berthouze, Nadia and...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/3173574.3173576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[introduce, deep, thermal, imaging, new, appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1–13</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>Many conversational agents (CAs) are developed...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173577</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Liao, Q. Vera and Mas-ud Hussain, Muhammed and...</td>\n",
       "      <td>inbook</td>\n",
       "      <td>10.1145/3173574.3173577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[many, conversational, agents, cas, developed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHI '18</td>\n",
       "      <td>Montreal QC, Canada</td>\n",
       "      <td>sustainability, smart homes, domestic, desider...</td>\n",
       "      <td>14</td>\n",
       "      <td>1–14</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>Research has shown that desirable designs shap...</td>\n",
       "      <td>10.1145/3173574.3173578</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173578</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Jensen, Rikke Hagensby and Strengers, Yolande ...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/3173574.3173578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[research, shown, desirable, designs, shape, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1–11</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>As the material becomes active in disclosing t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173579</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Barati, Bahareh and Giaccardi, Elisa and Karan...</td>\n",
       "      <td>inbook</td>\n",
       "      <td>10.1145/3173574.3173579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[material, becomes, active, disclosing, fullne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    series             location  \\\n",
       "0  CHI '18  Montreal QC, Canada   \n",
       "1  CHI '18  Montreal QC, Canada   \n",
       "2      NaN                  NaN   \n",
       "3  CHI '18  Montreal QC, Canada   \n",
       "4      NaN                  NaN   \n",
       "\n",
       "                                            keywords numpages pages  \\\n",
       "0  news media, cybersecurity, usable privacy and ...       12  1–12   \n",
       "1  sensing, material recognition, deep learning, ...       13  1–13   \n",
       "2                                                NaN       13  1–13   \n",
       "3  sustainability, smart homes, domestic, desider...       14  1–14   \n",
       "4                                                NaN       11  1–11   \n",
       "\n",
       "                                           booktitle  \\\n",
       "0  Proceedings of the 2018 CHI Conference on Huma...   \n",
       "1  Proceedings of the 2018 CHI Conference on Huma...   \n",
       "2  Proceedings of the 2018 CHI Conference on Huma...   \n",
       "3  Proceedings of the 2018 CHI Conference on Huma...   \n",
       "4  Proceedings of the 2018 CHI Conference on Huma...   \n",
       "\n",
       "                                            abstract                      doi  \\\n",
       "0  News coverage of security and privacy (S&amp;P...  10.1145/3173574.3173575   \n",
       "1  We introduce Deep Thermal Imaging, a new appro...  10.1145/3173574.3173576   \n",
       "2  Many conversational agents (CAs) are developed...                      NaN   \n",
       "3  Research has shown that desirable designs shap...  10.1145/3173574.3173578   \n",
       "4  As the material becomes active in disclosing t...                      NaN   \n",
       "\n",
       "                                       url            address  ...  \\\n",
       "0  https://doi.org/10.1145/3173574.3173575  New York, NY, USA  ...   \n",
       "1  https://doi.org/10.1145/3173574.3173576  New York, NY, USA  ...   \n",
       "2  https://doi.org/10.1145/3173574.3173577  New York, NY, USA  ...   \n",
       "3  https://doi.org/10.1145/3173574.3173578  New York, NY, USA  ...   \n",
       "4  https://doi.org/10.1145/3173574.3173579  New York, NY, USA  ...   \n",
       "\n",
       "                                              author      ENTRYTYPE  \\\n",
       "0  Das, Sauvik and Lo, Joanne and Dabbish, Laura ...  inproceedings   \n",
       "1  Cho, Youngjun and Bianchi-Berthouze, Nadia and...  inproceedings   \n",
       "2  Liao, Q. Vera and Mas-ud Hussain, Muhammed and...         inbook   \n",
       "3  Jensen, Rikke Hagensby and Strengers, Yolande ...  inproceedings   \n",
       "4  Barati, Bahareh and Giaccardi, Elisa and Karan...         inbook   \n",
       "\n",
       "                        ID month journal issn number volume issue_date  \\\n",
       "0  10.1145/3173574.3173575   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "1  10.1145/3173574.3173576   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "2  10.1145/3173574.3173577   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "3  10.1145/3173574.3173578   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "4  10.1145/3173574.3173579   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "\n",
       "                                      Token_abstract  \n",
       "0  [news, coverage, security, privacy, amp, p, ev...  \n",
       "1  [introduce, deep, thermal, imaging, new, appro...  \n",
       "2  [many, conversational, agents, cas, developed,...  \n",
       "3  [research, shown, desirable, designs, shape, u...  \n",
       "4  [material, becomes, active, disclosing, fullne...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nltk_tokenizer(_wd):\n",
    "    tokenized = RegexpTokenizer(r'\\w+').tokenize(_wd.lower())\n",
    "    return [w for w in tokenized if not w in stop_words]\n",
    "\n",
    "df['Token_abstract'] = df['abstract'].apply(nltk_tokenizer)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.abstract = df.abstract.fillna(\"\")\n",
    "df = df[df.abstract != \"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "series                                                      CHI '17\n",
       "location                                      Denver, Colorado, USA\n",
       "keywords          movement-based interaction, movement recogniti...\n",
       "numpages                                                         12\n",
       "pages                                                     4009–4020\n",
       "booktitle         Proceedings of the 2017 CHI Conference on Huma...\n",
       "abstract          Human movement has historically been approache...\n",
       "doi                                         10.1145/3025453.3025530\n",
       "url                         https://doi.org/10.1145/3025453.3025530\n",
       "address                                           New York, NY, USA\n",
       "publisher                       Association for Computing Machinery\n",
       "isbn                                                  9781450346559\n",
       "year                                                           2017\n",
       "title             Seeing, Sensing and Recognizing Laban Movement...\n",
       "author            Fdili Alaoui, Sarah and Fran\\c{c}oise, Jules a...\n",
       "ENTRYTYPE                                             inproceedings\n",
       "ID                                          10.1145/3025453.3025530\n",
       "month                                                           NaN\n",
       "journal                                                         NaN\n",
       "issn                                                            NaN\n",
       "number                                                          NaN\n",
       "volume                                                          NaN\n",
       "issue_date                                                      NaN\n",
       "Token_abstract    [human, movement, historically, approached, fu...\n",
       "Name: 5000, dtype: object"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>location</th>\n",
       "      <th>keywords</th>\n",
       "      <th>numpages</th>\n",
       "      <th>pages</th>\n",
       "      <th>booktitle</th>\n",
       "      <th>abstract</th>\n",
       "      <th>doi</th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>...</th>\n",
       "      <th>author</th>\n",
       "      <th>ENTRYTYPE</th>\n",
       "      <th>ID</th>\n",
       "      <th>month</th>\n",
       "      <th>journal</th>\n",
       "      <th>issn</th>\n",
       "      <th>number</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue_date</th>\n",
       "      <th>Token_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHI '18</td>\n",
       "      <td>Montreal QC, Canada</td>\n",
       "      <td>news media, cybersecurity, usable privacy and ...</td>\n",
       "      <td>12</td>\n",
       "      <td>1–12</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>News coverage of security and privacy (S&amp;amp;P...</td>\n",
       "      <td>10.1145/3173574.3173575</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173575</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Das, Sauvik and Lo, Joanne and Dabbish, Laura ...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/3173574.3173575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[news, coverage, security, privacy, amp, p, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHI '18</td>\n",
       "      <td>Montreal QC, Canada</td>\n",
       "      <td>sensing, material recognition, deep learning, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>1–13</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>We introduce Deep Thermal Imaging, a new appro...</td>\n",
       "      <td>10.1145/3173574.3173576</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173576</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Cho, Youngjun and Bianchi-Berthouze, Nadia and...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/3173574.3173576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[introduce, deep, thermal, imaging, new, appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1–13</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>Many conversational agents (CAs) are developed...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173577</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Liao, Q. Vera and Mas-ud Hussain, Muhammed and...</td>\n",
       "      <td>inbook</td>\n",
       "      <td>10.1145/3173574.3173577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[many, conversational, agents, cas, developed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHI '18</td>\n",
       "      <td>Montreal QC, Canada</td>\n",
       "      <td>sustainability, smart homes, domestic, desider...</td>\n",
       "      <td>14</td>\n",
       "      <td>1–14</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>Research has shown that desirable designs shap...</td>\n",
       "      <td>10.1145/3173574.3173578</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173578</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Jensen, Rikke Hagensby and Strengers, Yolande ...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/3173574.3173578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[research, shown, desirable, designs, shape, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1–11</td>\n",
       "      <td>Proceedings of the 2018 CHI Conference on Huma...</td>\n",
       "      <td>As the material becomes active in disclosing t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1145/3173574.3173579</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Barati, Bahareh and Giaccardi, Elisa and Karan...</td>\n",
       "      <td>inbook</td>\n",
       "      <td>10.1145/3173574.3173579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[material, becomes, active, disclosing, fullne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>CHI '15</td>\n",
       "      <td>Seoul, Republic of Korea</td>\n",
       "      <td>trackpad, clutching, performance, pointing, to...</td>\n",
       "      <td>4</td>\n",
       "      <td>4199–4202</td>\n",
       "      <td>Proceedings of the 33rd Annual ACM Conference ...</td>\n",
       "      <td>Clutching is usually assumed to be triggered b...</td>\n",
       "      <td>10.1145/2702123.2702134</td>\n",
       "      <td>https://doi.org/10.1145/2702123.2702134</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Nancel, Mathieu and Vogel, Daniel and Lank, Ed...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/2702123.2702134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[clutching, usually, assumed, triggered, lack,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>CHI '15</td>\n",
       "      <td>Seoul, Republic of Korea</td>\n",
       "      <td>eye-tracking, interaction science, menus, visu...</td>\n",
       "      <td>4</td>\n",
       "      <td>4203–4206</td>\n",
       "      <td>Proceedings of the 33rd Annual ACM Conference ...</td>\n",
       "      <td>Menu interfaces often arrange options into sem...</td>\n",
       "      <td>10.1145/2702123.2702177</td>\n",
       "      <td>https://doi.org/10.1145/2702123.2702177</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Brumby, Duncan P. and Zhuang, Susan</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/2702123.2702177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[menu, interfaces, often, arrange, options, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>CHI '15</td>\n",
       "      <td>Seoul, Republic of Korea</td>\n",
       "      <td>creativity, color picker, generative design, c...</td>\n",
       "      <td>10</td>\n",
       "      <td>4207–4216</td>\n",
       "      <td>Proceedings of the 33rd Annual ACM Conference ...</td>\n",
       "      <td>Although ubiquitous, color pickers have remain...</td>\n",
       "      <td>10.1145/2702123.2702173</td>\n",
       "      <td>https://doi.org/10.1145/2702123.2702173</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Jalal, Ghita and Maudet, Nolwenn and Mackay, W...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/2702123.2702173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[although, ubiquitous, color, pickers, remaine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>CHI '15</td>\n",
       "      <td>Seoul, Republic of Korea</td>\n",
       "      <td>eye movements, interaction science, reinforcem...</td>\n",
       "      <td>10</td>\n",
       "      <td>4217–4226</td>\n",
       "      <td>Proceedings of the 33rd Annual ACM Conference ...</td>\n",
       "      <td>One reason that human interaction with technol...</td>\n",
       "      <td>10.1145/2702123.2702483</td>\n",
       "      <td>https://doi.org/10.1145/2702123.2702483</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Chen, Xiuli and Bailly, Gilles and Brumby, Dun...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/2702123.2702483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[one, reason, human, interaction, technology, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>CHI '15</td>\n",
       "      <td>Seoul, Republic of Korea</td>\n",
       "      <td>selective undo, creativity support, bitmap editor</td>\n",
       "      <td>10</td>\n",
       "      <td>4227–4236</td>\n",
       "      <td>Proceedings of the 33rd Annual ACM Conference ...</td>\n",
       "      <td>Today's widely deployed painting applications ...</td>\n",
       "      <td>10.1145/2702123.2702543</td>\n",
       "      <td>https://doi.org/10.1145/2702123.2702543</td>\n",
       "      <td>New York, NY, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>Myers, Brad A. and Lai, Ashley and Le, Tam Min...</td>\n",
       "      <td>inproceedings</td>\n",
       "      <td>10.1145/2702123.2702543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[today, widely, deployed, painting, applicatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6914 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       series                  location  \\\n",
       "0     CHI '18       Montreal QC, Canada   \n",
       "1     CHI '18       Montreal QC, Canada   \n",
       "2         NaN                       NaN   \n",
       "3     CHI '18       Montreal QC, Canada   \n",
       "4         NaN                       NaN   \n",
       "...       ...                       ...   \n",
       "6909  CHI '15  Seoul, Republic of Korea   \n",
       "6910  CHI '15  Seoul, Republic of Korea   \n",
       "6911  CHI '15  Seoul, Republic of Korea   \n",
       "6912  CHI '15  Seoul, Republic of Korea   \n",
       "6913  CHI '15  Seoul, Republic of Korea   \n",
       "\n",
       "                                               keywords numpages      pages  \\\n",
       "0     news media, cybersecurity, usable privacy and ...       12       1–12   \n",
       "1     sensing, material recognition, deep learning, ...       13       1–13   \n",
       "2                                                   NaN       13       1–13   \n",
       "3     sustainability, smart homes, domestic, desider...       14       1–14   \n",
       "4                                                   NaN       11       1–11   \n",
       "...                                                 ...      ...        ...   \n",
       "6909  trackpad, clutching, performance, pointing, to...        4  4199–4202   \n",
       "6910  eye-tracking, interaction science, menus, visu...        4  4203–4206   \n",
       "6911  creativity, color picker, generative design, c...       10  4207–4216   \n",
       "6912  eye movements, interaction science, reinforcem...       10  4217–4226   \n",
       "6913  selective undo, creativity support, bitmap editor       10  4227–4236   \n",
       "\n",
       "                                              booktitle  \\\n",
       "0     Proceedings of the 2018 CHI Conference on Huma...   \n",
       "1     Proceedings of the 2018 CHI Conference on Huma...   \n",
       "2     Proceedings of the 2018 CHI Conference on Huma...   \n",
       "3     Proceedings of the 2018 CHI Conference on Huma...   \n",
       "4     Proceedings of the 2018 CHI Conference on Huma...   \n",
       "...                                                 ...   \n",
       "6909  Proceedings of the 33rd Annual ACM Conference ...   \n",
       "6910  Proceedings of the 33rd Annual ACM Conference ...   \n",
       "6911  Proceedings of the 33rd Annual ACM Conference ...   \n",
       "6912  Proceedings of the 33rd Annual ACM Conference ...   \n",
       "6913  Proceedings of the 33rd Annual ACM Conference ...   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     News coverage of security and privacy (S&amp;P...   \n",
       "1     We introduce Deep Thermal Imaging, a new appro...   \n",
       "2     Many conversational agents (CAs) are developed...   \n",
       "3     Research has shown that desirable designs shap...   \n",
       "4     As the material becomes active in disclosing t...   \n",
       "...                                                 ...   \n",
       "6909  Clutching is usually assumed to be triggered b...   \n",
       "6910  Menu interfaces often arrange options into sem...   \n",
       "6911  Although ubiquitous, color pickers have remain...   \n",
       "6912  One reason that human interaction with technol...   \n",
       "6913  Today's widely deployed painting applications ...   \n",
       "\n",
       "                          doi                                      url  \\\n",
       "0     10.1145/3173574.3173575  https://doi.org/10.1145/3173574.3173575   \n",
       "1     10.1145/3173574.3173576  https://doi.org/10.1145/3173574.3173576   \n",
       "2                         NaN  https://doi.org/10.1145/3173574.3173577   \n",
       "3     10.1145/3173574.3173578  https://doi.org/10.1145/3173574.3173578   \n",
       "4                         NaN  https://doi.org/10.1145/3173574.3173579   \n",
       "...                       ...                                      ...   \n",
       "6909  10.1145/2702123.2702134  https://doi.org/10.1145/2702123.2702134   \n",
       "6910  10.1145/2702123.2702177  https://doi.org/10.1145/2702123.2702177   \n",
       "6911  10.1145/2702123.2702173  https://doi.org/10.1145/2702123.2702173   \n",
       "6912  10.1145/2702123.2702483  https://doi.org/10.1145/2702123.2702483   \n",
       "6913  10.1145/2702123.2702543  https://doi.org/10.1145/2702123.2702543   \n",
       "\n",
       "                address  ...  \\\n",
       "0     New York, NY, USA  ...   \n",
       "1     New York, NY, USA  ...   \n",
       "2     New York, NY, USA  ...   \n",
       "3     New York, NY, USA  ...   \n",
       "4     New York, NY, USA  ...   \n",
       "...                 ...  ...   \n",
       "6909  New York, NY, USA  ...   \n",
       "6910  New York, NY, USA  ...   \n",
       "6911  New York, NY, USA  ...   \n",
       "6912  New York, NY, USA  ...   \n",
       "6913  New York, NY, USA  ...   \n",
       "\n",
       "                                                 author      ENTRYTYPE  \\\n",
       "0     Das, Sauvik and Lo, Joanne and Dabbish, Laura ...  inproceedings   \n",
       "1     Cho, Youngjun and Bianchi-Berthouze, Nadia and...  inproceedings   \n",
       "2     Liao, Q. Vera and Mas-ud Hussain, Muhammed and...         inbook   \n",
       "3     Jensen, Rikke Hagensby and Strengers, Yolande ...  inproceedings   \n",
       "4     Barati, Bahareh and Giaccardi, Elisa and Karan...         inbook   \n",
       "...                                                 ...            ...   \n",
       "6909  Nancel, Mathieu and Vogel, Daniel and Lank, Ed...  inproceedings   \n",
       "6910                Brumby, Duncan P. and Zhuang, Susan  inproceedings   \n",
       "6911  Jalal, Ghita and Maudet, Nolwenn and Mackay, W...  inproceedings   \n",
       "6912  Chen, Xiuli and Bailly, Gilles and Brumby, Dun...  inproceedings   \n",
       "6913  Myers, Brad A. and Lai, Ashley and Le, Tam Min...  inproceedings   \n",
       "\n",
       "                           ID month journal issn number volume issue_date  \\\n",
       "0     10.1145/3173574.3173575   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "1     10.1145/3173574.3173576   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "2     10.1145/3173574.3173577   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "3     10.1145/3173574.3173578   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "4     10.1145/3173574.3173579   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "...                       ...   ...     ...  ...    ...    ...        ...   \n",
       "6909  10.1145/2702123.2702134   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "6910  10.1145/2702123.2702177   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "6911  10.1145/2702123.2702173   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "6912  10.1145/2702123.2702483   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "6913  10.1145/2702123.2702543   NaN     NaN  NaN    NaN    NaN        NaN   \n",
       "\n",
       "                                         Token_abstract  \n",
       "0     [news, coverage, security, privacy, amp, p, ev...  \n",
       "1     [introduce, deep, thermal, imaging, new, appro...  \n",
       "2     [many, conversational, agents, cas, developed,...  \n",
       "3     [research, shown, desirable, designs, shape, u...  \n",
       "4     [material, becomes, active, disclosing, fullne...  \n",
       "...                                                 ...  \n",
       "6909  [clutching, usually, assumed, triggered, lack,...  \n",
       "6910  [menu, interfaces, often, arrange, options, se...  \n",
       "6911  [although, ubiquitous, color, pickers, remaine...  \n",
       "6912  [one, reason, human, interaction, technology, ...  \n",
       "6913  [today, widely, deployed, painting, applicatio...  \n",
       "\n",
       "[6914 rows x 24 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614402\n",
      "22375\n"
     ]
    }
   ],
   "source": [
    "tokens = [ t for d in df['Token_abstract'] for t in d]\n",
    "text = nltk.Text(tokens, name='abstract')\n",
    "print(len(text.tokens))\n",
    "print(len(set(text.tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('design', 5714), ('user', 4625), ('users', 4423), ('study', 3544), ('paper', 3253), ('use', 3058), ('system', 3015), ('based', 2940), ('data', 2907), ('results', 2612)]\n"
     ]
    }
   ],
   "source": [
    "print(text.vocab().most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAE8CAYAAAAxL51GAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABfaUlEQVR4nO2dd5hdVbXAf2taJjPplfQEUigBQibUgFQpAlIElKLAQ9EnVp48RMECqCiotAeoFBFBQYpAUIohoQeSSaWFhAQC6b3MpM3Men+sfTPn3jnnTsnM3GSyft93vnvvPufsvc+55+y191prry2qiuM4juNkIy/XFXAcx3F2fFxYOI7jOPXiwsJxHMepFxcWjuM4Tr24sHAcx3HqpSDXFWgJevTooYMHD27y+Rs3bqR9+/atnt7Wy26NMrzs1i+7Ncrwsre/7IZQXl6+QlV7xu5U1Ta3lZWV6fYwZcqUnKS39bJbowwvu22W4WU3zzn1AUzRhHbV1VCO4zhOvbiwcBzHcerFhYXjOI5TLy4sHMdxnHpxYeE4juPUiwsLx3Ecp15cWDiO4zj10iYn5TWVF99fytMzFrN7u02UleW6No7jODsOPrKI8OGyCp6YtpD3VmzJdVUcx3F2KFxYRBjQrQSApRXVOa6J4zjOjoULiwgDXVg4juPE4sIiwoBuFnxr2YYq1JebdRzH2YYLiwgdiwvpVlrElhpYvn5zrqvjOI6zw+DCIoOU3WLBqsoc18RxHGfHwYVFBgNdWDiO49TBhUUGA4PdwoWF4zhOLS4sMvCRheM4Tl1cWGSQsll84sLCcRxnGy4sMvCRheM4Tl1cWGTQp3N78gWWrtvMpq0+Oc9xHAdcWNQhP0/oWZoPwKerfXThOI4DLixi6R2EhauiHMdxDBcWMWwTFitdWDiO44ALi1h6d7BlPhas2pjjmjiO4+wYuLCIwdVQjuM46biwiCElLHyuheM4juHCIobeHWpHFh6q3HEcx4VFLKWFeXQpKWTj1mpWbPAlVh3HcVxYJOAzuR3HcWpxYZGAx4hyHMepxYVFAj6ycBzHqcWFRQIuLBzHcWpxYZGACwvHcZxaXFgkMNBtFo7jONtwYZFAn87F5OcJS9Zt8lDljuPs8riwSKAgP49+XdqjCgvXeIwox3F2bVpUWIjIRyIyS0Smi8iUkNZNRF4QkTnhs2tIFxG5VUTmishMERkdyefCcPwcEbmwJescxe0WjuM4RmuMLI5W1VGqOib8/iEwXlWHAePDb4CTgGFhuxS4E0y4AD8FDgYOAn6aEjAtzYBu7QG3WziO4+RCDXUacH/4fj9weiT9L2pMArqISB/gBOAFVV2lqquBF4ATW6OiqYl5vq6F4zi7OtKSgfJEZD6wGlDgD6r6RxFZo6pdwn4BVqtqFxEZB9ygqq+GfeOBK4GjgGJVvT6kXwNsVNWbMsq6FBuR0KdPn7Knn366yfWurKykpKSE1z7ZyO8mreWgvu24cmzXbelJx29venPmtSOW3RpleNmtX3ZrlOFlb3/ZDWHMmDHlES1QOqraYhvQL3z2AmYAnwHWZByzOnyOAw6PpI8HxgA/AK6OpF8D/CBbuWVlZbo9TJkyRVVVZ3yyWgddOU5P+P1LaelJx29vemuUkcuyW6MML7ttluFlN8859QFM0YR2tUXVUKq6MHwuA57AbA5Lg3qJ8LksHL4QGBA5vX9IS0pvcaJzLdRDlTuOswvTYsJCREpFpGPqO3A88DbwFJDyaLoQeDJ8fwr4SvCKOgRYq6qLgeeA40WkazBsHx/SWpzO7QvpWFxAxZZqVlV4qHLHcXZdClow797AE2aWoAB4SFWfFZHJwCMicgnwMXBOOP5fwOeAuUAlcDGAqq4SkeuAyeG4a1V1VQvWexsiwsBuJbyzaJ27zzqOs0vTYsJCVecB+8ekrwSOjUlX4LKEvO4F7m3uOjaEqLDon4sKOI7j7AD4DO568BhRjuM4LizqZYDP4nYcx3FhUR8e8sNxHMeFRb3UqqE8mKDjOLsuLizqoW+X9uQJLFq7ka01PtfCcZxdExcW9VBUkEefzhaqfHmFr2vhOM6uiQuLBpBSRS11YeE4zi6KC4sG4MLCcZxdHRcWDWBg9yAsNlTluCaO4zi5wYVFA0jNtVi03kcWjuPsmriwaAD79etMnkD54s288eHKXFfHcRyn1XFh0QAG9yjlW0cPRYHvPzydNZUegdZxnF0LFxYN5DvHDmN4t0KWrNvEVY/P8vUtHMfZpXBh0UAK8vP47sGd6dCugH+/vYRHpnyS6yo5juO0Gi4sGsFuHQq49rR9APjZU+/y4fINOa6R4zhO6+DCopGccUA/ThvVl41bq/ne36ezpaom11VyHMdpcVxYNBIR4brTR9K/a3tmLVzLb1+YnesqOY7jtDguLJpAp+JCbv7iKPIE/vDSPGYu3ZzrKjmO47QoLiyayJjB3fj2McMAuLN8nXtHOY7TpnFhsR18+5ihdCwuYFlFNSs2+NwLx3HaLi4stoOC/DyG9eoAwJxl63NcG8dxnJbDhcV2MqxXRwDmLnM3Wsdx2i4uLLaTYb3DyGKpCwvHcdouLiy2k6GuhnIcZxfAhcV2Mqy3qaF8ZOE4TlvGhcV20rdzMcUFwsqKLazc4PMtHMdpm7iw2E5EhP4dCwA3cjuO03ZxYdEM9O+UD8AcFxaO47RRXFg0AwM6FwI+snAcp+3iwqIZGLBtZOEeUY7jtE1cWDQD/TuZzcI9ohzHaau4sGgGepbkU1yYx7L1m1lbuTXX1XEcx2l2XFg0A3kiPjnPcZw2jQuLZiIVI8o9ohzHaYu0uLAQkXwRmSYi48LvISLypojMFZGHRaQopLcLv+eG/YMjeVwV0meLyAktXeemsG1k4XYLx3HaIK0xsvgu8F7k96+B36vqUGA1cElIvwRYHdJ/H45DRPYGvgTsA5wI3CEi+a1Q70YxPBX2w9VQjuO0QVpUWIhIf+Bk4O7wW4BjgEfDIfcDp4fvp4XfhP3HhuNPA/6uqptVdT4wFzioJevdFFLrWvhcC8dx2iLSksuBisijwK+AjsAPgIuASWH0gIgMAP6tqiNF5G3gRFX9NOz7EDgY+Fk4568h/Z5wzqMZZV0KXArQp0+fsqeffrrJ9a6srKSkpKRR6e3at+f8x5eytQYeOL0XJYV5jc6nqWU3R3pbKcPLbv2yW6MML3v7y24IY8aMKVfVMbE7VbVFNuAU4I7w/ShgHNADmBs5ZgDwdvj+NtA/su/DcPztwAWR9HuAs7KVXVZWptvDlClTmpR+4s0v66Arx+nUj1c1KZ/tKXt709tKGV522yzDy26ec+oDmKIJ7WpLqqHGAp8XkY+Av2Pqp1uALiJSEI7pDywM3xcG4UHY3xlYGU2POWeHonaJVVdFOY7TtmgxYaGqV6lqf1UdjBmoX1TV84EJwFnhsAuBJ8P3p8Jvwv4Xg6R7CvhS8JYaAgwD3mqpem8PbrdwHKetUlD/Ic3OlcDfReR6YBqmViJ8PiAic4FVmIBBVd8RkUeAd4Eq4DJVrW79atdPaonVD5a6R5TjOG2LVhEWqjoRmBi+zyPGm0lVNwFnJ5z/C+AXLVfD5mFoL181z3GctonP4G5GBncvoTBfWLhmIxWbq3JdHcdxnGbDhUUzUpCfx+49TBX14XIfXTiO03ZwYdHMDO3tYT8cx2l7uLBoZtx91nGctkijhYWIdBWR/VqiMm2BVPTZuR4jynGcNkSDhIWITBSRTiLSDZgK/ElEfteyVds5SbnP+sjCcZy2RENHFp1VdR1wJvAXVT0YOK7lqrXzMrh7Kfl5woJVlWyuarm4W47jOK1JQ4VFgYj0Ac7BYjw5CRQV5DG4ewmqsHC9u886jtM2aKiw+DnwHBYEcLKI7A7Mablq7dyk1rb4dJ0LC8dx2gYNncG9WFW3GbVVdZ7bLJIZ1qsD/wY+cWHhOE4boaEji9samOYAQ31k4ThOGyPryEJEDgUOA3qKyOWRXZ2AHW5p0x2F1FwLFxaO47QV6lNDFQEdwnEdI+nrqA0z7mQwpEcpeQJLNlSzuaqadgUuVx3H2bnJKixU9SXgJRH5s6p+3Ep12ukpLsxncPdS5q2o4K35qzhiWM9cV8lxHGe7aKjNop2I/FFEnheRF1Nbi9ZsJ+eMA/oBcNuLc3NcE8dxnO2nod5Q/wDuAu4GdsiFh3Y0Lhw7mLsmzuGt+at448OVHLpH91xXyXEcp8k0dGRRpap3qupbqlqe2lq0Zjs5nYoLOWV4KQC3jP8gx7VxHMfZPhoqLJ4WkW+KSB8R6ZbaWrRmbYCTh5bQsbiASfNWMWneylxXx3Ecp8k0VFhcCFwBvA6Uh21KS1WqrVBalMclhw8B4Jb/+IR3x3F2XhokLFR1SMy2e0tXri1w8dghdCwu4I15K3lr/qpcV8dxHKdJNDRE+VfitpauXFugc/tCLh4bRhduu3AcZyeloWqoAyPbEcDPgM+3UJ3aHJeMHULHdgW8NnclUz7y0YXjODsfDVVDfTuyfQ0Yjc3sdhpA55JCLho7GIBbxrvtwnGcnY+mrsFdAQxpzoq0dS45fAgd2hXwypwVvL9iS66r4ziO0ygaarN4WkSeCtszwGzgiZatWtuiS0kRFx02GIBH3vUlVx3H2blo6AzumyLfq4CPVfXTFqhPm+aSw4dw32vzmbF0C5PmreSQ3X1Wt+M4OwcNtVm8BLyPRZ7tCrgepQl0LS3iq0eYx/H/PDKDNZV+Gx3H2TloqBrqHOAt4GxsHe43RcRDlDeBy44eyrBuhSxcs5ErHp2Jqua6So7jOPXSUAP3j4EDVfVCVf0KcBBwTctVq+1SVJDH5Yd0pmNxAS+8u5Q/v/5RrqvkOI5TLw0VFnmquizye2UjznUy6FVawG++YEua//Jf7zHz0zW5rZDjOE49NLTBf1ZEnhORi0TkIuAZ4F8tV622z0n79uErhw5ia7XyrYemsW7T1lxXyXEcJ5GswkJEhorIWFW9AvgDsF/Y3gD+2Ar1a9P86HN7sXefTixYVclVj89y+4XjODss9Y0sbsbW20ZVH1fVy1X1cmyOxc0tW7W2T3FhPrefdwAlRfk8M3Mxf3vrk1xXyXEcJ5b6hEVvVZ2VmRjSBrdIjXYxdu/ZgV+esS8AP3/6HV5ZsJH1rpJyHGcHoz5h0SXLvvbZThSRYhF5S0RmiMg7IvLzkD5ERN4Ukbki8rCIFIX0duH33LB/cCSvq0L6bBE5oWGXtvNw+gH9OGdMfzZX1XDzm2sZfd0LXHD3m9z32nwWrKzMdfUcx3HqFRZTRORrmYki8lVsAaRsbAaOUdX9gVHAiSJyCPBr4PeqOhRYDVwSjr8EWB3Sfx+OQ0T2Br4E7AOcCNwhIvkNuLadiutOH8nVJ+/FXj0Kqa5RXp27gp8//S6fuXECx/3uJZ54fwOVW6pyXU3HcXZR6gv38T3gCRE5n1rhMAYoAs7IdqKatTYVBKkwbAocA5wX0u/Hwp3fCZwWvgM8CtwuIhLS/66qm4H5IjIXm+fxRr1XtxPRriCfrx6xOweUrGb3PfflpQ+WM/79ZUycvYy5yzYwdxk8O38C3zxqKOcdPJDiwjYnLx3H2YGRhnjgiMjRwMjw8x1VfbFBmdsIoBwYCvwfcCMwKYweEJEBwL9VdaSIvA2cmIo5JSIfAgdjAmSSqv41pN8Tznk0o6xLgUsB+vTpU/b00083pIqxVFZWUlJS0urpcfuqapSZS7fw97fX8eGaagC6t8/jrL07cMzg9mzZtLHFym6N6/Oyd/6yW6MML3v7y24IY8aMKVfVMbE7VbXFN8z2MQE4HJgbSR8AvB2+vw30j+z7EOgB3A5cEEm/BzgrW3llZWW6PUyZMiUn6dn2TZ48WV94Z4me8PuXdNCV43TQleP0iF+/qNf9/SV9f/E6ra6uabGyW+P6vOydt+zWKMPLbp5z6gOYogntakOjzm4XqrpGRCYAhwJdRKRAVauA/sDCcNjCIDw+FZECoDM2UzyVniJ6zi6DiHDc3r05Zs9ePDNrMb9/4QPmrajg7lVw97SX6VhcwOiBXRkzqCtlg7qiVTW5rrLjOG2IFhMWItIT2BoERXvgs5jRegJwFvB34ELgyXDKU+H3G2H/i6qqIvIU8JCI/A7oCwzDghrukuTlCafu35eTRu7GUzMW8dgbs5m/Dhat3cRLHyznpQ+WA9ClOI8nh1YwqHtpjmvsOE5boCVHFn2A+4PdIg94RFXHici7wN9F5HpgGqZWInw+EAzYqzAPKFT1HRF5BHgXW0vjMlWtbsF67xQU5Odx5uj+DNKllJWVsWjNRso/Xk35x6uZOHsZH62s5LYX53LT2fvnuqqO47QBWkxYqOpM4ICY9HmYN1Nm+iYsBHpcXr8AftHcdWxL9O3Snr5d2nPq/n1ZsHIIR900gSemLeQ7xwxjYPemGbscx3FSeOTYNsjA7iV8ZmAx1TXKnS/NzXV1HMdpA7iwaKOcuVcH8gQeLf+UhWs25ro6juPs5LiwaKP061jAKfv1ZWu1ctfED3NdHcdxdnJcWLRhvnXMUETg4cmfsGTtplxXx3GcnRgXFm2Y4b07ctLI3dhSXcMfXvbRheM4TceFRRvnW0cPA+ChNxewbL2PLhzHaRouLNo4e/ftxGf37s3mqhrufmV+rqvjOM5OiguLXYDvHGOjiwfe+Ji1mz0MiOM4jceFxS7Avv07c/SInmzcWs24DypyXR3HcXZCXFjsInz7WBtd/GtuJasqtuS4No7j7Gy4sNhFGD2wK0cM68GmKuWEm1/m4ckLqK6pfy0Tx3EccGGxS/GL0/dlWLdClq/fzJWPzeLkW1/hlTnLc10tx3F2AlxY7EIM7F7CL4/pxi1fGkW/Lu15f8l6vnzPW1x831vMWbo+19VzHGcHplUWP3J2HPJEOG1UP07YZzfufW0+d0z4kAmzl/PynBWcMaKEAw5Q8vIk19V0HGcHw0cWuyjFhfl886ihTLziKC44ZCCqyqPvVfCNv5ZTsbkq19VzHGcHw4XFLk6PDu24/vR9+fPFB1FaKDz/7lK+cOfrfLKqMtdVcxxnB8KFhQPAZ4b35IZju7N7z1LeX7Ke0/7vNSbNW5nrajmOs4PgwsLZRt+OBTzxzbEcObwnqyq2cMHdb/LQmwtyXS3HcXYAXFg4aXRuX8i9Fx3IVw8fQlWN8qMnZnH/jHWo+pwMx9mVcWHh1CE/T7j6lL258az9KMrP46kPKvnz6x/lulqO4+QQFxZOImePGcCNZ+8HwHXj3uXF95fmuEaO4+QKFxZOVk4b1Y9z9i6lRuHbD03j/SXrcl0lx3FygAsLp17O2bsDp+7fl4ot1Vzy5ym+iJLj7IK4sHDqRUS48az9OGBgFxau2cilfyln09bqXFfLcZxWxIWF0yCKC/P545fH0K9Le6Z/soYf/GMGNe4h5Ti7DC4snAbTs2M77r3oQDq0K2DczMXcM209sz5dy+YqH2U4TlvHAwk6jWLEbh257bwDuOTPk3n2w0qevf1VCvKEYb07sk/fTozs24matZupnr+K/DwhP08oCJ8lRfk+X8NxdlJcWDiN5ugRvbj3ogO5Z/wsFm3MZ96KCt5bvI73Fq/j0fJw0MtvxJ47onshP+2ygsOG9mi9CjuOs924sHCaxFEjetFxQxfKysqo2FzF+0vW8c6idby9cC3vfLyU9iUdqKpRalSpqrbPRWs2MnvlVs67+00O26M7PzhhBKMHds31pTiO0wBcWDjbTWm7AsoGdaNsUDcAysvLKSsrq3NcxeYqrv/Ha4ybu4nXP1zJmXe8zjF79uJ/jh/e2lV2HKeRuLBwWo3SdgWctVcHfnjmYfzplXnc+9p8Xnx/GS++v4wR3Qs5cdUHHDGsB/sP6EJhvvteOM6OhAsLp9XpXFLID04YwUVjB3PnxA95YNLHzF65ldnj53DL+Dl0aFfAIbt35/Ch3clfv4XSJevoVFxIp/aFlBblI+Ir+TlOa+PCwskZPTq045pT9uZ7xw3jwRfeYnFNZ16Zu4J5yyv4z3tL+c97IRbVxFe2nZOfJ3QsLqBYaug96TW6lRTStaSIrqVFdC0pZOuajey7fw1FBT4ycZzmxIWFk3M6FhdyYN9iyspGArBwzUZem7OCV+euYPany6nJb8e6TVtZt7GKjVurWVO5FYAlFWti85uw6HVu/dIBDO5R2lqX4DhtnhYTFiIyAPgL0BtQ4I+qeouIdAMeBgYDHwHnqOpqMd3CLcDngErgIlWdGvK6ELg6ZH29qt7fUvV2ck+/Lu0558ABnHPggDrG8q3VNazfVMWrk6fRb8gwVldsZXXlFlZXbmFVxVYemzyfmZ+u5eRbX+H6M0ZyxgH9c3gljtN2aMmRRRXwP6o6VUQ6AuUi8gJwETBeVW8QkR8CPwSuBE4ChoXtYOBO4OAgXH4KjMGETrmIPKWqq1uw7s4OSmF+Ht1Ki+jXsWCb91WUw7qs5+F5+TwzazHff3gGr3ywgmtPH0mHdj6IdpztocUUu6q6ODUyUNX1wHtAP+A0IDUyuB84PXw/DfiLGpOALiLSBzgBeEFVVwUB8QJwYkvV29m5KS3K4/bzDuDXX9iX4sI8Hp+2kFNufYWZn67JddUcZ6dGWiP8gogMBl4GRgILVLVLSBdgtap2EZFxwA2q+mrYNx4bcRwFFKvq9SH9GmCjqt6UUcalwKUAffr0KXv66aebXN/KykpKSkpaPb2tl90aZUTTP11Xxe8nreGjtVXkCXQtFory8yjMFwrzoDBPKMwX9ukmnLZ3F4rypdFl7IjX3RbL8LK3v+yGMGbMmHJVHRO7U1VbdAM6AOXAmeH3moz9q8PnOODwSPp4TPX0A+DqSPo1wA+ylVlWVqbbw5QpU3KS3tbLbo0yMtM3bqnSnz75tg7+4TgddGXyNvaG8TpuxiKtqalp9jo1Z147YtmtUYaX3Tzn1AcwRRPa1RZV5IpIIfAY8KCqPh6Sl4pIH1VdHNRMy0L6QmBA5PT+IW0hNrqIpk9syXo7bYfiwnx+9vl9+P5xw3ltylSG77kPW6pq2FJdw5aqGpat38Rvxs1iweqNXPbQVA4c3JVrTtmb/fp3yXXVHWeHoiW9oQS4B3hPVX8X2fUUcCFwQ/h8MpL+LRH5O2bgXhsEynPAL0UkFUToeOCqlqq30zbpXFJI79IChvbqUGdfr82LmFPTk989/wGTP1rN529/jTMP6McJfT30uuOkaMmRxVjgy8AsEZke0n6ECYlHROQS4GPgnLDvX5jb7FzMdfZiAFVdJSLXAZPDcdeq6qoWrLezi5GfJ5x/4CBO3b8v/zdhLve9+hGPT1vIP6fDsfOncO5BAzhyeC/y83zmuLPr0mLCQs1QnfR2HRtzvAKXJeR1L3Bv89XOcerSqbiQq07ai/MPGsSNz8/mmZmLeOHdpbzw7lL6dC7m7DEDOGeMz9twdk3c+dxxMhjYvYTbzj2A0wZu5YOt3Xh48id8vLKSW8fP4bYX57B/ryK+zKccv09vOhYX5rq6jtMquLBwnAS6FufzzbFD+cZn9mDSvJX8bfInPPf2EqYv3cL0f8yg6Ik8jhnRi8+P6ssxe/bKdXUdp0VxYeE49ZCXJxw2tAeHDe3Bqoot3PXMm0xfXcDkj1bx7DtLePadJZQW5VO2WyFnFyziiGE96FJSlOtqO06z4sLCcRpBt9IiTtijhB+VlbF47UaembmYp2csYsana3l5QTUvL5hGnsCoAV04cngvjhrRk337dc51tR1nu3Fh4ThNpE/n9nz1iN356hG78/HKCu55rpy5FUVM/mgVUxesYeqCNfz+Px/QrbSI4V2E4zfO58DB3dirT0cKfHEnZyfDhYXjNAODupdy2ohSysrK2LC5itfnruClD5YzcfZyFq7ZyKQKmLTwXQBKi/IZPagrYwZ1I2/DJqq6rqRHx3b06NCOTsUFvriTs0PiwsJxmpkO7Qo4fp/dOH6f3VBV5q2o4NGXprFcOzHlo1V8tLKSV+as4JU5K+yESZO2nVuUn0ePDkUM7wJ37VdNcWF+bi7CcTJwYeE4LYiIsEfPDhw3pISysv0BWLZ+E+UfrWbKx6t5e/4iqgtKWLFhMys2bGHD5ioWrd3EorXwzQen8ocvl/l65M4OgQsLx2llenUs5qR9+3DSvn0oL9+YtrjTxi3VvL9kHV+5+w1efH8Zlz8yg5u/OMpnjzs5x7ssjrMD0b4onwMGduXqI7rRoV0BT89YxNX/fDsVcdlxcoYLC8fZARnarZB7LhxDu4I8/vbWAm749/suMJyc4sLCcXZQDt69O3ddUEZBnvCHl+dxx8QPc10lZxfGhYXj7MAcvWcvfv/FUYjAjc/N5t9zK3JdJWcXxYWF4+zgnLp/X355xr4A3D1tPbeNn+MqKafVcWHhODsB5x40kJ+dujcC/PaFD/jW36axcYsvzuS0Hi4sHGcn4aKxQ/jh2C50aFfAMzMXc/YfXmfRmo25rpazi+DCwnF2Isb0Lebxbx7GwG4lvL1wHZ+//TXKP16d62o5uwAuLBxnJ2N47448edlYDt29Oys2bObcP05iwkc+wnBaFhcWjrMT0rW0iL9cchAXHjqILdU13D55LSf8/mV+9/xs3lm01g3gTrPj4T4cZyelMD+Pn582kj37dOK6p99m9tL1zF66nltfnEv/ru05YZ/dOGGf3di0pQZV9Wi2znbhwsJxdnLOPWggQ2QZmzsP4rl3lvD8O0v5dPVG7nl1Pve8Oh+AomeepUdp0bZQ6D06FLFp3TpeWf0BHdoVUFJUQGm7fEqLCli2cguDNmyme2mRCxhnGy4sHKcNUJgnHDK8J0cO78l1p41k2oLVPPv2EiZ+sJxPV1awqaomRLPdlH7iB3Ni8/vRi/+htCifgd1LGdy9hIHdS8jbUAk9VjNit450aOdNx66G/+OO08bIzxPGDO7GmMHduBooLy9nr333Z8X6LSzfsDmEQ9/M+3M/okvP3ajYXE3F5ioqtlRRuaWaj5asYvkmWL+pivcWr+O9xeu25X1n+esA9OvSnhG7dWTEbh0Z2rMDSxduYl2HZbTLz6OowLZ2BfmsdxVYm8GFhePsApQUFTCwewEDu5dsSysvWEFZ2Yg6x5aXlzN69GjWVG7l41WVfLyygo9XVjJl9gJWbC1i7rINLFyzkYVrNvLi+8tqT3x9cmzZHZ99nv7dShjYrT0DutooZfWSjSwtWkyeCAV5Qn7YPlq+hXYL19KxuIAO7QroUFxAuwJfAGpHwIWF4zh1EBG6lhbRtbSIUQO6AFDeZR1lZWVUVdfw0cpKZi8xg/r8FRUsWb6S9h06saWqms1VNWypqmHT1moWrq5k/ea6IxQA3pwaX/jEV9N+FhXkUZyndHh+PMWF+fa7MJ/iwjxKiwroqBUsLVrMfv07069Lex/FtBAuLBzHaRQF+XkM7dWBob06cDJ9ABuNRBdxSjFlyhR232s/PllVyYKwfbq6ko8XLadzly5U1Sg1NUpVjVJdo6xcsxYK27Nh81bWb6piw6YqtlTVsAVYt2VTnfxT/HO2CZ4eHYrYt19n9uvfhU2rK/mw5hMKC4SCvDwK8+1z+cotDN+0lY7FhS1yf9oqLiwcx2kxRIRupUV0Ky1i/zBCgWThkpmuqmyuquH1t8oZvvdINm21Ecvmqmo2b61h3aat/Kd8NsurS5jx6RpWbNjChNnLmTB7uWUwdWZsva568Xn6dC5mWO+ODOvVgeG9O1CzegsjNle58T4BvyuO4+ywiAjFhfl0Ls6nf9eS2GN6bl5EWVkZqsonqzYy49M1vL1wLR9+spgu3bpTVV3D1mpla3UNW6trmL9kNYsqali8dhOL127i5Q+Wb8vrqhef22a8H967IyN268CWVVvpuHR9HftKQb6wtXrXmfzowsJxnDaBiDAwuPmeun9fyssrKSvbv85x5eXljDpgNJ+squSDpeuZs2wDc5auZ8ZHy1i4oSbeeD/+5cRyO/3rubT5Kz06tEM3bGBJ4WIGdithYLcSOpfs/CovFxaO4+xy5OcJg3uUMrhHKcfvY2nl5eXsP+oAPl4VjPdL1vPB0vW898kKCtoVp9lWqmuUqpoaVlVsYd2mKtZtqmLe8vSFqR6YVWvA71hcwMBuJXSUzey/7D0Gdy9lULcSBvUopU+n4ta89CbjwsJxHCdQkJ/HHj07sEfPDnxu3+zGe4DJU6awx1772dyV9ZvDPJYtTJv9EZsLO/LJqko+WVXJ+k1VvLPIvMEmLZyXlkdRfh5dioWOEydSmJ9HYX4eBflCYX4emys30H/2VLqWFNKtpIguJWb/6VJSyMIVWyhdso7SogJK2xVQUpRPu4KWC/fnwsJxHKeJ5EUM+MN7d9yWXt5+1TYBo6qsqtjCglWVvFT+DnmdevPxykoWrKrgo5WVLF+/mWUVsKwifsncGUsXJ1dgwitpPwvyhG7FebwVL9u2CxcWjuM4LYiI0L1DO7p3aEfN8vaUlQ1L21+xuYoX3yhnz732Zkt1DVXVpuLaWq28/d5sevYbxJrKrayq2MKayi2sqtzKmsotLFm5FilsZzPwt1RRubmaLdU11LRQxGEXFo7jODmktF0BfTsWMCwyMklRuLodZaP6xZ4Xpx7bUlXDpMnlLVLPFlNwici9IrJMRN6OpHUTkRdEZE747BrSRURuFZG5IjJTREZHzrkwHD9HRC5sqfo6juPs7BQV5FFa1DLNeksufvRn4MSMtB8C41V1GDA+/AY4CRgWtkuBO8GEC/BT4GDgIOCnKQHjOI7jtB4tJixU9WVgVUbyacD94fv9wOmR9L+oMQnoIiJ9gBOAF1R1laquBl6grgByHMdxWhhpyeUXRWQwME5VR4bfa1S1S/guwGpV7SIi44AbVPXVsG88cCVwFFCsqteH9GuAjap6U0xZl2KjEvr06VP29NNPN7nelZWVlJTUnS3a0ultvezWKMPLbv2yW6MML3v7y24IY8aMKVfVMbE7VbXFNmAw8Hbk95qM/avD5zjg8Ej6eGAM8APg6kj6NcAP6iu3rKxMt4cpU6bkJL2tl90aZXjZbbMML7t5zqkPYIomtKstabOIY2lQLxE+U/PpFwIDIsf1D2lJ6Y7jOE4r0trC4ikg5dF0IfBkJP0rwSvqEGCtqi4GngOOF5GuwbB9fEhzHMdxWpEWm2chIn/DbA49RORTzKvpBuAREbkE+Bg4Jxz+L+BzwFygErgYQFVXich1QGoJrmtVNdNo7jiO47QwLWrgzhUishwTRk2lB7AiB+ltvezWKMPLbptleNnNc059DFLVnrF7kowZu/JGgpGnpdPbetlt/fp21bLb+vW1lbK3d2ttm4XjOI6zE+LCwnEcx6kXFxbx/DFH6W297NYow8tum2V42c1zTpNpkwZux3Ecp3nxkYXjOI5TLy4sHMdxnHpxYeE4juPUiwuLZkZEThWRRt1XEWkvIiNaqk4ZZeWJSKfWKKu1EZGmhdpMz2OP5qjLdpTfYs+CiOSLyIMtkG9XEdkvfD9WRNo3Y97bfT9EJL+56rMj0xzPfzZ8WVVARNoBX8Ci5EbvyS+A/6jq0THnjAWmq2qFiFwAjAZuAb4I3CwijwH3qur74WFNyudU4CagCBgiIqOwsCafD/GwBkTqtCfwfpZLeRe4BNgHKI6kFwPfAKqx0CmdROQWVb1RRM6MyWdtOOd7wKBQvgCqqruLSL9IeoqTVfXKyHU9Her7XlxFw/XtDxwRkl5R1RmR8w+j7v9RqKr3RPMRkRuw2GJ3Ax2AgSHfrwMTgGdVdb2IXI39R9er6lQR+Q1wPbAReBbYD/g+8DUR6R/u0yvAciwMTRIbsMW6eqvqyNBofh44WlWPzajreGw9lv8GPhOSXwLuUtWtSc8C8F703oa8fgMcmPBMDY+rk6peLyKDRKRIVbfEnDcIGKaq/wkNfoGqro+7aBGZGK6zACgHlonIa0B34E4RWRXu38vAq8DexLwvqvqxiPQEvkbd//uJhPvxZMJzUE7M/w08Gt7H+1T13XD85XHXFeFB4JdAX1U9SUT2Bg5V1XtCh+JTVd0sIkcBhwB/B9bF5NMT+N/MfMKxmXXdF3sek/jvuHsI9CPm+VfVb9ZzjY3CvaEAEXkWayDLsQYVAFX9bXjBz1TVtRnnzAT2xxqZP2N/1jmqemTouZ+LxbhS4D7gPOC0mHzKgWOAiap6QEibBfwTuAj4MOQBMAqYjjXkY4AZWCO+HzAF+BQTJudhL9X5WGN9pKqOEpHzsQfsh0C5qu4nIs9gD++EUMZR4T4chT2IN0bvCfbgfxETTKl0BfqranQ53COBe4H/Ip5RWAPxePh9BvBHVb1NRB4A9gjXGi1jKPCgqj4Yyvi/cC9GAmcBT0Xu4dtATbjGw7FG40bgJ6p6sIhMD/fkDOAU4HLgZVXdX0SKgAPDPbgGyA/3N+6ebwGuAP6gqgeISDEwLaQfFY4F6IQJpVeBQmoXAfsyUK2qX83yLGyN3tuQPhMTZHHP5kvROqXuRxAcfwH2wgRsReS09dh6MN1UdQ8RGQbcBfwf8GugV7gWCf/Fh+F6vwoMUNWfishMVU2NMPqG/+QHQF/seUl6X17HBEva+wf8KOF+fEL8c3Bg3P8NHAd8CXsf87DncjCwmWQOwd7bH4dnogCYpqr7ish07FkYjMW164UJtKUx+fTG3uO0fLCOV2Zdr8cWhLssnPtA+Dw/fH4u7h6Ga6/z/GtYR6jZaIlp4TvbRmTNjZh9TwILgHuAWyPb1LD/J8Al4fvUyHndsZ75R8C/sR7oqph8JoXjp0XOnQnMBooS6vQ4sG/k90jg0VQewMzwWQhMAt4J3/+BCY7oMc9hPdBUXr1D2pS4+xLq1S7y+7+BWVjDMzOyzQf+muW+zgRKI79LI3V6j9CRyTinPbZa4rlYY3tLSH8z5h7OiNyPXwHnRY8B3gmfdwMnRs45HLgKawReB+4I5SXd88kZ+X4Xa4Q2A/PCfZgf8v4WMCPmumaEz0kZef031tOMvbckP5uTY+7H9PD504RtOtbgRc+ZhY2q9oqp8yygD/A81kin/tMLgD+Ee/cU1rk4lCzvS6puMWUkvRtJz0Hi/x05/0hsmYOKcO7QhLKz3cNUva8Avh1XTn35ZKtrXF7A1KR7SMLzn/TuNXVzNZTxuojsq6qzYvY9Tm3vN8r+InIV9nJ8JtgpCkXk81gPZijwF+AgVV0mIl/DhrUvZ+RTKiLnAfmhN/cd7EXrCXShds2PKCOidVXVt0VkL2p7imtEZCSwBOv13IwJrRnAy0HdkOqNDlDVaI9oGab6egq4WEQOJb0HNg8TPKm0hzBh+Ctq11QHWK8WNXhY2Lc36aqxCtJ7kdXU9sLfBnYDFsO2tdhTfBUbdb0G/Dzs+ySorVRECrEG+z2gg4j8Afgs8OugbkzZk54Wkfexxvi/gypkEzAR6+H+CviXBnWNiFydcM8XBLVEavS3EHgReF1VryMDEfkvEdlDVT8Mv3eP3Id3Mp6FUdizl5dwby8k/tkcFq2TiJyVupeq+vOQVqKqlZF6fU5Vt4hI6ndBOH+pqsapEq/FOhWvqurkcB1zsGftQ2xUMkFVPwr5rY97X0Je40L5/8ooI/N+XIH9N+2Jfw4Wxv3fYmrgk7H3cjDwW0zNdATwbxG5mbqq2woR6R65h4dQ+85sFZFzsWUWTg1phWI373xgiKpeJyIDQ/lx+azP8myKiIxV1dfCj8PCvrXhHn4ZOCJyD+clPP/NiquhABF5F2vc52ONYEo/nxpStwcGqursyDm7Yeqeyar6SngwjgKOBe5RW4M8s5yTgHkZ+ZQAP8bW6hDsBbwO67k+iTWc2xprNV3/37DG9q8h+XxMXzkeeAzTff45pF0DPK+q8yNlCtajmiMidwADsVEHmO3mU+zl2Q/rBW0rHliNDYXHZ9TrO+Gl7E263vkhrOf6e+zFSqkC1mAv2xPhuNPDefOAjlhD+VYoI6X7Twm1lFBJ1ekgTGV2XNj3PPbCbMRsBLPCtfbBRgfPh5ezFFs7pVpESsP92gyMxWwKBwI1wBvY8xF3z3+MzZg9LNyb+ViD+IQGlUAUETkWU2/MC3UdBFysqhMyngWwZ+F6Vd0Ud29VdUHCs7l7XJ1U9aMg/O8BOqhq1L6zIfwnXwG+DXwTUx11wAT3P0n/v+OEVKr8fcL9OxwYho1Gr6Du+zIb2BruQ2nIP/VbQ7nRd2NouB7C/sznYCQx/zdBcGHv5esZdZ2D2RsyVbf3A7eFPN/GOm9nqepMMbvDN4A3VPVvIjIEUwcNxp6XY1R1LzGb46vhvqblg43Ykp7NMkxV1jlc42pMnbso5h4ehY2C6zz/qroy6T9qCi4s2GbYq4Oa8W2b0VFVh0itka2jxhgXs5QRm4+qfj5yTD6mmlknIu9gw/lZ2AOYqtNLYnrxqJH0Zcyg2ScqFEKeQ4DHtK7Ou1xVy4Lg+ALWQIL11B7ThAcj9Gbj6Aj8DGvQU/VVTN9eJiKzVHXfjLJHYw0KmM46m5eWhLxey3JMXH0znQRQM3BPjbknU1V1dBgxHIn1PA/DVD0nEHPPVXVTOLcUyNNgEBaRmzAh83jmvQyCKuXhM1tVs+nOEZFvEX9vf0yWZyqzTiHtTeLtO/thzhHRTsvdWKMVZSS1ase4Z+Rq7FlK3b8emDop6blpNkTkEo03fF+vqhsSzpmmZnuZqWZDKMScLQ4Jo6sR2P2YrapbI+fFCenU8zMtcm9nAGVx+YjZK4ap6n1hZNsho1PXGUAjNilJd0IoAfI1wQmhuXE1lBF3s1NpP8N6rhMBVHV66LktFZHOqT9SRNYT//KkmBOXj4g8RIynElCpqrfGZRR6mndhapLow/oYZsBO/d4TeCZ8j3o9dSIMuUND9mjYiJzbGRsRRL12rlXV+8UMwMND+mw1T565mHpsZUY+r4fh8pzQ6C3E1EPXYQ3uPapakXHOEGBxpCFuj/WqnwAOiBx3G9nv+VrqOgkUish3gfYicgDpBugSEZmHOQm8igngiyOqqLh73gXrjQ8GCkS2dXYvxozm1SKykdre8iWYF8xMCV4wIpLy0HoBOFtV14S8u2K93j0S7m058c9Umndfqk6qem34/CRST7Bnrz3mvfenkHc+0F5VL84o81RVfTpLp+HVyHa7qn4azot7P9ZitrHngL9F3qV/Yza/JQllPEBdT6LrgC+IyCata/j+Zcb1RstOCYA01a2IXIYZ0d8JeXUVkXNV9Q5J9lrbGu5bSuXUM3z/IbZOxNdEZJiYK3AZZiQfgY00C7FR69ik/w9TJV4KdMOeiX7AXSLyJWK8yVQ1ybmkSbiwMKZivc/V2EvdBVgiIksxd821GQ9bDTZsnxVe8ArsDwd7CBdjD3RKh9kHOD4hn73DSOJ8TPf/Q0wv+x8R+RVmO4gO/6eK2UVupPZhPR3rZXbOEApHYg9WDbW6VTBB+DXYJkTivF1ewIbNqdUMvwzcJyK3YkP0j8KxA0LD8Qm1Ot0o3wVKMFvMdZh3y4WYR865wK2hIXkF80Z6ElOJHRbJozqkjReRL1DbW58SU16UHwF7aMRNNNT1Jmw9999l3JMfAf9U1RoyiLnno7AGogfmRJA5AvxOXIVCD/YfoVd5bKjLncDBQI+UoAh5rBaRXiTf260Jz9ST1Hr3ZY5akuw74zE1RqoH3h54XkSOIcMdW0TOiDZEoTPQQVXXEby8RKRDRrk3Y+rNh7Dn5ktYgzcV6zDcFTn2BmxUc0XMNQPcFrmHx2H/y12YSuYpEanBVDxrVPUSEfkj5sYdVbXOx9Spa4NQvgZ71zpgBuRvqOr/pQoM/8XXMIeHnxHfgfwV1qHpJSK/wEZwKzDPuENDVgsj9TggXD+qukhEOob0pP/vslDum+GcOeH5eBJ7f/5Duh2wedFmtpjvjBvwJ+CEyO/jMRXQIZjB9zzMC2MYpse8C2vw4rZYbxdMTxyXT6ynEqZjzdxeDPvLMX3mtPD7NMzTaiUmtFLbrVije2iWa0/ydpkelxbKHhFJGx7S7sF6k1dhPerLgcsbcO93wwTJAsxwm1T2DKxBr8F6g+vC73WRYzph6sHU78eAXgnlfiEhfTjWcL4dfu+HqVbS7nnYN4uIB1xMXp/HhMFNwCkhLfWfxXnBlGOqjdT5gwiNady9zfJMZfPu64EZd5diz/ZfsV580v/9D0zIf4g9389j+vGHwv0uxWwbn2KN+0jMNfTj8J+Wh7S492J6+NwYs29WlmtIu4dYh2hm+BwUyr89/O6GCfP8yPkFmIowH3g3oYxZRDzywrEpD7pYL63wuSfWqH8L6xBNiTl2BvBW+J7ycIp6A8b+f2R4PYXrmBn337XE5iML4xBV/Vrqh5qR6SZV/bqILMZ6VZuBvxEM0GqqoDi95dfDKOHvWA/9XGzk8W2s95+WD9bDn4/96ds8lTS7PSStR6mqT4qtc/51VX0jUpfbsB4cYt4baaj1fpO8XTaKyOGq+mo4fyxmMC6NXq+qfhB6qAvCVhS2E4FnxSbnxamKlmEeUkuxXtFZhF4WsFxEPq+qT4WyTwNWqOr+cTdDRMZgwrGj/ZQ1mEHwV8A0MZ18mpMA5oFzHnUngh1LmKMQjp0ZVIUbtG4vXoEHQo9zHOm9wP/FDOSpGdPfDfcw1mMnHPNj4FWxeRKC6fwvxTot0XubIvpMPUTtM3WbJHv3iaqeXydRpEJERqvq1PC7DPu/h6rq2SJympoK8iHs/yrW+BHxGVgnYULI5yjM2F4pIudQq+48C/M+I+z7HTanA8xg+4bYnIros5Ma9S6I3kNMOPQN5acM3yeHTbHORQdqR2el2HyS6qBe+knMfXoWeDiUA+YE8Gz4HuulJeaRtQx7v1PUhHYipZraA/u/Hgl5dwnPz39hnVZI9s58SUR+hKlQP4s5ITyNjRLjvMmaFTdwAyLyPNab/HtI+iL2IJ6IeR6MDsdFDdBJhu/vYD2vsdgD8hrwPa11IeyEmQpShtCfRqqiWMORj/WMkmaQ3hPq+0NsSP0dbHTyPdJVBkNDvmlGv22F2ct/CzHeLpi3zv3UemSswvT/38V691GvoHwNagkJLpkiUqaq5WKT8+L4HrWTtV7CVFDzQh57YI1s33Dsp8CXVfXDoA5K2VEmquo4sQlql6nqK+H8wzF1QT7JTgKxEzGBL6nqgZJupJwejou757Owmf5rqG3YFFPnjNKg0grPzjSs4Y/1ggnH9QjHgPVgt62lLHXdXc9W1ZRKY1sa8HNspDGPDO8+EfkAUyE+jDkyrAnnHYg9/4vC8bth78GdqnqQiLyMNU5LMC+1jZjH2kOYbeIlMWMumUI9pJ+BvReHhvszCZsxvxB7V44LG5jr+FXYKCiO5dnuYSYicgk2OpwYru0z2Lv1N0zIjwuHFmMTNN/DXHO/Tq0n3gvA3UHAZHqtDaPWS2sg6ersZcAHWMfo+XCtF6nqxNDgb3MoUNUXQn1jvTOx+x3nhLCOGG8yVW3WsD4uLNj2gv6UWs+c17AXbi3WE7qAiAEae+i/RN3ZpYmzJsPLeC/W+yXk/V+YnjVF9GHtQ/IM0iR32weImcGtqt/Ncu33xSRrpPHvFBLWhd/tsGF21IvpDszIGOeSeQWmZog2mu1SjZ6Y59EJWMORj6kRfq2qP0jpvTV4soh5tkR76+didosTNcNNVUSmYjOjD0y47tj/Ssy4+i3gH2qeLWdhL+gXiL/n72JzaVZk5DMTOEpVV4Xfu2O9wCOIIXJcV6zxifr8b024t4dojEcX1jB3jZT1Mqa//zgccxD2/J4e6v93Vf1rGCFGvbS2is3QfgxTx91HrU6/CLgSU6mcjDWSf8V09FOpnX18AVCmqmfEXXd9iLmoH4Q1lpNVdUlkX6+M+3QwMYZvVZ0WBMpB4bjJqrooobx2WMN9VBPq+ifMZfpf4ffnsOf6S1gHQMjoACTkMyguPfX/5QoXFvUgtWEh0kJlYN5Kh2T0QGdSOxTOZAwxvV8Nczki5bXDGqLSuB6uqo7KOD462pmmMW6AWC+wTp1U9ZiY670gNByXx90PVf1dXLoku2RuAI6LNPgdsB7WL7HG7DNYD2wS5rJ4r4hMUtVDYsqYSXxv/UXMIPu3cJ1fxFQcvTDj4p+o6yTwR8xQOiujjLg5CudHX9SMe/48cHq0xx+OORcz1E7AGonzsNFZ6rjU/5HqBe4eGubvYsb36VgD8wbWa9x2b8Xm6/wVqMJGCCk6YT3YB7Ge8eMh/9OBP6nqbRl17IEZ+c9X1XyJicelqn8hBhHJV9XqyG/BhH1HrKMV7Uz8LOQZ67Ej5jX0v9SdGPcQJpheDNdxJNYJWoFNrOuL9dwHYp2kak0O7xIdkb6kqk8nXFdXrFN4Yaj3IOrGRkvyWuurwT08kl+lqtYJ8Cfp3mFF2Ci1QlU7ic2fiHIHNqp7hvT3uB32XF8Udy0aVIrNxS5tsxCRm1X1e5KgV1fTbReGRvd0bLi91d6LOnrL1MzrFyJZFGO9vEXYg/xKJO9XRaQqplolWGPxqSTMIJVkd9tYN0Dg7Iw6fYHgYit13U9Hhp5n5oSeszE9a6YeOcVGjXfJLNaIj7uqbggjozMxoXhLqpcnIr8Oh00Tkacw42qaWy0mWFaF753DZ0rt8dOMY0eFzyGRNMVGhIcDF4lI5lD/QKwHPQEzjq4DLhRzQ4675xXAdBGZQN1JihNDfgpcmeoVi+m2M0cPYILiQKz3eXQo85eYYIre20XUznMoj5y/HuvJvoSNOipCeb/GhM5tYaR4BrXeSE8AB0lCPK7wP2xzDY6UdYqIPIoF53tPrddZhQnYOp5gUhv/Kc5j50FM6J0S7vGFmKrpCuAADS7D4X14HesIHIIF5zxARI7GRjCpUdbJWJyxZ0Tk+pgR6XdE5FBV/VHG85yPTZq7FhvJfZ+6akpI9lpbFEY0URXtEhH5Qbi+isg5KQ1DStCeRq36MSUUBHtGhmB2oc9l1OMGrPP6Z+qSes6bjV16ZCH16NWDHvbb2HB7JunD7ROIUUtomBsQKSMP82R5i/je76nh9ybSH9bXqTuD9GxVnZFltHMrMTO4VTVlpIvW6wNVHS7J/vJzNTIBLgzjd8fsB3H8Fuul3o6pA76LjaYGYPFzoobT2zFVVKYKJTUiilWNYSOSG0jXPf9QVR+OOT4rSUN9zMaxBlOlRBuJLyfc89/GZaJmDzoTE0qKhcV4ImH08LqqHisik8NocjpwsFpU03cwtWTcvb1AVet0OEIDeKDWzlMpxlQv+wbh+E/gEU13hngPc+PWjLxeJ8Y1GBu1fIn04Hx/x2wdP6CucOmWOSqOlJGapBkNRDgZ6/wcpbXzXIqw/75IVceI2UIOUNWa8P0TzAbyWew/2oi9d0LMiDQ8a9HnoApz+KgSkTdV9eCk+gJnqOqC8HsQJnSPI31u0stYJzPTFVtVdfeYfLdpETLSRwPfVNWvxtWntdilhUUcYUg5QFVnht+xBmhVvSZyzja1REx+I7CewicJRbYL+Z5H+sPaDmusts38xGbjphqQUQTjIjbB539Ib7hS3VAlveeRF46/VVXT1gmQiL+8JMxwBl7QuuGyf40N+W+hbsiN3Uk3nA7HRkh9MXfMFB2B11T1goT7hIj8FTMWrsaMtJNVdYkkTCAkTMgixkkgkmem3vtfGm/LSLvnoSOxrXGLOf4OzEiZ8oz5YrjeVBiRSUH47An8UlXPFJEnsMb3e1ivcDWmnvgK8fd2CvGjvNupG0rlz6p6s4iIqqrUNZb/A/iOqi7OuI46z0HMtR4Z7ksXbHR1M+Y5FBW2Z2BCsY7HjgS1o4g8h3V4UnNx/oV1fJ4M13ka1mnrH67pV5gRfBkmPFNOKZnhPm4i3X7UDbM17id1w43vh8V0+yHWeXucuirMEzFVZZrXmqo+F/LvaIfGzxoPx0TnQ+WF+h+pqofGHLse0zhkjrJTwjj2ndEsIVmaggsLQGJi82MN1+Ui8j+RQ6MG6GIy1BLYC/0T0l/gJcBVqvpYI+uULRzFd0g3Lv4WUy29hjVET4VTTsV6VinPLMEE0nxsNvarMSqtHtikn1FYPKcUKfVFddKIIMu1RA2nizHBEBt4MBxfTPy6HA9gL+YRmMpkGtZ7+ww2+ro/HPdlTDXVnmQngc+TrvcehP2vrxFvy8gcYT6NqcG6ULfBVqwTsFeqpx4E8TuYC27m6OEDVR0ezSA0wJ0xwXCPxru7do/8LMZUhd1U9SeSEUpFVaeFc5JiQ+1FejyuFBMwu1Oma/Ba0oPzPYCpeV7HnpHM61lPgseOiJyCqagGYKPpEdgIYjbxdMJUVHmYqqczsL+qXhLKyuwAjCXdfrRtRCp1w40/iT137WPKVQ12PonxWhORfTFB0y2kr8CEXifqjrSirvFVWOfnT2pBR6P2wjxslNQd+2+iE36fxYTItIS6/ldMepNxYUHt8E8SYvNnHJsyQHeJU0vU02ieTEYDqCEEQ+SY3bBp/H/FRhupEUInbJGcPRPyLsAMgSdrrVtuR+AZVf1M3DnhmEyV1jNYL1GxCV4p9g3bANIXA+qINRALiV9M6GHSYypNxNZZ2EoCoZcb69UVRnEHYi/bN0J5mzJVHKER2KoJTgJBbXEMdfXehxLvthgV9or9Hxuxhi0601iA32Av8WVa64E0COvxV1F39HCUqnYWkfGasWBSOPdVLDhdnQWLYo4tV9WyLPuTHBEuSzhlJPGuwRAJzie1kYG/gxmizyO9R56yMzUaqesVF9eRmom5x9YxfKvqPmGUkfKMe0tr7UepDtj/Yna325LUQRnlxXmt3YB1TCaEY44CHsHel+lEbEGaMMM/nBfVZqQEyWPYpLw6bsmZaS3FLm3gjlAQHqZzMDtENlIG6M0SY/iOe+HFFlCaE849GvONPgvrKWRyAubd0B978FPCIhWOIpVnHcGDxU+KNihbgN5ivvexK8ZR14D/kogsA07VdA+gzpg7ZlIo8umq+r9iiwl9hBmwX8Zcgwsxjw6wXv+dmLdOErETwcJ9LMWMta9gevllIvKGxE8g3CxZwkyr6kqxZWbz1KK+3gyclFCnsyLfi7He6nuhrmkujUG1tBp4T0RS//GBmNpoLfAXtejBE7Be8SCxyVbDJd4LbR7wmpixOaqKmBj5nlJl1PtOa4wjgqq+FHesmP1oqNZ1De6QoWaJTogD60Ao9t9vFXNBjqvLVLGVCW+j1r7zCqZm64L1oruFMsEEUP8gHFJ0xEaE15Fu+L4U+FwYZUGtva2viPQNz38q3PhXSA833pvkeU6JXmspQRGubaKYQ8HY1Agzcv9ujbsfkXO/EyMkKyRmwq8krPSZ2RHdXlxYGNdio4XXND02f8pYGOctIaTPvB6Ovcg9Qq8jOiLoB/QMOtKZqvpzEfkt5uGQhqreD9wvIl9IUl2JBbSLEzx/Ad4S031D0FVjRu7MWDqpeER3ETODHJtVeyN1BdKPgFWR0UsnETmY2mfpZGyOwtrwch+Y0fN5MfTqs5Hk1fUkZm8ZGeq4RkTewEYu9weBBtZQX4T9X08Be4gt+dmTWs+wNeFlfAV4MAjIisyGP0KaIVtE1mGCUxIarj9RD6kGWkRmUxuivWPMoR+GLS9jf7ROqR7oOWQnNjZUEKS3YeqoIuzeVWDG7ahtY5v3XIbASbmivop1TNaJyDWYOvEs4h0BUh4792Gj2dR/c0FIKyV9NvjJhGVVie+wTIl2ALDG9EBqvebiyr4YG6H+QlXniwWxfAB7b+6jtvP4ATZKvodkr7W14Zqjc0xWElmbJUIx5uaccs44G5vz8gbQT0SmUSskU+qs8zBV9y3UTvg9j+yxwJoNV0PVgyR7S2Qavg/FehglmEompb5YjxnDvqLm7z0J63WvxGLNDCUGscio94Xz/0RQdamFIpkZETz7hUbv36p6ROhFbZuMpTYhKaVm+xVm/HsokhZrwMcEycOYZ0vUnfF4YHSGLn4Kpls/HevRH4T1CsdhPcuzNX2xn0cz1QgZ1x47EUxDsDkx9dpFoW67qWq7kB43gTDJSaAU80ATavXeD2oD1wAIz8VL2MudZHtJnFAWk18e8EVV/VuWY9KM0k1BTNceZyx/DvNu+gc2QvkK5oywJ9ZhmIA1RCk16IPE8z9aO9fhOsy4/BNN8CwKdYqbPzQda58arHYRkf8QY/hW1bFJZWepU8ozLU6FmeS1djg2x2QsZlNbiTl2jKSuLagXcLgGbzZJD43+OnXVWb9U1WhwzWhdm38J1Rh8ZAFIlgXus/Q0o0PwYqxxfALr3d0c6VmNxhqUbmLhrH9DrW/83Vmq9V+qeouInIAZt76M9Viep3ZR90qxtY5XYjO+UxNxMifjZItHlHkdJ2Hqle5hyP3d0AN+ScydUaJDajW3xQJV/aGI/IbaxYQqMe+VvYEJYqG/wYbKF2e5blQ1dV9ewrypABALcX4ENrr4CHPXfCVJZYDZDEZjhuVUHlMxYVcRacxXYbN2EwVF0ghTVW9POP6rpE8ou01ErlXVexOuuUbMmaKOsJCIURqIGqWvoTbygGK9+mvrEXgbNN5YjqrOldrJdveF3u3NmKttivJQ3/sz8wj5fC98PRnr5LQDekq690/0uh8HVorIBZFrPxd7plPvULSnPq9uLtuYgY2Cvk9tB6BDaIgz7WZHBlVn5ryhVCdvlSSrMD8N7/I/gRdEZDUWOHEPzKaXhz1Tgj2rJ2Xk/2usvehE7ZyhDpiaF+LVWaViKsG43n22lT6bD22FaIU7+oY1SgeRHhkyMXJnQh7tsIcwFTnycKw3djLmXdQeixT6BOaO931swlpSfql8bsF8uqE22uQ12MN2Jja8XYzN8UjKKzUJblj43QcLmZ7tOlKRNZ8L13AApgp5nNq4SCk1xj9DGVdjk6HAjH+nYMPrTtgo4SeY6m10PfeyN9Y4/jv83htTZ/wAG/EUZBz/b0z9klrLuh+mRnwv1Ht02I7CDJ5gNpMFmLrhfkz4/FeWOg2KbP0y6xBz/GxM4KZ+d8dCaGQ754ZwjQOojZjaLTw/AzKfT2wC6DXYpK0h4f7/p54y5mLqixvC/9o5pL+MqZ/+gnVovk+WdZwxYXkT5kH0YmQbh81VmRee0fuxBvEZTD34WNhWAeMi9/YpbOS6LDxPA7HG81ZMQJVjgqtLljrViQCMqVfvDvU4hlq114Nh//9gI4FBGdvocJ/Whs8PgJNi8j8S86QsCv/5qeG/SOUTt479TKzD9HHk+ZsPXBj2PxH+18FhuzqkfSGynY+FIroVU19tDeXPxObEzGxqe5h4f5s7w51xI8vi7I3Io2t4EaeF32khqDGviHswO8PRWK/rkSz53YeNIlKG8Y6YtxU0UvCEcw7HFvIBe9GH1HMdp2A9s5GY0CsPL0UvzMC2DIsY+1BIexgL2ZAK7V2CGf9ihWc9dc1s/AvIHrI67f/DVGbrw/YitSHenwLODMc0ujFv5PPwOjZ5LPW7CJtnkO2c+THbPDJCU4fvM4hviBLvU+SYgaGxuQMTktOxhq09Jth/ik0CHBqpQ+b2PCbA38MazHuxHnNsxyQc3ydShz5YRySf0HDH1HNMeManYQ1gbCOIjRpmYaOKmZFtPuZVGLtsQPj8KTbyfAWLCdY7ckwBpoIbiXWMUu/f+IT6vhpTp4q4OoVjdsNG36eF7w+E9MsxIZDSEtwMdI0pLy88Z4Mwt+dvh21/bLGlZm0nXQ1lrJCEBe6TSFJLACcmqHxGqurekSwmiEWXTOIS7AGYpxbFtTu16pv7sYYw5VFxHtYjjDVuBrvEGOJX5UpSr6Qica4l3SccQtjzjDL2UNUvSgiFHuos1LoLnoz5kT8jItdnuW6wcAqPiC1Oj5qNKDPkQpSKqMoAEwRTsYmHSfNbVpK+QuJ66oY42R7mAm+KSNqEMgneThoTY0tVh8RlJCKPxhmlsfASX8I6ImCG5OeyVUrM82gsps7bH2soX9VadetGTO+eOn5M5PRtczkwF+06akq1CZvbJoOpTfJbLCK3aPqEv6VYeP9qERkkIkVa1zX4QWyk9TZ1Z0FHeQjrYCR56k0Nz2fUblYd6vdz4OdB9fxFYLJYZN47SGc40FWye639VETuxqITr8dcpS8gfdLcbqr6ptR6aKUm6/bF3se+WGfnaGpVYlDrMBNlGNZRO530WGAPYJ3R22LOaTIuLIzLMCP0niKykBA8rp5zTol8jxq+78Vmkd6kqmvEXHKvAL4iIoeo6iQAMQ+iKVny/wfWW5sOoKaHTjVmjRU8Z5C8KlfSdQzBeimDSX9OziF+wtwWiY/bvyyLvSSJtMY/Q18cx+XYqGF3qfV6Ogs4Ohi96zgJ0ITGvJGkPJhSPBk+47ydADNgh2sZqKqXisUcG4E5GNyCqb8WYr30y7BRwfeojUWUh927r5MconoBNvnyl6r6jUjZp2AG6UGkB87LzONmsXAXKY+1xWJeSouonYwWx3ixGdrRGe3/Cd+TXIOXa0LAvyhqy7GuxWwdcVxBrd1MwjVm2s2WUbuMay/SV5ZMkQoBk+S1djHmAFBIrXCbo+ku6D/G1Ipx3mFVmKDZnfS2QbCOQk/qTvi9EhsdxcYCiymjyezS3lAxvYP2hBcOmqXBiJb1HvbiLwhJA7EecJUVVSf67HHYw3cIJjju07DokFjYi9szBM9lqvqVhLLfUluTIDUBqRR4I7PMjHNmYGqzzJhA3yJmwhymq76ajLj9mBdInRAMmrD2QCh7NHXjYp2lIQRLzPHFoV4nYIIh9aK8qTZz+wSswb0aG+qPlnQvsDqEHmerIiIPY+q+r6g5WvwWW0/hF5qxbsV2lLE/phL8DPYMzsFsdldh6qNZGmkUIj1gqJ3L8d+YS2l01nUn4OcaFqxKKPtM0j31ngjpSf/Fq5gAGE/6BL9Gh7EInZRo+PXNIf2bWAeoJ/aePYI932ep6iMx+SR6rYnIbM0IodMUROROVf3vRhyfGAtse+uSVs4uLixSD+kIzG/6SUyKn4rN8kyMU9SEsgZl268JXldicwfOxV7ObphhcAO1gkexntL7GaON1PmCGcv6Yb37X2HraDykGSGrM86LDaQmyWHQf4e91IdAw+L2Z0NsRvo2l1fNPuP7ESw6bMqd8zzMuDoi1PEWLBbQE9KA2bnNgdiEuzovl8aEhY+cM0UtQF7qHqcEdZ0QK5Fz9qPuZKysjamYq/XhWMOdesbnAcdqxvrjGdeRmstxk6p+kK2MpiB1Fwb7K9ZTf4faDotqE8JYSEL4dTF38odVdXrG8VNUdQwxJO0T81a6UVWzjfLrrVOW45Mm/D5DQiywhtSjoezSwiKF2CpgjQqT0Ur16o69zF/GhvnPYUJtBDF2gywCZxam3qizKleWss/DdKLPk+4ffpfGr5y2KunlaiySfcZ53PHvZgrKoJZ7ExOSQzD9fD4WTbe3ZA9L3xzXEA25kQoLX6Wq/5vlnNexkcRrYfTzR0ywgxlvUzrs1OejmJdZgxtTEZmCebylQoa/oqofiy3OdR02yoj+33dQd3awYq7mXyNmfYqEcs/EDOC9Qv23qbkkfVlcqF0Y7KFm6qk/QEz4dc0ecuMGLLZTZmjxVUn7MK+pPcgIFRM3gm9MncJIoQRz0jgK0ib8Pquqe0pCLLDmxIUFpGbQ7hcZmrbDvC62+0Hdjjo9gQmFB7BewuLIvsReT0Je92Nqq8mNOOdXmJD6kEhDhBkTHyMjDDrWIMe+XA0tM1J2atTSoIldSWo5TA02CnMSWBOE73FqAeSOjMtLE8JeNAcpdWCW/cdjI8ioKu9ibFne02KOryMkG1CHnqq6PCb9eWzEmql2PJT4kO1fwIRNeTRdk6MOzMVCyLwXs28m8cviltOInnoSkhB+vZ5z5sckq9riR7H7qOsIkjqpTieuMXUSm6D7PcwIXmfCr6r+X315NAvazO5VO+OGvaAzsJWxfoZJ+6tyXKdzgE7h+9WYp0PW+QlZ8nofUyF8SMSNr55z5hJx/QxpecA5CcfHulg2sb7Twmea+3GW49/DGriPwlYT0taGeuXFnFMaTcdGHSXN+P9F50n0wOw29brmYi68J2OOByn3zgcSjr0Ha3AaU6/OmMpwSth+G9Ji5xVlSZ/eyHJfq+//zkibGv7DLWzn/AHMFtGnsee15NaUOmHzlFJtwjWY2qlJbUJTNh9ZBCQmTEaO6xPtXV9PZInIJuQVay/RLGv6isg/sRj9yzLSk/S17TG1VDQY3F2qujHz2AbUdxwxi9hocpiHJHvQWEzo7ktdJ4FJxCz3qgkhFZpwDfOpVRltxYTYtRqCHSack6aTFosGC+Z4cUXMKSsxL7Al1KP2iOT5GPHh3OdiE/qezzj+j8SHbL+ehPUpEsq9BZtL8E8yjNViARzjFgZLeUu9E80r23ObUPYEYsKvaxaVoyR4pqnquGz7WrhOjRpxNzcuLHZQJEs8p1YqfyKmD59Mug77XeL1tXdR18jcWVXrC2wXV3YJjfSgqie/qJPAJ5gb7Xc1Jh5RZlpTEZFzSA+oNxqbZV/H7pJFJ31MqGsNtWuUpFDMo+lyMlRH9XQC6lyjWIyjPUhfb6I07J6N2a7mkR6yfQgJ61MklHtfTLKqrcE9Iam+RNaQaCpNUTlKXc+0Ekw4jsq2r4XrlNM2wedZ7Lhki+fUGiS5M/45fEbXP1BsTYnGzP1IRG1C3zJslDIHU6HNaUpeGU4C0zBhdjgwRERGa/pyr40eBWXharWJhYdjjf5N1Eb6zeTr1Oqky6kVFuswdcNGjazul0JE3tAsrqoJbJT4cO4navoyuvV670nyWuJxxyfGA1PVWF1/c5GtAc5C0iTT+va1ZJ1y2ia4sNhxOYf4yX0tjtgCQ3/Q+IWWkmYZ/1UaN+kwW/mJM84bmU/USeBUrXUSeFhEjgX+ISKp5V53w9QfzUWDZ66r6i3ALSLybY24M4vIMar6ooicKfGB+KaJrfXxNA2fhxAXzv1CTC21rYdan6pHEtYSx7y5osf9r6r+RiKhzaOordvQncYHRGwwksUTK8tpSZNM69vXknXKWZsAroZyEhCb2fxtDYvSR9KTZhnfSCMmHdZT9nTCjHOtDQ+ddenWhHyiqqA6LriSvtxr1rkcjaWxdpfIeVHf+zMwI+bRpLvMRj8zUc3uOtsOm92+BzYXZW3IqxM2mfFxbUCjIGEiGDFriWcct1JVu4tFo10dU9n7ReQFLJBhaib6+djqgcfVV4+GIFk8sbKc81liJpmqRYCN9VrTSKTYlqhTrnFh4cQiNo/iAMwAF7VNbCRGX4uFy0ikMUZJacKM84R84pwEblLVvRJ66vX1yhtTdqPtLlLX934U1pCnQpKkhIOGujY6woCIPEu8K+zPMBtENfYf12eDiF3TQVX3yTjuXWztjH+Tbo8hXMMqiVmPQURmaTPNQBaR17Rpa1p0J2GSabZ9LVmnXOJqKCeJaxLSfxunr22sh0oSQfc7Luhmu4jI17AJWvWuPBdDVBX0x6AKSq2VERf7R4kEwdse1BYpqhNQr57TxhDxvZfaCANlxEQYkNrlSFONziuY4f5TkumvqifGpMfFKspG0poOmdxJbbyj8kh6anS0O/C8NDIgYkOIdAimBKP0P2lc2JAjqVWNFRJmSEut19ozkbJi109vgTrlDB9ZOImILSoUXeR+mdSdZbwH8DfNMtmsCeU2esZ5Qj6JqiARGaKq8zOOr5PWmojIP4DvaHp01tQor06EAayReYj0xYHOV9XPZikj1hU27Ps8kQWCtIGuoGKePZ0xlV9m5NjUMYnxjkRkPbWjGqhd0hXq1+Nnq1ecB1aK+tR1d2Ah2qOBDz/ClhVOnEndknXKNS4snFiCvv9GbCEkweagXIF56GyXvrYBZTd6xnlCPomqoJSKK+P4clUti82sFZAE33vMrlInwgDmJTUqI49Y91+pDUVfQLwr7L+wjkHK9flcYIqqXtU8V5edOM+qJnoMNVd93gf2iozy8rCQOxtJn0kN9k78SRNWTWwruBrKSeLHWCTLZQBi4ZH/E3rl5dTqa7/bWH1tAzgYOF9EPiY9dEijbBZxqiAR6SwiXwA6Z9gtOtEAF9AW5mcJ6Ydjaqcnwu/TMRfm4yR+OdI4TklIT/E0MEpDIMEgsKdh0WhblIZ6Vm1H/vdjz+ma8Lsrpk7N1oufizlppFRrA7BIrqdmeq21Yp1yigsLJ4k8TZ+9vRLI2x59bSM4oRnzymQE1nB2Id1usR4LjJczsvSkXxKRf1MbYeBiVU25zd4G/B4bHbyOxcOKy7s+V1iwe5KK5dU58eDm57vUelYdnfKsasb890s1ygCqulpE6pvI1hF4T0Tewu7tQZid4SmwUSiNiBjbTHXKKS4snCSelfTFas7Flig9KvSCovrafs1ZcHMZyxPyfjLYMq5U1eZskJqMiLyqqocH3X1UL7zNIym4+2bO/r4WW7d5dcinGzb5rym9019h8zYmhHI/Q/qqcy3JJlXdJCKISDtVfV9EmjOIZ56IdM24T/W1fT/Jsu9H2H2eTiRiLLZaZUvWKafs0JVzWp/wsm5W1SuCmiYV9vgTbA3uuFnGO5WuVm0pz9Np3t5rk1HVw8Nn4ip6CeyXamzC+asa2zsVkbFqM7cfx+xTKYeGK1V1SeKJzUtDPauaym+BN4IDAdjSsL+o55zlmhHtVkSOUptncReNjGLbTHXKKW7gdtKIzG14QFW/HLN/u/W1OwIi8nvMHTIzpHrsmhk7ImKrGR6V0Tt9qTHzE1JG/TiDfy5oiGdVE/PdGwu7AvBipiCIOf5tbKRwI2bL+g0wRlUPTfJaa+k65RofWTiZFIktfHSYxExcU9XbpJErfO2gjAqf10bSlNqXd2egOXqnW4M7bX8RuTVzp2ZZIKglaEEPqG5AhareJyI9G+AmfTAWjuN1zH7xILXzWXoA7wZ7RoMixjZTnXKKCwsnk29g4Ra6UHfimorIGcSs8EXj9LU5R1s4eF1roLYs6BRqBdyZTeidnoLNsD6B9ElzbQZpWqyxrZibbHtsZDFfa5ec/VmO6pRTXA3lxCIil2h8pNNGrzq2oyIiJwP7kO7bf23yGW0TscCR39UmhA/ZGZAmxBoLKr4nsZFnTywE/xZVPTtXdco1PrJwYlHVe+LUTdjCObtRf+iKHZpgpCzBgvTdjYWYeCunlcoRweD/JWwFvbbIFlVVEUlNsCut7wTMjXoE8CNVvVZEvo2FU0nNOI/1WmvhOuUUFxZOLJKwoDzNp6/NNYepBRmcqao/F5HfYsHudlVeE5Hb2YkN/ll4RBofa+xibEGpY7DRxXpgGTTJa6256pRTXFg4SaQFtUshCSt87YSkFjqqFJG+2KTDPjmsT64ZFT53ZoN/Ej2BRzE37xHYHIr6wp8fHLwCp8G2SXOFOa5TTnFh4SQRq27KZbyeZmZc8O3/DbWG3buTD2/btAWDfxY+q6pXAtuCUYaR5JVZztkabDkpNVFPqLt4UyvXKae4sHCSyFQ3jQVeo3YhnhRN0dfuCNyErRp3BLbozytYOO1dErEIw78E+qrqSWEOwKFxTg47CyLy38A3gd1FZGZkV0fsWc7GrVhI8l4i8gvMpnV1juuUU9wbyoklSd3UVkYWIvIIpodOrc52HtBZVc/JXa1yR4g9dR/w4xAssgCY1pgJfjsaYkvHdsVCmURDl6xX1VXxZ6WdvycWzFCA8doMq9ptb51yiQsLZ5dERN5V1b3rS9tVkNqV76ZFXDljw507uyZ5ua6As2MhIq+Gz/Uisi6yrReRdbmuXzMyVUQOSf0QkYOBKTmsT66pEFsqNKWjPwRbn9txAB9ZOLsoYXLhCGBBSBoIzAaqMBvMDjs5qiUQkdFYuPN9gHcwb52zVHVm1hOdXQY3cDu7KnHrUO/KvIsZdCsxW84/gQ9yWSFnx8JHFo7jpAz+66hdVvU8oEtzhbdwdn5cWDiO4wZ/p17cwO04DrjB36kHH1k4juMGf6deXFg4joOIDMq2vyXXRXd2DlxYOI7jOPXiNgvHcRynXlxYOI7jOPXiwsJx6kFEfiwi74jITBGZHjyFWqqsiSIypqXyd5ym4jO4HScLInIocAowWlU3i0gPoCjH1XKcVsdHFo6TnT7AClXdDKCqK1R1kYj8REQmi8jbIvJHERHYNjL4vYhMEZH3RORAEXlcROaIyPXhmMEi8r6IPBiOeVRESjILFpHjReQNEZkqIv8QkQ4h/QYReTeMdG5qxXvh7MK4sHCc7DwPDBCRD0Tkjsg6H7er6oGqOhJoj40+UmxR1THAXcCTwGXASOCiENkVbE7DHaq6FxZm45vRQsMI5mrgOFUdjU2QuzycfwawT5j7cH0LXLPj1MGFheNkQVU3AGXApcBy4GERuQg4WkTeFJFZ2DrV+0ROeyp8zgLeUdXFYWQyDxgQ9n2iqqmV0f4KHJ5R9CHA3sBrIjIduBAYhIUN3wTcIyJnYoH/HKfFcZuF49SDqlYDE4GJQTh8HdgPGKOqn4jIz4DiyCmbw2dN5Hvqd+qdy5zglPlbgBdU9dzM+ojIQdgKbmcB38KEleO0KD6ycJwsiMgIERkWSRqFhcEAWBHsCGc1IeuBwXgOFuH11Yz9k4CxIjI01KNURIaH8jqr6r+A7wP7N6Fsx2k0PrJwnOx0AG4TkS5YnKS5mEpqDfA2sASY3IR8ZwOXici92FoSd0Z3quryoO76m4i0C8lXY2tNPCkixdjo4/ImlO04jcbDfThOKyMig4FxwTjuODsFroZyHMdx6sVHFo7jOE69+MjCcRzHqRcXFo7jOE69uLBwHMdx6sWFheM4jlMvLiwcx3Gcevl/eYmO2HiELysAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text.plot(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('skipped', 1), ('aquamarine', 1), ('elling', 1), ('mod', 1), ('mdp', 1), ('dissociated', 1), ('reformulating', 1), ('integrality', 1), ('megapixel', 1), ('quartic', 1), ('3cm', 1), ('polarizing', 1), ('acquirement', 1), ('haemodialysis', 1), ('adversity', 1), ('transcends', 1), ('paring', 1), ('physio', 1), ('catastrophes', 1), ('xhelp', 1), ('crowdmonitor', 1), ('duplications', 1), ('needless', 1), ('haiyan', 1), ('relationally', 1), ('dcs', 1), ('transilluminator', 1), ('pearl', 1), ('openpcr', 1), ('tinkerers', 1), ('macrotasks', 1), ('unskilled', 1), ('substantiates', 1), ('selfies', 1), ('27k', 1), ('neutralizes', 1), ('misclassified', 1), ('unwarranted', 1), ('byod', 1), ('dispatched', 1), ('imap', 1), ('tactons', 1), ('signified', 1), ('demenita', 1), ('multifi', 1), ('equalizes', 1), ('hyperboloidal', 1), ('parabolic', 1), ('75m2', 1), ('ceilings', 1), ('mandated', 1), ('federally', 1), ('southeastern', 1), ('irony', 1), ('alcoholic', 1), ('sober', 1), ('relapsing', 1), ('2842', 1), ('underrepresentation', 1), ('reinvented', 1), ('hemmed', 1), ('bottoms', 1), ('heralding', 1), ('turnover', 1), ('plazas', 1), ('kenyans', 1), ('transnationals', 1), ('ramallah', 1), ('amari', 1), ('perpetual', 1), ('extrinsically', 1), ('clans', 1), ('clash', 1), ('crpgs', 1), ('mentalising', 1), ('beta', 1), ('theta', 1), ('differentiator', 1), ('conversant', 1), ('awaits', 1), ('prewriting', 1), ('specimens', 1), ('biophysics', 1), ('polycephelum', 1), ('physarum', 1), ('slime', 1), ('chemotactic', 1), ('bpu', 1), ('biotic', 1), ('paralleling', 1), ('nss', 1), ('markerless', 1), ('insist', 1), ('reinitialization', 1), ('centimeters', 1), ('extroverted', 1), ('phsyiological', 1), ('masahiro', 1), ('anthropomorphize', 1), ('superimposition', 1), ('composited', 1), ('namers', 1), ('dressed', 1), ('detrimentally', 1), ('overhearing', 1), ('moreadvances', 1), ('decks', 1), ('jungle', 1), ('nomads', 1), ('borneo', 1), ('malaysian', 1), ('885', 1), ('unrelenting', 1), ('collocutors', 1), ('guider', 1), ('resurfacing', 1), ('stimulants', 1), ('tweaked', 1), ('textalive', 1), ('preprogramming', 1), ('prot', 1), ('terminologies', 1), ('electroencephalographic', 1), ('rejecting', 1), ('polylines', 1), ('polyline', 1), ('handbooks', 1), ('2448', 1), ('streetview', 1), ('substitutions', 1), ('usee', 1), ('uncomfortably', 1), ('crm', 1), ('sketchsliders', 1), ('mystery', 1), ('paving', 1), ('10x10', 1), ('delineating', 1), ('analogously', 1), ('257', 1), ('fowler', 1), ('christakis', 1), ('culotta', 1), ('district', 1), ('210k', 1), ('minutiae', 1), ('worsen', 1), ('commentaries', 1), ('poli', 1), ('piecing', 1), ('ugvc', 1), ('scrubbed', 1), ('measureable', 1), ('pavement', 1), ('shopkeepers', 1), ('sensr', 1), ('detracts', 1), ('billing', 1), ('blockly', 1), ('heap', 1), ('scl', 1), ('unobservability', 1), ('activations', 1), ('sock', 1), ('fists', 1), ('dpi', 1), ('biometrically', 1), ('5cm', 1), ('biocompatible', 1), ('seduced', 1), ('deleterious', 1), ('heel', 1), ('fluids', 1), ('replenish', 1), ('drinks', 1), ('spectacle', 1), ('fluidic', 1), ('tastybeats', 1), ('appetizing', 1), ('pedometers', 1), ('microsurveys', 1), ('disregard', 1), ('619', 1), ('materialised', 1), ('annotative', 1), ('extensiveness', 1), ('librarian', 1), ('renowned', 1), ('xml', 1), ('doh', 1), ('cutouts', 1), ('spinners', 1), ('nimble', 1), ('escalated', 1), ('risen', 1), ('subfield', 1), ('pushpins', 1), ('lots', 1), ('dynamicity', 1), ('centroidal', 1), ('enlarging', 1), ('overshoots', 1), ('trackpads', 1), ('359', 1), ('cathode', 1), ('940', 1), ('phonebooks', 1), ('trickle', 1), ('surges', 1), ('obscures', 1), ('aachen', 1), ('rwth', 1), ('ba', 1), ('ab', 1), ('prepares', 1), ('interleaves', 1), ('squeries', 1), ('perturb', 1), ('teamed', 1), ('disimprove', 1), ('extrapolated', 1), ('upstream', 1)]\n"
     ]
    }
   ],
   "source": [
    "lower_cnt = int(len(set(text.tokens)) * 0.01) * -1\n",
    "print(text.vocab().most_common()[:lower_cnt:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = df[['ID','Token_abstract']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=_d, tags=[uid]) for uid, _d in doc_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-249-b9090d204e0d>:19: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  epochs=model.iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 20\n",
    "\n",
    "model = Doc2Vec(\n",
    "#     window=10,\n",
    "#     size=150,\n",
    "#     alpha=0.025, \n",
    "#     min_alpha=0.025,\n",
    "#     min_count=2,\n",
    "#     dm =1,\n",
    "#     negative = 5,\n",
    "    seed = 9999)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('devices', 0.8098617792129517),\n",
       " ('phones', 0.7971692085266113),\n",
       " ('device', 0.7826195955276489),\n",
       " ('users', 0.7231123447418213),\n",
       " ('data', 0.719935417175293),\n",
       " ('system', 0.7176095247268677),\n",
       " ('design', 0.7122946977615356),\n",
       " ('video', 0.7116485834121704),\n",
       " ('displays', 0.704736590385437),\n",
       " ('gestures', 0.7036265134811401)]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('phone',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('10.1145/3025453.3025683',\n",
       " 'Virtual reality (VR) head-mounted displays (HMD) allow for a highly immersive experience and are currently becoming part of the living room entertainment. Current VR systems focus mainly on increasing the immersion and enjoyment for the user wearing the HMD (HMD user), resulting in all the bystanders (Non-HMD users) being excluded from the experience. We propose ShareVR, a proof-of-concept prototype using floor projection and mobile displays in combination with positional tracking to visualize the virtual world for the Non-HMD user, enabling them to interact with the HMD user and become part of the VR experience. We designed and implemented ShareVR based on the insights of an initial online survey (n=48) with early adopters of VR HMDs. We ran a user study (n=16) comparing ShareVRto a baseline condition showing how the interaction using ShareVR led to an increase of enjoyment, presence and social interaction. In a last step we implemented several experiences for ShareVR, exploring its design space and giving insights for designers of co-located asymmetric VR experiences.')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = 5001\n",
    "df['ID'][test_id], df['abstract'][test_id] #, df['Token_abstract'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual reality (VR) head-mounted displays (HMD) allow for a highly immersive experience and are currently becoming part of the living room entertainment. Current VR systems focus mainly on increasing the immersion and enjoyment for the user wearing the HMD (HMD user), resulting in all the bystanders (Non-HMD users) being excluded from the experience. We propose ShareVR, a proof-of-concept prototype using floor projection and mobile displays in combination with positional tracking to visualize the virtual world for the Non-HMD user, enabling them to interact with the HMD user and become part of the VR experience. We designed and implemented ShareVR based on the insights of an initial online survey (n=48) with early adopters of VR HMDs. We ran a user study (n=16) comparing ShareVRto a baseline condition showing how the interaction using ShareVR led to an increase of enjoyment, presence and social interaction. In a last step we implemented several experiences for ShareVR, exploring its design space and giving insights for designers of co-located asymmetric VR experiences.\n",
      "---------------------\n",
      "10.1145/2858036.2858490\t0.3610977530479431\n",
      "Microtask platforms are becoming commonplace tools for performing human research, producing gold-standard data, and annotating large datasets. These platforms connect requesters (researchers or companies) with large populations (crowds) of workers, who perform small tasks, typically taking less than five minutes each. A topic of ongoing research concerns the design of tasks that elicit high quality annotations. Here we identify a seemingly banal feature of nearly all crowdsourcing workflows that profoundly impacts workers' responses. Microtask assignments typically consist of a sequence of tasks sharing a common format (e.g., circle galaxies in an image). Using image-labeling, a canonical microtask format, we show that earlier tasks can have a strong influence on responses to later tasks, shifting the distribution of future responses by 30-50% (total variational distance). Specifically, prior tasks influence the content that workers focus on, as well as the richness and specialization of responses. We call this phenomenon intertask effects. We compare intertask effects to framing, effected by stating the requester's research interest, and find that intertask effects are on par or stronger. If uncontrolled, intertask effects could be a source of systematic bias, but our results suggest that, with appropriate task design, they might be leveraged to hone worker focus and acuity, helping to elicit reproducible, expert-level judgments. Intertask effects are a crucial aspect of human computation that should be considered in the design of any crowdsourced study.\n",
      "10.1145/800275.810943\t0.3456292450428009\n",
      "Computerized U.S. Census data has been most widely used for (1)\n",
      "employment, fertility, demographic and stratification research\n",
      "involving Public Use Sample (PUS) microdata on the national level,\n",
      "and (2) applied research (for planning, administration, marketing,\n",
      "and other applications) with summary (aggregated) data for\n",
      "localized (i.e., block, tract, community, etc.) geographic units. A\n",
      "third, highly productive avenue of research, involving Census PUS\n",
      "micro-data for localized urban units (i.e., SMSAs, counties and\n",
      "especially selected large-city neighborhoods), has not received the\n",
      "attention it merits, either among sophisticated public data users\n",
      "or among novice users.Three forms of current or future small area,\n",
      "Census microdata constitute resources for urban research. First,\n",
      "conventional 1970 Census PUS data sets are available for counties\n",
      "and/or SMSAs (with minimum populations of 250,000). Second, special\n",
      "tabulations for the two largest U.S. cities permit analysis of 1970\n",
      "household and person records group by (sub-county) urban\n",
      "neighborhoods (27 in New York City; 12 in Chicago). Third, 1980\n",
      "Census microdata, by allowing identification of geographic areas of\n",
      "smaller population size (100,000 population), will vastly expand\n",
      "the applications of localized research with the conventional PUS or\n",
      "special tabulations. In addition, the 1980 PUS microdata will, for\n",
      "the first time, allow comparative time-series analyses of county\n",
      "(or SMSA) area populations, over the 1970-1980 decade.In contrast\n",
      "to national PUS microdata research, local level analyses have the\n",
      "advantages of (1) smaller data set size and processing costs, (2)\n",
      "more immediate integration of computerized research hypotheses with\n",
      "additional sources of (qualitative) information and questions\n",
      "(stemming from direct knowledge of the communities studied), and\n",
      "(3) increased ability to zero in on specialized ethnic,\n",
      "occupational-industrial, migrant, age, etc. urban population groups\n",
      "which are disproportionately represented in particular local\n",
      "environments. Our own research projects (at various stages of\n",
      "development) which attempt to exploit these advantages include\n",
      "computerized analysis of:1. Patterns of household composition, and\n",
      "source and structure of family income, among Upper East Side and\n",
      "Upper West Side Manhattan residents with family incomes of $\n",
      "50,000. or more (as reported in the 1970 Census)2. Employment\n",
      "patterns of married women of Cuban immigrant background, in\n",
      "relation to family class position and period of immigration, for\n",
      "Hudson County, New Jersey3. Contrasts in the occupational positions\n",
      "and household patterns of first-generation and second-generation\n",
      "husbands and wives of Italian background in a New York City working\n",
      "class community (Astoria-Long Island City, Queens)4. Wives'\n",
      "employment patterns in relation to ethnic background and husbands'\n",
      "occupations and income levels in a working class community located\n",
      "in a manufacturing center (South Side, Chicago)5. Change in the\n",
      "social and demographic characteristics of succeeding groups of\n",
      "migrants to an expanding \"sunbelt\" metropolitan area (Albuquerque,\n",
      "New Mexico)6. Contrasts in local housing markets and housing\n",
      "availability, involving analysis of the number and characteristics\n",
      "of vacant housing units for New Jersey counties.These, as well as\n",
      "other projects we have assisted, have been undertaken with varied\n",
      "software resources, including packages (such as CENTS-AID) with\n",
      "unique hierarchical file processing capabilities, as well as more\n",
      "versatile (non-hierarchical), general purpose packages (such as\n",
      "SPSS). The advantages and research applications of small area,\n",
      "micro-databases can be realized with a range of software techniques\n",
      "and user-formulated research strategies.\n",
      "10.1145/800275.810943\t0.3456292450428009\n",
      "Computerized U.S. Census data has been most widely used for (1)\n",
      "employment, fertility, demographic and stratification research\n",
      "involving Public Use Sample (PUS) microdata on the national level,\n",
      "and (2) applied research (for planning, administration, marketing,\n",
      "and other applications) with summary (aggregated) data for\n",
      "localized (i.e., block, tract, community, etc.) geographic units. A\n",
      "third, highly productive avenue of research, involving Census PUS\n",
      "micro-data for localized urban units (i.e., SMSAs, counties and\n",
      "especially selected large-city neighborhoods), has not received the\n",
      "attention it merits, either among sophisticated public data users\n",
      "or among novice users.Three forms of current or future small area,\n",
      "Census microdata constitute resources for urban research. First,\n",
      "conventional 1970 Census PUS data sets are available for counties\n",
      "and/or SMSAs (with minimum populations of 250,000). Second, special\n",
      "tabulations for the two largest U.S. cities permit analysis of 1970\n",
      "household and person records group by (sub-county) urban\n",
      "neighborhoods (27 in New York City; 12 in Chicago). Third, 1980\n",
      "Census microdata, by allowing identification of geographic areas of\n",
      "smaller population size (100,000 population), will vastly expand\n",
      "the applications of localized research with the conventional PUS or\n",
      "special tabulations. In addition, the 1980 PUS microdata will, for\n",
      "the first time, allow comparative time-series analyses of county\n",
      "(or SMSA) area populations, over the 1970-1980 decade.In contrast\n",
      "to national PUS microdata research, local level analyses have the\n",
      "advantages of (1) smaller data set size and processing costs, (2)\n",
      "more immediate integration of computerized research hypotheses with\n",
      "additional sources of (qualitative) information and questions\n",
      "(stemming from direct knowledge of the communities studied), and\n",
      "(3) increased ability to zero in on specialized ethnic,\n",
      "occupational-industrial, migrant, age, etc. urban population groups\n",
      "which are disproportionately represented in particular local\n",
      "environments. Our own research projects (at various stages of\n",
      "development) which attempt to exploit these advantages include\n",
      "computerized analysis of:1. Patterns of household composition, and\n",
      "source and structure of family income, among Upper East Side and\n",
      "Upper West Side Manhattan residents with family incomes of $\n",
      "50,000. or more (as reported in the 1970 Census)2. Employment\n",
      "patterns of married women of Cuban immigrant background, in\n",
      "relation to family class position and period of immigration, for\n",
      "Hudson County, New Jersey3. Contrasts in the occupational positions\n",
      "and household patterns of first-generation and second-generation\n",
      "husbands and wives of Italian background in a New York City working\n",
      "class community (Astoria-Long Island City, Queens)4. Wives'\n",
      "employment patterns in relation to ethnic background and husbands'\n",
      "occupations and income levels in a working class community located\n",
      "in a manufacturing center (South Side, Chicago)5. Change in the\n",
      "social and demographic characteristics of succeeding groups of\n",
      "migrants to an expanding \"sunbelt\" metropolitan area (Albuquerque,\n",
      "New Mexico)6. Contrasts in local housing markets and housing\n",
      "availability, involving analysis of the number and characteristics\n",
      "of vacant housing units for New Jersey counties.These, as well as\n",
      "other projects we have assisted, have been undertaken with varied\n",
      "software resources, including packages (such as CENTS-AID) with\n",
      "unique hierarchical file processing capabilities, as well as more\n",
      "versatile (non-hierarchical), general purpose packages (such as\n",
      "SPSS). The advantages and research applications of small area,\n",
      "micro-databases can be realized with a range of software techniques\n",
      "and user-formulated research strategies.\n",
      "10.1145/2207676.2208619\t0.33913591504096985\n",
      "Online labor markets, such as Amazon's Mechanical Turk, have been used to crowdsource simple, short tasks like image labeling and transcription. However, expert knowledge is often lacking in such markets, making it impossible to complete certain classes of tasks. In this work we introduce an alternative mechanism for crowdsourcing tasks that require specialized knowledge or skill: communitysourcing --- the use of physical kiosks to elicit work from specific populations. We investigate the potential of communitysourcing by designing, implementing and evaluating Umati: the communitysourcing vending machine. Umati allows users to earn credits by performing tasks using a touchscreen attached to the machine. Physical rewards (in this case, snacks) are dispensed through traditional vending mechanics. We evaluated whether communitysourcing can accomplish expert work by using Umati to grade Computer Science exams. We placed Umati in a university Computer Science building, targeting students with grading tasks for snacks. Over one week, 328 unique users (302 of whom were students) completed 7771 tasks (7240 by students). 80% of users had never participated in a crowdsourcing market before. We found that Umati was able to grade exams with 2% higher accuracy (at the same price) or at 33% lower cost (at equivalent accuracy) than traditional single-expert grading. Mechanical Turk workers had no success grading the same exams. These results indicate that communitysourcing can successfully elicit high-quality expert work from specific communities.\n",
      "10.1145/1015528.810943\t0.3383657932281494\n",
      "Computerized U.S. Census data has been most widely used for (1)\n",
      "employment, fertility, demographic and stratification research\n",
      "involving Public Use Sample (PUS) microdata on the national level,\n",
      "and (2) applied research (for planning, administration, marketing,\n",
      "and other applications) with summary (aggregated) data for\n",
      "localized (i.e., block, tract, community, etc.) geographic units. A\n",
      "third, highly productive avenue of research, involving Census PUS\n",
      "micro-data for localized urban units (i.e., SMSAs, counties and\n",
      "especially selected large-city neighborhoods), has not received the\n",
      "attention it merits, either among sophisticated public data users\n",
      "or among novice users.Three forms of current or future small area,\n",
      "Census microdata constitute resources for urban research. First,\n",
      "conventional 1970 Census PUS data sets are available for counties\n",
      "and/or SMSAs (with minimum populations of 250,000). Second, special\n",
      "tabulations for the two largest U.S. cities permit analysis of 1970\n",
      "household and person records group by (sub-county) urban\n",
      "neighborhoods (27 in New York City; 12 in Chicago). Third, 1980\n",
      "Census microdata, by allowing identification of geographic areas of\n",
      "smaller population size (100,000 population), will vastly expand\n",
      "the applications of localized research with the conventional PUS or\n",
      "special tabulations. In addition, the 1980 PUS microdata will, for\n",
      "the first time, allow comparative time-series analyses of county\n",
      "(or SMSA) area populations, over the 1970-1980 decade.In contrast\n",
      "to national PUS microdata research, local level analyses have the\n",
      "advantages of (1) smaller data set size and processing costs, (2)\n",
      "more immediate integration of computerized research hypotheses with\n",
      "additional sources of (qualitative) information and questions\n",
      "(stemming from direct knowledge of the communities studied), and\n",
      "(3) increased ability to zero in on specialized ethnic,\n",
      "occupational-industrial, migrant, age, etc. urban population groups\n",
      "which are disproportionately represented in particular local\n",
      "environments. Our own research projects (at various stages of\n",
      "development) which attempt to exploit these advantages include\n",
      "computerized analysis of:1. Patterns of household composition, and\n",
      "source and structure of family income, among Upper East Side and\n",
      "Upper West Side Manhattan residents with family incomes of $\n",
      "50,000. or more (as reported in the 1970 Census)2. Employment\n",
      "patterns of married women of Cuban immigrant background, in\n",
      "relation to family class position and period of immigration, for\n",
      "Hudson County, New Jersey3. Contrasts in the occupational positions\n",
      "and household patterns of first-generation and second-generation\n",
      "husbands and wives of Italian background in a New York City working\n",
      "class community (Astoria-Long Island City, Queens)4. Wives'\n",
      "employment patterns in relation to ethnic background and husbands'\n",
      "occupations and income levels in a working class community located\n",
      "in a manufacturing center (South Side, Chicago)5. Change in the\n",
      "social and demographic characteristics of succeeding groups of\n",
      "migrants to an expanding \"sunbelt\" metropolitan area (Albuquerque,\n",
      "New Mexico)6. Contrasts in local housing markets and housing\n",
      "availability, involving analysis of the number and characteristics\n",
      "of vacant housing units for New Jersey counties.These, as well as\n",
      "other projects we have assisted, have been undertaken with varied\n",
      "software resources, including packages (such as CENTS-AID) with\n",
      "unique hierarchical file processing capabilities, as well as more\n",
      "versatile (non-hierarchical), general purpose packages (such as\n",
      "SPSS). The advantages and research applications of small area,\n",
      "micro-databases can be realized with a range of software techniques\n",
      "and user-formulated research strategies.\n",
      "10.1145/1015528.810943\t0.3383657932281494\n",
      "Computerized U.S. Census data has been most widely used for (1)\n",
      "employment, fertility, demographic and stratification research\n",
      "involving Public Use Sample (PUS) microdata on the national level,\n",
      "and (2) applied research (for planning, administration, marketing,\n",
      "and other applications) with summary (aggregated) data for\n",
      "localized (i.e., block, tract, community, etc.) geographic units. A\n",
      "third, highly productive avenue of research, involving Census PUS\n",
      "micro-data for localized urban units (i.e., SMSAs, counties and\n",
      "especially selected large-city neighborhoods), has not received the\n",
      "attention it merits, either among sophisticated public data users\n",
      "or among novice users.Three forms of current or future small area,\n",
      "Census microdata constitute resources for urban research. First,\n",
      "conventional 1970 Census PUS data sets are available for counties\n",
      "and/or SMSAs (with minimum populations of 250,000). Second, special\n",
      "tabulations for the two largest U.S. cities permit analysis of 1970\n",
      "household and person records group by (sub-county) urban\n",
      "neighborhoods (27 in New York City; 12 in Chicago). Third, 1980\n",
      "Census microdata, by allowing identification of geographic areas of\n",
      "smaller population size (100,000 population), will vastly expand\n",
      "the applications of localized research with the conventional PUS or\n",
      "special tabulations. In addition, the 1980 PUS microdata will, for\n",
      "the first time, allow comparative time-series analyses of county\n",
      "(or SMSA) area populations, over the 1970-1980 decade.In contrast\n",
      "to national PUS microdata research, local level analyses have the\n",
      "advantages of (1) smaller data set size and processing costs, (2)\n",
      "more immediate integration of computerized research hypotheses with\n",
      "additional sources of (qualitative) information and questions\n",
      "(stemming from direct knowledge of the communities studied), and\n",
      "(3) increased ability to zero in on specialized ethnic,\n",
      "occupational-industrial, migrant, age, etc. urban population groups\n",
      "which are disproportionately represented in particular local\n",
      "environments. Our own research projects (at various stages of\n",
      "development) which attempt to exploit these advantages include\n",
      "computerized analysis of:1. Patterns of household composition, and\n",
      "source and structure of family income, among Upper East Side and\n",
      "Upper West Side Manhattan residents with family incomes of $\n",
      "50,000. or more (as reported in the 1970 Census)2. Employment\n",
      "patterns of married women of Cuban immigrant background, in\n",
      "relation to family class position and period of immigration, for\n",
      "Hudson County, New Jersey3. Contrasts in the occupational positions\n",
      "and household patterns of first-generation and second-generation\n",
      "husbands and wives of Italian background in a New York City working\n",
      "class community (Astoria-Long Island City, Queens)4. Wives'\n",
      "employment patterns in relation to ethnic background and husbands'\n",
      "occupations and income levels in a working class community located\n",
      "in a manufacturing center (South Side, Chicago)5. Change in the\n",
      "social and demographic characteristics of succeeding groups of\n",
      "migrants to an expanding \"sunbelt\" metropolitan area (Albuquerque,\n",
      "New Mexico)6. Contrasts in local housing markets and housing\n",
      "availability, involving analysis of the number and characteristics\n",
      "of vacant housing units for New Jersey counties.These, as well as\n",
      "other projects we have assisted, have been undertaken with varied\n",
      "software resources, including packages (such as CENTS-AID) with\n",
      "unique hierarchical file processing capabilities, as well as more\n",
      "versatile (non-hierarchical), general purpose packages (such as\n",
      "SPSS). The advantages and research applications of small area,\n",
      "micro-databases can be realized with a range of software techniques\n",
      "and user-formulated research strategies.\n",
      "10.1145/3025453.3025687\t0.33650749921798706\n",
      "Mainstream crowdwork platforms treat microtasks as indivisible units; however, in this article, we propose that there is value in re-examining this assumption. We argue that crowdwork platforms can improve their value proposition for all stakeholders by supporting subcontracting within microtasks. After describing the value proposition of subcontracting, we then define three models for microtask subcontracting: real-time assistance, task management, and task improvement, and reflect on potential use cases and implementation considerations associated with each. Finally, we describe the outcome of two tasks on Mechanical Turk meant to simulate aspects of subcontracting. We reflect on the implications of these findings for the design of future crowd work platforms that effectively harness the potential of subcontracting workflows.\n",
      "10.1145/800275.810947\t0.3201315104961395\n",
      "The occasion for this discussion is our recent experience with a severe shortfall in computational capacity at The Pennsylvania State University. Although the details of this affliction may not be reproduced elsewhere, it is our opinion that the events we experienced stem from essential, underlying phenomena which do have wide currency. These are, first, that overall demand for computational facilities and services is increasing \"exponentially\" and shows no sign of slowdown, and, second, that resources (most especially including funds) to provide increases in the relevant supply of computing capacities are not keeping pace and can not be expected to do so.It is possible that technical advances can treat this disorder, but in the nature of the political/bureaucratic systems which are the vehicles for the delivery of such \"fixes\", acquiring them will not be painless. Concretely, it seems unlikely that faculty and students in colleges and universities can expect relief from recurrent boom-and-bust in computational resources, whether the duration of such cycles is measured in decades or days. It behooves us to ask whether the attendant pains must be endured, and whether they are conducive to easier and more productive use of computing systems. Our answers are, first, that such pain does not ennoble, and, second, that it often is counterproductive. Consequently, we must try to identify the proximate sources of the disrupting effects of these cyclic shortfalls and attempt to curb them, within our means.We propose that the appropriate guidelines for allocating scarce computing resources may be characterized as prescriptions for humane rationing. In the most general terms, these prescriptions are 1) that qualified users should be ensured a fair share of the available resource without unnecessary expenses of effort in competition for them and in queuing, and 2) that use of computing resources should be so governed as to insure that all user sessions are as free as possible of delays, encumbrances, and constraints induced by management practices rather than by inherent limits of hard and software.While rationing is unnecessary during the occasional boom in academic computing resources, we should have on the shelf the management tools which can make fair and effective allocation possible during the recurrent busts we may anticipate in the 1980's.\n",
      "10.1145/800275.810947\t0.3201315104961395\n",
      "The occasion for this discussion is our recent experience with a severe shortfall in computational capacity at The Pennsylvania State University. Although the details of this affliction may not be reproduced elsewhere, it is our opinion that the events we experienced stem from essential, underlying phenomena which do have wide currency. These are, first, that overall demand for computational facilities and services is increasing \"exponentially\" and shows no sign of slowdown, and, second, that resources (most especially including funds) to provide increases in the relevant supply of computing capacities are not keeping pace and can not be expected to do so.It is possible that technical advances can treat this disorder, but in the nature of the political/bureaucratic systems which are the vehicles for the delivery of such \"fixes\", acquiring them will not be painless. Concretely, it seems unlikely that faculty and students in colleges and universities can expect relief from recurrent boom-and-bust in computational resources, whether the duration of such cycles is measured in decades or days. It behooves us to ask whether the attendant pains must be endured, and whether they are conducive to easier and more productive use of computing systems. Our answers are, first, that such pain does not ennoble, and, second, that it often is counterproductive. Consequently, we must try to identify the proximate sources of the disrupting effects of these cyclic shortfalls and attempt to curb them, within our means.We propose that the appropriate guidelines for allocating scarce computing resources may be characterized as prescriptions for humane rationing. In the most general terms, these prescriptions are 1) that qualified users should be ensured a fair share of the available resource without unnecessary expenses of effort in competition for them and in queuing, and 2) that use of computing resources should be so governed as to insure that all user sessions are as free as possible of delays, encumbrances, and constraints induced by management practices rather than by inherent limits of hard and software.While rationing is unnecessary during the occasional boom in academic computing resources, we should have on the shelf the management tools which can make fair and effective allocation possible during the recurrent busts we may anticipate in the 1980's.\n",
      "10.1145/1015528.810947\t0.30602580308914185\n",
      "The occasion for this discussion is our recent experience with a severe shortfall in computational capacity at The Pennsylvania State University. Although the details of this affliction may not be reproduced elsewhere, it is our opinion that the events we experienced stem from essential, underlying phenomena which do have wide currency. These are, first, that overall demand for computational facilities and services is increasing \"exponentially\" and shows no sign of slowdown, and, second, that resources (most especially including funds) to provide increases in the relevant supply of computing capacities are not keeping pace and can not be expected to do so.It is possible that technical advances can treat this disorder, but in the nature of the political/bureaucratic systems which are the vehicles for the delivery of such \"fixes\", acquiring them will not be painless. Concretely, it seems unlikely that faculty and students in colleges and universities can expect relief from recurrent boom-and-bust in computational resources, whether the duration of such cycles is measured in decades or days. It behooves us to ask whether the attendant pains must be endured, and whether they are conducive to easier and more productive use of computing systems. Our answers are, first, that such pain does not ennoble, and, second, that it often is counterproductive. Consequently, we must try to identify the proximate sources of the disrupting effects of these cyclic shortfalls and attempt to curb them, within our means.We propose that the appropriate guidelines for allocating scarce computing resources may be characterized as prescriptions for humane rationing. In the most general terms, these prescriptions are 1) that qualified users should be ensured a fair share of the available resource without unnecessary expenses of effort in competition for them and in queuing, and 2) that use of computing resources should be so governed as to insure that all user sessions are as free as possible of delays, encumbrances, and constraints induced by management practices rather than by inherent limits of hard and software.While rationing is unnecessary during the occasional boom in academic computing resources, we should have on the shelf the management tools which can make fair and effective allocation possible during the recurrent busts we may anticipate in the 1980's.\n",
      "10.1145/1015528.810947\t0.30602580308914185\n",
      "The occasion for this discussion is our recent experience with a severe shortfall in computational capacity at The Pennsylvania State University. Although the details of this affliction may not be reproduced elsewhere, it is our opinion that the events we experienced stem from essential, underlying phenomena which do have wide currency. These are, first, that overall demand for computational facilities and services is increasing \"exponentially\" and shows no sign of slowdown, and, second, that resources (most especially including funds) to provide increases in the relevant supply of computing capacities are not keeping pace and can not be expected to do so.It is possible that technical advances can treat this disorder, but in the nature of the political/bureaucratic systems which are the vehicles for the delivery of such \"fixes\", acquiring them will not be painless. Concretely, it seems unlikely that faculty and students in colleges and universities can expect relief from recurrent boom-and-bust in computational resources, whether the duration of such cycles is measured in decades or days. It behooves us to ask whether the attendant pains must be endured, and whether they are conducive to easier and more productive use of computing systems. Our answers are, first, that such pain does not ennoble, and, second, that it often is counterproductive. Consequently, we must try to identify the proximate sources of the disrupting effects of these cyclic shortfalls and attempt to curb them, within our means.We propose that the appropriate guidelines for allocating scarce computing resources may be characterized as prescriptions for humane rationing. In the most general terms, these prescriptions are 1) that qualified users should be ensured a fair share of the available resource without unnecessary expenses of effort in competition for them and in queuing, and 2) that use of computing resources should be so governed as to insure that all user sessions are as free as possible of delays, encumbrances, and constraints induced by management practices rather than by inherent limits of hard and software.While rationing is unnecessary during the occasional boom in academic computing resources, we should have on the shelf the management tools which can make fair and effective allocation possible during the recurrent busts we may anticipate in the 1980's.\n",
      "10.1145/57167.57205\t0.2937696576118469\n",
      "Over forty years ago, Vannevar Bush articulated his vision of a “Memex” machine: “associative indexing, … whereby any item may be caused at will to select immediately and automatically another” [Bush 45]. In the sixties, Engelbart [Engelbart, English 68] built collaborative systems to provide idea structuring and sharing. Nelson [Nelson 81] coined “hypertext” and proposed world-wide networks for publishing, linking, annotating and indexing multiple versions of documents. With increasing numbers of research projects, papers, panels and conferences, and commercially available systems (e.g. Notecards by Xerox, Guide by Owl and HyperCard by Apple) in recent years, hypertext may be an idea whose time has finally come — or at least a phenomenon not to be ignored.The goal of this panel is not to define hypertext or hypermedia (at its simplest: non-linearly arranged and accessed information), debate its uniqueness, explain implementation issues, or survey the many applications and contributions in the field (see [Conklin 87] for an excellent survey of Hypertext, and the Proceedings of Hypertext '87 Workshop at University of North Carolina, Chapel Hill). Rather, we intend to approach it from the perspective of the information user: reader, searcher, author. The panel will address the following issues:\n",
      "Are the processes of authoring and understanding helped or hindered by the non-linear structure of hypertext, for which kinds of tasks and users? What is the difference between a hypertext writer and a knowledge engineer? In searching for information, what is the difference between browsing and querying?What experiments need to be done? What tools, environment or interfaces can improve the process of information creation and access? Can the overhead of creating or interpreting structure be reduced?When will hypertext replace paper, or should it? How do functions of author and reader co-evolve? Could this revolutionize society like the printing press? Why didn't the panelists create a multi-versioned, highly crossreferenced online entry for the proceedings? Is hypertext a technology in search of a problem?\n",
      "10.1145/2702123.2702146\t0.2830455005168915\n",
      "A large, seemingly overwhelming task can sometimes be transformed into a set of smaller, more manageable microtasks that can each be accomplished independently. For example, it may be hard to subjectively rank a large set of photographs, but easy to sort them in spare moments by making many pairwise comparisons. In crowdsourcing systems, microtasking enables unskilled workers with limited commitment to work together to complete tasks they would not be able to do individually. We explore the costs and benefits of decomposing macrotasks into microtasks for three task categories: arithmetic, sorting, and transcription. We find that breaking these tasks into microtasks results in longer overall task completion times, but higher quality outcomes and a better experience that may be more resilient to interruptions. These results suggest that microtasks can help people complete high quality work in interruption-driven environments.\n",
      "10.1145/3025453.3025640\t0.2822421193122864\n",
      "Speech transcription is an expensive service with high turnaround time for audio files containing languages spoken in developing countries and regional accents of well-represented languages. We present Respeak - a voice-based, crowd-powered system that capitalizes on the strengths of crowdsourcing and automatic speech recognition (instead of typing) to transcribe such audio files. We created Respeak and optimized its design through a series of cognitive experiments. We deployed it with 25 university students in India who completed 5464 micro-transcription tasks, transcribing 55 minutes of widely-varied audio content, and collectively earning USD 46 as mobile airtime. The Respeak engine aligned the transcript generated by five randomly selected users to transcribe Hindi and Indian English audio files with a word error rate (WER) of 8.6% and 15.2%, respectively. The cost of speech transcription was USD 0.83 per minute with a turnaround time of 39.8 hours, substantially less than industry standards. Using a mixed-methods analysis of cognitive experiments, system performance and qualitative interviews, we evaluate Respeak's design, user experience, strengths, and weaknesses. Our findings suggest that Respeak improves the quality of speech transcription while enhancing the earning potential of low-income populations in resource-constrained settings.\n"
     ]
    }
   ],
   "source": [
    "model.random.seed(9999)\n",
    "\n",
    "doc_list = df['Token_abstract'][test_id]\n",
    "\n",
    "# print(doc_list)\n",
    "\n",
    "inferred_vector = model.infer_vector(doc_list)\n",
    "# print(inferred_vector)\n",
    "return_docs = model.docvecs.most_similar(positive=[inferred_vector],topn=10)\n",
    "\n",
    "print(df['abstract'][test_id])\n",
    "\n",
    "print(\"---------------------\")\n",
    "\n",
    "for rd in return_docs:\n",
    "    for des in df[df['ID'] == rd[0]]['abstract']:\n",
    "        print (f'{rd[0]}\\t{rd[1]}\\n{des}')\n",
    "    \n",
    "# df[df['ID'] == return_docs[0][0]]\n",
    "# df['ID' == return_docs[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1145/2556288.2557069\t0.3707877993583679\n",
      "We present an approach to interactive recommending that combines the advantages of algorithmic techniques with the benefits of user-controlled, interactive exploration in a novel manner. The method extracts latent factors from a matrix of user rating data as commonly used in Collaborative Filtering, and generates dialogs in which the user iteratively chooses between two sets of sample items. Samples are chosen by the system for low and high values of each latent factor considered. The method positions the user in the latent factor space with few interaction steps, and finally selects items near the user position as recommendations.In a user study, we compare the system with three alternative approaches including manual search and automatic recommending. The results show significant advantages of our approach over the three competing alternatives in 15 out of 24 possible parameter comparisons, in particular with respect to item fit, interaction effort and user control. The findings corroborate our assumption that the proposed method achieves a good trade-off between automated and interactive functions in recommender systems.\n",
      "------------------------------------------\n",
      "10.1145/3290605.3300931\t0.3077163100242615\n",
      "When watching how-to videos related to physical tasks, users' hands are often occupied by the task, making voice input a natural fit. To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. From the studies, we distill seven navigation objectives and their underlying intents: pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. Our analysis found that users' navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 2) allow users to identify and refine their navigation objectives explicitly, and 3) support the seven interaction intents.\n",
      "------------------------------------------\n",
      "10.1145/2702123.2702397\t0.3037618398666382\n",
      "The possibility of leveraging technology to support children's learning in the real world is both appealing and technically challenging. We have been exploring factors in tangible games that may contribute to both learning and enjoyment with an eye toward technological feasibility and scalability. Previous research found that young children learned early physics principles better when interactively predicting and observing experimental comparisons on a physical earthquake table than when seeing a video of the same. Immersing children in the real world with computer vision-based feedback appears to evoke embodied cognition that enhances learning. In the current experiment, we replicated this intriguing result of the mere difference between observing the real world versus a flat-screen. Further, we explored whether a simple and scalable addition of physical control (such as shaking a tablet) would yield an increase in learning and enjoyment. Our 2x2 experiment found no evidence that adding simple forms of hands-on control enhances learning, while demonstrating a large impact of physical observation. A general implication for educational game design is that affording physical observation in the real world accompanied by interactive feedback may be more important than affording simple hands-on control on a tablet.\n",
      "------------------------------------------\n",
      "10.1145/1240624.1240670\t0.29077351093292236\n",
      "A proof of concept web search and navigation system was developed for older people for whom the Internet is seen as an alien territory. A joint industry/academia team deployed User Sensitive Inclusive Design principles, focusing on the usability of the interface for this user group. The search and navigation system that was developed was significantly preferred by the user group to that provided by a standard commercial (Internet Service Provider) system; it scored highly for ease of use and the participants reported increased confidence in their ability to master the Internet. Recorded quantitative measures showed fewer task errors. The outcome of the development was a successful \"proof of concept\" search and navigation system for older novice computer users together with approaches to design and development for those who wish to design for this user group.\n",
      "------------------------------------------\n",
      "10.1145/3290605.3300841\t0.28358834981918335\n",
      "Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks.\n",
      "------------------------------------------\n",
      "10.1145/1124772.1124787\t0.28083688020706177\n",
      "Privacy policy rules are often written in organizations by a team of people in different roles. Currently, people in these roles have no technological tools to guide the creation of clear and implementable high-quality privacy policy rules. High-quality privacy rules can be the basis for verifiable automated privacy access decisions. An empirical study was conducted with 36 users who were novices in privacy policy authoring to evaluate the quality of rules created and user satisfaction with two experimental privacy authoring tools and a control condition. Results show that users presented with scenarios were able to author significantly higher quality rules using either the natural language with a privacy rule guide tool or a structured list tool as compared to an unguided natural language control condition. The significant differences in quality were found in both user self-ratings of rule quality and objective quality scores. Users ranked the two experimental tools significantly higher than the control condition. Implications of the research and future research directions are discussed.\n",
      "------------------------------------------\n",
      "10.1145/30851.275639\t0.2759840488433838\n",
      "An experiment was conducted to evaluate user performance under four different menu item arrangements: alphabetic, probability of selection (most popular choices are positioned near the beginning of the list), random, and positionally constant (consistent assignment of individual items to screen positions). During the initial stages of practice, the rule-based approaches produced faster mean search times, but after moderate amounts of practice, the positionally constant arrangement appeared to be most efficient. People seem to remember quite easily the location of items on a display, indicating that positional constancy can be an important factor in increasing the efficiency of the search of computer menus and other displays.\n",
      "------------------------------------------\n",
      "10.1145/3290605.3300745\t0.27401769161224365\n",
      "Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing -- focusing on when and to whom users would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice.\n",
      "------------------------------------------\n",
      "10.1145/1518701.1518905\t0.27136045694351196\n",
      "We discuss the problem of assessing and aiding user performance in dynamic tasks that require rapid selection among multiple information sources. Motivated by research in human sequential learning, we develop a system that learns by observation to predict the information a user desires in different contexts. The model decides when the display should be updated, which is akin to the problem of scene segmentation, and then selects the situationally relevant information display. The model reduces the cognitive burden of selecting situation-relevant displays. We evaluate the system in a tank video game environment and find that the system boosts user performance. The fit of the model to user data provides a quantitative assessment of user behavior, which is useful in assessing individual differences and the progression from novice- to expert-level proficiency. We discuss the relative benefits of adopting a learning approach to predicting information preferences and possible avenues to reduce the negative consequences of automation.\n",
      "------------------------------------------\n",
      "10.1145/3173574.3173752\t0.27037298679351807\n",
      "We introduce FingerT9, leveraging the action of thumb-to-finger touching on the finger segments, to support same-side-hand (SSH) text entry on smartwatches. This is achieved by mapping a T9 keyboard layout to the finger segments. Our solution avoids the problems of fat finger and screen occlusion, and enables text entry using the same-side hand which wears the watch. In the pilot study, we determined the layout mapping preferred by the users. We conducted an experiment to compare the text-entry performances of FingerT9, the tilt-based SSH input, and the direct-touch non-SSH input. The results showed that the participants performed significantly faster and more accurately with FingerT9 than the tilt-based method. There was no significant difference between FingerT9 and direct-touch methods in terms of efficiency and error rate. We then conducted the second experiment to study the learning curve on SSH text entry methods: FingerT9 and the tilt-based input. FingerT9 gave significantly better long-term improvement. In addition, eyes-free text entry (i.e., looking at the screen output but not the keyboard layout mapped on the finger segments) was made possible once the participants were familiar with the keyboard layout.\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_id = 5004\n",
    "\n",
    "doc_list = df['Token_abstract'][test_id]\n",
    "\n",
    "inferred_vector = model.infer_vector(doc_list)\n",
    "return_docs = model.docvecs.most_similar(positive=[inferred_vector],topn=10)\n",
    "\n",
    "# print(return_docs)\n",
    "\n",
    "for rd in return_docs:\n",
    "  for des in df[df['ID'] == rd[0]]['abstract']:\n",
    "    print(f'{rd[0]}\\t{rd[1]}\\n{des}\\n------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래는 이전 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abstract = abstracts_by_year[:len(abstracts_by_year)-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_abstract = abstracts_by_year[len(abstracts_by_year)-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(data, tokens_only=False):\n",
    "    for year in data:\n",
    "        for i, abstract in enumerate(year):\n",
    "            tokens = gensim.utils.simple_preprocess(abstract)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # for training only, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(train_abstract))\n",
    "test_corpus = list(read_corpus(test_abstract, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['news', 'coverage', 'of', 'security', 'and', 'privacy', 'amp', 'events', 'is', 'pervasive', 'and', 'may', 'affect', 'the', 'salience', 'of', 'amp', 'threats', 'to', 'the', 'public', 'to', 'better', 'understand', 'this', 'coverage', 'and', 'its', 'effects', 'we', 'asked', 'what', 'types', 'of', 'amp', 'news', 'come', 'into', 'people', 'awareness', 'how', 'do', 'people', 'hear', 'about', 'and', 'share', 'this', 'news', 'over', 'two', 'years', 'we', 'recruited', 'participants', 'to', 'fill', 'out', 'survey', 'on', 'emergent', 'amp', 'news', 'events', 'we', 'identified', 'four', 'types', 'of', 'amp', 'news', 'financial', 'data', 'breaches', 'corporate', 'personal', 'data', 'breaches', 'high', 'sensitivity', 'systems', 'breaches', 'and', 'politicized', 'activist', 'cybersecurity', 'these', 'event', 'types', 'strongly', 'correlated', 'with', 'how', 'people', 'shared', 'amp', 'news', 'financial', 'data', 'breaches', 'were', 'shared', 'most', 'while', 'politicized', 'activist', 'cybersecurity', 'events', 'were', 'shared', 'least', 'furthermore', 'participants', 'age', 'gender', 'and', 'security', 'behavioral', 'intention', 'strongly', 'correlated', 'with', 'how', 'they', 'heard', 'about', 'and', 'shared', 'amp', 'news', 'males', 'more', 'often', 'felt', 'personal', 'responsibility', 'to', 'share', 'and', 'older', 'people', 'were', 'less', 'likely', 'to', 'hear', 'about', 'amp', 'news', 'through', 'conversation'], tags=[0]), TaggedDocument(words=['we', 'introduce', 'deep', 'thermal', 'imaging', 'new', 'approach', 'for', 'close', 'range', 'automatic', 'recognition', 'of', 'materials', 'to', 'enhance', 'the', 'understanding', 'of', 'people', 'and', 'ubiquitous', 'technologies', 'of', 'their', 'proximal', 'environment', 'our', 'approach', 'uses', 'low', 'cost', 'mobile', 'thermal', 'camera', 'integrated', 'into', 'smartphone', 'to', 'capture', 'thermal', 'textures', 'deep', 'neural', 'network', 'classifies', 'these', 'textures', 'into', 'material', 'types', 'this', 'approach', 'works', 'effectively', 'without', 'the', 'need', 'for', 'ambient', 'light', 'sources', 'or', 'direct', 'contact', 'with', 'materials', 'furthermore', 'the', 'use', 'of', 'deep', 'learning', 'network', 'removes', 'the', 'need', 'to', 'handcraft', 'the', 'set', 'of', 'features', 'for', 'different', 'materials', 'we', 'evaluated', 'the', 'performance', 'of', 'the', 'system', 'by', 'training', 'it', 'to', 'recognize', 'material', 'types', 'in', 'both', 'indoor', 'and', 'outdoor', 'environments', 'our', 'approach', 'produced', 'recognition', 'accuracies', 'above', 'in', 'images', 'of', 'indoor', 'materials', 'and', 'above', 'in', 'images', 'of', 'outdoor', 'materials', 'we', 'conclude', 'by', 'discussing', 'its', 'potentials', 'for', 'real', 'time', 'use', 'in', 'hci', 'applications', 'and', 'future', 'directions'], tags=[1])]\n"
     ]
    }
   ],
   "source": [
    "print(train_corpus[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['interaction', 'tasks', 'on', 'computer', 'screen', 'can', 'technically', 'be', 'scaled', 'to', 'much', 'larger', 'or', 'much', 'smaller', 'sized', 'input', 'control', 'area', 'by', 'adjusting', 'the', 'input', 'device', 'control', 'gain', 'or', 'the', 'control', 'display', 'ratio', 'however', 'human', 'performance', 'as', 'function', 'of', 'movement', 'scale', 'is', 'not', 'well', 'concluded', 'topic', 'this', 'study', 'introduces', 'new', 'task', 'paradigm', 'to', 'study', 'the', 'scale', 'effect', 'in', 'the', 'framework', 'of', 'the', 'steering', 'law', 'the', 'results', 'confirmed', 'shaped', 'performance', 'scale', 'function', 'and', 'rejected', 'straight', 'line', 'or', 'no', 'effect', 'hypotheses', 'in', 'the', 'literature', 'we', 'found', 'significant', 'scale', 'effect', 'in', 'path', 'steering', 'performance', 'although', 'its', 'impact', 'was', 'less', 'than', 'that', 'of', 'the', 'steering', 'law', 'index', 'of', 'difficulty', 'we', 'analyzed', 'the', 'scale', 'effects', 'in', 'two', 'plausible', 'causes', 'movement', 'joints', 'shift', 'and', 'motor', 'precision', 'limitation', 'the', 'theoretical', 'implications', 'of', 'the', 'scale', 'effects', 'to', 'the', 'validity', 'of', 'the', 'steering', 'law', 'and', 'the', 'practical', 'implications', 'of', 'input', 'device', 'size', 'and', 'zooming', 'functions', 'are', 'discussed', 'in', 'the', 'paper'], ['in', 'view', 'of', 'the', 'difficulties', 'in', 'evaluating', 'computer', 'pointing', 'devices', 'across', 'different', 'tasks', 'within', 'dynamic', 'and', 'complex', 'systems', 'new', 'performance', 'measures', 'are', 'needed', 'this', 'paper', 'proposes', 'seven', 'new', 'accuracy', 'measures', 'to', 'elicit', 'sometimes', 'subtle', 'differences', 'among', 'devices', 'in', 'precision', 'pointing', 'tasks', 'the', 'measures', 'are', 'target', 're', 'entry', 'task', 'axis', 'crossing', 'movement', 'direction', 'change', 'orthogonal', 'direction', 'change', 'movement', 'variability', 'movement', 'error', 'and', 'movement', 'offset', 'unlike', 'movement', 'time', 'error', 'rate', 'and', 'throughput', 'which', 'are', 'based', 'on', 'single', 'measurement', 'per', 'trial', 'the', 'new', 'measures', 'capture', 'aspects', 'of', 'movement', 'behaviour', 'during', 'trial', 'the', 'theoretical', 'basis', 'and', 'computational', 'techniques', 'for', 'the', 'measures', 'are', 'described', 'with', 'examples', 'given', 'an', 'evaluation', 'with', 'four', 'pointing', 'devices', 'was', 'conducted', 'to', 'validate', 'the', 'measures', 'causal', 'relationship', 'to', 'pointing', 'device', 'efficiency', 'viz', 'throughput', 'was', 'found', 'as', 'was', 'an', 'ability', 'to', 'discriminate', 'among', 'devices', 'in', 'situations', 'where', 'differences', 'did', 'not', 'otherwise', 'appear', 'implications', 'for', 'pointing', 'device', 'research', 'are', 'discussed']]\n"
     ]
    }
   ],
   "source": [
    "print(test_corpus[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word2VecKeyedVectors' object has no attribute 'get_vecattr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-1759e868292b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Word 'penalty' appeared {model.wv.get_vecattr('penalty', 'count')} times in the training corpus.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Word2VecKeyedVectors' object has no attribute 'get_vecattr'"
     ]
    }
   ],
   "source": [
    "print(f\"Word 'penalty' appeared {model.wv.get_vecattr('penalty', 'count')} times in the training corpus.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-08 04:57:37,657 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-12-08 04:57:37,658 : INFO : training model with 3 workers on 14494 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-12-08 04:57:38,368 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:38,372 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:38,382 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:38,383 : INFO : EPOCH - 1 : training on 884181 raw words (697989 effective words) took 0.7s, 968166 effective words/s\n",
      "2020-12-08 04:57:39,035 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:39,050 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:39,056 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:39,057 : INFO : EPOCH - 2 : training on 884181 raw words (697896 effective words) took 0.7s, 1040957 effective words/s\n",
      "2020-12-08 04:57:39,772 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:39,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:39,787 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:39,788 : INFO : EPOCH - 3 : training on 884181 raw words (698105 effective words) took 0.7s, 961315 effective words/s\n",
      "2020-12-08 04:57:40,372 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:40,381 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:40,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:40,388 : INFO : EPOCH - 4 : training on 884181 raw words (697879 effective words) took 0.6s, 1169143 effective words/s\n",
      "2020-12-08 04:57:41,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:41,089 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:41,093 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:41,093 : INFO : EPOCH - 5 : training on 884181 raw words (698144 effective words) took 0.7s, 993367 effective words/s\n",
      "2020-12-08 04:57:41,708 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:41,717 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:41,723 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:41,723 : INFO : EPOCH - 6 : training on 884181 raw words (698048 effective words) took 0.6s, 1112386 effective words/s\n",
      "2020-12-08 04:57:42,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:42,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:42,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:42,440 : INFO : EPOCH - 7 : training on 884181 raw words (698364 effective words) took 0.7s, 978507 effective words/s\n",
      "2020-12-08 04:57:43,186 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:43,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:43,199 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:43,199 : INFO : EPOCH - 8 : training on 884181 raw words (697473 effective words) took 0.8s, 921649 effective words/s\n",
      "2020-12-08 04:57:43,846 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:43,855 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:43,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:43,861 : INFO : EPOCH - 9 : training on 884181 raw words (697871 effective words) took 0.7s, 1060106 effective words/s\n",
      "2020-12-08 04:57:44,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:44,571 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:44,575 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:44,576 : INFO : EPOCH - 10 : training on 884181 raw words (697965 effective words) took 0.7s, 980422 effective words/s\n",
      "2020-12-08 04:57:45,214 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:45,223 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:45,231 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:45,231 : INFO : EPOCH - 11 : training on 884181 raw words (698164 effective words) took 0.7s, 1068918 effective words/s\n",
      "2020-12-08 04:57:45,852 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:45,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:45,867 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:45,868 : INFO : EPOCH - 12 : training on 884181 raw words (697222 effective words) took 0.6s, 1100768 effective words/s\n",
      "2020-12-08 04:57:46,549 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:46,563 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:46,569 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:46,570 : INFO : EPOCH - 13 : training on 884181 raw words (697626 effective words) took 0.7s, 997240 effective words/s\n",
      "2020-12-08 04:57:47,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:47,290 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:47,298 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:47,298 : INFO : EPOCH - 14 : training on 884181 raw words (698053 effective words) took 0.7s, 961907 effective words/s\n",
      "2020-12-08 04:57:47,950 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:47,956 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:47,964 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:47,964 : INFO : EPOCH - 15 : training on 884181 raw words (698200 effective words) took 0.7s, 1052061 effective words/s\n",
      "2020-12-08 04:57:48,601 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:48,606 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:48,614 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:48,615 : INFO : EPOCH - 16 : training on 884181 raw words (698222 effective words) took 0.6s, 1077695 effective words/s\n",
      "2020-12-08 04:57:49,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:49,271 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:49,272 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:49,272 : INFO : EPOCH - 17 : training on 884181 raw words (697619 effective words) took 0.7s, 1064930 effective words/s\n",
      "2020-12-08 04:57:49,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:49,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:49,917 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:49,917 : INFO : EPOCH - 18 : training on 884181 raw words (697514 effective words) took 0.6s, 1086924 effective words/s\n",
      "2020-12-08 04:57:50,548 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:50,557 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:50,560 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:50,561 : INFO : EPOCH - 19 : training on 884181 raw words (697885 effective words) took 0.6s, 1090432 effective words/s\n",
      "2020-12-08 04:57:51,193 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:51,205 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:51,210 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:51,211 : INFO : EPOCH - 20 : training on 884181 raw words (697659 effective words) took 0.6s, 1077736 effective words/s\n",
      "2020-12-08 04:57:51,966 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:51,973 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:51,981 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:51,981 : INFO : EPOCH - 21 : training on 884181 raw words (698280 effective words) took 0.8s, 910631 effective words/s\n",
      "2020-12-08 04:57:52,751 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:52,760 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:52,765 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:52,766 : INFO : EPOCH - 22 : training on 884181 raw words (698244 effective words) took 0.8s, 893651 effective words/s\n",
      "2020-12-08 04:57:53,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:53,429 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:53,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:53,435 : INFO : EPOCH - 23 : training on 884181 raw words (697823 effective words) took 0.7s, 1047546 effective words/s\n",
      "2020-12-08 04:57:54,071 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:54,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:54,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:54,085 : INFO : EPOCH - 24 : training on 884181 raw words (698261 effective words) took 0.6s, 1080282 effective words/s\n",
      "2020-12-08 04:57:54,723 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:54,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:54,736 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:54,736 : INFO : EPOCH - 25 : training on 884181 raw words (697804 effective words) took 0.6s, 1076557 effective words/s\n",
      "2020-12-08 04:57:55,390 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:55,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:55,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:55,412 : INFO : EPOCH - 26 : training on 884181 raw words (698379 effective words) took 0.7s, 1036538 effective words/s\n",
      "2020-12-08 04:57:56,179 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:56,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:56,195 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:56,196 : INFO : EPOCH - 27 : training on 884181 raw words (697730 effective words) took 0.8s, 895185 effective words/s\n",
      "2020-12-08 04:57:56,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:56,924 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:56,929 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:56,930 : INFO : EPOCH - 28 : training on 884181 raw words (697786 effective words) took 0.7s, 955111 effective words/s\n",
      "2020-12-08 04:57:57,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:57,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:57,635 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:57,635 : INFO : EPOCH - 29 : training on 884181 raw words (698021 effective words) took 0.7s, 992268 effective words/s\n",
      "2020-12-08 04:57:58,393 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:58,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:58,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:58,412 : INFO : EPOCH - 30 : training on 884181 raw words (697926 effective words) took 0.8s, 902996 effective words/s\n",
      "2020-12-08 04:57:59,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:59,168 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:59,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:59,175 : INFO : EPOCH - 31 : training on 884181 raw words (697871 effective words) took 0.8s, 919306 effective words/s\n",
      "2020-12-08 04:57:59,903 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:57:59,907 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:57:59,910 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:57:59,911 : INFO : EPOCH - 32 : training on 884181 raw words (698199 effective words) took 0.7s, 953006 effective words/s\n",
      "2020-12-08 04:58:00,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:58:00,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:58:00,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:58:00,604 : INFO : EPOCH - 33 : training on 884181 raw words (697883 effective words) took 0.7s, 1010668 effective words/s\n",
      "2020-12-08 04:58:01,338 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:58:01,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:58:01,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:58:01,353 : INFO : EPOCH - 34 : training on 884181 raw words (697809 effective words) took 0.7s, 937109 effective words/s\n",
      "2020-12-08 04:58:02,051 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:58:02,057 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:58:02,068 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:58:02,069 : INFO : EPOCH - 35 : training on 884181 raw words (698312 effective words) took 0.7s, 978817 effective words/s\n",
      "2020-12-08 04:58:02,788 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:58:02,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:58:02,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:58:02,804 : INFO : EPOCH - 36 : training on 884181 raw words (697859 effective words) took 0.7s, 952731 effective words/s\n",
      "2020-12-08 04:58:03,516 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:58:03,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:58:03,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:58:03,529 : INFO : EPOCH - 37 : training on 884181 raw words (697993 effective words) took 0.7s, 967633 effective words/s\n",
      "2020-12-08 04:58:04,204 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:58:04,214 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:58:04,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:58:04,220 : INFO : EPOCH - 38 : training on 884181 raw words (698205 effective words) took 0.7s, 1014507 effective words/s\n",
      "2020-12-08 04:58:04,899 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:58:04,906 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:58:04,916 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:58:04,917 : INFO : EPOCH - 39 : training on 884181 raw words (697996 effective words) took 0.7s, 1006281 effective words/s\n",
      "2020-12-08 04:58:05,663 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-08 04:58:05,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-08 04:58:05,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-08 04:58:05,681 : INFO : EPOCH - 40 : training on 884181 raw words (697936 effective words) took 0.8s, 917862 effective words/s\n",
      "2020-12-08 04:58:05,681 : INFO : training on a 35367240 raw words (27918215 effective words) took 28.0s, 996290 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.26277863e-03  4.54380393e-01  8.38448573e-03 -7.23871577e-04\n",
      " -1.18045337e-01 -1.65653676e-02 -2.78750181e-01 -2.70180047e-01\n",
      "  9.00969356e-02  6.08842015e-01  2.08029658e-01  2.70067751e-01\n",
      " -6.15713537e-01 -3.68705034e-01  2.16788203e-02  3.68731290e-01\n",
      " -2.56530847e-02  2.72740453e-01  3.76131088e-01 -4.68154475e-02\n",
      "  5.93313091e-02 -2.39998907e-01  6.57462656e-01 -1.32446274e-01\n",
      "  2.74022639e-01  3.46924633e-01  2.47120723e-01 -2.57308125e-01\n",
      " -4.08681154e-01  4.39266592e-01 -3.12493026e-01 -1.02270715e-01\n",
      "  4.32426095e-01  2.51613766e-01  8.59265447e-01 -1.39952824e-01\n",
      "  2.44776219e-01  1.42156601e-01  7.41507411e-02 -5.68861701e-02\n",
      " -8.06139827e-01 -1.00731134e-01  1.08326435e-01 -1.57043472e-01\n",
      " -2.84874230e-03  3.95684838e-01 -2.79494345e-01 -6.80232525e-01\n",
      "  3.14129472e-01  5.72198391e-01]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "702 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-4fed5a04da40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minferred_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minferred_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdocid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mranks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 702 is not in list"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Doc2VecKeyedVectors.most_similar of <gensim.models.keyedvectors.Doc2VecKeyedVectors object at 0x139d27160>>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 285, 1: 38, 2: 17, 3: 11, 7: 5, 6: 5, 5: 5, 18: 4, 367: 4, 11: 3, 14: 3, 135: 3, 10: 3, 9: 3, 335: 3, 617: 3, 664: 3, 46: 3, 376: 3, 257: 3, 466: 3, 16: 2, 13: 2, 4: 2, 44: 2, 12: 2, 57: 2, 41: 2, 51: 2, 405: 2, 531: 2, 694: 2, 513: 2, 453: 2, 402: 2, 461: 2, 140: 2, 575: 2, 579: 2, 253: 2, 264: 2, 290: 2, 440: 2, 653: 2, 332: 2, 675: 2, 639: 2, 655: 2, 230: 2, 150: 2, 311: 2, 411: 2, 684: 2, 289: 2, 577: 2, 189: 2, 419: 2, 407: 2, 356: 2, 597: 2, 187: 2, 195: 2, 382: 2, 76: 2, 437: 2, 69: 2, 502: 2, 177: 2, 63: 2, 64: 1, 43: 1, 30: 1, 48: 1, 40: 1, 26: 1, 654: 1, 281: 1, 573: 1, 477: 1, 59: 1, 635: 1, 500: 1, 563: 1, 521: 1, 562: 1, 77: 1, 668: 1, 71: 1, 377: 1, 37: 1, 325: 1, 224: 1, 547: 1, 450: 1, 138: 1, 634: 1, 436: 1, 665: 1, 526: 1, 679: 1, 467: 1, 669: 1, 196: 1, 607: 1, 374: 1, 379: 1, 364: 1, 687: 1, 425: 1, 661: 1, 438: 1, 496: 1, 509: 1, 463: 1, 623: 1, 45: 1, 345: 1, 308: 1, 570: 1, 681: 1, 696: 1, 293: 1, 168: 1, 238: 1, 690: 1, 588: 1, 600: 1, 676: 1, 498: 1, 553: 1, 549: 1, 202: 1, 60: 1, 338: 1, 638: 1, 447: 1, 548: 1, 643: 1, 421: 1, 220: 1, 350: 1, 234: 1, 375: 1, 650: 1, 123: 1, 537: 1, 312: 1, 624: 1, 627: 1, 231: 1, 418: 1, 626: 1, 166: 1, 590: 1, 471: 1, 378: 1, 126: 1, 8: 1, 255: 1, 203: 1, 327: 1, 384: 1, 96: 1, 555: 1, 217: 1, 317: 1, 397: 1, 611: 1, 244: 1, 658: 1, 122: 1, 21: 1, 299: 1, 28: 1, 339: 1, 697: 1, 305: 1, 210: 1, 137: 1, 401: 1, 268: 1, 291: 1, 56: 1, 121: 1, 495: 1, 546: 1, 413: 1, 142: 1, 478: 1, 396: 1, 523: 1, 683: 1, 576: 1, 271: 1, 606: 1, 36: 1, 651: 1, 201: 1, 481: 1, 66: 1, 342: 1, 32: 1, 444: 1, 525: 1, 354: 1, 474: 1, 652: 1, 430: 1, 341: 1, 533: 1, 432: 1, 689: 1, 191: 1, 522: 1, 252: 1, 470: 1, 394: 1, 241: 1, 329: 1, 406: 1, 164: 1, 292: 1, 578: 1, 693: 1, 103: 1, 566: 1, 649: 1, 416: 1, 459: 1, 469: 1, 148: 1, 330: 1, 280: 1, 27: 1, 460: 1, 167: 1, 273: 1, 227: 1, 254: 1, 179: 1, 99: 1, 545: 1, 219: 1, 321: 1, 251: 1, 536: 1, 518: 1, 107: 1, 507: 1, 647: 1, 412: 1, 17: 1, 133: 1, 267: 1, 47: 1, 240: 1, 212: 1, 160: 1, 592: 1, 98: 1, 582: 1, 398: 1, 97: 1, 105: 1, 559: 1})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 16,\n",
       " 0,\n",
       " 64,\n",
       " 0,\n",
       " 0,\n",
       " 13,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 11,\n",
       " 1,\n",
       " 0,\n",
       " 11,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 43,\n",
       " 4,\n",
       " 44,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 12,\n",
       " 6,\n",
       " 2,\n",
       " 135,\n",
       " 2,\n",
       " 18,\n",
       " 2,\n",
       " 0,\n",
       " 10,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 7,\n",
       " 57,\n",
       " 7,\n",
       " 2,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 41,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 11,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 18,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 30,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 40,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 26,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 51,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 654,\n",
       " 281,\n",
       " 367,\n",
       " 573,\n",
       " 477,\n",
       " 51,\n",
       " 59,\n",
       " 405,\n",
       " 635,\n",
       " 531,\n",
       " 335,\n",
       " 500,\n",
       " 563,\n",
       " 521,\n",
       " 694,\n",
       " 617,\n",
       " 664,\n",
       " 562,\n",
       " 46,\n",
       " 513,\n",
       " 77,\n",
       " 453,\n",
       " 402,\n",
       " 461,\n",
       " 668,\n",
       " 531,\n",
       " 140,\n",
       " 71,\n",
       " 376,\n",
       " 377,\n",
       " 617,\n",
       " 37,\n",
       " 325,\n",
       " 224,\n",
       " 575,\n",
       " 579,\n",
       " 253,\n",
       " 547,\n",
       " 450,\n",
       " 264,\n",
       " 138,\n",
       " 634,\n",
       " 436,\n",
       " 290,\n",
       " 665,\n",
       " 18,\n",
       " 440,\n",
       " 653,\n",
       " 526,\n",
       " 679,\n",
       " 467,\n",
       " 669,\n",
       " 196,\n",
       " 257,\n",
       " 607,\n",
       " 335,\n",
       " 332,\n",
       " 374,\n",
       " 379,\n",
       " 14,\n",
       " 364,\n",
       " 687,\n",
       " 425,\n",
       " 675,\n",
       " 639,\n",
       " 661,\n",
       " 438,\n",
       " 617,\n",
       " 496,\n",
       " 509,\n",
       " 664,\n",
       " 463,\n",
       " 623,\n",
       " 45,\n",
       " 655,\n",
       " 230,\n",
       " 345,\n",
       " 308,\n",
       " 579,\n",
       " 135,\n",
       " 150,\n",
       " 311,\n",
       " 570,\n",
       " 681,\n",
       " 10,\n",
       " 253,\n",
       " 411,\n",
       " 696,\n",
       " 293,\n",
       " 168,\n",
       " 238,\n",
       " 376,\n",
       " 684,\n",
       " 289,\n",
       " 690,\n",
       " 577,\n",
       " 588,\n",
       " 189,\n",
       " 600,\n",
       " 257,\n",
       " 676,\n",
       " 498,\n",
       " 553,\n",
       " 549,\n",
       " 419,\n",
       " 411,\n",
       " 202,\n",
       " 60,\n",
       " 338,\n",
       " 638,\n",
       " 447,\n",
       " 407,\n",
       " 548,\n",
       " 643,\n",
       " 421,\n",
       " 220,\n",
       " 350,\n",
       " 234,\n",
       " 375,\n",
       " 650,\n",
       " 123,\n",
       " 537,\n",
       " 312,\n",
       " 624,\n",
       " 639,\n",
       " 627,\n",
       " 231,\n",
       " 418,\n",
       " 626,\n",
       " 166,\n",
       " 356,\n",
       " 590,\n",
       " 466,\n",
       " 597,\n",
       " 471,\n",
       " 378,\n",
       " 126,\n",
       " 402,\n",
       " 187,\n",
       " 8,\n",
       " 255,\n",
       " 376,\n",
       " 203,\n",
       " 46,\n",
       " 327,\n",
       " 195,\n",
       " 384,\n",
       " 96,\n",
       " 597,\n",
       " 555,\n",
       " 217,\n",
       " 317,\n",
       " 140,\n",
       " 397,\n",
       " 611,\n",
       " 244,\n",
       " 461,\n",
       " 658,\n",
       " 122,\n",
       " 382,\n",
       " 21,\n",
       " 694,\n",
       " 289,\n",
       " 299,\n",
       " 28,\n",
       " 264,\n",
       " 339,\n",
       " 697,\n",
       " 305,\n",
       " 210,\n",
       " 137,\n",
       " 76,\n",
       " 150,\n",
       " 401,\n",
       " 268,\n",
       " 230,\n",
       " 453,\n",
       " 419,\n",
       " 291,\n",
       " 653,\n",
       " 407,\n",
       " 56,\n",
       " 44,\n",
       " 18,\n",
       " 675,\n",
       " 195,\n",
       " 121,\n",
       " 495,\n",
       " 655,\n",
       " 546,\n",
       " 413,\n",
       " 367,\n",
       " 142,\n",
       " 478,\n",
       " 437,\n",
       " 396,\n",
       " 523,\n",
       " 683,\n",
       " 576,\n",
       " 271,\n",
       " 606,\n",
       " 311,\n",
       " 36,\n",
       " 651,\n",
       " 201,\n",
       " 356,\n",
       " 481,\n",
       " 66,\n",
       " 342,\n",
       " 32,\n",
       " 444,\n",
       " 187,\n",
       " 466,\n",
       " 525,\n",
       " 354,\n",
       " 474,\n",
       " 652,\n",
       " 430,\n",
       " 341,\n",
       " 533,\n",
       " 432,\n",
       " 689,\n",
       " 664,\n",
       " 191,\n",
       " 335,\n",
       " 69,\n",
       " 522,\n",
       " 252,\n",
       " 437,\n",
       " 69,\n",
       " 135,\n",
       " 470,\n",
       " 394,\n",
       " 241,\n",
       " 329,\n",
       " 406,\n",
       " 164,\n",
       " 292,\n",
       " 684,\n",
       " 440,\n",
       " 578,\n",
       " 693,\n",
       " 103,\n",
       " 566,\n",
       " 57,\n",
       " 649,\n",
       " 290,\n",
       " 416,\n",
       " 189,\n",
       " 459,\n",
       " 257,\n",
       " 13,\n",
       " 469,\n",
       " 405,\n",
       " 148,\n",
       " 330,\n",
       " 280,\n",
       " 502,\n",
       " 27,\n",
       " 460,\n",
       " 167,\n",
       " 273,\n",
       " 227,\n",
       " 254,\n",
       " 179,\n",
       " 99,\n",
       " 41,\n",
       " 545,\n",
       " 219,\n",
       " 513,\n",
       " 321,\n",
       " 575,\n",
       " 251,\n",
       " 46,\n",
       " 536,\n",
       " 76,\n",
       " 518,\n",
       " 177,\n",
       " 107,\n",
       " 507,\n",
       " 63,\n",
       " 382,\n",
       " 647,\n",
       " 412,\n",
       " 466,\n",
       " 63,\n",
       " 367,\n",
       " 17,\n",
       " 133,\n",
       " 367,\n",
       " 267,\n",
       " 47,\n",
       " 332,\n",
       " 240,\n",
       " 212,\n",
       " 577,\n",
       " 177,\n",
       " 160,\n",
       " 502,\n",
       " 592,\n",
       " 98,\n",
       " 582,\n",
       " 398,\n",
       " 97,\n",
       " 105,\n",
       " 559]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (679): «information infrastructures have become integral components of policy debates related to climate change and sustainability to better understand this relationship we studied the tools used to forecast and respond to sea level rise in the san francisco bay area where active debates on how to best prepare for this issues are underway and will have important consequences for the future of the region drawing on months of qualitative research we argue that competing visions of the problem are intimately intertwined with different elements of information infrastructure and beliefs about the role of data in policymaking current infrastructure in the region far from being neutral actor in these debates exhibits an infrastructural bias privileging some approaches over others we identify some of the tactics that community organizations deploy to subvert the claims of sea level rise experts and advance their own perspective which prioritizes considerations of justice over technical expertise»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (306, 0.8200528025627136): «design research is generative intuitive experiential and tactical documenting the design research process helps to communicate these decisions judgements and values that are embodied in design products yet practices for documenting design research are underreported in the chi community particularly for immersive design research field studies we contribute the debrief clock fieldnote practice for documenting design research field studies comprising collaborative discussion sessions and the production of written research accounts we show how the debrief clock practice emerged in the context of digital community noticeboard project with very remote australian aboriginal community and explain three key purposes of debrief clock as an early stage data recording and analysis process tactical manoeuvre in responsive project planning and mechanism for personal debriefing and reflexivity we conclude with series of open practical ethical and methodological questions to advance the discussion of design research documentation practices»\n",
      "\n",
      "SECOND-MOST (436, 0.6141198873519897): «algorithmic decision making systems are increasingly being adopted by government public service agencies researchers policy experts and civil rights groups have all voiced concerns that such systems are being deployed without adequate consideration of potential harms disparate impacts and public accountability practices yet little is known about the concerns of those most likely to be affected by these systems we report on workshops conducted to learn about the concerns of affected communities in the context of child welfare services the workshops involved study participants including families involved in the child welfare system employees of child welfare agencies and service providers our findings indicate that general distrust in the existing system contributes significantly to low comfort in algorithmic decision making we identify strategies for improving comfort through greater transparency and improved communication strategies we discuss the implications of our study for accountable algorithm design for child welfare applications»\n",
      "\n",
      "MEDIAN (248, 0.33666521310806274): «lgbt people adjust the presentation of their gender and sexual identities in response to social pressures but their level of visibility differs between social media we interviewed seventeen lgbt students at socially conservative university to investigate how do social media affect lgbt user experience of managing self presentation and how do social media affect participation in lgbt communities we develop implications for design to support queering social media give people abilities to present themselves with selective visibility enabling choices about privacy and sharing in contrast with the hci design principle of indiscriminate making visible that is enable participants to define their social media identities in their own ways conduct studies with methodology likewise ensures that participants can define their gender and sexual identities in their own ways rather than according to predetermined vocabulary»\n",
      "\n",
      "LEAST (369, 0.04585975408554077): «many online communities cater to the critical and unmet needs of individuals challenged with mental illnesses generally communities engender characteristic linguistic practices known as norms conformance to these norms or linguistic accommodation encourages social approval and acceptance this paper investigates whether linguistic accommodation impacts specific social feedback the support received by an individual in an online mental health community we first quantitatively derive two measures for each post in these communities the linguistic accommodation it exhibits and the level of support it receives thereafter we build statistical framework to examine the relationship between these measures although the extent to which accommodation is associated with support varies we find positive link between the two consistent across reddit communities serving various psychological needs we discuss how our work surfaces tension in the functioning of these sensitive communities and present design implications for improving their support provisioning mechanisms»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.6235948204994202),\n",
       " (502, 0.6180746555328369),\n",
       " (539, 0.6692728996276855),\n",
       " (124, 0.6379819512367249),\n",
       " (211, 0.6773279905319214),\n",
       " (163, 0.6865946650505066),\n",
       " (9, 0.7033212780952454),\n",
       " (499, 0.6609477996826172),\n",
       " (1, 0.6195513606071472),\n",
       " (438, 0.6866633892059326),\n",
       " (113, 0.6472609043121338),\n",
       " (590, 0.6547167897224426),\n",
       " (165, 0.625514805316925),\n",
       " (359, 0.6511269211769104),\n",
       " (699, 0.6399871110916138),\n",
       " (240, 0.6274611353874207),\n",
       " (278, 0.6793270111083984),\n",
       " (609, 0.7168976664543152),\n",
       " (696, 0.6425620913505554),\n",
       " (660, 0.6484107971191406),\n",
       " (254, 0.6639687418937683),\n",
       " (21, 0.662481963634491),\n",
       " (440, 0.5982522964477539),\n",
       " (79, 0.6471951603889465),\n",
       " (24, 0.6375259757041931),\n",
       " (3, 0.690064013004303),\n",
       " (690, 0.6536182761192322),\n",
       " (96, 0.6596326231956482),\n",
       " (18, 0.7068015336990356),\n",
       " (625, 0.6782551407814026),\n",
       " (30, 0.6490764617919922),\n",
       " (564, 0.5912740230560303),\n",
       " (32, 0.6658360362052917),\n",
       " (679, 0.605497419834137),\n",
       " (5, 0.6344475150108337),\n",
       " (14, 0.6490961313247681),\n",
       " (374, 0.6788525581359863),\n",
       " (619, 0.6366742253303528),\n",
       " (130, 0.6532626152038574),\n",
       " (604, 0.6382983326911926),\n",
       " (88, 0.6285233497619629),\n",
       " (317, 0.6570169925689697),\n",
       " (522, 0.6842398643493652),\n",
       " (237, 0.6814792156219482),\n",
       " (469, 0.6595537066459656),\n",
       " (554, 0.6691622734069824),\n",
       " (102, 0.6391705274581909),\n",
       " (646, 0.6308450698852539),\n",
       " (538, 0.6942254900932312),\n",
       " (655, 0.6645036935806274),\n",
       " (653, 0.6303028464317322),\n",
       " (143, 0.6676245331764221),\n",
       " (668, 0.6705632209777832),\n",
       " (305, 0.6417027711868286),\n",
       " (27, 0.6076640486717224),\n",
       " (569, 0.6334949731826782),\n",
       " (19, 0.6214125752449036),\n",
       " (58, 0.6483756303787231),\n",
       " (33, 0.6292812824249268),\n",
       " (59, 0.664477527141571),\n",
       " (674, 0.6636530160903931),\n",
       " (478, 0.657264232635498),\n",
       " (649, 0.6040761470794678),\n",
       " (27, 0.6205006837844849),\n",
       " (382, 0.6185961365699768),\n",
       " (272, 0.6475893259048462),\n",
       " (689, 0.6412048935890198),\n",
       " (67, 0.6684588193893433),\n",
       " (52, 0.6348225474357605),\n",
       " (263, 0.676353931427002),\n",
       " (70, 0.6640909314155579),\n",
       " (647, 0.6411648988723755),\n",
       " (62, 0.6168187856674194),\n",
       " (346, 0.6411287188529968),\n",
       " (30, 0.6797455549240112),\n",
       " (596, 0.6330323815345764),\n",
       " (529, 0.6562542915344238),\n",
       " (619, 0.683891236782074),\n",
       " (661, 0.6188936233520508),\n",
       " (83, 0.6824626922607422),\n",
       " (696, 0.6731860637664795),\n",
       " (116, 0.6532014012336731),\n",
       " (526, 0.6523601412773132),\n",
       " (91, 0.6233346462249756),\n",
       " (41, 0.6484442949295044),\n",
       " (638, 0.6873371601104736),\n",
       " (42, 0.6108070015907288),\n",
       " (234, 0.6110740900039673),\n",
       " (88, 0.6863809823989868),\n",
       " (142, 0.6417101621627808),\n",
       " (102, 0.6133867502212524),\n",
       " (612, 0.685104489326477),\n",
       " (92, 0.6351767778396606),\n",
       " (558, 0.6440593004226685),\n",
       " (701, 0.6276217103004456),\n",
       " (95, 0.6201280355453491),\n",
       " (377, 0.6749883890151978),\n",
       " (97, 0.6611800789833069),\n",
       " (110, 0.6549166440963745),\n",
       " (470, 0.6141071319580078),\n",
       " (445, 0.664032518863678),\n",
       " (607, 0.62740159034729),\n",
       " (603, 0.6401499509811401),\n",
       " (625, 0.6424572467803955),\n",
       " (303, 0.6696794629096985),\n",
       " (655, 0.6684297919273376),\n",
       " (115, 0.6537219285964966),\n",
       " (238, 0.6773892641067505),\n",
       " (571, 0.6872302889823914),\n",
       " (625, 0.7053321003913879),\n",
       " (143, 0.6503118276596069),\n",
       " (573, 0.6658604741096497),\n",
       " (475, 0.6544116139411926),\n",
       " (626, 0.6606966257095337),\n",
       " (695, 0.6349664330482483),\n",
       " (673, 0.6648089289665222),\n",
       " (564, 0.6149322390556335),\n",
       " (625, 0.6309229135513306),\n",
       " (487, 0.6452791094779968),\n",
       " (1, 0.6360442042350769),\n",
       " (83, 0.6230974197387695),\n",
       " (643, 0.6919522285461426),\n",
       " (13, 0.6923874020576477),\n",
       " (604, 0.618022084236145),\n",
       " (115, 0.6479066014289856),\n",
       " (166, 0.6194148063659668),\n",
       " (200, 0.6404623985290527),\n",
       " (353, 0.6668240427970886),\n",
       " (98, 0.6696988344192505),\n",
       " (108, 0.6759825348854065),\n",
       " (413, 0.6026851534843445),\n",
       " (686, 0.6874943375587463),\n",
       " (100, 0.6693447232246399),\n",
       " (650, 0.6864749193191528),\n",
       " (188, 0.6347131729125977),\n",
       " (663, 0.6617162227630615),\n",
       " (432, 0.6071815490722656),\n",
       " (12, 0.644190788269043),\n",
       " (456, 0.6163191795349121),\n",
       " (635, 0.6382787227630615),\n",
       " (615, 0.6431894302368164),\n",
       " (135, 0.584775447845459),\n",
       " (693, 0.6380851864814758),\n",
       " (521, 0.6044415235519409),\n",
       " (451, 0.6347122192382812),\n",
       " (145, 0.7028040289878845),\n",
       " (587, 0.6268796920776367),\n",
       " (147, 0.6889415383338928),\n",
       " (625, 0.6627411842346191),\n",
       " (651, 0.6146513223648071),\n",
       " (47, 0.6389005780220032),\n",
       " (463, 0.634933352470398),\n",
       " (189, 0.6693125367164612),\n",
       " (153, 0.5989055037498474),\n",
       " (681, 0.6572782397270203),\n",
       " (596, 0.6440140604972839),\n",
       " (238, 0.6597188115119934),\n",
       " (157, 0.6699149012565613),\n",
       " (156, 0.7172181010246277),\n",
       " (159, 0.6499082446098328),\n",
       " (124, 0.6715283393859863),\n",
       " (161, 0.7225356698036194),\n",
       " (676, 0.6802637577056885),\n",
       " (100, 0.6512449979782104),\n",
       " (609, 0.6610317826271057),\n",
       " (621, 0.6755462288856506),\n",
       " (289, 0.6322972774505615),\n",
       " (207, 0.6358378529548645),\n",
       " (357, 0.6423102617263794),\n",
       " (59, 0.6755881905555725),\n",
       " (543, 0.5998989939689636),\n",
       " (295, 0.6272585988044739),\n",
       " (172, 0.6726820468902588),\n",
       " (47, 0.6245668530464172),\n",
       " (522, 0.664385974407196),\n",
       " (625, 0.6923210620880127),\n",
       " (54, 0.7002251148223877),\n",
       " (268, 0.6345953941345215),\n",
       " (228, 0.6327225565910339),\n",
       " (195, 0.6263738870620728),\n",
       " (701, 0.6803661584854126),\n",
       " (687, 0.6922926902770996),\n",
       " (678, 0.6290712952613831),\n",
       " (183, 0.7225298285484314),\n",
       " (574, 0.6565626263618469),\n",
       " (328, 0.710771381855011),\n",
       " (625, 0.644839346408844),\n",
       " (427, 0.6458590030670166),\n",
       " (603, 0.6622791290283203),\n",
       " (586, 0.5986748933792114),\n",
       " (314, 0.6686268448829651),\n",
       " (147, 0.6687400937080383),\n",
       " (699, 0.7051100730895996),\n",
       " (699, 0.6443213224411011),\n",
       " (274, 0.6198809742927551),\n",
       " (195, 0.6813288927078247),\n",
       " (442, 0.5521106719970703),\n",
       " (281, 0.6342768669128418),\n",
       " (198, 0.6872971057891846),\n",
       " (635, 0.6380500197410583),\n",
       " (332, 0.632841169834137),\n",
       " (444, 0.6013158559799194),\n",
       " (92, 0.6406965851783752),\n",
       " (67, 0.668609619140625),\n",
       " (196, 0.5978816151618958),\n",
       " (195, 0.6149740219116211),\n",
       " (294, 0.6946960091590881),\n",
       " (477, 0.6088854074478149),\n",
       " (208, 0.6645604372024536),\n",
       " (101, 0.6443119645118713),\n",
       " (98, 0.7178266048431396),\n",
       " (563, 0.6591103672981262),\n",
       " (212, 0.6723157167434692),\n",
       " (284, 0.6756043434143066),\n",
       " (129, 0.6657658219337463),\n",
       " (681, 0.6704896092414856),\n",
       " (30, 0.6405614614486694),\n",
       " (672, 0.66151362657547),\n",
       " (625, 0.6418712735176086),\n",
       " (642, 0.6467239260673523),\n",
       " (589, 0.6505326628684998),\n",
       " (619, 0.7042264938354492),\n",
       " (596, 0.6274593472480774),\n",
       " (681, 0.747136652469635),\n",
       " (1, 0.6492055654525757),\n",
       " (155, 0.6438300013542175),\n",
       " (626, 0.6712971329689026),\n",
       " (427, 0.6164713501930237),\n",
       " (18, 0.7014161348342896),\n",
       " (229, 0.6951618790626526),\n",
       " (59, 0.6340643167495728),\n",
       " (15, 0.6284940242767334),\n",
       " (646, 0.6530221700668335),\n",
       " (427, 0.6620302796363831),\n",
       " (674, 0.6481380462646484),\n",
       " (272, 0.6550267338752747),\n",
       " (670, 0.6688798069953918),\n",
       " (1, 0.6539351344108582),\n",
       " (107, 0.6319238543510437),\n",
       " (428, 0.7201259136199951),\n",
       " (689, 0.623917818069458),\n",
       " (316, 0.6765091419219971),\n",
       " (681, 0.6698276996612549),\n",
       " (114, 0.6463528871536255),\n",
       " (609, 0.6627888679504395),\n",
       " (196, 0.6330012679100037),\n",
       " (139, 0.6159079074859619),\n",
       " (27, 0.631342887878418),\n",
       " (681, 0.6751153469085693),\n",
       " (27, 0.6287510991096497),\n",
       " (681, 0.6839997172355652),\n",
       " (603, 0.6451276540756226),\n",
       " (154, 0.6575964093208313),\n",
       " (344, 0.6243517398834229),\n",
       " (377, 0.6197966933250427),\n",
       " (346, 0.6620146632194519),\n",
       " (666, 0.6514880061149597),\n",
       " (642, 0.6454815864562988),\n",
       " (258, 0.712817907333374),\n",
       " (79, 0.6292363405227661),\n",
       " (632, 0.6827165484428406),\n",
       " (44, 0.6143996715545654),\n",
       " (576, 0.5646808743476868),\n",
       " (328, 0.6871889233589172),\n",
       " (423, 0.6401702165603638),\n",
       " (242, 0.6432352066040039),\n",
       " (646, 0.608555793762207),\n",
       " (267, 0.706383466720581),\n",
       " (655, 0.67691570520401),\n",
       " (687, 0.6067587733268738),\n",
       " (328, 0.6091182827949524),\n",
       " (530, 0.6243389844894409),\n",
       " (535, 0.6330428719520569),\n",
       " (143, 0.6524025797843933),\n",
       " (295, 0.6120135188102722),\n",
       " (16, 0.7060046195983887),\n",
       " (604, 0.7260459661483765),\n",
       " (393, 0.6710848212242126),\n",
       " (582, 0.7186396718025208),\n",
       " (611, 0.6267070770263672),\n",
       " (598, 0.6200355291366577),\n",
       " (619, 0.6500346660614014),\n",
       " (676, 0.6234974265098572),\n",
       " (344, 0.6161870360374451),\n",
       " (105, 0.6285554766654968),\n",
       " (246, 0.6068529486656189),\n",
       " (18, 0.6430131196975708),\n",
       " (13, 0.6566882729530334),\n",
       " (288, 0.6797921657562256),\n",
       " (686, 0.6633330583572388),\n",
       " (89, 0.6492293477058411),\n",
       " (133, 0.6760792136192322),\n",
       " (292, 0.7033132314682007),\n",
       " (293, 0.6498388051986694),\n",
       " (70, 0.6067047715187073),\n",
       " (585, 0.5980737805366516),\n",
       " (443, 0.6185824275016785),\n",
       " (687, 0.6309577822685242),\n",
       " (186, 0.6733332872390747),\n",
       " (299, 0.6991941332817078),\n",
       " (77, 0.6373289227485657),\n",
       " (332, 0.6504770517349243),\n",
       " (173, 0.6429311037063599),\n",
       " (104, 0.6150119304656982),\n",
       " (59, 0.5900532007217407),\n",
       " (164, 0.6581530570983887),\n",
       " (277, 0.7513576745986938),\n",
       " (307, 0.6756675839424133),\n",
       " (308, 0.6479483842849731),\n",
       " (579, 0.6092251539230347),\n",
       " (151, 0.6438263654708862),\n",
       " (95, 0.6610455513000488),\n",
       " (316, 0.6575658321380615),\n",
       " (274, 0.6301846504211426),\n",
       " (134, 0.6447230577468872),\n",
       " (401, 0.6291943192481995),\n",
       " (674, 0.6761353611946106),\n",
       " (231, 0.596765398979187),\n",
       " (439, 0.6268998384475708),\n",
       " (596, 0.6452843546867371),\n",
       " (274, 0.6553812026977539),\n",
       " (40, 0.6639395952224731),\n",
       " (106, 0.6499939560890198),\n",
       " (681, 0.6953645348548889),\n",
       " (650, 0.6026179790496826),\n",
       " (116, 0.6462343335151672),\n",
       " (432, 0.6138177514076233),\n",
       " (327, 0.7150909304618835),\n",
       " (139, 0.647181510925293),\n",
       " (699, 0.659548282623291),\n",
       " (389, 0.6603493094444275),\n",
       " (226, 0.6636400818824768),\n",
       " (695, 0.6776388883590698),\n",
       " (292, 0.6471410989761353),\n",
       " (428, 0.6669026613235474),\n",
       " (522, 0.6603185534477234),\n",
       " (40, 0.6371638178825378),\n",
       " (188, 0.612558126449585),\n",
       " (45, 0.6498091816902161),\n",
       " (209, 0.6248109936714172),\n",
       " (596, 0.6206610798835754),\n",
       " (378, 0.6472161412239075),\n",
       " (101, 0.6072806715965271),\n",
       " (491, 0.6444270610809326),\n",
       " (582, 0.6053158044815063),\n",
       " (617, 0.6680607199668884),\n",
       " (236, 0.6637557744979858),\n",
       " (208, 0.6230548024177551),\n",
       " (654, 0.6461267471313477),\n",
       " (94, 0.6816924214363098),\n",
       " (206, 0.600554883480072),\n",
       " (351, 0.655265212059021),\n",
       " (352, 0.6525964736938477),\n",
       " (192, 0.7035171389579773),\n",
       " (18, 0.664137601852417),\n",
       " (389, 0.617135763168335),\n",
       " (387, 0.6284483671188354),\n",
       " (687, 0.6557482481002808),\n",
       " (83, 0.61418616771698),\n",
       " (655, 0.6866272687911987),\n",
       " (693, 0.6221466064453125),\n",
       " (681, 0.6467506289482117),\n",
       " (362, 0.6535478830337524),\n",
       " (679, 0.6699172854423523),\n",
       " (652, 0.6604183912277222),\n",
       " (41, 0.6166071891784668),\n",
       " (696, 0.6569679975509644),\n",
       " (604, 0.6461833715438843),\n",
       " (535, 0.6350586414337158),\n",
       " (646, 0.6370701193809509),\n",
       " (263, 0.6660268306732178),\n",
       " (89, 0.659985363483429),\n",
       " (619, 0.6819997429847717),\n",
       " (78, 0.6254516243934631),\n",
       " (99, 0.6026577949523926),\n",
       " (475, 0.6505354642868042),\n",
       " (672, 0.6941415667533875),\n",
       " (700, 0.5930059552192688),\n",
       " (581, 0.7050037384033203),\n",
       " (91, 0.6047820448875427),\n",
       " (13, 0.6503889560699463),\n",
       " (605, 0.6522876620292664),\n",
       " (693, 0.712635338306427),\n",
       " (46, 0.6182944774627686),\n",
       " (50, 0.6792085766792297),\n",
       " (101, 0.6211566925048828),\n",
       " (291, 0.683914840221405),\n",
       " (248, 0.6382244825363159),\n",
       " (581, 0.6172569990158081),\n",
       " (567, 0.6923832893371582),\n",
       " (88, 0.6133139133453369),\n",
       " (145, 0.613892138004303),\n",
       " (392, 0.6478309631347656),\n",
       " (451, 0.6595985889434814),\n",
       " (215, 0.6855195164680481),\n",
       " (334, 0.655234158039093),\n",
       " (13, 0.6786718964576721),\n",
       " (689, 0.6713280081748962),\n",
       " (2, 0.6349587440490723),\n",
       " (678, 0.6338121891021729),\n",
       " (677, 0.6496525406837463),\n",
       " (607, 0.6515702605247498),\n",
       " (200, 0.6414127349853516),\n",
       " (609, 0.6008715629577637),\n",
       " (628, 0.6820012331008911),\n",
       " (83, 0.6835516691207886),\n",
       " (690, 0.6979949474334717),\n",
       " (582, 0.6359454393386841),\n",
       " (124, 0.6649951934814453),\n",
       " (53, 0.6761651635169983),\n",
       " (687, 0.7041106224060059),\n",
       " (17, 0.6475839018821716),\n",
       " (88, 0.6588629484176636),\n",
       " (629, 0.6530905365943909),\n",
       " (27, 0.6072272062301636),\n",
       " (687, 0.6445298790931702),\n",
       " (674, 0.6600796580314636),\n",
       " (513, 0.6879342794418335),\n",
       " (607, 0.6627752780914307),\n",
       " (23, 0.6573237180709839),\n",
       " (52, 0.7149972915649414),\n",
       " (146, 0.6280120015144348),\n",
       " (669, 0.591878354549408),\n",
       " (598, 0.6593040227890015),\n",
       " (47, 0.6320943236351013),\n",
       " (77, 0.614789605140686),\n",
       " (646, 0.6391432881355286),\n",
       " (511, 0.6983629465103149),\n",
       " (558, 0.6936641931533813),\n",
       " (387, 0.6613460779190063),\n",
       " (604, 0.6470106244087219),\n",
       " (639, 0.6154985427856445),\n",
       " (516, 0.7436705231666565),\n",
       " (240, 0.6480221748352051),\n",
       " (90, 0.6282997727394104),\n",
       " (100, 0.692223072052002),\n",
       " (40, 0.6662728786468506),\n",
       " (27, 0.627768337726593),\n",
       " (173, 0.627196729183197),\n",
       " (102, 0.6167209148406982),\n",
       " (696, 0.6548938751220703),\n",
       " (499, 0.643310010433197),\n",
       " (499, 0.6357185244560242),\n",
       " (173, 0.677693247795105),\n",
       " (48, 0.6285765171051025),\n",
       " (684, 0.6482064723968506),\n",
       " (601, 0.616019070148468),\n",
       " (638, 0.6469204425811768),\n",
       " (597, 0.6320317983627319),\n",
       " (452, 0.6882487535476685),\n",
       " (54, 0.6939665079116821),\n",
       " (55, 0.6623077988624573),\n",
       " (436, 0.6674338579177856),\n",
       " (241, 0.6616238355636597),\n",
       " (240, 0.6403316855430603),\n",
       " (85, 0.6430407762527466),\n",
       " (9, 0.6897440552711487),\n",
       " (344, 0.6344913244247437),\n",
       " (225, 0.5987491607666016),\n",
       " (1, 0.605514407157898),\n",
       " (64, 0.6209031939506531),\n",
       " (470, 0.7039055824279785),\n",
       " (86, 0.6426684260368347),\n",
       " (505, 0.6468775868415833),\n",
       " (146, 0.6507874131202698),\n",
       " (131, 0.7107256650924683),\n",
       " (573, 0.685982882976532),\n",
       " (70, 0.6841083765029907),\n",
       " (596, 0.6979997158050537),\n",
       " (110, 0.603108823299408),\n",
       " (619, 0.6434998512268066),\n",
       " (99, 0.7415409088134766),\n",
       " (76, 0.644581139087677),\n",
       " (112, 0.6282943487167358),\n",
       " (59, 0.6861739158630371),\n",
       " (79, 0.6488968133926392),\n",
       " (94, 0.6771799921989441),\n",
       " (81, 0.6116963624954224),\n",
       " (322, 0.676876425743103),\n",
       " (662, 0.6364910006523132),\n",
       " (604, 0.65535968542099),\n",
       " (664, 0.6544128656387329),\n",
       " (353, 0.6630382537841797),\n",
       " (655, 0.6354498863220215),\n",
       " (596, 0.6770148873329163),\n",
       " (354, 0.6194208860397339),\n",
       " (687, 0.6768170595169067),\n",
       " (687, 0.6872203350067139),\n",
       " (683, 0.6373978853225708),\n",
       " (69, 0.6794191002845764),\n",
       " (605, 0.6180456280708313),\n",
       " (46, 0.662885308265686),\n",
       " (83, 0.60599285364151),\n",
       " (446, 0.6441572904586792),\n",
       " (681, 0.6871591806411743),\n",
       " (533, 0.6158264875411987),\n",
       " (609, 0.7245256304740906),\n",
       " (61, 0.656105637550354),\n",
       " (27, 0.6431090831756592),\n",
       " (459, 0.6606080532073975),\n",
       " (173, 0.685196042060852),\n",
       " (512, 0.6626607775688171),\n",
       " (652, 0.6786193251609802),\n",
       " (653, 0.695848286151886),\n",
       " (681, 0.6491516828536987),\n",
       " (406, 0.6208183169364929),\n",
       " (660, 0.6523023843765259),\n",
       " (558, 0.6516622304916382),\n",
       " (461, 0.6711655259132385),\n",
       " (197, 0.6314972043037415),\n",
       " (114, 0.6946226954460144),\n",
       " (115, 0.6232104897499084),\n",
       " (103, 0.6404895782470703),\n",
       " (681, 0.6531957387924194),\n",
       " (191, 0.6719852685928345),\n",
       " (28, 0.657323956489563),\n",
       " (112, 0.6339575052261353),\n",
       " (647, 0.7048818469047546),\n",
       " (331, 0.5960195064544678),\n",
       " (509, 0.635909914970398),\n",
       " (124, 0.6441172957420349),\n",
       " (478, 0.6141692399978638),\n",
       " (359, 0.6258851289749146),\n",
       " (679, 0.6543999314308167),\n",
       " (128, 0.6612626910209656),\n",
       " (360, 0.6598802208900452),\n",
       " (127, 0.6223064064979553),\n",
       " (217, 0.67646723985672),\n",
       " (626, 0.6145715117454529),\n",
       " (106, 0.6596158742904663),\n",
       " (687, 0.6430608034133911),\n",
       " (647, 0.6412632465362549),\n",
       " (668, 0.6531336903572083),\n",
       " (521, 0.6113477945327759),\n",
       " (208, 0.6296360492706299),\n",
       " (195, 0.6463901996612549),\n",
       " (90, 0.6590560078620911),\n",
       " (681, 0.6649292707443237),\n",
       " (161, 0.6378673911094666),\n",
       " (17, 0.6279811859130859),\n",
       " (238, 0.6516870856285095),\n",
       " (145, 0.6452366709709167),\n",
       " (365, 0.6207166314125061),\n",
       " (180, 0.6893668174743652),\n",
       " (79, 0.6630372405052185),\n",
       " (603, 0.6605268716812134),\n",
       " (694, 0.6824030876159668),\n",
       " (681, 0.6571236252784729),\n",
       " (332, 0.661458432674408),\n",
       " (153, 0.6648880839347839),\n",
       " (660, 0.6385205388069153),\n",
       " (687, 0.6316942572593689),\n",
       " (157, 0.6555675268173218),\n",
       " (687, 0.7000741958618164),\n",
       " (347, 0.661234974861145),\n",
       " (451, 0.6823289394378662),\n",
       " (237, 0.6553425192832947),\n",
       " (646, 0.6445538997650146),\n",
       " (27, 0.633012592792511),\n",
       " (633, 0.6535832285881042),\n",
       " (332, 0.5954792499542236),\n",
       " (165, 0.6155754923820496),\n",
       " (646, 0.6763542890548706),\n",
       " (485, 0.6993576884269714),\n",
       " (672, 0.747940719127655),\n",
       " (84, 0.612693190574646),\n",
       " (211, 0.623760998249054),\n",
       " (346, 0.6614009737968445),\n",
       " (690, 0.7383413910865784),\n",
       " (173, 0.7111291885375977),\n",
       " (70, 0.6345728635787964),\n",
       " (113, 0.6333847045898438),\n",
       " (608, 0.6522588729858398),\n",
       " (217, 0.679570734500885),\n",
       " (596, 0.684126079082489),\n",
       " (232, 0.6480345129966736),\n",
       " (424, 0.7023142576217651),\n",
       " (657, 0.6762799620628357),\n",
       " (416, 0.6366779804229736),\n",
       " (91, 0.6752825379371643),\n",
       " (424, 0.6466107368469238),\n",
       " (273, 0.6477861404418945),\n",
       " (666, 0.5861189961433411),\n",
       " (606, 0.6248555183410645),\n",
       " (577, 0.6336902976036072),\n",
       " (343, 0.6133972406387329),\n",
       " (190, 0.619886040687561),\n",
       " (11, 0.6617830395698547),\n",
       " (192, 0.7096563577651978),\n",
       " (135, 0.6219087243080139),\n",
       " (564, 0.6128113269805908),\n",
       " (64, 0.682486355304718),\n",
       " (96, 0.6468542218208313),\n",
       " (20, 0.6890827417373657),\n",
       " (13, 0.6661084294319153),\n",
       " (570, 0.694229006767273),\n",
       " (694, 0.642638623714447),\n",
       " (625, 0.6790378093719482),\n",
       " (277, 0.6503579616546631),\n",
       " (684, 0.6459932923316956),\n",
       " (609, 0.6569761037826538),\n",
       " (473, 0.616428554058075),\n",
       " (653, 0.5710524320602417),\n",
       " (617, 0.6226537823677063),\n",
       " (672, 0.667137861251831),\n",
       " (655, 0.6687880754470825),\n",
       " (32, 0.5954800844192505),\n",
       " (344, 0.6649166941642761),\n",
       " (212, 0.6713117957115173),\n",
       " (597, 0.7045949697494507),\n",
       " (576, 0.6587768793106079),\n",
       " (215, 0.6643721461296082),\n",
       " (108, 0.6176835298538208),\n",
       " (688, 0.6378669738769531),\n",
       " (88, 0.6667079329490662),\n",
       " (647, 0.6369709968566895),\n",
       " (254, 0.6523338556289673),\n",
       " (661, 0.6311041712760925),\n",
       " (688, 0.6266689300537109),\n",
       " (696, 0.6613158583641052),\n",
       " (279, 0.6885569095611572),\n",
       " (682, 0.6931313872337341),\n",
       " (165, 0.6084086298942566),\n",
       " (86, 0.6007159948348999),\n",
       " (144, 0.6161423921585083),\n",
       " (91, 0.6886816024780273),\n",
       " (332, 0.6145443916320801),\n",
       " (195, 0.6172960996627808),\n",
       " (638, 0.6296486258506775),\n",
       " (655, 0.7257347106933594),\n",
       " (672, 0.6164883375167847),\n",
       " (598, 0.7260310649871826),\n",
       " (501, 0.586765706539154),\n",
       " (696, 0.6825078129768372),\n",
       " (161, 0.664888322353363),\n",
       " (131, 0.6179037690162659),\n",
       " (674, 0.6333385109901428),\n",
       " (83, 0.6322034001350403),\n",
       " (438, 0.6314023733139038),\n",
       " (570, 0.6597263216972351),\n",
       " (293, 0.6530789136886597),\n",
       " (650, 0.6515178084373474),\n",
       " (516, 0.6220547556877136),\n",
       " (663, 0.6814388036727905),\n",
       " (646, 0.6577234864234924),\n",
       " (296, 0.6486995220184326),\n",
       " (161, 0.6631879210472107),\n",
       " (176, 0.6220057606697083),\n",
       " (304, 0.6479889154434204),\n",
       " (597, 0.6301940679550171),\n",
       " (16, 0.6491736769676208),\n",
       " (499, 0.5945821404457092),\n",
       " (221, 0.6961796283721924),\n",
       " (604, 0.6053772568702698),\n",
       " (522, 0.6794977784156799),\n",
       " (75, 0.710470974445343),\n",
       " (395, 0.6116310954093933),\n",
       " (402, 0.6907029151916504),\n",
       " (263, 0.6391646265983582),\n",
       " (546, 0.7121603488922119),\n",
       " (596, 0.7603204846382141),\n",
       " (332, 0.6550725698471069),\n",
       " (570, 0.6892338395118713),\n",
       " (684, 0.7012331485748291),\n",
       " (599, 0.6421895623207092),\n",
       " (387, 0.6285009980201721),\n",
       " (625, 0.6510471701622009),\n",
       " (619, 0.6659868359565735),\n",
       " (317, 0.6438582539558411),\n",
       " (273, 0.6656860113143921),\n",
       " (9, 0.6573918461799622),\n",
       " (23, 0.6312676668167114),\n",
       " (276, 0.6312666535377502),\n",
       " (558, 0.6506330966949463),\n",
       " (39, 0.6200200319290161),\n",
       " (279, 0.6832449436187744),\n",
       " (597, 0.6570472717285156),\n",
       " (635, 0.6325861811637878),\n",
       " (198, 0.6530667543411255),\n",
       " (98, 0.633566677570343),\n",
       " (687, 0.6586270928382874),\n",
       " (596, 0.6434335112571716),\n",
       " (430, 0.6835946440696716),\n",
       " (105, 0.6658059358596802),\n",
       " (241, 0.6317978501319885),\n",
       " (170, 0.6080389022827148),\n",
       " (3, 0.6549975275993347),\n",
       " (388, 0.6103557348251343),\n",
       " (696, 0.6375049352645874),\n",
       " (62, 0.6482831239700317),\n",
       " (269, 0.6345261931419373),\n",
       " (164, 0.7106061577796936),\n",
       " (206, 0.6347553730010986),\n",
       " (258, 0.6109052896499634),\n",
       " (687, 0.6607027053833008),\n",
       " (607, 0.624039888381958),\n",
       " (213, 0.6592282056808472),\n",
       " (596, 0.6601186394691467),\n",
       " (570, 0.643295407295227),\n",
       " (381, 0.6657857894897461),\n",
       " (479, 0.6207618117332458),\n",
       " (646, 0.6078670620918274)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (82): «uber is ride sharing platform that is part of the gig economy where the platform supports and coordinates labor market in which there are large number of ephemeral piecemeal jobs despite numerous efforts to understand the impacts of these platforms and their algorithms on uber drivers how to better serve and support drivers with these platforms remains an open challenge in this paper we frame uber through the lens of stakeholder theory to highlight drivers position in the workplace which helps inform the design of more ethical and effective platform to this end we analyzed uber drivers forum discussions about their lived experiences of working with the uber platform we identify and discuss the impact of the stakes that drivers have in relation to both the uber corporation and their passengers and look at how these stakes impact both the platform and drivers practices»\n",
      "\n",
      "Similar Document (526, 0.6523601412773132): «many people struggle to control their use of digital devices however our understanding of the design mechanisms that support user self control remains limited in this paper we make two contributions to hci research in this space first we analyse apps and browser extensions from the google play chrome web and apple app stores to identify common core design features and intervention strategies afforded by current tools for digital self control second we adapt and apply an integrative dual systems model of self regulation as framework for organising and evaluating the design features found our analysis aims to help the design of better tools in two ways by identifying how through well established model of self regulation current tools overlap and differ in how they support self control and ii by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOI -> simliarity?\n",
    "# string, string -> similiarity?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
